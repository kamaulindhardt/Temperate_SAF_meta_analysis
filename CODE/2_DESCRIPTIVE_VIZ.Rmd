---
title: "2_DESCRIPTIVE_VIZ"
author: "M.K.K. Lindhardt"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.


# STEP 0 PREPARING SCRIPT AND READ IN THE DATA


```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    patchwork,        # ggplot2 API for sequentially building up a plot
    ###################################################################################################################
    # Spatial Data
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    rnaturalearth,    # For world map data
    rnaturalearthdata, 
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
```


## Loading the two datasets (imputed and non-imputed)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Define file paths
non_imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom_tshering.rds"))
imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom_tshering.rds"))

# Read in the non-imputed dataset
non_imp_dataset <- non_imp_data_rom %>%
  as.data.frame()

# Read in the imputed dataset
imp_dataset <- imp_data_rom %>%
  as.data.frame()
})
```


## Assisseng Imputations



Assessment of Missing Data for Moderators
Imputation of Missing Values for Moderators Using mice()
Post-Imputation Assessment of Moderators
Selection of Moderators for Analysis
Fitting the Multivariate Random-Effects Model with Selected Moderators

```{r}
# Define the function for missing data assessment
assess_missing_data <- function(dataset, moderators, dataset_name = "Dataset") {
  
  cat("\nStarting missing data assessment for", dataset_name, "...\n")
  
  # Step 1: Count the number of missing values for each moderator
  missing_summary <- dataset %>%
    summarise(across(all_of(moderators), ~ sum(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_count")

  # Print the missing summary table
  cat("\nNumber of Missing Values for Each Moderator:\n")
  print(missing_summary)

  # Step 2: Create a basic bar chart of missing counts
  missing_plot <- ggplot(missing_summary, aes(x = reorder(variable, -missing_count), y = missing_count)) +
    geom_bar(stat = "identity", fill = "#0072B2") +
    labs(
      title = paste("Number of Missing Data for Moderator Variables -", dataset_name),
      x = "Moderator Variable",
      y = "Number of Missing Values"
    ) +
    scale_y_continuous(labels = scales::comma) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Step 3: Count missingness for each moderator by response_variable
  missing_by_response <- dataset %>%
    group_by(response_variable) %>%
    summarise(across(all_of(moderators), ~ sum(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = -response_variable, names_to = "moderator", values_to = "missing_count")

  # Print the summary table for missingness by response_variable
  cat("\nNumber of Missing Values by Response Variable for Each Moderator:\n")
  print(missing_by_response)

  # Step 4: Create a heatmap for missingness by response_variable
  missing_heatmap <- ggplot(missing_by_response, aes(x = moderator, y = response_variable, fill = missing_count)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "#56B1F7", high = "#132B43", na.value = "gray90") +
    labs(
      title = paste("Heatmap of Missing Data by Moderator and Response Variable -", dataset_name),
      x = "Moderator Variable",
      y = "Response Variable",
      fill = "Number of Missing Values"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Display the plots
  print(missing_plot)
  print(missing_heatmap)
  
  cat("\nMissing data assessment completed for", dataset_name, ".\n")
}
```

## Assessing missingness in moderator-response variable combinations (Evidence Gap Map)

```{r}
# Define moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width",
                "organic", "tillage")

# Total counts per response variable (for completeness %)
total_counts <- imp_dataset %>%
  count(response_variable, name = "n_total")

# Count non-missing observations per (response_variable Ã— moderator)
completeness_matrix <- imp_dataset %>%
  select(response_variable, all_of(moderators)) %>%
  pivot_longer(cols = -response_variable, names_to = "Moderator", values_to = "Value") %>%
  filter(!is.na(Value)) %>%
  count(response_variable, Moderator, name = "n_present") %>%
  complete(response_variable, Moderator = moderators, fill = list(n_present = 0)) %>%
  left_join(total_counts, by = "response_variable") %>%
  mutate(
    percent_present = 100 * n_present / n_total,
    label = paste0(n_present, "\n(", round(percent_present, 1), "%)")
  )

# Reorder factors
completeness_matrix <- completeness_matrix %>%
  mutate(
    Moderator = factor(Moderator, levels = moderators),
    response_variable = fct_reorder(response_variable, n_present, .fun = sum, .desc = TRUE)
  )

# Plot
ggplot(completeness_matrix, aes(x = Moderator, y = response_variable, fill = n_present)) +
  geom_tile(color = "white", linewidth = 0.5) +
  geom_text(aes(label = label), size = 3.2, color = "black", lineheight = 0.9) +
  scale_fill_gradient(low = "#F7FCFD", high = "#00441B", name = "n (non-missing)") +
  labs(
    title = "Moderator Data Coverage across Response Variables",
    subtitle = "Non-Missing Observations (Count and Percent) in Imputed Dataset",
    x = "Moderator",
    y = "Response Variable"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid = element_blank(),
    legend.position = "right"
  )
```






# STEP 1 SPATIAL DISTRIBUTION 


```{r}
# Step 1: Filter distinct studies based on coordinates
distinct_studies <- imp_dataset |> 
  filter(!is.na(final_lat) & !is.na(final_lon)) |> 
  distinct(id_article, .keep_all = TRUE)

# Step 2: Convert the data to an 'sf' object
study_points_sf <- st_as_sf(
  distinct_studies,
  coords = c("final_lon", "final_lat"),
  crs = 4326,    # Coordinate Reference System (WGS84)
  remove = FALSE # Keep the original longitude and latitude columns
)

# Step 3: Get the world map data using 'rnaturalearth'
world_map <- ne_countries(scale = "medium", returnclass = "sf")

# Step 4: Create the map using 'ggplot2'
map_plot <- ggplot(data = world_map) +
  geom_sf() +  # Plot the world map
  geom_sf(data = study_points_sf, aes(color = response_variable), size = 3, alpha = 0.7) +
  scale_color_viridis_d(option = "C") +  # Use a color palette for points
  theme_minimal() +
  labs(
    title = "Geographical Distribution of Distinct Studies",
    x = "Longitude",
    y = "Latitude",
    color = "Study Location"
  ) +
  theme(
    legend.position = "top"
  )

# Step 5: Display the map
print(map_plot)
```




# STEP 2 TEMPORAL DISTRIBUTION


Step 2: Distribution of Studies Over Time

```{r}
# Histogram for the distribution of entries over time (assuming study_year_start represents 'Year' - otherwise 'experiment_year')
imp_dataset |> 
  ggplot(aes(x = as.Date(experiment_year))) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Entries Over Time", x = "Year", y = "Number of Entries") +
  theme_minimal()
```

```{r}
# Histogram for the distribution of unique studies over time
imp_dataset |> 
  distinct(id_article, experiment_year) |> 
ggplot(aes(x = as.Date(experiment_year))) +
  geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
  labs(title = "Distribution of Unique Studies Over Time", x = "Year", y = "Number of Studies") +
  theme_minimal()
```

Step 3: Distribution of Studies Across Moderators

```{r}
# Bar plot for crop_type
imp_dataset |> 
  ggplot(aes(x = crop_type)) +
  geom_bar(fill = "cornflowerblue") +
  labs(title = "Distribution of Entries Across Tree-Crop Combinations", x = "Tree-Crop Combination", y = "Number of Entries") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
```{r}
# Bar plot for season
imp_dataset |>
  ggplot(aes(x = season)) +
  geom_bar(fill = "darkorange") +
  labs(title = "Distribution of Entries Across Seasons", x = "Season", y = "Number of Entries") +
  theme_minimal()

```

```{r}
# Bar plot for alley width category
```

Step 4: Effect Size Distribution



Step 5: Explore Moderators and Levels

```{r}
# Faceted bar plots for different moderators
imp_dataset |> 
  ggplot(aes(x = response_variable)) +
  geom_bar(aes(fill = season)) +
  facet_wrap(~ crop_type) +
  labs(title = "Number of Entries by Response Variable and Season", x = "Response Variable", y = "Number of Entries") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

Step 6: Distribution in Space (Using generated Categorized Location Column)

```{r}
# Bar plot for the number of studies per bioclim_sub_regions
imp_dataset |> 
  ggplot(aes(x = bioclim_sub_regions)) +
  geom_bar(fill = "steelblue") +
  labs(title = "Number of Studies Per Bioclimatic subregion", x = "Bioclimat region", y = "Number of Studies") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

