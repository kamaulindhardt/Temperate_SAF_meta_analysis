---
title: "1_DATA_PREP"
author: "M.K.K. Lindhardt"
date: "2024-11-14"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    ###################################################################################################################
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science (data wrangling, visualization, etc.)
    readr,            # For fast reading and writing of CSV files
    dlookr,           # Diagnose, explore, and transform data efficiently
    skimr,            # Summary statistics for data frames, tibbles, and vectors
    janitor,          # Cleaning and renaming data columns for tidy data
    readxl,           # Reading Excel files
    vroom,            # High-performance reading of large datasets
    missForest,       # Random forest imputation for missing data
    mice,             # Multiple imputation for multivariate missing data
    missRanger,       # Chained random forest imputation for large datasets
    conflicted,       # Resolves conflicts in function names across packages
    future,           # Enables parallel processing for faster computation
    future.apply,     # Apply functions in parallel over lists or arrays
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization (part of tidyverse)
    patchwork,        # Combine and arrange ggplots in complex layouts
    RColorBrewer,     # Color palettes for visualizations
    gt,               # Generate stylish publication-ready tables
    corrplot,         # Correlation matrix visualization
    scales,           # Generate pseudo-log scale plots and other scaling options
    forcats,          # For working with and reordering factors
    ggrepel,          # Add text directly to a ggplot
    scales,           # Modify axis scales of plots
    ###################################################################################################################
    # Spatial Data Analysis
    tidygeocoder,     # Unified geocoding interface for forward and reverse geocoding
    raster,           # Handle raster data and analyze spatial layers
    sp,               # Provides spatial data classes and methods
    sf,               # Simple feature handling for vector data
    rnaturalearth,    # Access world map data for visualization
    rnaturalearthdata, # Supporting data for rnaturalearth
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # Conduct meta-analyses and calculate effect sizes
    clubSandwich,     # Cluster-robust variance estimators for linear regression
    philentropy,      # Compute Jensen-Shannon Divergence and other divergence measures
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # Streamline exploratory data analysis
    SmartEDA,         # Automated exploratory data analysis
    inspectdf,        # Inspect data frames for structure and quality
    naniar,           # Explore and visualize missing data patterns
    VIM,              # Visualize and impute missing values
    corrplot,         # Visualize correlations between variables
    ###################################################################################################################
    # Machine Learning and Modeling (Tidymodels Framework)
    tidymodels,       # Unified framework for machine learning and modeling
    vip,              # Visualize variable importance from models
    caret,            # Train machine learning models with cross-validation
    randomForest,     # Train random forest models and evaluate variable importance
    recipes,          # Preprocessing data for machine learning
    ranger,           # High-performance random forests
    yardstick,        # Metrics for model performance evaluation
    tune,             # Hyperparameter tuning for machine learning models
    rsample,          # Generate resamples and cross-validation folds
    workflows,        # Combine recipes and models into workflows
    parsnip,          # Define machine learning models
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy and robust file referencing
    styler            # Automatically format and style R code
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("col_factor", "scales")
conflict_prefer("geocode", "tidygeocoder")
conflict_prefer("chisq.test", "stats")
conflict_prefer("step", "stats")
conflict_prefer("margin", "ggplot2")
conflict_prefer("intersect", "base")
```
```{r}
# Set a global theme and color scale
# Define the global color palette
global_palette <- c(
  "#ffd700", 
  "#ffb14e", 
  "#fa8775", 
  "#ea5f94", 
  "#cd34b5", 
  "#9d02d7", 
  "#0000ff"
)


custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)

# Define global ggplot2 scales for color and fill
scale_fill_global <- scale_fill_viridis_d(option = "D")  # Discrete
scale_color_global <- scale_color_viridis_d(option = "D")  # Discrete

scale_fill_global <- scale_fill_viridis_c(option = "D")  # Continuous
scale_color_global <- scale_color_viridis_c(option = "D")  # Continuous
```


Loading the dataset (main metadata database)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({
  # Final database as 'meta-data' (v6) is having updates on the misplaced sample number (_n) and standard error (_se).
  # Manually modifying the SD columns to "control_sd" and "silvo_sd" in Excel!
  # Also adding these columns manually: 
  # silvo_var (variance as either _se or _sd), 
  # silvo_se	(standard error),
  # silvo_sd	(standard deviation),
  # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
  # control_var (variance as either _se or _sd), 
  # control_se (standard error),
  # control_sd (standard deviation),
  # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),

  database <- readxl::read_excel(
    here("DATA", "Meta_data_v6.xlsx"), 
    sheet = "Quantatitive data"
  )
  
  # Dummy data where silvo_mean has been multiplied with 1.2 to check for larger effect size estimates
  # database_dummy <- readxl::read_excel(
  #   here("DATA", "Meta_data_dummy_test_high_silvo_mean_se.xlsx"), 
  #   sheet = "Quantatitive data"
  # )
    
})


```

**Glimpse (taking a look at the data)**
```{r Glimpse the dataset, eval=FALSE}
database %>% dplyr::glimpse() 

# Rows: 1,075
# Columns: 35
# Rows: 1,126
# Columns: 35
```

```{r}
database %>% summary() 
```

```{r}
database |> skim()
```


#############
# STEP 1
##########################################################################################################################################
DATA PREPROCESSING
##########################################################################################################################################

####################################
GENERIC PREPROCESSING
####################################

And in step 4, generate unique study identifier ('exp_id')

```{r}
# Function to safely convert to numeric, replacing non-numeric values with NA
safe_as_numeric <- function(x) {
  suppressWarnings(as.numeric(x))
}

# Data Preprocessing
database_clean <- database |>
  # Step 1: Clean column names
  janitor::clean_names() |>
  
  # Step 2: Convert id_article and id_obs to integer
  mutate(
    id_article = as.integer(id_article),
    id_obs = as.integer(id_obs)
  ) |>
  
  # Step 3: Convert standard errors and other numeric columns
            # silvo_var (variance as either _se or _sd), 
            # silvo_se	(standard error),
            # silvo_sd	(standard deviation),
            # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
            # control_var (variance as either _se or _sd), 
            # control_se (standard error),
            # control_sd (standard deviation),
            # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),
  mutate(
    silvo_mean = safe_as_numeric(silvo_mean),
    silvo_se = safe_as_numeric(silvo_se),
    silvo_sd = safe_as_numeric(silvo_sd),
    silvo_n = safe_as_numeric(silvo_n),
    control_mean = safe_as_numeric(control_mean),
    control_se = safe_as_numeric(control_se),
    control_sd = safe_as_numeric(control_sd),
    control_n = safe_as_numeric(control_n),
    tree_age = safe_as_numeric(tree_age),
    no_tree_per_m = as.character(no_tree_per_m)) |> 
  
  # Step 4: Create Identifiers (Experiment, Treatment, Common Control)
  # Group data by relevant columns for Treatment ID
  group_by(id_article, tree_type, crop_type, location, experiment_year) |>
  mutate(treat_id = cur_group_id()) |>
  ungroup() |>
  
  # Group data by relevant columns for Experiment ID
  # The exp_id variable is created as a unique identifier for experiments, 
  # based on grouping by: id_article (the article ID), location (the geographical location of the experiment), and 
  # the experiment_year (the year the experiment was conducted)
  group_by(id_article, location, experiment_year) |>
  mutate(exp_id = cur_group_id()) |>
  ungroup() |> 
  
  # Step 5: Ensure no infinite or NaN values are present in any columns
  mutate(across(everything(), ~ifelse(is.infinite(.) | is.nan(.), NA, .))
         ) |> 
  
  # Step 6: Convert "NA" strings to real NA values, excluding 'id_article' and 'id_obs'
  mutate(
    across(
      .cols = where(is.character) & !c("id_article", "id_obs"),
      .fns = ~ na_if(., "NA")
    )
  ) |>
  
  # Step 7: Convert year columns to date format
 # Convert to proper Date format using "YYYY-01-01"
 mutate(
    experiment_year = as.Date(paste0(experiment_year, "-01-01")),
    year_est_exp = as.Date(paste0(year_est_exp, "-01-01")),
    #study_year_start = as.Date(paste0(study_year_start, "-01-01")),
    #study_year_end = as.Date(paste0(study_year_end, "-01-01"))
  ) |> 
  # Step 8: Rename Latitude and Longitude to lat and lon
  rename(
    lat = latitude,
    lon = longitude
  ) |>
  
  # Step 9: Convert lat and lon to numeric coordinates
  mutate(
    lat = str_replace_all(lat, "[°NS]", "") |> safe_as_numeric(),
    lon = str_replace_all(lon, "[°EW]", "") |> safe_as_numeric(),
    lat = if_else(str_detect(lat, "S$"), -lat, lat),
    lon = if_else(str_detect(lon, "W$"), -lon, lon)
  ) |>
  
  # Step 10: Create a Coherent 'site_x' Column
  mutate(
    # If `lat` and `lon` are present, use them; otherwise, use the `location` name
    site_x = case_when(
      !is.na(lat) & !is.na(lon) ~ paste(lat, lon, sep = ", "),
      !is.na(location) ~ location,
      TRUE ~ NA_character_
    )
  ) 
```



```{r}
database_clean |> filter(id_article == 10)
```

####################################
GEOSPATIAL PREPROCESSING
####################################

In the Excel meta-data file, I am manually changing 'France (south west)' to 'France' and 'South East England(Cambridgeshire)' to 'Cambridgeshire, England' and 
'Bramham in northern England' to 'Bramham, England'

```{r}
# Step 1: Extract Coordinates from `site_x` if available
database_clean <- database_clean |>
  mutate(
    # Extract latitude: Matches integers or decimals before a comma
    extracted_lat = str_extract(site_x, "[-]?\\d+(\\.\\d+)?(?=, )"),
    # Extract longitude: Matches integers or decimals after a comma and space
    extracted_lon = str_extract(site_x, "(?<=, )[-]?\\d+(\\.\\d+)?")
  ) |>
  mutate(
    # Convert extracted values to numeric
    extracted_lat = as.numeric(extracted_lat),
    extracted_lon = as.numeric(extracted_lon),
    # Use extracted coordinates directly as final coordinates
    final_lat = extracted_lat,
    final_lon = extracted_lon,
    # Create the `exp_site_loc` column with final coordinates
    exp_site_loc = if_else(!is.na(final_lat) & !is.na(final_lon),
                           paste(final_lat, final_lon, sep = ", "),
                           NA_character_)
  ) |>
  # Remove intermediate columns
  select(-extracted_lat, -extracted_lon) |>
  
  # Step 2: Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n
  )
```

Checking if any missing values in coordinates

```{r}
# Filter rows where either final_lat or final_lon is missing
missing_coordinates <- database_clean |>
  filter(is.na(final_lat) | is.na(final_lon))

# View the rows with missing coordinates
missing_coordinates

# No missing coordinates
# 0 rows | 1-10 of 39 columns
```


Add geographical sub-regions to the dataset

```{r}
# Load Köppen-Geiger Climate Data (as a raster file)
kg_climate <- raster(here("DATA", "koppen_geiger_tif", "1991_2020", "koppen_geiger_0p1.tif"))


# Preserve final_lat and final_lon before conversion
database_clean <- database_clean |> 
  mutate(
    preserved_lat = final_lat,
    preserved_lon = final_lon
  )

# Convert your dataset to an sf object using preserved lat/lon columns
database_clean_sf <- database_clean |>
  drop_na(preserved_lat, preserved_lon) |>
  st_as_sf(coords = c("preserved_lon", "preserved_lat"), crs = 4326)

# Extract climate zone for each observation using spatial overlay
# Beck, H.E., T.R. McVicar, N. Vergopolan, A. Berg, N.J. Lutsko, A. Dufour, Z. Zeng, X. Jiang, A.I.J.M. van Dijk, D.G. MirallesHigh-resolution (1 km) Köppen-Geiger maps for 1901–2099 based on constrained CMIP6 projectionsScientific Data 10, 724, doi:10.1038/s41597-023–02549‑6 (2023)
# The variable 'climate_zone' represents the climate classification code assigned to each data point based on its geographical coordinates (latitude and longitude) from the Köppen-Geiger map. The climate_zone information was extracted using a spatial overlay.
database_clean_sf <- database_clean_sf |>
  mutate(
    climate_zone = extract(kg_climate, st_coordinates(database_clean_sf))
  )

# Classify sub-regions based on the climate zone
# Refine classifications for temperate climates and assign broader regions for others
database_clean_sf <- database_clean_sf %>%
  mutate(
    # Assign specific Köppen-Geiger classifications to climate zones
    climate_zone = case_when(
      climate_zone == 1 ~ "Tropical, rainforest",
      climate_zone == 2 ~ "Tropical, monsoon",
      climate_zone == 3 ~ "Tropical, savannah",
      climate_zone == 4 ~ "Arid, desert, hot",
      climate_zone == 5 ~ "Arid, desert, cold",
      climate_zone == 6 ~ "Arid, steppe, hot",
      climate_zone == 7 ~ "Arid, steppe, cold",
      climate_zone == 8 ~ "Temperate, dry summer, hot summer",
      climate_zone == 9 ~ "Temperate, dry summer, warm summer",
      climate_zone == 10 ~ "Temperate, dry summer, cold summer",
      climate_zone == 11 ~ "Temperate, dry winter, hot summer",
      climate_zone == 12 ~ "Temperate, dry winter, warm summer",
      climate_zone == 13 ~ "Temperate, dry winter, cold summer",
      climate_zone == 14 ~ "Temperate, no dry season, hot summer",
      climate_zone == 15 ~ "Temperate, no dry season, warm summer",
      climate_zone == 16 ~ "Temperate, no dry season, cold summer",
      climate_zone == 17 ~ "Cold, dry summer, hot summer",
      climate_zone == 18 ~ "Cold, dry summer, warm summer",
      climate_zone == 19 ~ "Cold dry summer, cold summer",
      climate_zone == 20 ~ "Cold dry summer, very cold winter",
      climate_zone == 21 ~ "Cold, dry winter, hot summer",
      climate_zone == 22 ~ "Cold, dry winter, warm summer",
      climate_zone == 23 ~ "Cold, dry winter, cold summer",
      climate_zone == 24 ~ "Cold, dry winter, very cold winter",
      climate_zone == 25 ~ "Cold, no dry season, hot summer",
      climate_zone == 26 ~ "Cold, no dry season, warm summer",
      climate_zone == 27 ~ "Cold, no dry season, cold summer",
      climate_zone == 28 ~ "Cold, no dry season, very cold winter",
      climate_zone == 29 ~ "Polar, tundra",
      climate_zone == 30 ~ "Polar, frost",
      TRUE ~ "Unclassified"
    ),
    
    # Assign refined geographical regions
    bioclim_sub_regions = case_when(
      # Tropical climates
      climate_zone %in% c(
        "Tropical, rainforest", "Tropical, monsoon", "Tropical, savannah"
      ) ~ "Tropical Climates",
      
      # Arid climates
      climate_zone %in% c(
        "Arid, desert, hot", "Arid, desert, cold", "Arid, steppe, hot", "Arid, steppe, cold"
      ) ~ "Arid Climates",
      
      # Refined temperate climates
      climate_zone %in% c(
        "Temperate, dry summer, hot summer", "Temperate, dry summer, warm summer", 
        "Temperate, dry winter, hot summer", "Temperate, dry winter, warm summer"
      ) ~ "Dry and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, hot summer", "Temperate, no dry season, warm summer"
      ) ~ "Wet and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, dry summer, cold summer", "Temperate, dry winter, cold summer"
      ) ~ "Dry and Cold Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, cold summer"
      ) ~ "Wet and Cold Temperate",
      
      # Cold climates
      climate_zone %in% c(
        "Cold, dry summer, hot summer", "Cold, dry summer, warm summer", 
        "Cold dry summer, cold summer", "Cold dry summer, very cold winter", 
        "Cold, dry winter, hot summer", "Cold, dry winter, warm summer", 
        "Cold, dry winter, cold summer", "Cold, dry winter, very cold winter",
        "Cold, no dry season, hot summer", "Cold, no dry season, warm summer", 
        "Cold, no dry season, cold summer", "Cold, no dry season, very cold winter"
      ) ~ "Cold Climates",
      
      # Polar climates
      climate_zone %in% c(
        "Polar, tundra", "Polar, frost"
      ) ~ "Polar Climates",
      
      TRUE ~ "Unclassified"
    )
  )
```


Checking for unclassified in climate_zone and bioclim_sub_regions or if any observations have odd classes e.g. 'Tropical Climates'

```{r}
# Check classification coverage
database_clean_sf %>%
  filter(climate_zone == "Unclassified" | bioclim_sub_regions == "Unclassified") %>%
  head()

# Check classification of BioClim that is classified as 'Tropical'
database_clean_sf %>%
  filter(bioclim_sub_regions == "Tropical Climates") 
```





```{r}
# Rename back to 'database_clean'

# Relocate columns to the desired order
database_clean <- database_clean_sf |>
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, control_mean, 
    silvo_n, control_n,
    silvo_se, control_se,
    silvo_sd, control_sd 
  )

# Preview the resulting data
database_clean |> 
  glimpse()

# Rows: 1,126
# Columns: 44
```


```{r}
# Create the bar chart
database_clean |> 
  ggplot(aes(x = bioclim_sub_regions)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(
    title = "Distribution of Observations by BioClim Subregions",
    x = "BioClim Subregions",
    y = "Count of Observations"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 14, face = "bold"),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12)
  )
```


################################################################################
ASSESSING THE GENERATED RANDOM-FACTOR VARIABLES exp_id and treat_id 
################################################################################

Missingness Assessment for exp_id Visualization

```{r}
# database_clean |> as.data.frame() |>
#   str()
```


```{r}
# Visualize exp_id distribution across components
database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(
    # Convert all columns to character for consistency
    id_article = as.character(id_article),
    experiment_year = as.character(experiment_year)
  ) %>%
  group_by(id_article, location, experiment_year) %>%
  summarise(exp_id_count = n_distinct(exp_id), .groups = "drop") %>%
  pivot_longer(
    cols = c(id_article, location, experiment_year),
    names_to = "component",
    values_to = "value"
  ) %>%
  ggplot(aes(x = component, y = exp_id_count, fill = component)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of exp_id Across Components",
    x = "Component",
    y = "Count of exp_id"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```
```{r}
# Heatmap for year-location relationship
# Function to plot heatmap for year and a chosen variable
plot_heatmap <- function(data, y_var) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(y_var)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(y_var), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", y_var),
      x = "Experiment Year",
      y = y_var,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for location
plot_heatmap(database_clean, "location")

# Example usage: Plot for site
plot_heatmap(database_clean, "site")

# Example usage: Plot for bioclim_sub_region
plot_heatmap(database_clean, "bioclim_sub_regions")
```

```{r}
# Function to plot heatmap for year and chosen variable (moderators or response variables)
plot_heatmap_moderator_response <- function(data, var_type) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(var_type)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(var_type), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", var_type),
      x = "Experiment Year",
      y = var_type,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for moderators
plot_heatmap_moderator_response(database_clean, "tree_type")

# Example usage: Plot for response variables
plot_heatmap_moderator_response(database_clean, "response_variable")
```


```{r}
# Step 2: Explore Aggregation Level
# Count unique `exp_id` values at each location level
aggregation_summary <- database_clean %>%
  as.data.frame() |> 
  select(-geometry) |> 
  group_by(location) %>%
  summarise(
    n_exp_id = n_distinct(exp_id),
    n_obs = n(),
    .groups = "drop"
  )

# View summary of aggregation
aggregation_summary

# Step 3: Visualize Aggregation Level
aggregation_summary |> 
  ggplot(aes(x = reorder(location, n_exp_id), y = n_exp_id)) +
  geom_col(fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Distribution of exp_id Across Locations",
    x = "Location",
    y = "Number of exp_id"
  ) +
  theme_minimal()
```


```{r}
# Summarize missingness across moderators and response variables
missingness_summary <- database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(exp_id) %>%
  summarise(
    # Count missing values for moderators
    missing_moderators = sum(
      is.na(tree_type) | is.na(crop_type) | is.na(age_system) | 
      is.na(tree_age) | is.na(season) | is.na(soil_texture) | 
      is.na(no_tree_per_m) | is.na(tree_height) | is.na(alley_width)
    ),
    # Count missing values for response variables
    missing_response = sum(
      is.na(silvo_mean) | is.na(control_mean)
    ),
    total_missing = missing_moderators + missing_response,
    n_obs = n(),
    .groups = "drop"
  )
```

Publication-ready map that visualizes the ecosystem services (response variables) reported in each study (id_article),
```{r}
# Step 1: Simplify the dataset for visualization
geo_data <- database_clean %>%
  group_by(lat = final_lat, lon = final_lon, response_variable) %>%
  summarize(
    n_studies = n_distinct(id_article),
    .groups = "drop"
  ) %>%
  filter(!is.na(lat) & !is.na(lon)) # Remove rows with missing coordinates

# Step 2: Base world map
world_map <- map_data("world")


# Step 4: Create the map
geo_distribution_of_studies_map <- ggplot() +
  # Add base map polygons
  geom_polygon(
    data = world_map,
    aes(x = long, y = lat, group = group),
    fill = "gray90", color = "gray70", size = 0.4
  ) +
   # Add jittered points for studies
  geom_jitter(
    data = geo_data,
    aes(x = lon, y = lat, color = response_variable, size = as.factor(n_studies)),
    alpha = 0.8,
    width = 0.8,  # Adjust jitter width (longitude)
    height = 0.75  # Adjust jitter height (latitude)
  ) +
  # Apply custom colors
  scale_color_manual(values = custom_colors, name = "Ecosystem Service") +
  scale_size_manual(
    name = "n studies for the given locataion",
    values = c(2, 3, 4, 5, 6, 7), # Assign size values for bins 1-6
    breaks = as.character(1:6),  # Ensure breaks correspond to whole numbers
    labels = as.character(1:6)   # Labels for the legend
  ) +
  # Add labels and theme adjustments
  labs(
    title = "Geographical Distribution of Ecosystem Services in Silvoarable Agroforestry Studies (Northern Hemisphere)",
    x = "Longitude",
    y = "Latitude"
  ) +
  coord_cartesian(ylim = c(20, 90)) +  # Restrict to the northern hemisphere
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    legend.title = element_text(face = "bold"),
    legend.position = "right",
    panel.grid = element_blank(),
    axis.line = element_line(color = "gray50")
  )

geo_distribution_of_studies_map
```

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.title = element_text(size = 80),
    legend.position = "top",
    legend.text = element_text(size = 80),
    axis.text.x = element_text(size = 100)
                               #angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
geo_distribution_of_studies_map <- geo_distribution_of_studies_map + theme_custom

# Save the map plot
ggsave(
  filename = file.path(output_dir, "geo_distribution_of_studies_map.png"), # Name of the file
  plot = geo_distribution_of_studies_map, 
  width = 20, height = 10, dpi = 600, # Specify dimensions and resolution
  bg = "white" # Ensure a white background for publication-ready output
)
```


Visualize Missingness (Facet Plot for Moderators and Responses)
```{r}
# Reshape the missingness summary for visualization
missingness_long <- missingness_summary %>%
  pivot_longer(
    cols = c(missing_moderators, missing_response),
    names_to = "missingness_type",
    values_to = "missing_count"
  )

# Summarize missingness data for better grouping and understanding
missingness_long_summary <- missingness_long %>%
  group_by(missingness_type, n_obs_group = cut(n_obs, breaks = seq(0, max(n_obs, na.rm = TRUE), by = 10))) %>%
  summarise(mean_missing = mean(missing_count, na.rm = TRUE), .groups = "drop")

# Separate data for moderators and response variables
moderators_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_moderators) %>%
  mutate(missingness_type = "Moderators")

response_variables_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_response) %>%
  mutate(missingness_type = "Response Variables")

# Plot Moderators Missingness
moderators_data %>%
  ggplot(aes(x = as.factor(n_obs), y = missing_moderators, fill = missingness_type)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness Overview for Moderators",
    x = "Number of Observations per exp_id (Grouped)",
    y = "Average Missing Values Count"
  ) +
  scale_fill_manual(values = c("blue")) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


Bar Chart: Missingness by Moderators (Exp ID Count)
```{r}
# Count missing values for each moderator
# Ensure all columns have the same data type before pivoting
missingness_moderators <- database_clean %>%
  as.data.frame() %>%
  select(
    exp_id, tree_type, crop_type, age_system, tree_age, season, 
    soil_texture, no_tree_per_m, tree_height, alley_width
  ) %>%
  mutate(across(-exp_id, as.character)) %>%  # Convert all non-exp_id columns to character
  pivot_longer(
    cols = -exp_id,
    names_to = "moderator",
    values_to = "value"
  ) %>%
  group_by(moderator) %>%
  summarise(
    exp_id_with_missing = sum(is.na(value)),  # Count the number of exp_id with missing values
    .groups = "drop"
  )

# Bar chart of missingness across moderators
missingness_moderators |> 
  ggplot(aes(x = moderator, y = exp_id_with_missing, fill = moderator)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness in Moderators",
    subtitle = "Number of exp_id with Missing Values for Each Moderator",
    x = "Moderator",
    y = "Count of exp_id with Missing Values"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```












#############
# STEP 2
##########################################################################################################################################
CALCULATING META-ANALYSIS QUANTITATIVE DATA (Std Dev., Std. Err. etc.)
##########################################################################################################################################

```{r}
database_clean |> glimpse()
```


##########################################################################################################################################
CALCULATING STANDARD DEVIATION FROM EXISTING STANDARD ERROR
##########################################################################################################################################

```{r}
# Calculate standard deviations from standard errors where _sd_info is FALSE
database_clean_sd <- database_clean %>%
  mutate(
    # Calculate standard deviation for silvo group where _sd_info is FALSE
    silvo_sd_from_se = ifelse(
      !silvo_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(silvo_se) * sqrt(as.numeric(silvo_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    ),
    
    # Calculate standard deviation for control group where _sd_info is FALSE
    control_sd_from_se = ifelse(
      !control_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(control_se) * sqrt(as.numeric(control_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    )
    ) |> 
      mutate(
        # Prioritize original SD for silvo group
        silvo_sd_merged = ifelse(is.na(silvo_sd), silvo_sd_from_se, silvo_sd),  
        # Prioritize original SD for control group
        control_sd_merged = ifelse(is.na(control_sd), control_sd_from_se, control_sd)
      ) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, silvo_sd_from_se, silvo_sd_merged,
    control_mean, control_se, control_sd, control_n, control_sd_from_se, control_sd_merged
  )
```

```{r}
database_clean_sd |> glimpse()
```


Checking for missing data in control_sd and silvo_sd

```{r}
# Calculate percentage of missing SD values for control and silvo groups in _sd_final
missing_control_sd_merged <- sum(is.na(database_clean_sd$control_sd_merged)) / nrow(database_clean_sd) * 100
missing_silvo_sd_merged <- sum(is.na(database_clean_sd$silvo_sd_merged)) / nrow(database_clean_sd) * 100

message("Percentage of missing SD values for control group (_sd_final): ", round(missing_control_sd_merged, 2), "%")
message("Percentage of missing SD values for silvo group (_sd_final): ", round(missing_silvo_sd_merged, 2), "%")

# Filter rows with missing SD values in _sd_final
missing_sd_final <- database_clean_sd %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged)) %>%
  relocate(
    id_article, id_obs, response_variable, location,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_n,
    control_mean, control_se, control_sd, control_sd_from_se, control_sd_merged, control_n
  )

# Display rows with missing data in _sd_final
missing_sd_final |> glimpse()

# Rows: 184
# Columns: 53
# $ id_article              <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …
# $ id_obs                  <int> 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 354, 355, 356, 357, 358, 359, …
# $ response_variable       <chr> "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield"…
# $ location                <chr> "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Ge…
# $ silvo_mean              <dbl> 1.48, 1.44, 5.91, 5.23, 6.59, 5.97, 7.53, 7.55, 0.66, 0.34, 11.81, 7.67, 14.27, 9.79, 16.04, 16.69, 3.50, 3.10, 5.90, 5.00, …
# $ silvo_se                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd_from_se        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd_merged         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_n                 <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
# $ control_mean            <dbl> 6.21, 7.63, 5.58, 7.38, 7.10, 7.53, 7.93, 7.90, 12.94, 15.21, 13.67, 13.62, 15.16, 14.74, 16.02, 14.79, 6.30, 6.40, 6.90, 7.…
# $ control_se              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd_from_se      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd_merged       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_n               <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
# $ treat_id                <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 16, 16, 17, 17, 18, 18, 24, 24, 20, 20, 21, 21, 16, …
# $ exp_id  
```

Dataset that is used as non-imputed

```{r}
# This is the non-imputed dataset (used for analysis WITHOUT imputation)
database_clean_sd 
```



#############
# STEP 3
##########################################################################################################################################
ASSESS MISSINGNESS PATTERNS OF DATA BEFORE IMPUTATION
##########################################################################################################################################

```{r}
# Check missingness summary for `control_sd` and `silvo_sd`
missingness_summary <- database_clean_sd %>%
  as.data.frame() %>%
  summarise(
    total_rows = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    percent_missing_control_sd = mean(is.na(control_sd_merged)) * 100,
    percent_missing_silvo_sd = mean(is.na(silvo_sd_merged)) * 100
  )



# Add missingness indicators to the dataset
database_clean_sd_missingness <- database_clean_sd %>%
  as.data.frame() %>%
  mutate(
    missing_control_sd = ifelse(is.na(control_sd_merged), 1, 0),
    missing_silvo_sd = ifelse(is.na(silvo_sd_merged), 1, 0)
  )

missingness_summary

# Description:df [1 × 5]
# total_rows
# <int>
# missing_control_sd
# <int>
# missing_silvo_sd
# <int>
# percent_missing_control_sd
# <dbl>
# percent_missing_silvo_sd
# <dbl>
# 1126	184	184	16.34103	16.34103
```

```{r}
# Visualize missingness across response variables and moderators
missingness_plot <- database_clean_sd_missingness %>%
  select(response_variable, missing_control_sd, missing_silvo_sd) %>%
  group_by(response_variable) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd) * 100,
    missing_silvo_sd = mean(missing_silvo_sd) * 100
  ) %>%
  pivot_longer(cols = c(missing_control_sd, missing_silvo_sd),
               names_to = "Variable",
               values_to = "Percent_Missing") %>%
  ggplot(aes(x = response_variable, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Percentage of Standard Deviation Across Response Variables",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_plot
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data <- database_clean_sd_missingness %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged))

# Summarize the counts of response variables for the filtered data
missing_sd_summary <- missing_sd_data %>%
  group_by(response_variable) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Plot the distribution of response variables for missing sd data
ggplot(missing_sd_summary, aes(x = reorder(response_variable, -count), y = count, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of Response Variables with Missing Standard Deviation",
    x = "Response Variable",
    y = "Count of Missing Entries"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data_rel <- database_clean_sd_missingness %>%
  mutate(missing_sd = ifelse(is.na(control_sd_merged) | is.na(silvo_sd_merged), 1, 0))

# database_clean_sd_missingness |> filter(response_variable == "Soil quality") |> nrow()

# Calculate the percentage of missing sd values relative to total observations for each response variable
missing_sd_summary_rel <- missing_sd_data_rel %>%
  group_by(response_variable) %>%
  summarise(
    total_observations = n(),
    missing_sd_count = sum(missing_sd),
    percent_missing = (missing_sd_count / total_observations) * 100
  ) %>%
  arrange(desc(percent_missing))

missing_sd_summary_rel
```

```{r}
# Plot the relative missingness
missing_sd_summary_rel |> 
  ggplot(aes(x = reorder(response_variable, -percent_missing), y = percent_missing, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Relative Missingness of Standard Deviation by Response Variable",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Response Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Assess missingness patterns across moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

missingness_by_moderators <- database_clean_sd_missingness %>%
  select(all_of(moderators), missing_control_sd, missing_silvo_sd) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100))

missingness_by_moderators

# Visualize missingness with a heatmap
heatmap_missingness <- database_clean_sd_missingness %>%
  select(control_sd, silvo_sd, response_variable, all_of(moderators)) %>%
  naniar::gg_miss_upset()

heatmap_missingness
```

##########################################################################################################################################
Assess missingness patterns for _sd variables by location and study ID (id_article)
##########################################################################################################################################

```{r}
# Calculate missingness by location
missing_by_location <- database_clean_sd_missingness %>%
  group_by(location) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by location
cat("\nMissingness by Location:\n")
print(missing_by_location)
```

```{r}
# Missingness by location
ggplot(missing_by_location, aes(x = reorder(location, -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Location",
    x = "Location",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```
```{r}
# Calculate missingness by study ID (id_article)
missing_by_study <- database_clean_sd_missingness %>%
  group_by(id_article) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by study ID
cat("\nMissingness by Study ID:\n")
print(missing_by_study)
```

```{r}
# Missingness by study ID
missing_by_study |> 
  ggplot(aes(x = reorder(as.factor(id_article), -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Study ID",
    x = "Study ID",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```


##########################################################################################################################################
Little's MCAR test for missingness
##########################################################################################################################################

Implications of missing.patterns:
A high number of missing patterns indicates complex missingness in your dataset, which might suggest that the data is not Missing Completely at Random (MCAR). Instead, it might be Missing at Random (MAR) or Not Missing at Random (NMAR).

```{r}
####################################################################################################################
# Prepare the data for missingness assessment
database_clean_sd_df <- database_clean_sd |> as.data.frame() |> select(-geometry) 
####################################################################################################################



# Select the variables for the test
test_data <- database_clean_sd_df %>%
  select(control_sd_merged, silvo_sd_merged, everything())  # Include control_sd_merged, silvo_sd_merged, and all variables

# Convert non-numeric columns to numeric using one-hot encoding or factor levels
test_data_numeric <- test_data %>%
  mutate(across(where(is.character), ~ as.numeric(as.factor(.)))) %>%  # Convert characters to numeric
  mutate(across(where(is.factor), as.numeric)) %>%                     # Convert factors to numeric
  select(where(~ sum(!is.na(.)) > 0))                                  # Remove columns with all missing values

# Check for problematic values
problematic_values <- test_data_numeric %>%
  summarise(across(everything(), ~ sum(is.infinite(.)) + sum(is.nan(.)) + sum(is.na(.))))

problematic_values |> glimpse()

# Exclude columns with more than 50% missing values
test_data_cleaned <- test_data_numeric %>%
  # Keep control_sd_merged and silvo_sd_merged
  select(control_sd_merged, silvo_sd_merged, response_variable, experiment_year, year_est_exp, exp_id,
         # Moderators info
         tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width) %>%  
  # Remove columns with >50% missing
  select(where(~ sum(is.na(.)) < nrow(test_data_numeric) * 0.5)) |> 
  # Convert date-time columns to numeric (e.g., extract the year)
  mutate(
    experiment_year = as.numeric(format(experiment_year, "%Y")),
    year_est_exp = as.numeric(format(year_est_exp, "%Y"))
  )

# Confirm all columns are numeric
all(sapply(test_data_cleaned, is.numeric)) 

# Check which columns are not numeric
non_numeric_cols <- sapply(test_data_cleaned, function(col) !is.numeric(col))
names(non_numeric_cols[non_numeric_cols])

# Inspect missing values after cleaning
colSums(is.na(test_data_cleaned))

# Perform Little's MCAR test on cleaned data
mcar_test <- naniar::mcar_test(test_data_cleaned)
mcar_test
```

```{r}
# Visualize missingness pattern
md.pattern(database_clean_sd_df)

# Heatmap of missing data

aggr_plot <- VIM::aggr(database_clean_sd_df, col = c('navyblue', 'red'), numbers = TRUE, sortVars = TRUE, 
                  labels = names(database_clean_sd_df), cex.axis = .7, gap = 3, ylab = c("Missingness", "Pattern"))
aggr_plot
```

```{r}
# Add missing indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd <- test_data_cleaned %>%
  mutate(
    missing_control_sd = is.na(control_sd_merged),
    missing_silvo_sd = is.na(silvo_sd_merged)
  )

# Check relationship between missingness and other variables
ggplot(test_data_cleaned_sd, aes(x = tree_age, fill = missing_control_sd)) +
  geom_histogram(position = "dodge") +
  labs(title = "Relationship Between Tree Age and Missingness in control_sd_merged")
```

Fit logistic regression models to see if missingness depends on observed variables.

```{r}
# Test if missingness depends on observed variables using logistic regression

# Add missingness indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd_test <- test_data_cleaned %>%
  mutate(
    missing_control_sd = as.numeric(is.na(control_sd_merged)),
    missing_silvo_sd = as.numeric(is.na(silvo_sd_merged))
  )
# Check levels of categorical variables
levels(test_data_cleaned_sd_test$tree_type)
levels(test_data_cleaned_sd_test$crop_type)
levels(test_data_cleaned_sd_test$age_system)
levels(test_data_cleaned_sd_test$season)
levels(test_data_cleaned_sd_test$soil_texture)
levels(test_data_cleaned_sd_test$no_tree_per_m)
levels(test_data_cleaned_sd_test$alley_width)


# Test 1: Logistic regression using no interactions between specified moderators
missing_control_model_1 <- glm(
  missing_control_sd ~ (tree_type + crop_type + age_system + tree_age + season + soil_texture + no_tree_per_m + tree_height + alley_width), #^2,
  data = test_data_cleaned_sd_test, family = binomial
)

missing_silvo_model_1 <- glm(
  missing_silvo_sd ~ (tree_type + crop_type + age_system + tree_age + season + soil_texture + no_tree_per_m + tree_height + alley_width), #^2,
  data = test_data_cleaned_sd_test, family = binomial
)

# Summarize results for Test 1
cat("\nTest 1: Logistic regression results using specified moderators\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_1)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_1)

# Test 2: Logistic regression using response variables
missing_control_model_2 <- glm(
  missing_control_sd ~ response_variable,
  data = test_data_cleaned_sd_test, family = binomial
)

missing_silvo_model_2 <- glm(
  missing_silvo_sd ~ response_variable,
  data = test_data_cleaned_sd_test, family = binomial
)

# Summarize results for Test 2
cat("\nTest 2: Logistic regression results using response variables\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_2)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_2)

```



The updated logistic regression analysis highlights that missingness in both `control_sd` and `silvo_sd` is systematically linked to observed variables, confirming that the missing data are not random. Several factors, including tree type, crop type, season, soil texture, tree age, and tree height, significantly influence missingness patterns. Tree type plays a particularly important role, with systems involving "fruit/nut & other" trees showing increased rates of missingness, likely due to variations in experimental protocols and challenges inherent in measuring more complex systems. In contrast, simpler systems such as those involving timber trees exhibit lower missingness rates, reflecting more standardized data collection methods. Similarly, crop type is a key factor, as cereal crops consistently display lower missingness, whereas systems involving tuber or root crops often experience higher rates of missing data, potentially due to logistical or methodological complexities specific to these cropping systems.

Environmental factors such as season and soil texture further contribute to missingness patterns. Extreme seasonal conditions, such as those associated with winter or summer stress, appear to hinder consistent data collection, resulting in higher rates of missingness. Similarly, difficult soil textures, particularly clay, are associated with significant missingness, likely reflecting the logistical challenges of managing experiments in these conditions. The analysis also reveals that tree age inversely correlates with missingness. Older tree systems tend to have more complete data, likely due to their greater experimental stability and maturity, whereas younger tree systems frequently experience missing data, reflecting the challenges of monitoring developing systems over shorter study durations. Tree height, on the other hand, is positively associated with missingness, as taller trees present additional challenges for data collection, particularly in accessing upper canopy layers or quantifying their influence on understory crops.

Complex response variables, such as biodiversity and greenhouse gas emissions, are also more prone to missing data. These variables often involve indirect measurements or multi-step processes, which increases the likelihood of incomplete reporting. In contrast, simpler response variables tend to have more complete datasets, reflecting less demanding measurement protocols. The statistical analysis provides strong evidence for these patterns, with significant coefficients for tree type, crop type, season, soil texture, tree height, and response variables, confirming that missingness follows a systematic and structured pattern.

These findings underscore the validity of treating missingness as "Missing at Random" (MAR), where the probability of missing data depends on observed variables. This MAR assumption supports the use of imputation techniques that incorporate predictors such as tree type, crop type, environmental conditions, and response variables into the imputation models. By leveraging these systematic relationships, imputation approaches can reduce bias and preserve the structural integrity of the dataset. This ensures that downstream analyses remain robust and reliable, even in the context of the diverse and variable experimental settings characteristic of temperate silvoarable agroforestry systems. Understanding these mechanisms of missingness is therefore critical for addressing data gaps and maintaining the reliability of meta-analytic insights.


```{r}
# Step 1: Summarize Missingness by Tree Type and Crop Type
missing_summary_tree_crop <- test_data_cleaned_sd_test %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd, na.rm = TRUE) * 100,
    missing_silvo_sd = mean(missing_silvo_sd, na.rm = TRUE) * 100,
    .groups = "drop"
  )

# Print Summary Table
missing_summary_tree_crop
```

```{r}
# Step 2: Visualize Missingness by Tree Type and Crop Type

# Plot for Control SD Missingness
plot_control_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_control_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Control SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Control SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot for Silvo SD Missingness
plot_silvo_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_silvo_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Silvo SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Silvo SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



plot_control_missingness
plot_silvo_missingness
```


```{r}
# Step 3: Statistical Tests to Confirm Associations
# Chi-Square Test for Independence between Tree Type and Control SD Missingness
chi_sq_tree_control <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_tree_control

# Chi-Square Test for Independence between Crop Type and Control SD Missingness
chi_sq_crop_control <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_crop_control

# Chi-Square Test for Independence between Tree Type and Silvo SD Missingness
chi_sq_tree_silvo <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_tree_silvo

# Chi-Square Test for Independence between Crop Type and Silvo SD Missingness
chi_sq_crop_silvo <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_crop_silvo

# Step 4: Logistic Regression Models for Tree Type and Crop Type
# Logistic Regression for Control SD
logit_control <- glm(missing_control_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_control

# Logistic Regression for Silvo SD
logit_silvo <- glm(missing_silvo_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_silvo
```

The updated analysis confirms strong associations between missingness in both `control_sd` and `silvo_sd` and the observed variables `tree_type` and `crop_type`. Results from Pearson's Chi-squared tests reveal significant relationships for both tree type and crop type. For `tree_type`, the chi-square statistic is extremely high (X² = 76.96, p < 2.2e-16), indicating a strong dependency between tree type and missingness in `control_sd` and `silvo_sd`. Similarly, the association between `crop_type` and missingness is significant, though weaker, with a chi-square statistic of X² = 9.10 and p = 0.01058. These results clearly demonstrate that missingness is not randomly distributed but is instead systematically linked to specific experimental factors.

Logistic regression models further substantiate these findings. Both tree type and crop type have positive coefficients when predicting missingness for `control_sd` and `silvo_sd`. The intercept reflects a baseline low probability of missingness, while the positive coefficients for tree type (0.083) and crop type (0.389) indicate that certain tree and crop types increase the likelihood of missing data. The residual deviance for both models is substantially reduced compared to the null deviance, demonstrating an improved model fit, with an AIC value of 999.6 for each. These statistical results highlight the structured nature of missingness, reinforcing that it is "Missing at Random" (MAR), as it depends on observable factors like tree type and crop type.

The implications of these findings are significant for the setup and interpretation of the meta-regression analysis. First, it is essential to include variables such as `tree_type` and `crop_type` as moderators in the model to account for variability linked to experimental conditions. By doing so, the analysis will better capture the systematic relationships in the data and reduce potential biases in effect size estimates. Furthermore, addressing missing data is critical to ensure reliable results. Imputation methods such as predictive mean matching or upper quartile imputation are well-suited to handle MAR scenarios, as they leverage the systematic relationships identified in the dataset to estimate plausible values for missing observations. These methods help preserve the structural integrity of the data and maintain the robustness of downstream analyses.

Given the systematic nature of missingness, additional steps are necessary to ensure the meta-regression models are robust. Sensitivity analyses should be conducted to assess the impact of imputation methods on the final results. Comparing models fitted on imputed datasets with those using only complete cases will validate the stability of findings. Furthermore, the inclusion of tree and crop type as moderators may introduce complex interactions with other variables, necessitating the exploration of potential effect modifications. Testing for heterogeneity across studies by incorporating random effects or interaction terms is also crucial to accurately capture variability within the dataset.

Finally, diagnostic evaluations, including tests for publication bias and model performance metrics, must be incorporated to ensure the reliability and validity of the results. The systematic associations between missingness and observed variables underscore the importance of carefully handling missing data and refining model specifications. These steps will support a robust and interpretable meta-regression analysis, enabling meaningful insights into the relationships driving variability in temperate silvoarable agroforestry systems.


```{r}
# Correctly aggregate missingness percentages by tree_type and crop_type
missingness_distribution_corrected <- database_clean_sd_df %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = sum(missing_control_sd_merged, na.rm = TRUE) / n() * 100,
    missing_silvo_sd = sum(missing_silvo_sd_merged, na.rm = TRUE) / n() * 100,
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(missing_control_sd, missing_silvo_sd),
    names_to = "Variable",
    values_to = "Percent_Missing"
  )

# Re-generate plots with corrected aggregation
missingness_tree_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = tree_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Tree Type",
    x = "Tree Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_crop_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = crop_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Crop Type",
    x = "Crop Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the corrected plots
print(missingness_tree_plot_corrected)
print(missingness_crop_plot_corrected)
```



The updated visualizations highlight the percentage of missing values in `control_sd` and `silvo_sd` across tree type and crop type categories. For tree type, missingness patterns reveal that "fruit/nut & other" exhibits the highest proportion of missing values, exceeding 60% for both variables. In contrast, "biomass" shows moderate missingness, with rates around 40%, while "timber" has the lowest missingness, approximately 20%. These findings indicate that missingness is strongly dependent on tree type, with "fruit/nut & other" particularly affected, possibly due to measurement challenges or variability in experimental setups.

Similarly, crop type exhibits a pronounced influence on missingness rates. Cereal crops demonstrate minimal missingness, with percentages below 20%, suggesting standardized or easier measurement practices for this crop type. In contrast, legumes exhibit moderate missingness, averaging 30-40%, while tuber/root crops face the highest rates, exceeding 60% for both variables. This substantial variability underscores that specific crop types, like tuber/root crops, may present greater challenges in data collection or experimental consistency.

These patterns reinforce the importance of tailoring imputation strategies to account for category-specific influences. For example, tree type and crop type should be included as key predictors in imputation models to address the observed disparities. Additionally, the significantly higher missingness in "fruit/nut & other" tree types and tuber/root crops indicates that these categories warrant particular attention to mitigate biases introduced by missing data. Further validation through statistical testing can refine these insights and guide the application of targeted imputation techniques to preserve data integrity across diverse categories.

















#############
# STEP 4
##########################################################################################################################################
HANDELING OF MISSING VALUES IN THE DATASET - IMPUTATION
##########################################################################################################################################

Perform imputation on  silvo_sd, control_sd using a variety of methods:

"mice" (Multivariate Imputation by Chained Equations), 
Upper Quartile, 
Mean Imputation,
Bayesian
Linear regression imputation (norm.predict)


```{r}
database_clean_sd |> glimpse()
```

The imputation process below is designed to ensure that that imputation only occur when _sd

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Start time tracking
start.time <- Sys.time()

#######################################################################################
# Step 1: Check and enforce correct data types
#######################################################################################
col_for_impute <- database_clean_sd |> 
  as.data.frame() |> 
  select(-geometry) |> 
  select(
    # Columns that need to be imputed are standard deviations (_sd) for both control and silvo groups
    silvo_sd_merged, control_sd_merged, 
    # Columns that are used by mice to impute values
    tree_age, crop_type, tree_type, bioclim_sub_regions, experiment_year, alley_width, # silvo_se, control_se, silvo_n, control_n,
    # IDs that are used to back-link imputed values to the dataset
    id_article, id_obs, treat_id, exp_id
  ) |> 
  mutate(
    silvo_sd_merged = as.numeric(silvo_sd_merged),
    control_sd_merged = as.numeric(control_sd_merged),
    # silvo_se = as.numeric(silvo_se),
    # control_se = as.numeric(control_se),
    # silvo_n = as.numeric(silvo_n),
    # control_n = as.numeric(control_n),
    tree_age = as.numeric(tree_age),
    crop_type = as.factor(crop_type),
    tree_type = as.factor(tree_type),
    bioclim_sub_regions = as.factor(bioclim_sub_regions),
    alley_width = as.factor(alley_width),
    id_article = as.numeric(id_article),
    id_obs = as.numeric(id_obs),
    treat_id = as.numeric(treat_id),
    exp_id = as.numeric(exp_id)
  )

#######################################################################################
# Step 2: Define the function for each imputation method
#######################################################################################
impute_data <- function(data, method_name) {
  if (method_name == "mean_imputation") {
    #######################################################################################
    # Mean Imputation (mean)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(is.na(silvo_sd_merged), mean(silvo_sd_merged, na.rm = TRUE), silvo_sd_merged),
        control_sd_merged = ifelse(is.na(control_sd_merged), mean(control_sd_merged, na.rm = TRUE), control_sd_merged)
      )
    return(data)

  } else if (method_name == "upper_quartile") {
    #######################################################################################
    # Upper Quartile Imputation (uq)
    #######################################################################################
    upper_quartile_variance <- data %>%
      summarise(across(c(silvo_sd_merged, control_sd_merged), ~ quantile(.^2, 0.75, na.rm = TRUE))) %>%
      pivot_longer(cols = everything(), names_to = "variable", values_to = "upper_quartile")

    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(is.na(silvo_sd_merged), sqrt(upper_quartile_variance$upper_quartile[1]), silvo_sd_merged),
        control_sd_merged = ifelse(is.na(control_sd_merged), sqrt(upper_quartile_variance$upper_quartile[2]), control_sd_merged)
      )
    return(data)

  } else if (method_name == "linear_imputation") {
    #######################################################################################
    # Linear Regression Imputation (lr)
    #######################################################################################
    data <- data %>%
      mutate(
        crop_type = as.numeric(as.factor(crop_type)),
        tree_type = as.numeric(as.factor(tree_type)),
        bioclim_sub_regions = as.numeric(as.factor(bioclim_sub_regions)),
        alley_width = as.numeric(as.factor(alley_width))
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "norm.predict",     # Imputed using linear regression
      "control_sd_merged" = "norm.predict",   # Imputed using linear regression
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",                        # Not imputed
      "crop_type" = "",                       # Not imputed
      "tree_type" = "",                       # Not imputed
      "bioclim_sub_regions" = "",             # Not imputed
      "experiment_year" = "",                 # Not imputed
      "alley_width" = "",                     # Not imputed
      "id_article" = "",                      # Not imputed
      "id_obs" = "",                          # Not imputed
      "treat_id" = "",                        # Not imputed
      "exp_id" = ""                           # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "bayesian") {
    #######################################################################################
    # Bayesian Imputation (by)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(silvo_sd_merged < 0, 0, silvo_sd_merged),
        control_sd_merged = ifelse(control_sd_merged < 0, 0, control_sd_merged)
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "norm.nob",   # Imputed using Bayesian regression
      "control_sd_merged" = "norm.nob", # Imputed using Bayesian regression
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",                  # Not imputed
      "crop_type" = "",                 # Not imputed
      "tree_type" = "",                 # Not imputed
      "bioclim_sub_regions" = "",       # Not imputed
      "experiment_year" = "",           # Not imputed
      "alley_width" = "",               # Not imputed
      "id_article" = "",                # Not imputed
      "id_obs" = "",                    # Not imputed
      "treat_id" = "",                  # Not imputed
      "exp_id" = ""                     # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "pmm") {
    #######################################################################################
    # Predictive Mean Matching (pmm)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "pmm",     # Imputed using predictive mean matching
      "control_sd_merged" = "pmm",   # Imputed using predictive mean matching
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",               # Not imputed
      "crop_type" = "",              # Not imputed
      "tree_type" = "",              # Not imputed
      "bioclim_sub_regions" = "",    # Not imputed
      "experiment_year" = "",        # Not imputed
      "alley_width" = "",            # Not imputed
      "id_article" = "",             # Not imputed
      "id_obs" = "",                 # Not imputed
      "treat_id" = "",               # Not imputed
      "exp_id" = ""                  # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "rf") {
    #######################################################################################
    # Random Forest Imputation (rf)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "rf",   # Imputed using random forest
      "control_sd_merged" = "rf", # Imputed using random forest
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",            # Not imputed
      "crop_type" = "",           # Not imputed
      "tree_type" = "",           # Not imputed
      "bioclim_sub_regions" = "", # Not imputed
      "experiment_year" = "",     # Not imputed
      "alley_width" = "",         # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",              # Not imputed
      "treat_id" = "",            # Not imputed
      "exp_id" = ""               # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else {
    stop("Invalid method name.")
  }
}

#######################################################################################
# Step 3: Apply each imputation method
#######################################################################################
imputation_methods <- c("mean_imputation", "upper_quartile", "linear_imputation", "bayesian", "pmm", "rf")
imputed_datasets <- list()

# Separate storage for raw mids objects
imputed_mids_pmm <- NULL
imputed_mids_rf <- NULL
imputed_mids_bayesian <- NULL
imputed_mids_linear <- NULL

# Iterate through imputation methods
for (method_name in imputation_methods) {
  cat("Applying", method_name, "imputation...\n")
  
  tryCatch({
    if (method_name %in% c("pmm", "rf", "bayesian", "linear_imputation")) {
      imputed_mids <- impute_data(col_for_impute, method_name)
      
      # Save mids objects for diagnostics
      if (method_name == "pmm") imputed_mids_pmm <- imputed_mids
      if (method_name == "rf") imputed_mids_rf <- imputed_mids
      if (method_name == "bayesian") imputed_mids_bayesian <- imputed_mids
      if (method_name == "linear_imputation") imputed_mids_linear <- imputed_mids
      
      # Store completed dataset
      imputed_datasets[[method_name]] <- mice::complete(imputed_mids)
    } else {
      # Direct dataset modification for other methods
      imputed_datasets[[method_name]] <- impute_data(col_for_impute, method_name)
    }
  }, error = function(e) {
    cat("Error applying", method_name, "imputation:", e$message, "\n")
  })
}

# Summary of results
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  if (!is.null(imputed_datasets[[method_name]])) {
    print(summary(imputed_datasets[[method_name]]))
  } else {
    cat("No data available for", method_name, "\n")
  }
}

#######################################################################################
# Step 4: Compare Results
#######################################################################################
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  print(summary(imputed_datasets[[method_name]]))
}

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, "\n")

##########################################################################
# imputed_mids_pmm and imputed_mids_linear are the raw mids objects for PMM and linear regression respectively
# imputed_datasets contains completed and capped datasets


##########################################################################
# Last run (16/01-25)
# Total time taken: 2.12917 mins

# Last run (22/01-25)
# Total time taken: 2.82369 mins
```

```{r}
imputed_datasets |> str()
```
```{r}
# imputed_mids_pmm
# imputed_mids_rf
# imputed_mids_bayesian
# imputed_mids_linear

# List of mids objects
mids_objects <- list(
  linear = imputed_mids_linear,
  bayesian = imputed_mids_bayesian,
  pmm = imputed_mids_pmm,
  rf = imputed_mids_rf
)

mids_objects |> str()
```

```{r}
# Ensure `database_clean_sd` has the required columns
original_metadata <- database_clean_sd %>%
  select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged)
```


```{r}
# Ensure consistent data types between original and imputed datasets
imputed_datasets <- lapply(imputed_datasets, function(data) {
  data %>%
    mutate(
      crop_type = as.factor(crop_type),
      tree_type = as.factor(tree_type),
      bioclim_sub_regions = as.factor(bioclim_sub_regions),
      alley_width = as.factor(alley_width)
    )
})

# Add original values to the dataset for comparison with each imputation method
visualization_data <- bind_rows(
  lapply(names(imputed_datasets), function(method) {
    # Extract imputed data and append original values for each method
    imputed_data <- imputed_datasets[[method]]
    bind_rows(
      data.frame(
        id_article = original_metadata$id_article,
        id_obs = original_metadata$id_obs,
        treat_id = original_metadata$treat_id,
        exp_id = original_metadata$exp_id,
        Variable = "silvo_sd_merged",
        Value = original_metadata$silvo_sd_merged,
        source = "Original",
        method = method
      ),
      data.frame(
        id_article = imputed_data$id_article,
        id_obs = imputed_data$id_obs,
        treat_id = imputed_data$treat_id,
        exp_id = imputed_data$exp_id,
        Variable = "silvo_sd_merged",
        Value = imputed_data$silvo_sd_merged,
        source = method,
        method = method
      ),
      data.frame(
        id_article = original_metadata$id_article,
        id_obs = original_metadata$id_obs,
        treat_id = original_metadata$treat_id,
        exp_id = original_metadata$exp_id,
        Variable = "control_sd_merged",
        Value = original_metadata$control_sd_merged,
        source = "Original",
        method = method
      ),
      data.frame(
        id_article = imputed_data$id_article,
        id_obs = imputed_data$id_obs,
        treat_id = imputed_data$treat_id,
        exp_id = imputed_data$exp_id,
        Variable = "control_sd_merged",
        Value = imputed_data$control_sd_merged,
        source = method,
        method = method
      )
    )
  })
)

visualization_data |> str()
```


```{r}
# Plot densities with original values overlaid on each imputation method
# Update the visualization with improved legend handling
# Plot densities with original values overlaid
ggplot(visualization_data, aes(x = Value)) +
  # Original values: red dotted line
  geom_density(
    data = subset(visualization_data, source == "Original"),
    aes(color = "Original"),
    size = 1.5,
    linetype = "dotted",
    show.legend = TRUE
  ) +
  # Imputed densities with predefined colors
  geom_density(
    data = subset(visualization_data, source != "Original"),
    aes(fill = source),
    alpha = 0.5,
    size = 1,
    color = NA # No border for filled densities
  ) +
  # Facet by method and variable
  facet_wrap(~ method + Variable, scales = "free") +
  # Pseudo log scale for better visualization of spread
  scale_x_continuous(trans = "pseudo_log") +
  # Define manual color scales for imputation methods and original
  scale_color_manual(
    values = c("Original" = "red"), # Red for original
    name = "Legend"
  ) +
  scale_fill_manual(
    values = c(
      "bayesian" = "red",
      "linear_imputation" = "yellow",
      "mean_imputation" = "green",
      "pmm" = "blue",
      "rf" = "orange",
      "upper_quartile" = "pink"
    ),
    name = "Imputation Method"
  ) +
  # General plot formatting
  theme_minimal() +
  labs(
    title = "Density Comparison of Imputed vs. Original Values (Pseudo Log Scale)",
    x = "Value (Pseudo Log Scale)",
    fill = "Imputation Method",
    color = "Legend"
  ) +
  theme(
    strip.text = element_text(size = 10, face = "bold"),
    legend.position = "top",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
  )
```
```{r}
# original_metadata |> str()
# imputed_datasets |> str()
  
# Function to process and add imputation indicators
prepare_imputation_data <- function(original, imputed_datasets) {
  # Initialize list to store datasets with imputation indicators
  processed_data <- list()
  
  # Loop through each imputation method
  for (method in names(imputed_datasets)) {
    # Join original and imputed datasets
    joined_data <- original %>%
      left_join(imputed_datasets[[method]], 
                by = c("id_article", "id_obs", "treat_id", "exp_id"),
                suffix = c(".original", ".imputed"))
    
    # Add column to indicate if the value was imputed
    joined_data <- joined_data %>%
      mutate(
        is_imputed_silvo = is.na(silvo_sd_merged.original) & !is.na(silvo_sd_merged.imputed),
        is_imputed_control = is.na(control_sd_merged.original) & !is.na(control_sd_merged.imputed),
        source = method
      )
    
    # Gather variables for visualization
    processed_data[[method]] <- joined_data %>%
      select(id_article, id_obs, treat_id, exp_id, source,
             silvo_sd_merged.original, silvo_sd_merged.imputed, 
             control_sd_merged.original, control_sd_merged.imputed,
             is_imputed_silvo, is_imputed_control) %>%
      pivot_longer(
        cols = starts_with("silvo_sd_merged") | starts_with("control_sd_merged"),
        names_to = c("Variable", ".value"),
        names_pattern = "(.*)\\.(.*)"
      )
  }
  
  # Combine all processed datasets
  combined_data <- bind_rows(processed_data)
  return(combined_data)
}
```

```{r}
# Generate the visualization data with imputation indicators
visualization_data_insights <- prepare_imputation_data(original_metadata, imputed_datasets)

# Combine original and imputed datasets
visualization_data_density_combi <- original_metadata %>%
  select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged) %>%
  pivot_longer(cols = c("silvo_sd_merged", "control_sd_merged"), names_to = "Variable", values_to = "Value") %>%
  mutate(source = "Original") %>%
  bind_rows(
    lapply(names(imputed_datasets), function(method) {
      imputed_datasets[[method]] %>%
        select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged) %>%
        pivot_longer(cols = c("silvo_sd_merged", "control_sd_merged"), names_to = "Variable", values_to = "Value") %>%
        mutate(source = method)
    }) %>%
      bind_rows()
  )

# Plot densities with red outline for original and colored lines for imputation methods
ggplot(visualization_data, aes(x = Value)) +
  # Add original density with a red dotted line
  geom_density(
    data = subset(visualization_data, source == "Original"),
    aes(color = "Original"),
    size = 2,
    linetype = "dotted"
  ) +
  # Add imputed densities with specified colors
  geom_density(
    data = subset(visualization_data, source != "Original"),
    aes(fill = source),
    alpha = 0.8,
    size = 1
  ) +
  # Facet for variables
  facet_wrap(~ Variable, scales = "free") +
  # Apply pseudo-log scale for x-axis
  scale_x_continuous(trans = "pseudo_log") +
  # Define colors for original and imputation methods
  scale_color_manual(
    values = c("Original" = "red"),
    name = "Original Data"
  ) +
  scale_fill_manual(
    values = c(
      "bayesian" = "red",
      "linear_imputation" = "yellow",
      "mean_imputation" = "green",
      "pmm" = "blue",
      "rf" = "orange",
      "upper_quartile" = "pink"
    ),
    name = "Imputation Method"
  ) +
  # Customize theme
  theme_minimal() +
  labs(
    title = "Density Comparison of Imputed vs. Original Values (Pseudo Log Scale)",
    x = "Value (Pseudo Log Scale)",
    y = "Density"
  ) +
  theme(
    legend.position = "top",
    strip.text = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```



```{r}
# Check convergence of imputations
plot(imputed_mids_linear)
plot(imputed_mids_bayesian)
plot(imputed_mids_pmm)
plot(imputed_mids_rf)
```
```{r}
# Compare observed vs. imputed values for MICE datasets
stripplot(imputed_mids_linear, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_bayesian, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_pmm, silvo_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_rf, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
```
```{r}
visualization_data |> str()

imputed_datasets |> str()
```


```{r}
# Non-MICE-based imputed datasets
non_mice_imputed_datasets <- imputed_datasets[c("mean_imputation", "upper_quartile")]

# Add the method column to each dataset in non_mice_imputed_datasets
non_mice_imputed_datasets <- lapply(names(non_mice_imputed_datasets), function(method_name) {
  dataset <- non_mice_imputed_datasets[[method_name]]
  dataset$method <- method_name
  return(dataset)
})


# non_mice_imputed_datasets |> str()

# Function to calculate evaluation metrics for non-MICE imputations
calculate_non_mice_metrics <- function(imputed_data, observed_data) {
  data.frame(
    method = unique(imputed_data$method),
    # Silvo metrics
    mean_silvo_sd = mean(imputed_data$silvo_sd_merged, na.rm = TRUE),
    sd_silvo_sd = sd(imputed_data$silvo_sd_merged, na.rm = TRUE),
    range_silvo_sd = max(imputed_data$silvo_sd_merged, na.rm = TRUE) - min(imputed_data$silvo_sd_merged, na.rm = TRUE),
    medae_silvo_sd = median(abs(observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged), na.rm = TRUE),
    mpe_silvo_sd = mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged) / observed_data$silvo_sd_merged, na.rm = TRUE) * 100,
    ks_silvo_sd = suppressWarnings(ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic),
    variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
    r2_silvo_sd = cor(observed_data$silvo_sd_merged, imputed_data$silvo_sd_merged, use = "complete.obs")^2,
    rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),

    # Control metrics
    mean_control_sd = mean(imputed_data$control_sd_merged, na.rm = TRUE),
    sd_control_sd = sd(imputed_data$control_sd_merged, na.rm = TRUE),
    range_control_sd = max(imputed_data$control_sd_merged, na.rm = TRUE) - min(imputed_data$control_sd_merged, na.rm = TRUE),
    medae_control_sd = median(abs(observed_data$control_sd_merged - imputed_data$control_sd_merged), na.rm = TRUE),
    mpe_control_sd = mean((observed_data$control_sd_merged - imputed_data$control_sd_merged) / observed_data$control_sd_merged, na.rm = TRUE) * 100,
    ks_control_sd = suppressWarnings(ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic),
    variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE),
    r2_control_sd = cor(observed_data$control_sd_merged, imputed_data$control_sd_merged, use = "complete.obs")^2,
    rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE))
  )
}

# Apply function to calculate metrics for all non-MICE datasets
non_mice_metrics <- do.call(rbind, lapply(non_mice_imputed_datasets, function(imputed_data) {
  calculate_non_mice_metrics(imputed_data, observed_data = original_metadata)
}))

non_mice_metrics |> str()
```

```{r}
# Function to calculate metrics for MICE-based imputations
calculate_mice_metrics <- function(mids_object, observed_data) {
  imputed_summaries <- lapply(1:mids_object$m, function(i) {
    imputed_data <- mice::complete(mids_object, i)
    data.frame(
      method = mids_object$method,
      iteration = i,
      # Silvo metrics
      mean_silvo_sd = mean(imputed_data$silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(imputed_data$silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = max(imputed_data$silvo_sd_merged, na.rm = TRUE) - min(imputed_data$silvo_sd_merged, na.rm = TRUE),
      medae_silvo_sd = median(abs(observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged), na.rm = TRUE),
      mpe_silvo_sd = mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged) / observed_data$silvo_sd_merged, na.rm = TRUE) * 100,
      ks_silvo_sd = suppressWarnings(ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic),
      variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
      r2_silvo_sd = cor(observed_data$silvo_sd_merged, imputed_data$silvo_sd_merged, use = "complete.obs")^2,
      rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),

      # Control metrics
      mean_control_sd = mean(imputed_data$control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(imputed_data$control_sd_merged, na.rm = TRUE),
      range_control_sd = max(imputed_data$control_sd_merged, na.rm = TRUE) - min(imputed_data$control_sd_merged, na.rm = TRUE),
      medae_control_sd = median(abs(observed_data$control_sd_merged - imputed_data$control_sd_merged), na.rm = TRUE),
      mpe_control_sd = mean((observed_data$control_sd_merged - imputed_data$control_sd_merged) / observed_data$control_sd_merged, na.rm = TRUE) * 100,
      ks_control_sd = suppressWarnings(ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic),
      variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE),
      r2_control_sd = cor(observed_data$control_sd_merged, imputed_data$control_sd_merged, use = "complete.obs")^2,
      rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE))
    )
  })
  do.call(rbind, imputed_summaries)
}

# Apply function to all MICE objects
mice_based_metrics <- do.call(rbind, lapply(mids_objects, calculate_mice_metrics, observed_data = original_metadata))

mice_based_metrics |> str()
```
```{r}
# Combine non-MICE-based and MICE-Based Metrics

# Summarize metrics for MICE-based imputations
mice_based_summary <- mice_based_metrics %>%
  group_by(method) %>%
  summarize(
    mean_ks_silvo_sd = mean(ks_silvo_sd, na.rm = TRUE),
    sd_ks_silvo_sd = sd(ks_silvo_sd, na.rm = TRUE),
    mean_ks_control_sd = mean(ks_control_sd, na.rm = TRUE),
    sd_ks_control_sd = sd(ks_control_sd, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(method != "" & !is.na(method)) # Remove empty or NA method values

# Prepare non-MICE-based metrics for visualization
non_mice_summary <- non_mice_metrics %>%
  mutate(
    mean_ks_silvo_sd = ks_silvo_sd,
    sd_ks_silvo_sd = NA, # No standard deviation for single values
    mean_ks_control_sd = ks_control_sd,
    sd_ks_control_sd = NA # No standard deviation for single values
  ) %>%
  select(method, mean_ks_silvo_sd, sd_ks_silvo_sd, mean_ks_control_sd, sd_ks_control_sd)


# Combine summaries
combined_summarised_imputation <- bind_rows(
  non_mice_summary,
  mice_based_summary
)

# Rename the method column values in combined_summarised_imputation
combined_summarised_imputation <- combined_summarised_imputation %>%
  mutate(method = case_when(
    method == "mean_imputation" ~ "Mean",
    method == "upper_quartile" ~ "Upper Quartile",
    method == "norm.nob" ~ "MICE: Bayesian Regression",
    method == "norm.predict" ~ "MICE: Linear",
    method == "pmm" ~ "MICE: Predictive Mean Matching",
    method == "rf" ~ "MICE: Random Forest",
    TRUE ~ method # Retain original value for unlisted methods
  ))

# Check the result
combined_summarised_imputation |> str()
```

Visualize the Metrics with Bar Charts and Error Bars

```{r}
# Pivot the data to a long format
combined_summarised_imputation_long <- combined_summarised_imputation %>%
  pivot_longer(
    cols = starts_with("mean_ks"),
    names_to = "metric_type",
    values_to = "mean_ks"
  ) %>%
  mutate(
    sd_ks = ifelse(metric_type == "mean_ks_silvo_sd", sd_ks_silvo_sd, sd_ks_control_sd),
    metric_type = case_when(
      metric_type == "mean_ks_silvo_sd" ~ "Silvo SD",
      metric_type == "mean_ks_control_sd" ~ "Control SD",
      TRUE ~ metric_type
    )
  )


# Combined plot with facets and custom colors
combined_summarised_imputation_plot <- combined_summarised_imputation_long |> 
  ggplot(aes(x = method, y = mean_ks, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_ks - sd_ks, ymax = mean_ks + sd_ks),
                width = 0.2, position = position_dodge(0.9)) +
  facet_wrap(~ metric_type, scales = "free_y") +
  scale_fill_manual(
    values = c(
      "MICE: Bayesian Regression" = "red",
      "MICE: Linear" = "yellow",
      "Mean" = "green",
      "MICE: Predictive Mean Matching" = "blue",
      "MICE: Random Forest" = "orange",
      "Upper Quartile" = "pink"
    )
  ) +
  theme_minimal() +
  labs(
    title = "KS Statistic Across Imputation Methods",
    x = "Imputation Method",
    y = "KS Statistic",
    fill = "Method"
  ) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold")
  )

combined_summarised_imputation_plot
```
Save the plot
```{r}
# Define the output folder path
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 60),        # Increase axis text size
    axis.title = element_text(size = 80),       # Increase axis title size
    legend.position = "none",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to the plot
combined_summarised_imputation_plot <- combined_summarised_imputation_plot + theme_custom

# Save the plots
ggsave(
  filename = file.path(output_dir, "combined_summarised_imputation_plot.png"),
  plot = combined_summarised_imputation_plot,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)
```
*Notice that only the MICE imputations have errorbars (variation), because they are including iterations!

The plot illustrates the KS statistic for Silvo SD and Control SD across different imputation methods, highlighting variations in performance. Non-MICE methods, such as Mean and Upper Quartile, exhibit higher KS statistics, suggesting larger deviations from the observed data distributions. In contrast, MICE-based methods, particularly Random Forest and Predictive Mean Matching, demonstrate the lowest KS statistics with minimal variation, indicating better alignment with observed distributions. Bayesian Regression and Linear methods show moderate consistency, with Linear slightly less effective. The error bars further emphasize the variability in MICE methods, while non-MICE approaches show no such variation. Overall, MICE methods, especially Random Forest and Predictive Mean Matching, are more effective at preserving the similarity between imputed and observed distributions.



The Kolmogorov-Smirnov (KS) statistics evaluate the differences between the distributions of observed and imputed data, with lower values indicating closer alignment. The results show that Random Forest consistently achieves the lowest KS statistics, making it the most effective method for preserving the original distributions of both `silvo_sd_merged` and `control_sd_merged`. Bayesian imputation also performs well, with low and consistent KS values, suggesting a strong ability to retain the data's original characteristics. In contrast, linear imputation consistently produces high KS statistics, indicating a poor match with the observed data, while predictive mean matching (PMM) exhibits moderate performance, with some variability across imputations. Overall, Random Forest and Bayesian methods are the most reliable for maintaining distributional similarity, while linear imputation is the least suitable.

The Kolmogorov-Smirnov (KS) test is a statistical tool used to evaluate the quality of imputed data. It assesses how well the distribution of imputed values for a specific variable matches the distribution of the original, observed data. The test calculates the maximum difference between the cumulative distribution functions (CDFs) of the observed and imputed data. A larger difference (a larger KS statistic) indicates a greater discrepancy between the distributions. If the KS test yields a statistically significant result (p-value below a chosen threshold), it suggests that the imputation method may not accurately capture the underlying distribution of the variable, potentially leading to biased results in subsequent analyses.

Essentially, the KS test helps determine if the imputed data is plausible and realistically reflects the characteristics of the original data, ensuring the reliability of any analyses conducted using the imputed dataset.

Reference: "Diagnosing problems with imputation models using the Kolmogorov-Smirnov test: a simulation study" (https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-144)


Now, selecting the best of the random forest imputations

```{r}
# Function to summarize each iteration for the Random Forest mids object
summarize_rf_mids <- function(mids_rf, observed_data) {
  rf_summaries <- list()
  
  for (i in 1:mids_rf$m) { # Iterate over the number of imputations in the mids object
    imputed_data <- mice::complete(mids_rf, i) # Extract the i-th imputed dataset
    
    # Summarize the imputed dataset
    summary <- data.frame(
      imputation = i,
      ks_silvo_sd = ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic,
      ks_control_sd = ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic,
      rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),
      rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE)),
      variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
      variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE)
    )
    
    rf_summaries[[i]] <- summary
  }
  
  # Combine all summaries into a single data frame
  rf_summaries_df <- bind_rows(rf_summaries)
  return(rf_summaries_df)
}

# Generate summaries for the Random Forest mids object
rf_summaries_df <- summarize_rf_mids(mids_objects$rf, observed_data = col_for_impute)

# Step 3: Choose the Best Random Forest Imputation
chosen_rf_imputation <- rf_summaries_df %>%
  mutate(
    total_score = ks_silvo_sd + ks_control_sd + rmse_silvo_sd + rmse_control_sd +
      abs(variance_ratio_silvo - 1) + abs(variance_ratio_control - 1)
  ) %>%
  arrange(total_score) %>%
  slice(1)

# Extract the corresponding dataset
chosen_rf_iteration <- as.integer(chosen_rf_imputation$imputation)
imputed_rf_best <- mice::complete(mids_objects$rf, chosen_rf_iteration)

# Add the best iteration of Random Forest to the imputed datasets
imputed_datasets$rf_best <- imputed_rf_best

# Output the chosen dataset
imputed_datasets$rf_best
```

##########################################################################################################################################
Visually examine the imputed values - from best selected rf imputation
##########################################################################################################################################


```{r}
################################################################################################
# Visualize Imputed Values - Best Selected RF Imputation
################################################################################################

# Check if imputed data exists
if (!is.null(imputed_datasets$rf_best$silvo_sd_merged) && 
    length(imputed_datasets$rf_best$silvo_sd_merged) > 0) {
  # Continue with the original code for silvo_sd
} else {
  # Handle the case where imputed data for silvo_sd is missing
  warning("Imputed data for silvo_sd is missing. Skipping this variable.")
}

# Rest of the code remains the same

# Combine observed (original) and imputed (rf_best) values for plotting
best_rf_plot_data <- bind_rows(
  # Original data for silvo_sd
  data.frame(
    value = original_metadata$silvo_sd_merged,
    type = "Original",
    method = "rf_best",
    variable = "silvo_sd"
  ),
  # Imputed data for silvo_sd
  data.frame(
    value = imputed_datasets$rf_best$silvo_sd_merged,
    type = "Imputed",
    method = "rf_best",
    variable = "silvo_sd"
  ),
  # Original data for control_sd
  data.frame(
    value = original_metadata$control_sd_merged,
    type = "Original",
    method = "rf_best",
    variable = "control_sd"
  ),
  # Imputed data for control_sd
  data.frame(
    value = imputed_datasets$rf_best$control_sd_merged,
    type = "Imputed",
    method = "rf_best",
    variable = "control_sd"
  )
)

# Function for density plot generation with original data as a dotted line
generate_density_plot <- function(data, title_suffix, scale_type = "linear") {
  plot <- ggplot(data) +
    geom_density(
      data = data %>% filter(type == "Imputed"),
      aes(x = value, fill = type),
      alpha = 0.5
    ) +
    geom_density(
      data = data %>% filter(type == "Original"),
      aes(x = value, color = type),
      linetype = "dotted",
      size = 1
    ) +
    facet_grid(variable ~ method) +
    labs(
      title = paste("Density Comparison:", title_suffix),
      x = ifelse(scale_type == "linear", "Value", "Value (Pseudo-Log Scale)"),
      y = "Density"
    ) +
    theme_minimal() +
    scale_fill_manual(values = c("Imputed" = "orange")) +
    scale_color_manual(values = c("Original" = "red")) +
    theme(strip.text = element_text(size = 10, face = "bold"))
  
  if (scale_type == "pseudo_log") {
    plot <- plot + scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1)) +
      scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))
  }
  
  return(plot)
}

# Generate plots for the best RF imputation
plot_rf_best_pseudo <- generate_density_plot(
  data = best_rf_plot_data,
  title_suffix = "Best RF Imputation (Pseudo-Log Scale)",
  scale_type = "pseudo_log"
)

plot_rf_best_linear <- generate_density_plot(
  data = best_rf_plot_data,
  title_suffix = "Best RF Imputation (Linear Scale)",
  scale_type = "linear"
)

# Print the plots
plot_rf_best_pseudo
plot_rf_best_linear
```


Save the plots
```{r}
# Define the output folder path
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 30),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
plot_rf_best_pseudo <- plot_rf_best_pseudo + theme_custom
plot_rf_best_linear <- plot_rf_best_linear + theme_custom

# Save the plots
ggsave(
  filename = file.path(output_dir, "plot_rf_best_pseudo.png"),
  plot = plot_rf_best_pseudo,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "plot_rf_best_linear.png"),
  plot = plot_rf_best_linear,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)
```






##########################################################################################################################################
More quantitative statistical assessment
##########################################################################################################################################



```{r}
# a. Descriptive Statistics
# Calculate and compare mean, standard deviation, and range for key variables (e.g., silvo_se, control_se).

# a. Descriptive Statistics
# Calculate descriptive statistics for each imputation method
compare_stats <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      mean_silvo_sd = mean(silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = diff(range(silvo_sd_merged, na.rm = TRUE)),
      mean_control_sd = mean(control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(control_sd_merged, na.rm = TRUE),
      range_control_sd = diff(range(control_sd_merged, na.rm = TRUE))
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_stats)



# b. Variance Explained
# Calculate variance for silvo_se and control_se
compare_variance <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      var_silvo_sd = var(silvo_sd_merged, na.rm = TRUE),
      var_control_sd = var(control_sd_merged, na.rm = TRUE)
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_variance)
```

```{r}
# Calculate Jensen-Shannon divergence for each method - The Jensen-Shannon Divergence (JSD) is a statistical measure of similarity (or dissimilarity) between two 
# probability distributions. It quantifies how different one probability distribution is from another and is widely used in information theory, machine learning, 
# and statistics.

# Function to calculate JSD safely
calculate_jsd <- function(observed, imputed) {
  if (length(imputed) > 1 && length(observed) > 1) {
    observed_density <- density(observed)$y
    imputed_density <- density(imputed)$y
    
    # Normalize to probabilities
    observed_density <- observed_density / sum(observed_density)
    imputed_density <- imputed_density / sum(imputed_density)
    
    # Calculate JSD
    return(JSD(rbind(observed_density, imputed_density)))
  } else {
    return(NA) # Return NA if densities cannot be calculated
  }
}

# Calculate JSD for each method
compare_jsd <- lapply(imputed_datasets, function(data) {
  if (inherits(data, "mids")) {
    data <- mice::complete(data) # Handle mids objects
  }
  
  # Filter numeric columns for density calculation
  observed_silvo <- col_for_impute$silvo_sd_merged[!is.na(col_for_impute$silvo_sd_merged)]
  imputed_silvo <- data$silvo_sd_merged[is.na(col_for_impute$silvo_sd_merged)]
  
  observed_control <- col_for_impute$control_sd_merged[!is.na(col_for_impute$control_sd_merged)]
  imputed_control <- data$control_sd_merged[is.na(col_for_impute$control_sd_merged)]
  
  list(
    jsd_silvo = calculate_jsd(observed_silvo, imputed_silvo),
    jsd_control = calculate_jsd(observed_control, imputed_control)
  )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_jsd)


# Add an identifier column to each data frame and convert them to long format
compare_stats_long <- compare_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

compare_variance_long <- compare_variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

compare_jsd_long <- compare_jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine all data frames into one
combined_metrics <- bind_rows(compare_stats_long, compare_variance_long, compare_jsd_long)

# View the combined data frame
combined_metrics
```



```{r}
# Ensure `database_clean_sd` is converted to a plain data frame and the `geometry` column is removed
database_clean_sd_df <- database_clean_sd %>%
  as.data.frame() |> 
  select(-geometry)

# Recalculate the metrics for the original dataset
original_metrics <- list(
  # Descriptive statistics
  descriptive_stats = database_clean_sd_df %>%
    summarise(
      mean_silvo_sd = mean(silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = diff(range(silvo_sd_merged, na.rm = TRUE)),
      mean_control_sd = mean(control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(control_sd_merged, na.rm = TRUE),
      range_control_sd = diff(range(control_sd_merged, na.rm = TRUE))
    ) %>%
    mutate(method = "original"),
  
  # Variance comparison
  variance = database_clean_sd_df %>%
    summarise(
      var_silvo_sd = var(silvo_sd_merged, na.rm = TRUE),
      var_control_sd = var(control_sd_merged, na.rm = TRUE)
    ) %>%
    mutate(method = "original"),
  
  # Jensen-Shannon divergence (JSD)
  jsd = list(
    jsd_silvo = 0, # No divergence for original dataset
    jsd_control = 0
  ) %>%
    bind_rows() %>%
    mutate(method = "original")
)

# Convert metrics to long format for visualization
original_descriptive_long <- original_metrics$descriptive_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

original_variance_long <- original_metrics$variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

original_jsd_long <- original_metrics$jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine original metrics with imputed dataset metrics
original_combined <- bind_rows(original_descriptive_long, original_variance_long, original_jsd_long)
combined_metrics_with_original <- bind_rows(combined_metrics, original_combined)

combined_metrics_with_original |> distinct(method)
```

```{r}
prepared_data_gt <- combined_metrics_with_original %>%
  # Pivot wider to make methods the columns
  pivot_wider(names_from = method, values_from = value) %>%
  # Add absolute relative difference columns
  mutate(
    across(
      -c(metric, original, category), # Exclude non-numeric columns
      ~ ifelse(
        grepl("^jsd_", metric) & . == 0, NA,  # Set `NA` where `jsd_` metrics are 0.00
        ifelse(is.na(original) | original == 0, NA, abs((. - original) / original)) # Otherwise compute relative difference
      ),
      .names = "{.col}_relative"
    )
  ) %>%
  # Add a new column to extract the prefix (e.g., mean_, sd_, etc.)
  mutate(metric_group = sub("_.*", "", metric)) %>%
  # Sort rows first by the group (e.g., mean, sd) and then by the original metric order
  arrange(metric_group, metric)

# Display structure for verification
prepared_data_gt |> glimpse()
```


```{r}
# Create the updated plot
combined_metrics_comparison_with_original <- combined_metrics_with_original |> 
  ggplot(aes(x = method, y = value, fill = method)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.8) +
  facet_wrap(~ category + metric, scales = "free_y", ncol = 3) +
  labs(
    title = "Comparison of Imputation Methods Across Metrics (Including Original Dataset)",
    x = "Method",
    y = "Value",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  ) +
  scale_fill_manual(
    values = c(
      "mean_imputation" = "green",
      "upper_quartile" = "pink",
      "linear_imputation" = "yellow",
      "bayesian" = "red",
      "pmm" = "blue",
      "rf" = "orange",
      "rf_best" = "purple",
      "original" = "black"
    )
  )

combined_metrics_comparison_with_original
```

Save the comparison diagnostics bar chart
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as PDF

combined_metrics_comparison_with_original <- combined_metrics_comparison_with_original + theme_custom

ggsave(
  filename = file.path(output_dir, "combined_metrics_comparison_with_original.png"),
  plot = combined_metrics_comparison_with_original,
  width = 14, height = 18, dpi = 400,
  bg = "white"
)
```

```{r}
# Apply color shading to all `_relative` columns
comparison_gt <- prepared_data_gt %>%
   # Reorder the columns in the data frame before passing to gt
  select(
    metric, category, original, 
    linear_imputation,
    linear_imputation_relative,
    mean_imputation, 
    mean_imputation_relative,
    upper_quartile, 
    upper_quartile_relative, 
    bayesian,
    bayesian_relative,
    pmm, 
    pmm_relative,  
    rf,
    rf_relative,
    rf_best,  
    rf_best_relative
    ) |> 
  # Set `metric` as row names
  gt() %>%
  data_color(
    columns = ends_with("_relative"), # Target all _relative columns
    method = "numeric", # Use numeric method for gradient mapping
    palette = c(
    "#00FF00", # Bright Green
    "#80FF00", # Light Green
    "#A8FF00", # Lime Green
    "#FFFF00", # Yellow
    "#FFA500", # Orange
    "#FF4500", # Orange-Red
    "#FF0000", # Bright Red
    "#8B0000"  # Dark Red
),
    domain = c(0, 0.45), # Domain for relative differences
    na_color = "#f0f0f0" # Light gray for missing/NA values
  ) %>%
  tab_header(
    title = "Comparison of Imputation Methods Across Metrics",
    subtitle = "Including Original Data and Relative Differences"
  ) %>%
  cols_label(
    original = "Original",
    linear_imputation = "Linear Imputation",
    linear_imputation_relative = "Linear Imputation Relative",
    mean_imputation = "Mean Imputation",
    mean_imputation_relative = "Mean Imputation Relative",
    upper_quartile = "Upper Quartile",
    upper_quartile_relative = "Upper Quartile Relative",
    bayesian = "Bayesian",
    bayesian_relative = "Bayesian Relative",
    pmm = "PMM",
    pmm_relative = "PMM Relative",
    rf = "Random Forest",
    rf_relative = "Random Forest Relative",
    rf_best = "Random Forest Best",
    rf_best_relative = "Random Forest Best Relative"
    ) %>%
  fmt_number(
    columns = c(original, 
                linear_imputation,
                mean_imputation,
                upper_quartile,
                pmm,
                rf,
                rf_best),
    decimals = 2
  ) %>%
  fmt_number(
    columns = ends_with("_relative"),
    decimals = 3
  ) %>%
  sub_missing(
    columns = ends_with("_relative"),
    missing_text = "NA"
  ) %>%
  tab_options(
    table.font.size = "small",
    column_labels.font.size = "medium"
  )

# Display the table
comparison_gt
```



The performance comparison of imputation methods reveals notable differences in their ability to preserve statistical properties and align with the original dataset. Evaluations are based on metrics such as mean, range, standard deviation (SD), variance, and Jensen-Shannon divergence (JSD).

**Upper Quartile**, despite preserving descriptive statistics such as mean and variance effectively, exhibits some of the highest JSD values (0.9556 for control and 0.9410 for silvo). This indicates a significant distortion of the original data distribution, making it less reliable for analyses that depend on the alignment of distributions.

**PMM (Predictive Mean Matching)** and **Random Forest (RF)** methods deliver a balanced performance across most metrics. PMM achieves lower JSD values (0.8169 for control and 0.7251 for silvo), suggesting better alignment with the original distribution. Additionally, PMM maintains relatively stable variance and SD values. RF performs similarly, with particularly low relative differences in variance and SD, though it slightly trails PMM in JSD alignment. The **RF Best** refinement further improves performance, with the lowest JSD values among all methods (0.0223 for control and 0.2758 for silvo) and minimal deviation in descriptive statistics.

**Mean Imputation** and **Bayesian** methods exhibit biases in their imputed values. Mean Imputation shows significant upward deviations in variance (16.4% for control and 16.4% for silvo), leading to less precise variance preservation. Bayesian imputation introduces moderate relative differences in SD and variance, which, although smaller than those for Mean Imputation, reflect distributional inconsistencies.

**Linear Imputation** maintains moderate performance with minimal relative differences across most metrics but does not outperform PMM or RF in any significant way. Its performance remains consistent but unspectacular, making it a reasonable, if not optimal, choice.

**Conclusion:** **RF Best** and **PMM** emerge as the most reliable imputation methods, balancing distributional alignment (low JSD) and consistency in descriptive statistics. In contrast, **Upper Quartile** is less suitable due to high JSD values, despite its stability in means and variances. **Bayesian** and **Mean Imputation** show upward biases in key metrics, and Linear Imputation offers moderate but unremarkable performance. Selecting the most appropriate method depends on the analysis goals, with RF Best and PMM being the most versatile options.


Save the comparison gt table
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as HTML
gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.html"))

# Save as PDF
# gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.pdf"))

```



```{r}
imputed_datasets |> glimpse()
```




#############
# STEP 5
##########################################################################################################################################
MERGING THE IMPUTED DATASET BACK TO THE ORIGINAL DATA AND VISUALISE
##########################################################################################################################################

```{r}
##############
# SMART SELECTION OF IMPUTATION METHOD - USING RF_BEST IMPUTATION ONLY
############################################################################

# Step 1: Select only the rf_best imputed dataset
rf_best_imputed_data <- imputed_datasets$rf_best %>%
  select(id_article, id_obs, 
         silvo_sd_rf_best = silvo_sd_merged, 
         control_sd_rf_best = control_sd_merged)

# Check for missing values in the entire dataset
any_na <- any(is.na(rf_best_imputed_data))

# Print result
if (any_na) {
  print("The rf_best_imputed_data contains missing values.")
} else {
  print("The rf_best_imputed_data does not contain any missing values.")
}

# Optionally, to see how many missing values per column
colSums(is.na(rf_best_imputed_data))


# Step 2: Merge the rf_best-imputed data back into the original dataset
merged_rf_best_data <- database_clean_sd_df %>%
  full_join(
    rf_best_imputed_data,
    by = c("id_article", "id_obs"),
    suffix = c("_original", "_imputed")
  ) %>% 
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best
  )


# Step 4: Add a column indicating the imputation method used
merged_rf_best_data <- merged_rf_best_data %>%
  mutate(imputation_method = "RF Best")

# Step 5: Preview the structure of the merged dataset
merged_rf_best_data |> glimpse()

# Additional Notes:
# - Only the RF Best imputed dataset is used for this workflow.
# - The `imputation_method` column reflects that RF Best was applied.
# - The recalculation of _sd_from_se ensures compatibility for rows with missing original SD values.
```
```{r}
merged_rf_best_data |> glimpse()
```


```{r}
# Assessing the data for missingness

merged_rf_best_data |> select(
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best,
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n)|> 
  skim()
```

```{r}
# Inspect the dataset to understand the column names
# colnames(merged_rf_best_data)

# Skim the data and extract the required metrics
skimmed_data <- merged_rf_best_data |> 
  select(
    # silvo_se, control_se, 
    silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best
    #silvo_mean, control_mean, silvo_n, control_n
  ) |> 
  skimr::skim() |> 
  as_tibble() |> 
  select(skim_variable = skim_variable, complete_rate = complete_rate, 
         numeric_mean = numeric.mean, numeric_sd = numeric.sd)

# Rename columns for better readability
skimmed_data <- skimmed_data |> 
  rename(
    variable = skim_variable,
    mean = numeric_mean,
    sd = numeric_sd
  )

# Convert the data to long format for plotting
skimmed_data_long <- skimmed_data |> 
  pivot_longer(
    cols = c(complete_rate, mean, sd),
    names_to = "metric",
    values_to = "value"
  )

# Create the bar plot with faceting by metric
skimmed_data_long |> 
  ggplot(aes(x = variable, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.8) +
  facet_wrap(~ metric, scales = "free_y", ncol = 1) +
  labs(
    title = "Comparison of Variance Metrics Across Variables",
    x = "Variable",
    y = "Value",
    fill = "Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  )

```




```{r}
# Make a new _sd_final for `silvo_sd` and `control_sd` with Random Forest imputed values if originally merged _sd values are missing

merged_data <- merged_rf_best_data %>%
  mutate(
    # For `silvo_sd`, check if the original value is missing (NA)
    # If missing, use the imputed value (`silvo_sd_rf_best`)
    # Otherwise, retain the original value (`silvo_sd_merged`)
    silvo_sd_final = ifelse(is.na(silvo_sd_merged), silvo_sd_rf_best, silvo_sd_merged),
    
    # For `control_sd`, check if the original value is missing (NA)
    # If missing, use the imputed value (`control_sd_rf_best`)
    # Otherwise, retain the original value (`control_sd_merged`)
    control_sd_final = ifelse(is.na(control_sd_merged), control_sd_rf_best, control_sd_merged)
  )

# The '_sd_final'  will be used in the escalc() effect size calculations!
```


```{r}
# Identify rows where imputation occurred
imputation_evaluation <- merged_data %>%
  filter(
    (is.na(silvo_sd_merged) & !is.na(silvo_sd_final)) |
    (is.na(control_sd_merged) & !is.na(control_sd_final))
  ) %>%
  select(id_article, id_obs, exp_id) %>%
  distinct()

# Count the number of unique articles where imputation occurred
n_imputed_studies <- imputation_evaluation %>%
  distinct(id_article) %>%
  nrow()

cat("Number of unique articles with imputed values:", n_imputed_studies, "\n")

# Last go (24/01-2025) 
# Number of unique articles with imputed values: 11 
```


```{r}
# Calculate missing counts and proportions for the _sd
missing_summary <- merged_data %>%
  summarise(
    total_obs = n(),

    # Missing counts for original dataset
    silvo_sd_original_missing = sum(is.na(silvo_sd_merged)),
    control_sd_original_missing = sum(is.na(control_sd_merged)),

    # Missing counts for imputed dataset
    silvo_sd_imputed_missing = sum(is.na(silvo_sd_final)),
    control_sd_imputed_missing = sum(is.na(control_sd_final))
  ) %>%
  mutate(
    # Proportions for original dataset
    silvo_sd_original_proportion = silvo_sd_original_missing / total_obs,
    control_sd_original_proportion = control_sd_original_missing / total_obs,

    # Proportions for imputed dataset
    silvo_sd_imputed_proportion = silvo_sd_imputed_missing / total_obs,
    control_sd_imputed_proportion = control_sd_imputed_missing / total_obs
  )

missing_summary
```

```{r}
original_data <- database_clean_sd_df %>%
  select(id_article, id_obs, 
         silvo_sd_final = silvo_sd_merged, silvo_sd_from_se, silvo_sd,  
         control_sd_final = control_sd_merged, control_sd_from_se, control_sd) %>%
  mutate(data_source = "Original")

imputed_data <- merged_data %>%
  select(id_article, id_obs, 
         silvo_sd_final, silvo_sd_from_se, silvo_sd,  
         control_sd_final, control_sd_from_se, control_sd) %>%
  mutate(data_source = "Imputed")

# Combine original and imputed data
combined_data <- bind_rows(original_data, imputed_data)
```

```{r}
# Check for duplicates
duplicates <- merged_data %>%
  group_by(id_article, id_obs) %>%
  filter(n() > 1)

# Check for rows with imputed values
imputation_check <- merged_data %>%
  filter(is.na(silvo_sd_merged) & !is.na(silvo_sd_final))

# View summaries
print(duplicates)
print(imputation_check)
```


##########################################################################################################################################
VISUAL DIAGNOSTIGS OF MERGED DATA WITH SELECTED IMPUTATION METHOD
##########################################################################################################################################

```{r}
# imputed_datasets |> str()
```

```{r}

# Filter relevant columns for analysis
imputation_analysis_data <- merged_data %>%
  select(imputation_method, 
         silvo_sd_merged, silvo_sd_rf_best, 
         control_sd_merged, control_sd_rf_best) %>%
  pivot_longer(
    cols = c(silvo_sd_merged, silvo_sd_rf_best, 
             control_sd_merged, control_sd_rf_best),
    names_to = "variable",
    values_to = "value"
  ) %>%
  mutate(
    group = case_when(
      grepl("^silvo", variable) ~ "Silvo",
      grepl("^control", variable) ~ "Control"
    ),
    variable = case_when(
      grepl("_sd_merged", variable) ~ "SD Merged",
      grepl("_sd_rf_best", variable) ~ "SD RF Best"
    )
  ) %>%
  drop_na(value)  # Remove rows with NA values

# Create a boxplot for _sd_merged and _sd_rf_best side by side by imputation_method
boxplot <- ggplot(imputation_analysis_data, aes(x = variable, y = value, fill = imputation_method)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +  # Boxplot without outlier points
  geom_jitter(color = "black", size = 0.5, alpha = 0.5, width = 0.2) +  # Add jitter for individual points
  facet_wrap(~group, scales = "free_y") +  # Facet by group (Silvo and Control)
  labs(
    title = "Comparison of Merged and RF-Best SD by Imputation Method",
    x = "SD Type",
    y = "Value",
    fill = "Imputation Method"
  ) +
  scale_y_continuous(trans = "pseudo_log") +  # Apply pseudo-log scale to y-axis
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  )

# Print the boxplot
print(boxplot)
```



Quality check of imputation using QQ-plot 

```{r}
# Pivot data to long format for easier plotting
qq_imp_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_sd_final, control_sd_final),
    names_to = "variable",
    values_to = "value"
  ) |> 
  # Replace NA with 0 (or another strategy if preferred)
  mutate(value = ifelse(is.na(value), 0, value)) 

# Compute theoretical quantiles and prepare the data for jitter
qq_data_jitter <- qq_imp_data %>%
  group_by(variable, data_source) %>%
  mutate(
    theoretical = qnorm((rank(value, na.last = "keep") - 0.5) / sum(!is.na(value))) # Compute theoretical quantiles
  ) %>%
  ungroup() 

# Enhanced Q-Q Plot with Fixed Scales and Confidence Intervals
qqplot_imp_combined <- qq_data_jitter %>%
  ggplot(aes(x = theoretical, y = value, color = data_source, shape = data_source)) +
  geom_point(
    position = position_jitter(width = 0.05, height = 0.05),
    alpha = 0.8,
    size = 1.5
  ) + # Jitter points
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black", size = 1) + # Reference line
  facet_wrap(~variable, scales = "fixed", ncol = 2) + # Fixed scales for consistent comparison
  scale_y_continuous(trans = "log10", breaks = scales::log_breaks(base = 10)) + # Log scale for y-axis
  labs(
    title = "Q-Q Plots for Original vs. Imputed Data",
    subtitle = "Assessing Distributional Similarity with Enhanced Features",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles (Log Scale)",
    color = "Data Source",
    shape = "Data Source"
  ) +
  scale_color_manual(
    values = c("Imputed" = "#1f78b4", "Original" = "#33a02c") # Distinct colors for clarity
  ) +
  scale_shape_manual(
    values = c("Imputed" = 16, "Original" = 17) # Consistent point shapes
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 14, face = "italic", hjust = 0.5),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = "bold"),
    strip.text = element_text(size = 14, face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Print the improved Q-Q plot
print(qqplot_imp_combined)
```

The Q-Q plot above compares the theoretical quantiles of the original and imputed data distributions for control_sd and silvo_sd, with a log-transformed y-axis to account for the wide range of values. The dashed reference line represents perfect agreement between the theoretical and sample quantiles. Points close to this line indicate good alignment between the original and imputed distributions.

For control_sd_final, the imputed data closely matches the original data in the lower quantile range, but some divergence occurs at higher quantiles. This suggests the imputation replicates the original distribution well for smaller and moderate values but overestimates variability in the upper tail. A similar pattern is observed for silvo_sd_final, where the imputed data aligns well with the original distribution in lower and mid-range quantiles but shows slight overestimation in the higher quantiles. The log-transformed scale effectively highlights these deviations across all ranges of the data.

Overall, the imputation method appears robust for most of the distribution, particularly in the central range, which is often the most critical for analysis. However, the slight overestimation in the upper quantiles suggests a potential limitation in handling extreme values. If these deviations are significant for downstream analyses, further refinement of the imputation model may be required to better address variability in the tails of the distribution.

Saving QQ-plot

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
qqplot_imp_combined <- qqplot_imp_combined + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "qqplot_imp_combined_enhanced_rf_log_scale.png"),
  plot = qqplot_imp_combined,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```



Again, checking the imputed control_sd and silvo_sd density distribution (imputation = Random Forest (best))
```{r}
# Combine the data for silvo_se and control_se into long format
density_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_sd_final, control_sd_final),
    names_to = "variable",
    values_to = "value"
  )

# Filter out non-positive values for log transformation
density_data_clean <- density_data %>%
  filter(value > 0) # Keep only positive values

# Improved density plot with custom x-axis labels
density_plot_clean <- density_data_clean %>%
  ggplot(aes(x = value, color = data_source, fill = data_source)) +
  geom_density(alpha = 0.4, na.rm = TRUE) + # Add density plot with transparency
  scale_x_log10(
    breaks = scales::trans_breaks("log10", function(x) 10^x), # Define breaks at log10 intervals
    labels = scales::trans_format("log10", scales::math_format(10^.x)) # Format labels as 10^x
  ) +
  labs(
    title = "Density Distribution of silvo_se and control_se (Log-Transformed)",
    x = "Value (Log Scale)",
    y = "Density",
    color = "Data Source",
    fill = "Data Source"
  ) +
  facet_wrap(~variable, scales = "free_x", ncol = 2) + # Separate plots for silvo_se and control_se
  scale_color_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "bottom"
  )

# Display the density plot
density_plot_clean
```

Save density distribution plot of imputed control_se and silvo_se

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
density_plot_clean <- density_plot_clean + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "density_plot_clean_rf.png"),
  plot = density_plot_clean,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```


#############
# STEP 6
##########################################################################################################################################
SAVING TWO VERSIONS OF PREPROCESSED DATA FOR FURTHER ANALYSIS AND VISUALIZATION - RECALCULATION OF _SD WHERE THE ORIGINAL _SD IS MISSING
##########################################################################################################################################

```{r}
# Imputed dataset where _se is imputed and then subsequently used to calculate _sd
imp_rf_best <- merged_data |> 
  as.data.frame() |> 
  # (remove geometry if necessary)
  # select(-geometry) |> 
  # Relocate columns to the desired order 
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_final,
    # Imputation info
    imputation_method 
  )

# Preview the dataset structure silvo_sd_calculated_from_se
glimpse(imp_rf_best)
```
```{r}
imp_rf_best |> skim()
```

```{r}
# Non-imputed dataset (remove geometry if necessary)
non_imp_dataset <- database_clean_sd |> 
  as.data.frame() |> 
  # (remove geometry if necessary)
  select(-geometry) |> 
  # Rename existing _sd columns to _sd_original
  rename(
    silvo_sd_final = silvo_sd_merged,
    control_sd_final = control_sd_merged) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final,
    # Imputation info
    # imputation_method 
  )

# Preview the dataset structure silvo_sd_calculated_from_se
glimpse(non_imp_dataset)
```


```{r}
non_imp_dataset |> skim()
```



DATASET COMPARISON (CATEGORICAL AND NUMERICAL DATA)

```{r}
###############################
# DATASET COMPARISON SCRIPT
###############################

# Function to filter valid columns with non-NA values and valid variance
filter_valid_columns <- function(df) {
  df %>% select(where(~ !all(is.na(.)) && var(., na.rm = TRUE) > 0))
}

# -----------------
# CATEGORICAL DATA
# -----------------
imp_rf_best_categorical <- imp_rf_best %>%
  select(where(is.factor) | where(is.character)) %>%
  select(where(~ !all(is.na(.))))

non_imp_dataset_categorical <- non_imp_dataset %>%
  select(where(is.factor) | where(is.character)) %>%
  select(where(~ !all(is.na(.))))

if (ncol(imp_rf_best_categorical) > 0 && ncol(non_imp_dataset_categorical) > 0) {
  common_columns <- intersect(names(imp_rf_best_categorical), names(non_imp_dataset_categorical))
  imp_rf_best_categorical <- imp_rf_best_categorical %>% select(all_of(common_columns))
  non_imp_dataset_categorical <- non_imp_dataset_categorical %>% select(all_of(common_columns))

  if (ncol(imp_rf_best_categorical) > 0 && ncol(non_imp_dataset_categorical) > 0) {
    cat_plot <- inspect_cat(imp_rf_best_categorical, non_imp_dataset_categorical) %>% show_plot()
    print(cat_plot)
  } else {
    cat("No common valid categorical columns found for comparison.\n")
  }
} else {
  cat("One or both datasets have no valid categorical columns to compare.\n")
}

# -----------------
# NUMERICAL DATA
# -----------------
imp_rf_best_numeric <- imp_rf_best %>% select(where(is.numeric)) %>% filter_valid_columns()
non_imp_dataset_numeric <- non_imp_dataset %>% select(where(is.numeric)) %>% filter_valid_columns()

if (ncol(imp_rf_best_numeric) > 0 && ncol(non_imp_dataset_numeric) > 0) {
  imp_rf_best_numeric$dataset <- "imputed"
  non_imp_dataset_numeric$dataset <- "non-imputed"

  combined_data <- bind_rows(imp_rf_best_numeric, non_imp_dataset_numeric)
  combined_long <- combined_data %>%
    pivot_longer(cols = -dataset, names_to = "variable", values_to = "value")

  numeric_plot <- ggplot(combined_long, aes(x = value, fill = dataset)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~variable, scales = "free") +
    labs(title = "Density Plots for Numeric Variables", x = "Value", y = "Density") +
    theme_minimal()

  print(numeric_plot)
} else {
  cat("One or both datasets have no valid numeric columns to compare.\n")
}

# -----------------------------
# COLUMN-WISE SIMILARITY CHECK
# -----------------------------
if (ncol(imp_rf_best) > 0 && ncol(non_imp_dataset) > 0) {
  cor_plot <- inspect_cor(imp_rf_best, non_imp_dataset) %>% show_plot()
  print(cor_plot)

  na_plot <- inspect_na(imp_rf_best, non_imp_dataset) %>% show_plot()
  print(na_plot)
} else {
  cat("One or both datasets are empty or invalid for column-wise comparison.\n")
}
```


```{r}
# SAVING TWO VERSIONS OF PREPROCESSED DATA AS RDS

# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save the non-imputed dataset as RDS
saveRDS(non_imp_dataset,
        file = file.path(output_dir, "non_imp_dataset.rds"))


# Save the best-imputed dataset as RDS
saveRDS(imp_rf_best,
        file = file.path(output_dir, "imp_rf_best_dataset.rds"))

# Print confirmation messages
cat("Datasets saved successfully:\n")
cat("- Non-imputed dataset: non_imp_dataset.rds\n")
cat("- Best-imputed dataset: imp_rf_best_dataset.rds\n")
```





#############
# STEP 7
##########################################################################################################################################
CALCULATING EFFECT SIZES FOR IMPUTED AND NON-IMPUTED DATASETS
##########################################################################################################################################

Loading datasets
```{r}
# Load the non-imputed and imputed datasets
non_imp_dataset <- readRDS(file.path(output_dir, "non_imp_dataset.rds"))

# Load the imputed dataset
imp_rf_best <- readRDS(file.path(output_dir, "imp_rf_best_dataset.rds"))
```



```{r}
non_imp_dataset |> glimpse()
imp_rf_best |> glimpse()
```


```{r}
# Step 1: Define Target Columns
target_columns <- c("silvo_sd_rf_best", "control_sd_rf_best")

# Step 2: Calculate Upper Quartile Variance by `sub_response_variable`
upper_quartile_variance <- imp_rf_best %>%
  group_by(sub_response_variable) %>%
  summarise(
    silvo_sd_rf_best_uq = quantile(silvo_sd_rf_best^2, 0.95, na.rm = TRUE),
    control_sd_rf_best_uq = quantile(control_sd_rf_best^2, 0.95, na.rm = TRUE),
    .groups = "drop"
  )

# Step 3: Identify High Variance Observations by `sub_response_variable`
thresholds <- imp_rf_best %>%
  group_by(sub_response_variable) %>%
  summarise(
    silvo_threshold = quantile(silvo_sd_rf_best^2, 0.95, na.rm = TRUE) +
      1.5 * IQR(silvo_sd_rf_best^2, na.rm = TRUE),
    control_threshold = quantile(control_sd_rf_best^2, 0.95, na.rm = TRUE) +
      1.5 * IQR(control_sd_rf_best^2, na.rm = TRUE),
    .groups = "drop"
  )

# Merge thresholds and upper quartile variance back to the original data
imp_rf_best_with_thresholds <- imp_rf_best %>%
  left_join(thresholds, by = "sub_response_variable") %>%
  left_join(upper_quartile_variance, by = "sub_response_variable")

# Filter high variance rows for `silvo_sd_rf_best`
high_variance_silvo_sd_rf_best <- imp_rf_best_with_thresholds %>%
  mutate(variance = silvo_sd_rf_best^2) %>%
  filter(variance > silvo_threshold) %>%
  select(id_article, id_obs, sub_response_variable, variance, silvo_sd_rf_best, control_sd_rf_best)

# Filter high variance rows for `control_sd_rf_best`
high_variance_control_sd_rf_best <- imp_rf_best_with_thresholds %>%
  mutate(variance = control_sd_rf_best^2) %>%
  filter(variance > control_threshold) %>%
  select(id_article, id_obs, sub_response_variable, variance, silvo_sd_rf_best, control_sd_rf_best)

# Combine high variance rows
high_variance_rows <- bind_rows(high_variance_silvo_sd_rf_best, high_variance_control_sd_rf_best) %>%
  distinct()

# Step 4: Replace High Variance Values with the Condition
imp_rf_best_uq <- imp_rf_best_with_thresholds %>%
  mutate(
    silvo_sd_rf_best_uq = ifelse(
      id_obs %in% high_variance_rows$id_obs & id_article %in% high_variance_rows$id_article & is.na(silvo_sd_merged),
      sqrt(silvo_sd_rf_best_uq),
      silvo_sd_rf_best
    ),
    control_sd_rf_best_uq = ifelse(
      id_obs %in% high_variance_rows$id_obs & id_article %in% high_variance_rows$id_article & is.na(control_sd_merged),
      sqrt(control_sd_rf_best_uq),
      control_sd_rf_best
    )
  ) 

# Step 5: View Updated Dataset
imp_rf_best_uq %>% glimpse()
imp_rf_best_uq |> skim()
```

```{r}
# Function to prepare data for plotting
prepare_plot_data <- function(dataset, id) {
  dataset %>%
    select(silvo_sd_rf_best, silvo_sd_rf_best_uq, control_sd_rf_best, control_sd_rf_best_uq) %>%
    pivot_longer(cols = everything(),
                 names_to = "Variable",
                 values_to = "Value") %>%
    mutate(Dataset = id)
}

# Prepare datasets for visualization
imp_rf_best_plot_data <- prepare_plot_data(imp_rf_best_uq, "imp_rf_best_uq")

# Combine datasets (if needed, extend for multiple datasets)
combined_plot_data <- imp_rf_best_plot_data

# Adjust data for visualization
filtered_plot_data <- combined_plot_data %>%
  filter(!is.na(Value))  # Remove rows with missing values

# Re-plot with improved adjustments
ggplot(filtered_plot_data, aes(x = Variable, y = Value, fill = Dataset)) +
  geom_violin(alpha = 0.4, scale = "width", position = position_dodge(width = 0.8)) + # Separate violins
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.7, position = position_dodge(width = 0.8)) + # Separate boxplots
  geom_jitter(
    aes(color = Dataset), 
    position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), 
    alpha = 0.4
  ) + # Add jittered points without overlap
  labs(
    title = "Comparison of _uq vs Non-_uq Variables",
    x = "Variable",
    y = "Value"
  ) +
  scale_fill_brewer(palette = "Set2") + # Use color palette for violins and boxplots
  scale_color_brewer(palette = "Set2") + # Match colors for jitter points
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Adjust axis label angle
    legend.position = "top" # Place legend at the top
  )
```

Check what observations has different values in _sd_rf_best_uq as compared to _sd_rf_best

```{r}
# Identify differences in values between _sd_rf_best and _sd_rf_best_uq
differences <- imp_rf_best_uq %>%
  filter(
    silvo_sd_rf_best != silvo_sd_rf_best_uq |
    control_sd_rf_best != control_sd_rf_best_uq
  ) %>%
  select(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se,  
    control_se, control_sd, control_sd_from_se, 
    # Updated variance columns
    silvo_sd_rf_best, silvo_sd_rf_best_uq,
    control_sd_rf_best, control_sd_rf_best_uq
  )

# Display the differences
differences %>% glimpse()

# Rows: 13
# Columns: 32
# $ id_article            <dbl> 10, 10, 10, 10, 10, 13, 29, 29, 29, 29, 29, 30, 33
# $ id_obs                <dbl> 364, 371, 379, 383, 384, 493, 873, 877, 878, 889, 899, 913, 1048


differences |> select(
  # Updated variance columns
    silvo_sd_rf_best, silvo_sd_rf_best_uq,
    control_sd_rf_best, control_sd_rf_best_uq) |> 
  skim()
```


```{r}
imp_rf_best <- imp_rf_best_uq |> 
  mutate(
    control_sd_final = control_sd_rf_best_uq,
    silvo_sd_final = silvo_sd_rf_best_uq
  )
```




#############
# STEP 7
##########################################################################################################################################
EFFECT SIZE CALCULATION
##########################################################################################################################################

```{r}
# Function for data preparation before escalc() effect size calculation

prep_dataset_for_rom <- function(data) {
  data %>%
    # Step 1: Filter out rows where the standard deviations are zero or negative
    # - Standard deviation (SD) must be positive for valid statistical calculations.
    filter(silvo_sd_final > 0, control_sd_final > 0) %>%
    
    # Step 2: Adjust the sign of mean values for specific response variables
    # - For variables like "Greenhouse gas emissions," "Pests and Diseases," and "Water quality,"
    #   lower values are considered better. We negate the mean values to reflect this correctly.
    mutate(
      silvo_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"),
                          -silvo_mean, silvo_mean),
      control_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"),
                            -control_mean, control_mean)
    ) %>%
    
    # Step 3: Exclude specific response variables from analysis
    # - "Soil water content" is excluded due to inconsistent data or limited measurements.
    filter(response_variable != "Soil water content") %>%
    
    # Step 4: Remove rows with missing values in key columns
    # - Ensures complete data for effect size calculation.
    filter(!is.na(silvo_mean) & !is.na(control_mean) &
           !is.na(silvo_n) & !is.na(control_n) &
           !is.na(silvo_sd_final) & !is.na(control_sd_final)) %>%
    
    # Step 5: Shift mean values to be positive
    # - Calculate a shift value (min_value_shift) based on the absolute minimum value
    #   of the means, ensuring all values are positive for transformations.
    mutate(
      min_value_shift = abs(min(c(silvo_mean, control_mean), na.rm = TRUE)) + 1,
      silvo_mean = silvo_mean + min_value_shift,
      control_mean = control_mean + min_value_shift
    ) %>%
    
    # Step 6: Reorder columns for better readability and organization
    # - Places important columns (e.g., identifiers, means, SEs, SDs, sample sizes) at the front of the data frame.
    relocate(id_article, response_variable, measured_metrics, measured_unit,
             silvo_mean, silvo_n, silvo_sd_final, control_mean, control_n, control_sd_final) %>%
    
    # Step 7: Sort the data by article ID and response variable for consistency
    # - Sorting helps ensure that the data is organized and facilitates easier inspection and analysis.
    arrange(id_article, response_variable)
}
```

```{r}
# Apply the data preparation function to both non-imputed and imputed datasets
# - This creates cleaned and prepared datasets for effect size calculation.
non_imp_data_prep <- prep_dataset_for_rom(non_imp_dataset)
imp_data_prep <- prep_dataset_for_rom(imp_rf_best)
```

```{r}
# Generic function for effect size calculation using `escalc()`

# This function can be applied to both imputed and non-imputed datasets.

calculate_effect_sizes <- function(data, measure = "ROM") {
  # Check if the required columns are present in the dataset
  required_columns <- c("silvo_mean", "silvo_n", "silvo_sd_final", 
                        "control_mean", "control_n", "control_sd_final",
                        "id_article", "id_obs", "experiment_year")
  
  if (!all(required_columns %in% names(data))) {
    stop("The dataset is missing one or more required columns.")
  }
  
  # Calculate effect sizes using `escalc()`
  result <- escalc(
    measure = measure,           # Specify the effect size measure (default is "ROM").
    
    # Experimental group (silvo_) parameters:
    m1i = silvo_mean,            # Mean of the experimental (silvo) group.
    sd1i = silvo_sd_final,       # Standard deviation of the experimental (silvo) group.
    n1i = silvo_n,               # Sample size of the experimental (silvo) group.
    
    # Control group (control_) parameters:
    m2i = control_mean,          # Mean of the control group.
    sd2i = control_sd_final,     # Standard deviation of the control group.
    n2i = control_n,             # Sample size of the control group.
    
    # Study labels for identification:
    slab = paste(id_article, ", ", experiment_year, sep = ""),
    
    # The input dataset:
    data = data
  ) %>%
    as.data.frame()              # Convert the result to a data frame for easier handling.
  
  # Return the resulting data frame with calculated effect sizes
  return(result)
}
```

```{r}
# Inspect the input data to `escalc()`
imp_data_prep %>%
  select(id_article, response_variable, 
         silvo_mean, silvo_n, silvo_sd_final, 
         control_mean, control_n, control_sd_final) %>%
  filter(is.na(silvo_sd_final) | is.na(control_sd_final) | silvo_sd_final <= 0 | control_sd_final <= 0)
```

```{r}
# Apply the function to both non-imputed and imputed datasets

################################################################################################################

# function for effect size calculation using `escalc()`
non_imp_data_rom <- calculate_effect_sizes(non_imp_data_prep,
                                           # SMD (Standardized Mean Difference)
                                           # ROM (Log-Transformed Ratio)
                                           measure = "ROM") |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )


################################################################################################################

# function for effect size calculation using `escalc()`
imp_data_rom <- calculate_effect_sizes(imp_data_prep,
                                       # SMD (Standardized Mean Difference)
                                       # ROM (Log-Transformed Ratio)
                                       measure = "ROM") |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )
```

```{r}
imp_data_rom |> glimpse()
```

```{r}
# Create the boxplot for the effect size (yi)
# Order response variables by descending median effect size
imp_data_rom_reorder <- imp_data_rom %>%
  mutate(response_variable = fct_reorder(response_variable, yi, .fun = median, .desc = FALSE))

# Create the boxplot with ordered response variables
boxplot_raw_effect_size <- imp_data_rom_reorder |> 
  ggplot(aes(y = response_variable, x = yi, fill = response_variable)) +
  geom_vline(xintercept = 0, linetype = "dotted", color = "red", size = 0.8) + # Add red dotted line at x = 0
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  labs(
    title = "Raw Effect Sizes (yi) Across Response Variables",
    x = "Raw Effect Size (yi)",
    y = "Response Variable"
  ) +
  scale_x_continuous(
    trans = pseudo_log_trans(sigma = 0.1), # Apply pseudo-log transformation
    breaks = c(0, 0.1, 1, 10, 100),       # Custom breaks
    labels = c("0", "0.1", "1", "10", "100") # Relatable labels
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 12), # Adjust y-axis text size
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels
    legend.position = "none"
  )

boxplot_raw_effect_size
```


Save raw effect size plot of each response variable

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.position = "none",
    axis.text.x = element_text(size = 100,
                               angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
boxplot_raw_effect_size <- boxplot_raw_effect_size + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "boxplot_raw_effect_size.png"),
  plot = boxplot_raw_effect_size,
  width = 16, height = 8, dpi = 600,
  bg = "white"
)
```



```{r}
# Prepare the data for plotting
data_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(
    cols = c(control_mean, silvo_mean),
    names_to = "Group",
    values_to = "Mean"
  )

# Create the boxplot with a log-transformed y-axis
ggplot(data_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  facet_wrap(~ response_variable, scales = "free") +
  labs(
    title = "Comparison of Mean Values for Control and Silvo Groups by Response Variable (Log Scale)",
    x = "Group",
    y = "Mean Value (Log Scale)"
  ) +
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )
```

```{r}
# Boxplot comparison for control and silvo groups
imp_data_rom_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(cols = c(control_mean, silvo_mean), names_to = "Group", values_to = "Mean")

ggplot(imp_data_rom_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ response_variable, scales = "free") +  # Facet by response variable
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  labs(
    title = "Distribution of Means for Control and Silvo Groups",
    x = "Group",
    y = "Mean Value"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")
```

```{r}
# Step 1: Define high variance threshold per `sub_response_variable`
high_variance_thresholds <- imp_data_rom %>%
  group_by(sub_response_variable) %>%
  summarise(
    high_threshold = quantile(vi, 0.95, na.rm = TRUE),
    low_threshold = quantile(vi, 0.05, na.rm = TRUE),
    .groups = "drop"
  )

# Step 2: Merge thresholds back to the main dataset
imp_data_rom_with_thresholds <- imp_data_rom %>%
  left_join(high_variance_thresholds, by = "sub_response_variable")

# Step 3: Filter high and low variance observations
extreme_variance_rows <- imp_data_rom_with_thresholds %>%
  filter(vi > high_threshold | vi < low_threshold) %>%
  arrange(desc(vi)) %>%
  select(
    # Relevant columns
    id_article, id_obs, sub_response_variable, response_variable, measured_metrics,
    yi, vi, silvo_mean, control_mean, 
    silvo_n, control_n, silvo_se, control_se, 
    silvo_sd_final, control_sd_final,
    silvo_sd_from_se, control_sd_from_se,
    silvo_sd_merged, control_sd_merged
  )

# Step 4: Summarize extreme variance observations (taking into account that it might be sub_response_variable dependent)
extreme_variance_summary <- extreme_variance_rows %>%
  group_by(id_article, sub_response_variable) %>%
  summarise(
    num_extreme_obs = n(),
    avg_variance = mean(vi, na.rm = TRUE),
    max_variance = max(vi, na.rm = TRUE),
    min_variance = min(vi, na.rm = TRUE),
    response_variables = paste(unique(response_variable), collapse = ", "),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_variance))

# Step 5: Isolate unique articles with high variance
unique_high_variance_articles <- extreme_variance_rows %>%
  distinct(id_article, sub_response_variable) %>%
  arrange(id_article)

# Step 6: Optional Export to CSV
# write.csv(extreme_variance_rows, "extreme_variance_rows.csv", row.names = FALSE)
# write.csv(extreme_variance_summary, "extreme_variance_summary.csv", row.names = FALSE)
# write.csv(unique_high_variance_articles, "unique_high_variance_articles.csv", row.names = FALSE)

# View Results
list(
  extreme_rows = extreme_variance_rows,
  summary = extreme_variance_summary,
  unique_articles = unique_high_variance_articles
)
```

```{r}
# Step 1: Define thresholds for high and low variance per `sub_response_variable`
variance_thresholds <- imp_data_rom %>%
  group_by(sub_response_variable) %>%
  summarise(
    high_variance_threshold = quantile(vi, 0.95, na.rm = TRUE),
    low_variance_threshold = quantile(vi, 0.05, na.rm = TRUE),
    .groups = "drop"
  )

# Step 2: Merge thresholds back to the original data
imp_data_rom_with_thresholds <- imp_data_rom %>%
  left_join(variance_thresholds, by = "sub_response_variable")

# Step 3: Filter high and non-high variance observations
high_variance_data <- imp_data_rom_with_thresholds %>%
  filter(vi > high_variance_threshold)

non_high_variance_data <- imp_data_rom_with_thresholds %>%
  filter(!(vi > high_variance_threshold))
```


```{r}
# Plot for high variance
high_variance_plot <- high_variance_data %>%
  ggplot(aes(x = factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, width = 0.6) +  # Remove default outliers
  geom_jitter(
    aes(color = response_variable), 
    position = position_jitter(width = 0.1, height = 0), 
    alpha = 0.8, size = 2
  ) +  # Add jittered points
  labs(title = "High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

# Plot for non-high variance
non_high_variance_plot <- non_high_variance_data %>%
  ggplot(aes(x = factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, width = 0.6) +  # Remove default outliers
  geom_jitter(
    aes(color = response_variable), 
    position = position_jitter(width = 0.1, height = 0), 
    alpha = 0.8, size = 2
  ) +  # Add jittered points
  labs(title = "Non-High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Combine plots side by side
combined_plot <- high_variance_plot + non_high_variance_plot + 
  plot_layout(ncol = 2)

# Display the combined plot
print(combined_plot)
```

```{r}
# High variance plot for individual observations with increased jitter

# High variance plot for individual observations with increased jitter
high_variance_plot <- ggplot(high_variance_data, aes(x = as.factor(id_article), y = vi, color = response_variable)) +
  geom_point(position = position_jitter(width = 0.3, height = 0), size = 3, alpha = 0.7) +  # Jittered points
  geom_text_repel(
    aes(label = id_obs),
    position = position_jitter(width = 0.3, height = 3),  # Adjust label positioning
    size = 3,
    max.overlaps = Inf
  ) +
  labs(
    title = "High Variance Observations (Individual, Jittered)",
    x = "Article ID",
    y = "Variance (vi) [Pseudo Log Transformed]",
    color = "Response Variable"
  ) +
  scale_color_manual(values = global_palette) +  # Use predefined color palette
  scale_y_continuous(
    trans = pseudo_log_trans(sigma = 0.1),  # Pseudo log transformation
    breaks = c(0, 0.1, 1, 10, 30),
    labels = c("0", "0.1", "1", "10", "30")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Non-high variance plot with aggregated boxplots
non_high_variance_plot <- ggplot(non_high_variance_data, aes(x = as.factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.color = "blue", alpha = 0.7, outlier.size = 2) +  # Boxplots with adjusted outlier color and size
  geom_jitter(
    aes(color = response_variable),
    position = position_jitter(width = 0.2, height = 0),  # Add jittered points to boxplots
    alpha = 0.6, size = 2
  ) +
  labs(
    title = "Non-High Variance Observations (Boxplots + Points)",
    x = "Article ID",
    y = "Variance (vi) [Pseudo Log Transformed]",
    fill = "Response Variable",
    color = "Response Variable"
  ) +
  scale_fill_manual(values = global_palette) +  # Use predefined color palette
  scale_color_manual(values = global_palette) +  # Match jitter points to boxplot fill
  scale_y_continuous(
    trans = pseudo_log_trans(sigma = 0.1),  # Pseudo log transformation
    breaks = c(0, 0.01, 0.1, 1),
    labels = c("0", "0.01", "0.1", "1")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Combine the two plots
combined_plot_high_var_plot <- high_variance_plot + non_high_variance_plot +
  plot_layout(ncol = 2, widths = c(1, 1)) &
  theme(
    plot.margin = margin(10, 10, 10, 10)
  )

# Display the combined plot
print(combined_plot_high_var_plot)
```

Save the high-variance plot
```{r}
# Saving manually from the 'Plots -> Export -> Save as image -> dimension (2000::800)'
```




####################################################################################################################################################

Heterogeneity Analysis
Compare the heterogeneity statistics between the meta-analyses conducted on the imputed and non-imputed datasets. This will help you understand if the imputation has influenced the heterogeneity of the studies.
####################################################################################################################################################

```{r}
# Prepare the original data
original_data_x <- non_imp_data_rom %>%
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
         silvo_sd_final, control_sd_final, 
         yi, vi) |> 
  mutate(data_source = "Original") |> 
  as.data.frame() 

imputed_data_y <- imp_data_rom |> 
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
          silvo_sd_final, control_sd_final, 
         yi, vi) |> 
  mutate(data_source = "Imputed") 

# Combine the original and imputed data
combined_data <- bind_rows(original_data_x, imputed_data_y)

# Join the original and imputed data to directly compare
comparison_data <- original_data_x %>%
  full_join(imputed_data_y, by = c("id_article", "exp_id", "id_obs", "response_variable"), 
            suffix = c("_original", "_imputed")) %>%
  distinct()

# Advarsel: Detected an unexpected many-to-many relationship between `x` and `y`.

comparison_data |> glimpse()
```

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################


# Fit random-effects models on both datasets
rma_non_imp <- rma(yi = yi_original, vi = vi_original, data = comparison_data)
rma_imp <- rma(yi = yi_imputed, vi = vi_imputed, data = comparison_data)

# Print heterogeneity statistics
cat("Non-Imputed Data - Heterogeneity (I^2):", rma_non_imp$I2, "\n")
cat("Non-Imputed Data - Between-study variance (tau^2):", rma_non_imp$tau2, "\n")

cat("Imputed Data - Heterogeneity (I^2):", rma_imp$I2, "\n")
cat("Imputed Data - Between-study variance (tau^2):", rma_imp$tau2, "\n")

##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
time.taken
##############################################################
# Last go (12/01-2025)
# Advarsel: 184 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.93201 
# Imputed Data - Between-study variance (tau^2): 0.01006262 
# Time difference of 3.647738 secs

# Last go (16/01-2025)
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 15.35531 
# Non-Imputed Data - Between-study variance (tau^2): 2.04823e-06 
# Imputed Data - Heterogeneity (I^2): 15.35531 
# Imputed Data - Between-study variance (tau^2): 2.04823e-06 
# Time difference of 0.9310322 secs

# Last go (24/01-2025)
# Advarsel: 181 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 19.85375 
# Non-Imputed Data - Between-study variance (tau^2): 2.782961e-06 
# Imputed Data - Heterogeneity (I^2): 99.99114 
# Imputed Data - Between-study variance (tau^2): 0.01757954 
# Time difference of 5.538544 secs
```
 
 
 
Kolmogorov-Smirnov Test
The Kolmogorov-Smirnov (KS) test can be used to compare the distributions of effect sizes.

```{r}
# Kolmogorov-Smirnov test
ks_test_result <- ks.test(non_imp_data_rom$yi, imp_data_rom$yi)
print(ks_test_result)

# Last go (12/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.032653, p-value = 0.6621
# alternative hypothesis: two-sided

# Last go (16/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.033209, p-value = 0.6425
# alternative hypothesis: two-sided

# Last go (24/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.031708, p-value = 0.6984
# alternative hypothesis: two-sided
```

The Kolmogorov-Smirnov (KS) test was performed to compare the distributions of effect sizes (ROM) between the non-imputed and imputed datasets. The test statistic (\(D = 0.0317\)) and its corresponding p-value (\(p = 0.6984\)) indicate no significant difference between the two distributions. This suggests that the imputed and non-imputed datasets share similar underlying distributions, and the null hypothesis of no difference cannot be rejected. While the warning about approximate p-values due to ties in the data highlights a potential limitation, the results strongly suggest that the imputation process preserved the original distributional characteristics of effect sizes.

However, significant differences are evident when considering metrics for heterogeneity and between-study variance. For the non-imputed dataset, heterogeneity was relatively low (\(I^2 = 19.85\%\)) with minimal between-study variance (\(\tau^2 = 2.78 \times 10^{-6}\)), reflecting limited variability among studies. Conversely, the imputed dataset exhibited exceptionally high heterogeneity (\(I^2 = 99.99\%\)) and substantially increased between-study variance (\(\tau^2 = 0.0176\)). These findings indicate that the imputation process introduced substantial variability into the dataset, altering its structure and potentially complicating meta-analytic interpretation.

The warnings regarding the extreme ratio of the largest to smallest sampling variances underscore potential instability in the meta-analytic models, particularly for the imputed dataset. This issue, common in meta-analyses involving imputed data, necessitates careful consideration, as it can impair the stability and reliability of meta-analytic results.

The KS test results confirm that the imputation process preserved the overall distribution of effect sizes. However, the sharp increase in heterogeneity and between-study variance in the imputed dataset raises concerns about the imputation’s impact on the dataset's internal structure. These changes could influence the reliability of conclusions drawn from the meta-analysis and warrant additional scrutiny.

To address these issues, it is essential to ensure transparency in reporting differences between the datasets, conduct sensitivity analyses to assess the robustness of results, and evaluate the influence of imputation on model stability. While the imputation preserved the original distributional characteristics of effect sizes, the substantial increase in variability underscores the importance of carefully interpreting results and mitigating the effects of imputation on meta-analytic findings.


 
```{r}
# Descriptive statistics for non-imputed data
summary_non_imp <- non_imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Descriptive statistics for imputed data
summary_imp <- imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Print summaries
summary_non_imp
summary_imp

# Last go (16/01-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02767394	0.003205885	0.2501374
# 
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.0237652	0.00181963	0.2388941	

# Last go (24/01-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02631194	0.003205885	0.2468501	
# 
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02328872	0.001916168	0.2360473
```
 
```{r}
# Density plot for non-imputed data
density_plot_non_imp <- ggplot(non_imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Density Plot: Non-Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Density plot for imputed data
density_plot_imp <- ggplot(imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Density Plot: Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Boxplot for non-imputed data
boxplot_non_imp <- ggplot(non_imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Boxplot: Non-Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Boxplot for imputed data
boxplot_imp <- ggplot(imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Boxplot: Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Arrange the plots in a 2x2 layout
(density_plot_non_imp | boxplot_non_imp) /
(density_plot_imp | boxplot_imp)

```


##########################################################################################################################################
ASSESSING CORRELATION BETWEEN RESPONSE VARIABLES
##########################################################################################################################################

```{r}
non_imp_data_rom |> glimpse()
imp_data_rom |> glimpse()
```

```{r}
##########################################################################
# Visual Diagnostics for Predictor Redundancy and Model Fit
##########################################################################

# Set up data
# Testing on the imputed dataset
moderators_data <- imp_data_rom %>%
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>%
  as.data.frame()

##########################################################################
# Fit a linear model with moderators
##########################################################################

lm_model <- lm(yi ~ tree_type + crop_type + age_system + season + soil_texture, 
               data = imp_data_rom)
```

```{r}
##########################################################################
# 1. Correlation Analysis
##########################################################################
# Convert categorical variables to numeric for correlation matrix
moderators_numeric <- model.matrix(~ . + 0, data = moderators_data) %>% as.data.frame()

# Calculate correlation matrix
cor_matrix <- cor(moderators_numeric, use = "pairwise.complete.obs")

# Visualize correlation matrix
corrplot::corrplot(cor_matrix, method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45, title = "Correlation Matrix of Moderators")
```

```{r}
##########################################################################
# 2. Variance Inflation Factor (VIF)
##########################################################################

# Calculate VIF for predictors
vif_values <- car::vif(lm_model)

# Print VIF values
print(vif_values)

# Plot VIF values
barplot(vif_values, main = "Variance Inflation Factors (VIF)",
        col = "blue", horiz = TRUE, las = 1, xlab = "VIF Value")
```

The Variance Inflation Factor (VIF) helps identify if predictors in a regression model are too similar or correlated with each other. When predictors are highly related, it can make it difficult to determine the individual impact of each predictor, as their effects overlap. VIF measures how much the variance of a predictor's coefficient is inflated due to this overlap.

For categorical variables with multiple levels, the Generalized VIF (GVIF) is used. GVIF adjusts for the number of levels in a categorical variable, providing a way to compare them with other predictors. A scaled version of GVIF helps interpret these adjusted values more easily.

In this analysis, the predictors all have low VIF values. The largest adjusted GVIF is 1.17 for soil texture, which is far below the commonly used thresholds of 5 or 10 for concern. This indicates there is no significant multicollinearity among the predictors, meaning they are not overly correlated with one another.

Since none of the predictors exhibit high VIF values, no corrective actions are needed, such as removing variables or combining them into fewer components. The predictors are providing independent and valuable information to the model, and the results can be interpreted without concerns about redundancy or instability.

In summary, the VIF analysis confirms that the model's predictors are sufficiently independent and do not cause issues with multicollinearity. This ensures the model's results are clear, reliable, and interpretable.






```{r}
# Convert categorical variables to factors (if not already factors)
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor))

# Create dummy variables for categorical predictors
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%  # -1 to exclude the intercept
  as.data.frame()

# Calculate pairwise correlations
correlation_matrix <- cor(predictors_numeric, use = "pairwise.complete.obs")

# Visualize the correlation matrix
corrplot::corrplot(correlation_matrix, method = "circle")

# Visualize correlations with a heatmap
heatmap(correlation_matrix, symm = TRUE)

# PCA
pca_results <- prcomp(predictors_numeric, scale. = TRUE)
summary(pca_results)
biplot(pca_results)
```

```{r}
# Convert categorical variables to factors and create dummy variables
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor))

# Create numeric predictors with dummy variables
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%
  as.data.frame()

# Ensure the response is aligned with predictors
# Keep only rows where both predictors and response are not missing
aligned_data <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width, yi) %>%
  drop_na()

# Split aligned data into predictors and response
predictors_numeric <- model.matrix(~ . - 1, data = aligned_data %>% 
                                     select(-yi)) %>% 
  as.data.frame()


response_filled <- aligned_data$yi

# Fit the Random Forest model
library(randomForest)
rf_model <- randomForest(x = predictors_numeric, y = response_filled, importance = TRUE)

# Display feature importance
varImpPlot(rf_model)
```

The results from the random forest analysis and the correlation matrix provide insight into how the predictors (tree type, crop type, age system, season, and soil texture) influence the variability in your dataset and how they relate to each other.

The random forest model was employed to evaluate the relative importance of variables considered as moderators in the meta-regression model (`rma.mv`). Random forest is particularly suitable for this purpose due to its ability to handle complex interactions and non-linear relationships between predictors, making it an effective tool for identifying which moderators most strongly influence the response variable. The model assessed the importance of these moderators using two key metrics: the percentage increase in mean squared error (%IncMSE) and increase in node purity (IncNodePurity). These metrics reflect how much each moderator improves the model's predictive power and reduces uncertainty.

###############################################

The results highlight tree age and experiment year as the most influential moderators. These variables significantly impact both %IncMSE and IncNodePurity, indicating their critical role in explaining variations in the response variable within the meta-analytic framework. Their importance suggests that temporal factors, such as the age of the tree systems and the year of the experiments, are vital in shaping the observed outcomes across studies.

Moderators related to soil texture, such as sand and silt, were also identified as moderately important, reflecting the role of soil properties in influencing the outcomes under study. Tree type and crop type, including specific categories like "Fruit, nut & other" and "Legume," were somewhat less influential but still contributed meaningfully to explaining variability in the response. Their inclusion underscores the importance of agroforestry and crop-specific characteristics as moderators in the meta-regression.

Variables like alley width and certain crop or tree types, such as tuber/root crops and timber trees, showed relatively lower importance. This indicates that their moderating effects are less pronounced in this context, suggesting they may not need to be prioritized in the meta-regression model.

The random forest results emphasize the hierarchy of moderator importance, with tree age and experiment year standing out as dominant predictors. This refined understanding can improve the meta-regression model by focusing on the most impactful moderators, simplifying the model structure while maintaining its explanatory and predictive power.

###########################################

The correlation matrix reveals the relationships between predictors. Strong correlations (shown as larger, darker circles) suggest that some predictors may overlap in the information they provide. For example, if "tree type" and "crop type" have a high positive or negative correlation, this could mean they are not entirely independent, potentially leading to redundancy in the model. This aligns with earlier findings of multicollinearity, where predictors interfere with each other.

From the PCA results, the first three principal components (PC1, PC2, and PC3) explain approximately 79% of the variance in the data. This means most of the variation in your dataset can be summarized using fewer dimensions, reducing complexity while retaining the critical patterns. The decreasing proportion of variance explained by PC4 and PC5 suggests these components add less unique information.

Overall, while "tree type" and "crop type" seem to be the most influential predictors, their high correlation with other variables might complicate the interpretation. You should consider techniques like feature selection, dimensionality reduction, or removing redundant variables to improve model clarity and performance.


###########################################


The results of the random forest analysis reveal important limitations and implications for reporting and communicating overall meta-analysis findings. By identifying tree age and experiment year as the dominant moderators, the analysis highlights a key limitation of heterogeneity within the dataset. This underscores the challenge of attributing outcomes to specific factors when a few moderators exert disproportionate influence. Such dominance may mask the contributions of less impactful moderators and complicate the interpretation of their individual roles in the meta-analysis.

One limitation lies in the reliance on moderators that capture temporal or environmental variability, such as experiment year or soil texture. These factors, while essential, may vary considerably across studies, making it difficult to disentangle their effects from study-specific conditions. Additionally, the relatively lower importance of certain moderators, such as alley width or specific tree and crop types, raises questions about whether these variables are consistently measured or reported across studies. Inconsistent data collection or reporting practices may contribute to their diminished influence, emphasizing the importance of standardized reporting in future studies.

Communicating the meta-analysis results requires careful consideration of these limitations. Overemphasis on the dominant moderators, such as tree age, may oversimplify the nuanced interactions present in agroforestry systems. Researchers and stakeholders must be cautious not to generalize findings without acknowledging the variability that less prominent moderators can introduce. This is particularly relevant when translating findings into practical recommendations, as the applicability of results to diverse settings may be constrained.

The findings also highlight the need for transparency when reporting results. Explicitly addressing the hierarchical importance of moderators, as identified by the random forest analysis, can help contextualize the results and guide readers in understanding the limitations of the analysis. Clear communication about the variability and potential biases introduced by dominant moderators is essential for ensuring that the conclusions of the meta-analysis are interpreted appropriately and applied responsibly in decision-making contexts.

###########################################


```{r}
# Prepare the data
# Convert categorical variables to factors
imp_data_rom <- imp_data_rom %>%
  mutate(across(where(is.character), as.factor))

# Define the predictors and response
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width)


response <- imp_data_rom$yi

# Combine predictors and response into a single dataset
complete_data <- cbind(predictors, response = response) %>%
  na.omit() # Remove rows with missing values to ensure compatibility


# complete_data |> str()
# 'data.frame':	808 obs. of  7 variables:
#  $ tree_age       : num  2 2 2 9 9 9 9 8 8 8 ...
#  $ crop_type      : Factor w/ 3 levels "Cereal","Legume",..: 1 1 1 1 1 1 1 1 1 1 ...
#  $ tree_type      : Factor w/ 3 levels "Biomass","Fruit,nut & other",..: 2 2 2 2 2 2 2 1 1 1 ...
#  $ soil_texture   : Factor w/ 3 levels "Clay","Sand",..: 1 1 1 1 1 1 1 3 3 3 ...
#  $ experiment_year: Date, format: "2011-01-01" "2011-01-01" "2011-01-01" "2011-01-01" ...
#  $ alley_width    : Factor w/ 2 levels "Narrow","Wide": 2 2 2 2 2 2 2 2 2 2 ...
#  $ response       : num  0.633 0.199 0.771 0.137 0.182 ...
#  - attr(*, "na.action")= 'omit' Named int [1:290] 329 330 331 332 333 334 335 336 337 338 ...
#   ..- attr(*, "names")= chr [1:290] "329" "330" "331" "332" ...

# Tidymodels Random Forest Workflow

# Step 1: Create a recipe for preprocessing
rf_recipe <- recipe(response ~ ., data = complete_data) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%  # Convert categorical predictors to dummies
  step_normalize(all_numeric_predictors())       # Normalize numeric predictors

# Step 2: Specify the Random Forest model
rf_spec <- rand_forest(
  mode = "regression",
  mtry = tune(),         # Number of predictors sampled at each split
  trees = 500,           # Number of trees
  min_n = tune()         # Minimum samples per node
) %>%
  set_engine("ranger", importance = "permutation")  # Use permutation importance

# Step 3: Define a workflow
rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_spec)

# Step 4: Create cross-validation folds
set.seed(123)

cv_splits <- vfold_cv(complete_data, v = 5)

# Step 5: Tune the model
rf_res <- tune_grid(
  rf_workflow,
  resamples = cv_splits,
  grid = 10,  # Number of parameter combinations to try
  metrics = metric_set(rmse, rsq)  # Evaluation metrics
)

# Step 6: Finalize the model with the best parameters
# Finalize the model with the best parameters
best_rf <- finalize_workflow(
  rf_workflow,
  select_best(rf_res, metric = "rmse") # Explicitly name the argument 'metric'
)

# Step 7: Fit the finalized model
final_rf_fit <- fit(best_rf, data = complete_data)

# Step 8: Compute and visualize variable importance
# Extract the fitted model
rf_final_model <- final_rf_fit %>% extract_fit_parsnip()

# Visualize Variable Importance
vip(rf_final_model) +
  ggtitle("Variable Importance from Random Forest Model") +
  theme_minimal()

```

##########################################################################
# 3. Stepwise Regression
##########################################################################

Stepwise regression iteratively adds or removes predictors from a model to optimize the Akaike Information Criterion (AIC), balancing goodness-of-fit with model complexity. Starting with an initial model, predictors are evaluated through forward selection (adding predictors) and backward elimination (removing predictors). This process identifies the most relevant variables while discarding redundant or insignificant ones, improving model interpretability and predictive performance. It mitigates multicollinearity and avoids overfitting by ensuring parsimony. However, results should be interpreted cautiously, as stepwise methods may exclude theoretically important predictors.

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################

# Set up data (imputed dataset)
moderators_data <- imp_data_rom %>%
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>%
  as.data.frame()

##########################################################################
# Fit a linear model with moderators
lm_model <- lm(yi ~ tree_type + crop_type + age_system + season + soil_texture, 
               data = imp_data_rom)

##########################################################################
# Stepwise regression using AIC
stepwise_model <- step(lm_model, direction = "both", trace = TRUE)

# Summary of the stepwise regression model
summary(stepwise_model)



##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
time.taken
##############################################################
# Last go (24/01-2025)
# Start:  AIC=-3165.5
# yi ~ tree_type + crop_type + age_system + season + soil_texture
# 
#                Df Sum of Sq    RSS     AIC
# <none>                      56.760 -3165.5
# - soil_texture  2   0.35747 57.118 -3162.7
# - tree_type     2   0.36934 57.129 -3162.5
# - season        1   0.33810 57.098 -3161.1
# - age_system    2   0.49991 57.260 -3160.0
# - crop_type     2   0.79088 57.551 -3154.5
# 
# Call:
# lm(formula = yi ~ tree_type + crop_type + age_system + season + 
#     soil_texture, data = imp_data_rom)
# 
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -1.44664 -0.06225 -0.00045  0.05106  2.72286 
# 
# Coefficients:
#                                 Estimate Std. Error t value Pr(>|t|)    
# (Intercept)                    0.0327965  0.0245682   1.335 0.182186    
# tree_typeFruit,nut & other     0.0001449  0.0180118   0.008 0.993583    
# tree_typeTimber               -0.0477382  0.0195547  -2.441 0.014797 *  
# crop_typeLegume                0.0653241  0.0197544   3.307 0.000975 ***
# crop_typeTuber,root and other -0.0482183  0.0325947  -1.479 0.139347    
# age_systemMedium              -0.0061044  0.0180220  -0.339 0.734887    
# age_systemYoung                0.0521375  0.0203419   2.563 0.010511 *  
# seasonWinter                  -0.0477622  0.0189099  -2.526 0.011687 *  
# soil_textureSand               0.0046211  0.0193535   0.239 0.811329    
# soil_textureSilt              -0.0435694  0.0215358  -2.023 0.043309 *  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.2302 on 1071 degrees of freedom
#   (14 observations deleted due to missingness)
# Multiple R-squared:  0.06863,	Adjusted R-squared:  0.06081 
# F-statistic: 8.769 on 9 and 1071 DF,  p-value: 8.363e-13
# 
# Time difference of 0.2677081 secs
```

The stepwise regression analysis evaluated the impact of moderators (tree type, crop type, age system, season, and soil texture) on the response variable (\(yi\)). The final model retained all predictors, as their removal increased the AIC from its optimal value (-3165.5), confirming that each variable contributed meaningfully to explaining variations in the response variable.

### **Moderator Effects:**
- **Tree Type:**
  - Timber trees significantly reduced the response variable (\(p = 0.015\)), emphasizing their unique role compared to the reference group.
  - "Fruit, nut, and other" trees showed no significant effect (\(p = 0.994\)), indicating minimal influence.

- **Crop Type:**
  - Legumes were positively and significantly associated with the response variable (\(p < 0.001\)), highlighting their potential benefits.
  - Tuber, root, and other crops had no significant effect (\(p = 0.139\)).

- **Age System:**
  - Young systems had a significant positive effect (\(p = 0.011\)), suggesting greater benefits during early stages of system development.
  - Medium-aged systems showed no significant impact (\(p = 0.735\)).

- **Season:**
  - Winter significantly decreased the response variable (\(p = 0.012\)), reflecting clear seasonal differences.

- **Soil Texture:**
  - Silt had a significant negative effect (\(p = 0.043\)), indicating possible context-dependent influences.
  - Sand showed no significant effect (\(p = 0.811\)).

### **Model Performance:**
The model explained 6.9% of the variance in the response variable (\(R^2 = 0.0686\)), indicating that the included moderators contribute meaningfully but still leave most variability unexplained. The adjusted \(R^2\) was slightly lower (\(R^2_{adj} = 0.0608\)), reflecting a modest fit. The overall model was statistically significant (\(F(9, 1071) = 8.77\), \(p < 0.001\)), underscoring the collective influence of the predictors on the response variable. The residual standard error was 0.230, showing the degree of variation not captured by the model.

### **Implications for Meta-Analysis:**
The results identify key moderators—tree type, crop type, age system, season, and soil texture—as influential in explaining variations in the response variable. Specifically:
- **Legumes** and **young systems** showed consistent positive effects, suggesting management practices promoting these features could enhance outcomes.
- **Timber trees**, **winter seasons**, and **silt soils** were associated with reductions in the response variable, indicating areas requiring further investigation or context-specific management strategies.

Despite the significance of these moderators, the relatively low \(R^2\) suggests that additional factors, unmeasured moderators, or interactions may play a significant role. This underscores the need for further exploration of potential nonlinear relationships, interactions, and additional variables to better understand the complexity of the dataset.

### **Conclusion:**
The analysis highlights the importance of specific moderators while revealing the need to refine the model to account for unexplained variability. These findings provide valuable insights for meta-analyses and suggest future efforts should focus on identifying additional drivers and incorporating interaction effects to enhance model explanatory power.


##########################################################################
# 4. Principal Component Analysis (PCA)
##########################################################################

```{r}
# Perform PCA on the numeric moderator data
pca_results <- prcomp(moderators_numeric, scale. = TRUE)

pca_results |> str()

screeplot(pca_results, type = "lines", main = "Scree Plot for PCA")

# Calculate proportion of variance explained
explained_variance <- (pca_results$sdev^2) / sum(pca_results$sdev^2)

# Create a scree plot
plot(explained_variance, type = "b", pch = 19, col = "blue",
     xlab = "Principal Components", ylab = "Proportion of Variance Explained",
     main = "Scree Plot for PCA")

barplot(explained_variance, names.arg = paste0("PC", 1:length(explained_variance)),
        col = "skyblue", xlab = "Principal Components", ylab = "Proportion of Variance",
        main = "Variance Explained by Principal Components")

# Biplot of the first two components
biplot(pca_results, scale = 0, main = "PCA Biplot")
```

##########################################################################
# 5. Cross-Validation
##########################################################################

```{r}
# Define predictors and response
predictors <- imp_data_rom %>% 
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>% # Convert to factors first
  mutate(across(everything(), as.numeric))   # Convert to numeric
response <- imp_data_rom$yi

# Check the structure of predictors
str(predictors)

# Remove rows with missing values in predictors or response
complete_cases <- complete.cases(predictors, response)
predictors <- predictors[complete_cases, ]
response <- response[complete_cases]

# Create a train/test split
set.seed(123)
train_index <- caret::createDataPartition(response, p = 0.8, list = FALSE)
train_data <- predictors[train_index, ]
train_response <- response[train_index]
test_data <- predictors[-train_index, ]
test_response <- response[-train_index]

# Ensure training data has no missing values
if (anyNA(train_data) || anyNA(train_response)) {
  stop("Training data contains missing values. Please clean your data.")
}

# Train a linear model with cross-validation
cv_model <- caret::train(
  x = train_data, 
  y = train_response, 
  method = "lm", 
  trControl = caret::trainControl(method = "cv", number = 10)
)

# Evaluate on test set
predictions <- predict(cv_model, newdata = test_data)
results <- caret::postResample(predictions, test_response)

# Print cross-validation results
print(cv_model)
print("Performance on test data:")
print(results)

# Last go (24/01-2025)
# 'data.frame':	1095 obs. of  5 variables:
#  $ tree_type   : num  2 2 2 2 2 2 2 1 1 1 ...
#  $ crop_type   : num  1 1 1 1 1 1 1 1 1 1 ...
#  $ age_system  : num  3 3 3 2 2 2 2 2 2 2 ...
#  $ season      : num  1 1 1 1 1 1 1 2 2 2 ...
#  $ soil_texture: num  1 1 1 1 1 1 1 3 3 3 ...
#  - attr(*, "digits")= Named num [1:9] 4 4 4 4 4 4 4 4 4
#   ..- attr(*, "names")= chr [1:9] "est" "se" "test" "pval" ...
#  - attr(*, "yi.names")= chr "yi"
#  - attr(*, "vi.names")= chr "vi"
# Linear Regression 
# 
# 865 samples
#   5 predictor
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 778, 779, 778, 779, 779, 777, ... 
# Resampling results:
# 
#   RMSE       Rsquared    MAE      
#   0.2274347  0.03785515  0.1181042
# 
# Tuning parameter 'intercept' was held constant at a value of TRUE
# [1] "Performance on test data:"
#       RMSE   Rsquared        MAE 
# 0.19616264 0.04730264 0.12006283 
```


The cross-validation analysis assessed the predictive performance of selected meta-analysis moderators—tree type, crop type, age system, season, and soil texture—on the variability of the response variable (\(yi\)). Using a dataset of 1,095 observations with numerically encoded categorical moderators, linear regression was performed with a split of 80% for training and 20% for testing. A 10-fold cross-validation approach was applied to evaluate model performance.

During cross-validation, the model achieved a Root Mean Square Error (RMSE) of 0.2274, a Mean Absolute Error (MAE) of 0.1181, and an \(R^2\) of 0.0379, indicating small prediction errors but limited explanatory power, with the moderators accounting for only 3.8% of the variability in \(yi\). On the test set, the model yielded consistent results, with an RMSE of 0.1962, an MAE of 0.1201, and an \(R^2\) of 0.0473. The stable RMSE across datasets suggests no overfitting; however, the low \(R^2\) highlights the limited ability of the predictors to explain the variability in the response variable.

These results indicate that while the selected moderators contribute to predicting \(yi\), their collective explanatory power is minimal. The findings suggest that additional moderators, interaction effects, or non-linear relationships may need to be explored to better capture the complexity of the data. Advanced modeling approaches, such as mixed-effects models or machine learning techniques, could also help improve predictive performance.

In conclusion, the analysis demonstrates the importance of the selected moderators but also reveals their limitations in explaining the response variable. Future efforts should focus on expanding the scope of potential predictors and refining the model to account for the substantial unexplained variability.


#############
# STEP 8
##########################################################################################################################################
SAVING FINAL PREPROCESSED META-DATASETS (IMPUTED AND NON-IMPUTED) - THESE ARE USED FOR RMA.MV() MODELLING
##########################################################################################################################################


Saving the datasets that is used for the rma.mv() modelling

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as RDS files

## NON-IMPUTED
saveRDS(non_imp_data_rom,
        file = here::here(output_dir, "non_imp_data_rom.rds"))

## IMPUTED
saveRDS(imp_data_rom,
        file = here::here(output_dir, "imp_data_rom.rds"))



# Confirmation message
cat("Files saved successfully to:", output_dir, "\n")
```

git fetch origin
git pull origin main
git push origin HEAD:refs/heads/main --force

