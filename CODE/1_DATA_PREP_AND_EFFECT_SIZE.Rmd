---
title: "1_DATA_PREP"
author: "M.K.K. Lindhardt"
date: "2024-11-14"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    ###################################################################################################################
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science (data wrangling, visualization, etc.)
    readr,            # For fast reading and writing of CSV files
    dlookr,           # Diagnose, explore, and transform data efficiently
    skimr,            # Summary statistics for data frames, tibbles, and vectors
    janitor,          # Cleaning and renaming data columns for tidy data
    readxl,           # Reading Excel files
    vroom,            # High-performance reading of large datasets
    missForest,       # Random forest imputation for missing data
    mice,             # Multiple imputation for multivariate missing data
    missRanger,       # Chained random forest imputation for large datasets
    conflicted,       # Resolves conflicts in function names across packages
    future,           # Enables parallel processing for faster computation
    future.apply,     # Apply functions in parallel over lists or arrays
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization (part of tidyverse)
    patchwork,        # Combine and arrange ggplots in complex layouts
    RColorBrewer,     # Color palettes for visualizations
    gt,               # Generate stylish publication-ready tables
    corrplot,         # Correlation matrix visualization
    scales,           # Generate pseudo-log scale plots and other scaling options
    forcats,          # For working with and reordering factors
    ggrepel,          # Add text directly to a ggplot
    ###################################################################################################################
    # Spatial Data Analysis
    tidygeocoder,     # Unified geocoding interface for forward and reverse geocoding
    raster,           # Handle raster data and analyze spatial layers
    sp,               # Provides spatial data classes and methods
    sf,               # Simple feature handling for vector data
    rnaturalearth,    # Access world map data for visualization
    rnaturalearthdata, # Supporting data for rnaturalearth
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # Conduct meta-analyses and calculate effect sizes
    clubSandwich,     # Cluster-robust variance estimators for linear regression
    philentropy,      # Compute Jensen-Shannon Divergence and other divergence measures
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # Streamline exploratory data analysis
    SmartEDA,         # Automated exploratory data analysis
    inspectdf,        # Inspect data frames for structure and quality
    naniar,           # Explore and visualize missing data patterns
    VIM,              # Visualize and impute missing values
    corrplot,         # Visualize correlations between variables
    ###################################################################################################################
    # Machine Learning and Modeling (Tidymodels Framework)
    tidymodels,       # Unified framework for machine learning and modeling
    vip,              # Visualize variable importance from models
    caret,            # Train machine learning models with cross-validation
    randomForest,     # Train random forest models and evaluate variable importance
    recipes,          # Preprocessing data for machine learning
    ranger,           # High-performance random forests
    yardstick,        # Metrics for model performance evaluation
    tune,             # Hyperparameter tuning for machine learning models
    rsample,          # Generate resamples and cross-validation folds
    workflows,        # Combine recipes and models into workflows
    parsnip,          # Define machine learning models
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy and robust file referencing
    styler            # Automatically format and style R code
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("col_factor", "scales")
conflict_prefer("geocode", "tidygeocoder")
conflict_prefer("chisq.test", "stats")
conflict_prefer("step", "stats")
conflict_prefer("margin", "ggplot2")
```
```{r}
# Set a global theme and color scale
# Define the global color palette
global_palette <- c(
  "#ffd700", 
  "#ffb14e", 
  "#fa8775", 
  "#ea5f94", 
  "#cd34b5", 
  "#9d02d7", 
  "#0000ff"
)


custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)

# Define global ggplot2 scales for color and fill
scale_fill_global <- scale_fill_viridis_d(option = "D")  # Discrete
scale_color_global <- scale_color_viridis_d(option = "D")  # Discrete

scale_fill_global <- scale_fill_viridis_c(option = "D")  # Continuous
scale_color_global <- scale_color_viridis_c(option = "D")  # Continuous
```


Loading the dataset (main metadata database)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({
  # Final database as 'meta-data'
  # Manually modifying the SD columns to "control_sd" and "silvo_sd" in Excel!
  # Also adding these columns manually: 
  # silvo_var (variance as either _se or _sd), 
  # silvo_se	(standard error),
  # silvo_sd	(standard deviation),
  # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
  # control_var (variance as either _se or _sd), 
  # control_se (standard error),
  # control_sd (standard deviation),
  # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),

  database <- readxl::read_excel(
    here("DATA", "Meta_data_v5.xlsx"), 
    sheet = "Quantatitive data"
  )
  
  # Dummy data where silvo_mean has been multiplied with 1.2 to check for larger effect size estimates
  # database_dummy <- readxl::read_excel(
  #   here("DATA", "Meta_data_dummy_test_high_silvo_mean_se.xlsx"), 
  #   sheet = "Quantatitive data"
  # )
    
})


```

**Glimpse (taking a look at the data)**
```{r Glimpse the dataset, eval=FALSE}
database %>% dplyr::glimpse() 

# Rows: 1,075
# Columns: 35
# Rows: 1,126
# Columns: 35
```

```{r}
database %>% summary() 
```

```{r}
database |> skim()
```


#############
# STEP 1
##########################################################################################################################################
DATA PREPROCESSING
##########################################################################################################################################

####################################
GENERIC PREPROCESSING
####################################

And in step 4, generate unique study identifier ('exp_id')

```{r}
# Function to safely convert to numeric, replacing non-numeric values with NA
safe_as_numeric <- function(x) {
  suppressWarnings(as.numeric(x))
}

# Data Preprocessing
database_clean <- database |>
  # Step 1: Clean column names
  janitor::clean_names() |>
  
  # Step 2: Convert id_article and id_obs to integer
  mutate(
    id_article = as.integer(id_article),
    id_obs = as.integer(id_obs)
  ) |>
  
  # Step 3: Convert standard errors and other numeric columns
            # silvo_var (variance as either _se or _sd), 
            # silvo_se	(standard error),
            # silvo_sd	(standard deviation),
            # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
            # control_var (variance as either _se or _sd), 
            # control_se (standard error),
            # control_sd (standard deviation),
            # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),
  mutate(
    silvo_mean = safe_as_numeric(silvo_mean),
    silvo_se = safe_as_numeric(silvo_se),
    silvo_sd = safe_as_numeric(silvo_sd),
    silvo_n = safe_as_numeric(silvo_n),
    control_mean = safe_as_numeric(control_mean),
    control_se = safe_as_numeric(control_se),
    control_sd = safe_as_numeric(control_sd),
    control_n = safe_as_numeric(control_n),
    tree_age = safe_as_numeric(tree_age),
    no_tree_per_m = as.character(no_tree_per_m)) |> 
  
  # Step 4: Create Identifiers (Experiment, Treatment, Common Control)
  # Group data by relevant columns for Treatment ID
  group_by(id_article, tree_type, crop_type, location, experiment_year) |>
  mutate(treat_id = cur_group_id()) |>
  ungroup() |>
  
  # Group data by relevant columns for Experiment ID
  # The exp_id variable is created as a unique identifier for experiments, 
  # based on grouping by: id_article (the article ID), location (the geographical location of the experiment), and 
  # the experiment_year (the year the experiment was conducted)
  group_by(id_article, location, experiment_year) |>
  mutate(exp_id = cur_group_id()) |>
  ungroup() |> 
  
  # Step 5: Ensure no infinite or NaN values are present in any columns
  mutate(across(everything(), ~ifelse(is.infinite(.) | is.nan(.), NA, .))
         ) |> 
  
  # Step 6: Convert "NA" strings to real NA values, excluding 'id_article' and 'id_obs'
  mutate(
    across(
      .cols = where(is.character) & !c("id_article", "id_obs"),
      .fns = ~ na_if(., "NA")
    )
  ) |>
  
  # Step 7: Convert year columns to date format
 # Convert to proper Date format using "YYYY-01-01"
 mutate(
    experiment_year = as.Date(paste0(experiment_year, "-01-01")),
    year_est_exp = as.Date(paste0(year_est_exp, "-01-01")),
    #study_year_start = as.Date(paste0(study_year_start, "-01-01")),
    #study_year_end = as.Date(paste0(study_year_end, "-01-01"))
  ) |> 
  # Step 8: Rename Latitude and Longitude to lat and lon
  rename(
    lat = latitude,
    lon = longitude
  ) |>
  
  # Step 9: Convert lat and lon to numeric coordinates
  mutate(
    lat = str_replace_all(lat, "[°NS]", "") |> safe_as_numeric(),
    lon = str_replace_all(lon, "[°EW]", "") |> safe_as_numeric(),
    lat = if_else(str_detect(lat, "S$"), -lat, lat),
    lon = if_else(str_detect(lon, "W$"), -lon, lon)
  ) |>
  
  # Step 10: Create a Coherent 'site_x' Column
  mutate(
    # If `lat` and `lon` are present, use them; otherwise, use the `location` name
    site_x = case_when(
      !is.na(lat) & !is.na(lon) ~ paste(lat, lon, sep = ", "),
      !is.na(location) ~ location,
      TRUE ~ NA_character_
    )
  ) 
```



```{r}
database_clean |> filter(id_article == 10)
```

####################################
GEOSPATIAL PREPROCESSING
####################################

In the Excel meta-data file, I am manually changing 'France (south west)' to 'France' and 'South East England(Cambridgeshire)' to 'Cambridgeshire, England' and 
'Bramham in northern England' to 'Bramham, England'

```{r}
# Step 1: Extract Coordinates from `site_x` if available
database_clean <- database_clean |>
  mutate(
    # Extract latitude: Matches integers or decimals before a comma
    extracted_lat = str_extract(site_x, "[-]?\\d+(\\.\\d+)?(?=, )"),
    # Extract longitude: Matches integers or decimals after a comma and space
    extracted_lon = str_extract(site_x, "(?<=, )[-]?\\d+(\\.\\d+)?")
  ) |>
  mutate(
    # Convert extracted values to numeric
    extracted_lat = as.numeric(extracted_lat),
    extracted_lon = as.numeric(extracted_lon),
    # Use extracted coordinates directly as final coordinates
    final_lat = extracted_lat,
    final_lon = extracted_lon,
    # Create the `exp_site_loc` column with final coordinates
    exp_site_loc = if_else(!is.na(final_lat) & !is.na(final_lon),
                           paste(final_lat, final_lon, sep = ", "),
                           NA_character_)
  ) |>
  # Remove intermediate columns
  select(-extracted_lat, -extracted_lon) |>
  
  # Step 2: Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n
  )
```

Checking if any missing values in coordinates

```{r}
# Filter rows where either final_lat or final_lon is missing
missing_coordinates <- database_clean |>
  filter(is.na(final_lat) | is.na(final_lon))

# View the rows with missing coordinates
missing_coordinates

# No missing coordinates
# 0 rows | 1-10 of 39 columns
```


Add geographical sub-regions to the dataset

```{r}
# Load Köppen-Geiger Climate Data (as a raster file)
kg_climate <- raster(here("DATA", "koppen_geiger_tif", "1991_2020", "koppen_geiger_0p1.tif"))


# Preserve final_lat and final_lon before conversion
database_clean <- database_clean |> 
  mutate(
    preserved_lat = final_lat,
    preserved_lon = final_lon
  )

# Convert your dataset to an sf object using preserved lat/lon columns
database_clean_sf <- database_clean |>
  drop_na(preserved_lat, preserved_lon) |>
  st_as_sf(coords = c("preserved_lon", "preserved_lat"), crs = 4326)

# Extract climate zone for each observation using spatial overlay
# Beck, H.E., T.R. McVicar, N. Vergopolan, A. Berg, N.J. Lutsko, A. Dufour, Z. Zeng, X. Jiang, A.I.J.M. van Dijk, D.G. MirallesHigh-resolution (1 km) Köppen-Geiger maps for 1901–2099 based on constrained CMIP6 projectionsScientific Data 10, 724, doi:10.1038/s41597-023–02549‑6 (2023)
# The variable 'climate_zone' represents the climate classification code assigned to each data point based on its geographical coordinates (latitude and longitude) from the Köppen-Geiger map. The climate_zone information was extracted using a spatial overlay.
database_clean_sf <- database_clean_sf |>
  mutate(
    climate_zone = extract(kg_climate, st_coordinates(database_clean_sf))
  )

# Classify sub-regions based on the climate zone
# Refine classifications for temperate climates and assign broader regions for others
database_clean_sf <- database_clean_sf %>%
  mutate(
    # Assign specific Köppen-Geiger classifications to climate zones
    climate_zone = case_when(
      climate_zone == 1 ~ "Tropical, rainforest",
      climate_zone == 2 ~ "Tropical, monsoon",
      climate_zone == 3 ~ "Tropical, savannah",
      climate_zone == 4 ~ "Arid, desert, hot",
      climate_zone == 5 ~ "Arid, desert, cold",
      climate_zone == 6 ~ "Arid, steppe, hot",
      climate_zone == 7 ~ "Arid, steppe, cold",
      climate_zone == 8 ~ "Temperate, dry summer, hot summer",
      climate_zone == 9 ~ "Temperate, dry summer, warm summer",
      climate_zone == 10 ~ "Temperate, dry summer, cold summer",
      climate_zone == 11 ~ "Temperate, dry winter, hot summer",
      climate_zone == 12 ~ "Temperate, dry winter, warm summer",
      climate_zone == 13 ~ "Temperate, dry winter, cold summer",
      climate_zone == 14 ~ "Temperate, no dry season, hot summer",
      climate_zone == 15 ~ "Temperate, no dry season, warm summer",
      climate_zone == 16 ~ "Temperate, no dry season, cold summer",
      climate_zone == 17 ~ "Cold, dry summer, hot summer",
      climate_zone == 18 ~ "Cold, dry summer, warm summer",
      climate_zone == 19 ~ "Cold dry summer, cold summer",
      climate_zone == 20 ~ "Cold dry summer, very cold winter",
      climate_zone == 21 ~ "Cold, dry winter, hot summer",
      climate_zone == 22 ~ "Cold, dry winter, warm summer",
      climate_zone == 23 ~ "Cold, dry winter, cold summer",
      climate_zone == 24 ~ "Cold, dry winter, very cold winter",
      climate_zone == 25 ~ "Cold, no dry season, hot summer",
      climate_zone == 26 ~ "Cold, no dry season, warm summer",
      climate_zone == 27 ~ "Cold, no dry season, cold summer",
      climate_zone == 28 ~ "Cold, no dry season, very cold winter",
      climate_zone == 29 ~ "Polar, tundra",
      climate_zone == 30 ~ "Polar, frost",
      TRUE ~ "Unclassified"
    ),
    
    # Assign refined geographical regions
    bioclim_sub_regions = case_when(
      # Tropical climates
      climate_zone %in% c(
        "Tropical, rainforest", "Tropical, monsoon", "Tropical, savannah"
      ) ~ "Tropical Climates",
      
      # Arid climates
      climate_zone %in% c(
        "Arid, desert, hot", "Arid, desert, cold", "Arid, steppe, hot", "Arid, steppe, cold"
      ) ~ "Arid Climates",
      
      # Refined temperate climates
      climate_zone %in% c(
        "Temperate, dry summer, hot summer", "Temperate, dry summer, warm summer", 
        "Temperate, dry winter, hot summer", "Temperate, dry winter, warm summer"
      ) ~ "Dry and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, hot summer", "Temperate, no dry season, warm summer"
      ) ~ "Wet and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, dry summer, cold summer", "Temperate, dry winter, cold summer"
      ) ~ "Dry and Cold Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, cold summer"
      ) ~ "Wet and Cold Temperate",
      
      # Cold climates
      climate_zone %in% c(
        "Cold, dry summer, hot summer", "Cold, dry summer, warm summer", 
        "Cold dry summer, cold summer", "Cold dry summer, very cold winter", 
        "Cold, dry winter, hot summer", "Cold, dry winter, warm summer", 
        "Cold, dry winter, cold summer", "Cold, dry winter, very cold winter",
        "Cold, no dry season, hot summer", "Cold, no dry season, warm summer", 
        "Cold, no dry season, cold summer", "Cold, no dry season, very cold winter"
      ) ~ "Cold Climates",
      
      # Polar climates
      climate_zone %in% c(
        "Polar, tundra", "Polar, frost"
      ) ~ "Polar Climates",
      
      TRUE ~ "Unclassified"
    )
  )
```


Checking for unclassified in climate_zone and bioclim_sub_regions or if any observations have odd classes e.g. 'Tropical Climates'

```{r}
# Check classification coverage
database_clean_sf %>%
  filter(climate_zone == "Unclassified" | bioclim_sub_regions == "Unclassified") %>%
  head()

# Check classification of BioClim that is classified as 'Tropical'
database_clean_sf %>%
  filter(bioclim_sub_regions == "Tropical Climates") 
```





```{r}
# Rename back to 'database_clean'

# Relocate columns to the desired order
database_clean <- database_clean_sf |>
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n
  )

# Preview the resulting data
database_clean |> 
  glimpse()

# Rows: 1,126
# Columns: 44
```


```{r}
# Create the bar chart
database_clean |> 
  ggplot(aes(x = bioclim_sub_regions)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(
    title = "Distribution of Observations by BioClim Subregions",
    x = "BioClim Subregions",
    y = "Count of Observations"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 14, face = "bold"),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12)
  )
```


################################################################################
ASSESSING THE GENERATED RANDOM-FACTOR VARIABLES exp_id and treat_id 
################################################################################

Missingness Assessment for exp_id Visualization

```{r}
# database_clean |> as.data.frame() |>
#   str()
```


```{r}
# Visualize exp_id distribution across components
database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(
    # Convert all columns to character for consistency
    id_article = as.character(id_article),
    experiment_year = as.character(experiment_year)
  ) %>%
  group_by(id_article, location, experiment_year) %>%
  summarise(exp_id_count = n_distinct(exp_id), .groups = "drop") %>%
  pivot_longer(
    cols = c(id_article, location, experiment_year),
    names_to = "component",
    values_to = "value"
  ) %>%
  ggplot(aes(x = component, y = exp_id_count, fill = component)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of exp_id Across Components",
    x = "Component",
    y = "Count of exp_id"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```
```{r}
# Heatmap for year-location relationship
# Function to plot heatmap for year and a chosen variable
plot_heatmap <- function(data, y_var) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(y_var)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(y_var), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", y_var),
      x = "Experiment Year",
      y = y_var,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for location
plot_heatmap(database_clean, "location")

# Example usage: Plot for site
plot_heatmap(database_clean, "site")

# Example usage: Plot for bioclim_sub_region
plot_heatmap(database_clean, "bioclim_sub_regions")
```

```{r}
# Function to plot heatmap for year and chosen variable (moderators or response variables)
plot_heatmap_moderator_response <- function(data, var_type) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(var_type)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(var_type), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", var_type),
      x = "Experiment Year",
      y = var_type,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for moderators
plot_heatmap_moderator_response(database_clean, "tree_type")

# Example usage: Plot for response variables
plot_heatmap_moderator_response(database_clean, "response_variable")
```


```{r}
# Step 2: Explore Aggregation Level
# Count unique `exp_id` values at each location level
aggregation_summary <- database_clean %>%
  as.data.frame() |> 
  select(-geometry) |> 
  group_by(location) %>%
  summarise(
    n_exp_id = n_distinct(exp_id),
    n_obs = n(),
    .groups = "drop"
  )

# View summary of aggregation
aggregation_summary

# Step 3: Visualize Aggregation Level
aggregation_summary |> 
  ggplot(aes(x = reorder(location, n_exp_id), y = n_exp_id)) +
  geom_col(fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Distribution of exp_id Across Locations",
    x = "Location",
    y = "Number of exp_id"
  ) +
  theme_minimal()
```


```{r}
# Summarize missingness across moderators and response variables
missingness_summary <- database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(exp_id) %>%
  summarise(
    # Count missing values for moderators
    missing_moderators = sum(
      is.na(tree_type) | is.na(crop_type) | is.na(age_system) | 
      is.na(tree_age) | is.na(season) | is.na(soil_texture) | 
      is.na(no_tree_per_m) | is.na(tree_height) | is.na(alley_width)
    ),
    # Count missing values for response variables
    missing_response = sum(
      is.na(silvo_mean) | is.na(control_mean)
    ),
    total_missing = missing_moderators + missing_response,
    n_obs = n(),
    .groups = "drop"
  )
```

Publication-ready map that visualizes the ecosystem services (response variables) reported in each study (id_article),
```{r}
# Step 1: Simplify the dataset for visualization
geo_data <- database_clean %>%
  group_by(lat = final_lat, lon = final_lon, response_variable) %>%
  summarize(
    n_studies = n_distinct(id_article),
    .groups = "drop"
  ) %>%
  filter(!is.na(lat) & !is.na(lon)) # Remove rows with missing coordinates

# Step 2: Base world map
world_map <- map_data("world")


# Step 4: Create the map
geo_distribution_of_studies_map <- ggplot() +
  # Add base map polygons
  geom_polygon(
    data = world_map,
    aes(x = long, y = lat, group = group),
    fill = "gray90", color = "gray70", size = 0.4
  ) +
   # Add jittered points for studies
  geom_jitter(
    data = geo_data,
    aes(x = lon, y = lat, color = response_variable, size = as.factor(n_studies)),
    alpha = 0.8,
    width = 0.8,  # Adjust jitter width (longitude)
    height = 0.75  # Adjust jitter height (latitude)
  ) +
  # Apply custom colors
  scale_color_manual(values = custom_colors, name = "Ecosystem Service") +
  scale_size_manual(
    name = "n studies for the given locataion",
    values = c(2, 3, 4, 5, 6, 7), # Assign size values for bins 1-6
    breaks = as.character(1:6),  # Ensure breaks correspond to whole numbers
    labels = as.character(1:6)   # Labels for the legend
  ) +
  # Add labels and theme adjustments
  labs(
    title = "Geographical Distribution of Ecosystem Services in Silvoarable Agroforestry Studies (Northern Hemisphere)",
    x = "Longitude",
    y = "Latitude"
  ) +
  coord_cartesian(ylim = c(20, 90)) +  # Restrict to the northern hemisphere
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    legend.title = element_text(face = "bold"),
    legend.position = "right",
    panel.grid = element_blank(),
    axis.line = element_line(color = "gray50")
  )

geo_distribution_of_studies_map
```

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.title = element_text(size = 80),
    legend.position = "top",
    legend.text = element_text(size = 80),
    axis.text.x = element_text(size = 100)
                               #angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
geo_distribution_of_studies_map <- geo_distribution_of_studies_map + theme_custom

# Save the map plot
ggsave(
  filename = file.path(output_dir, "geo_distribution_of_studies_map.png"), # Name of the file
  plot = geo_distribution_of_studies_map, 
  width = 20, height = 10, dpi = 600, # Specify dimensions and resolution
  bg = "white" # Ensure a white background for publication-ready output
)
```


Visualize Missingness (Facet Plot for Moderators and Responses)
```{r}
# Reshape the missingness summary for visualization
missingness_long <- missingness_summary %>%
  pivot_longer(
    cols = c(missing_moderators, missing_response),
    names_to = "missingness_type",
    values_to = "missing_count"
  )

# Summarize missingness data for better grouping and understanding
missingness_long_summary <- missingness_long %>%
  group_by(missingness_type, n_obs_group = cut(n_obs, breaks = seq(0, max(n_obs, na.rm = TRUE), by = 10))) %>%
  summarise(mean_missing = mean(missing_count, na.rm = TRUE), .groups = "drop")

# Separate data for moderators and response variables
moderators_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_moderators) %>%
  mutate(missingness_type = "Moderators")

response_variables_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_response) %>%
  mutate(missingness_type = "Response Variables")

# Plot Moderators Missingness
moderators_data %>%
  ggplot(aes(x = as.factor(n_obs), y = missing_moderators, fill = missingness_type)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness Overview for Moderators",
    x = "Number of Observations per exp_id (Grouped)",
    y = "Average Missing Values Count"
  ) +
  scale_fill_manual(values = c("blue")) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


Bar Chart: Missingness by Moderators (Exp ID Count)
```{r}
# Count missing values for each moderator
# Ensure all columns have the same data type before pivoting
missingness_moderators <- database_clean %>%
  as.data.frame() %>%
  select(
    exp_id, tree_type, crop_type, age_system, tree_age, season, 
    soil_texture, no_tree_per_m, tree_height, alley_width
  ) %>%
  mutate(across(-exp_id, as.character)) %>%  # Convert all non-exp_id columns to character
  pivot_longer(
    cols = -exp_id,
    names_to = "moderator",
    values_to = "value"
  ) %>%
  group_by(moderator) %>%
  summarise(
    exp_id_with_missing = sum(is.na(value)),  # Count the number of exp_id with missing values
    .groups = "drop"
  )

# Bar chart of missingness across moderators
missingness_moderators |> 
  ggplot(aes(x = moderator, y = exp_id_with_missing, fill = moderator)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness in Moderators",
    subtitle = "Number of exp_id with Missing Values for Each Moderator",
    x = "Moderator",
    y = "Count of exp_id with Missing Values"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```












#############
# STEP 2
##########################################################################################################################################
CALCULATING META-ANALYSIS QUANTITATIVE DATA (Std Dev., Std. Err. etc.)
##########################################################################################################################################

```{r}
database_clean |> glimpse()
```


##########################################################################################################################################
CALCULATING STANDARD DEVIATION FROM EXISTING STANDARD ERROR
##########################################################################################################################################

```{r}
# Calculate standard deviations from standard errors where _sd_info is FALSE
database_clean_sd <- database_clean %>%
  mutate(
    # Calculate standard deviation for silvo group where _sd_info is FALSE
    silvo_sd_from_se = ifelse(
      !silvo_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(silvo_se) * sqrt(as.numeric(silvo_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    ),
    
    # Calculate standard deviation for control group where _sd_info is FALSE
    control_sd_from_se = ifelse(
      !control_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(control_se) * sqrt(as.numeric(control_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    )
    ) |> 
      mutate(
        # Prioritize original SD for silvo group
        silvo_sd_merged = ifelse(is.na(silvo_sd), silvo_sd_from_se, silvo_sd),  
        # Prioritize original SD for control group
        control_sd_merged = ifelse(is.na(control_sd), control_sd_from_se, control_sd)
      ) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, silvo_sd_from_se, silvo_sd_merged,
    control_mean, control_se, control_sd, control_n, control_sd_from_se, control_sd_merged
  )
```

```{r}
database_clean_sd |> glimpse()
```


Checking for missing data in control_sd and silvo_sd

```{r}
# Calculate percentage of missing SD values for control and silvo groups in _sd_final
missing_control_sd_merged <- sum(is.na(database_clean_sd$control_sd_merged)) / nrow(database_clean_sd) * 100
missing_silvo_sd_merged <- sum(is.na(database_clean_sd$silvo_sd_merged)) / nrow(database_clean_sd) * 100

message("Percentage of missing SD values for control group (_sd_final): ", round(missing_control_sd_merged, 2), "%")
message("Percentage of missing SD values for silvo group (_sd_final): ", round(missing_silvo_sd_merged, 2), "%")

# Filter rows with missing SD values in _sd_final
missing_sd_final <- database_clean_sd %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged)) %>%
  relocate(
    id_article, id_obs, response_variable, location,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_n,
    control_mean, control_se, control_sd, control_sd_from_se, control_sd_merged, control_n
  )

# Display rows with missing data in _sd_final
missing_sd_final
```

Dataset that is used as non-imputed

```{r}
# This is the dataset that is used for analysis before imputation
database_clean_sd |> glimpse()
```



#############
# STEP 3
##########################################################################################################################################
ASSESS MISSINGNESS PATTERNS OF DATA BEFORE IMPUTATION
##########################################################################################################################################

```{r}
# Check missingness summary for `control_sd` and `silvo_sd`
missingness_summary <- database_clean_sd %>%
  as.data.frame() %>%
  summarise(
    total_rows = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    percent_missing_control_sd = mean(is.na(control_sd_merged)) * 100,
    percent_missing_silvo_sd = mean(is.na(silvo_sd_merged)) * 100
  )



# Add missingness indicators to the dataset
database_clean_sd_missingness <- database_clean_sd %>%
  as.data.frame() %>%
  mutate(
    missing_control_sd = ifelse(is.na(control_sd_merged), 1, 0),
    missing_silvo_sd = ifelse(is.na(silvo_sd_merged), 1, 0)
  )

missingness_summary
```

```{r}
# Visualize missingness across response variables and moderators
missingness_plot <- database_clean_sd_missingness %>%
  select(response_variable, missing_control_sd, missing_silvo_sd) %>%
  group_by(response_variable) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd) * 100,
    missing_silvo_sd = mean(missing_silvo_sd) * 100
  ) %>%
  pivot_longer(cols = c(missing_control_sd, missing_silvo_sd),
               names_to = "Variable",
               values_to = "Percent_Missing") %>%
  ggplot(aes(x = response_variable, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Percentage of Standard Deviation Across Response Variables",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_plot
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data <- database_clean_sd_missingness %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged))

# Summarize the counts of response variables for the filtered data
missing_sd_summary <- missing_sd_data %>%
  group_by(response_variable) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Plot the distribution of response variables for missing sd data
ggplot(missing_sd_summary, aes(x = reorder(response_variable, -count), y = count, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of Response Variables with Missing Standard Deviation",
    x = "Response Variable",
    y = "Count of Missing Entries"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data_rel <- database_clean_sd_missingness %>%
  mutate(missing_sd = ifelse(is.na(control_sd_merged) | is.na(silvo_sd_merged), 1, 0))

# database_clean_sd_missingness |> filter(response_variable == "Soil quality") |> nrow()

# Calculate the percentage of missing sd values relative to total observations for each response variable
missing_sd_summary_rel <- missing_sd_data_rel %>%
  group_by(response_variable) %>%
  summarise(
    total_observations = n(),
    missing_sd_count = sum(missing_sd),
    percent_missing = (missing_sd_count / total_observations) * 100
  ) %>%
  arrange(desc(percent_missing))

missing_sd_summary_rel
```

```{r}
# Plot the relative missingness
missing_sd_summary_rel |> 
  ggplot(aes(x = reorder(response_variable, -percent_missing), y = percent_missing, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Relative Missingness of Standard Deviation by Response Variable",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Response Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Assess missingness patterns across moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

missingness_by_moderators <- database_clean_sd_missingness %>%
  select(all_of(moderators), missing_control_sd, missing_silvo_sd) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100))

missingness_by_moderators

# Visualize missingness with a heatmap
heatmap_missingness <- database_clean_sd_missingness %>%
  select(control_sd, silvo_sd, response_variable, all_of(moderators)) %>%
  naniar::gg_miss_upset()

heatmap_missingness
```

##########################################################################################################################################
Assess missingness patterns for _sd variables by location and study ID (id_article)
##########################################################################################################################################

```{r}
# Calculate missingness by location
missing_by_location <- database_clean_sd_missingness %>%
  group_by(location) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by location
cat("\nMissingness by Location:\n")
print(missing_by_location)
```

```{r}
# Missingness by location
ggplot(missing_by_location, aes(x = reorder(location, -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Location",
    x = "Location",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```
```{r}
# Calculate missingness by study ID (id_article)
missing_by_study <- database_clean_sd_missingness %>%
  group_by(id_article) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by study ID
cat("\nMissingness by Study ID:\n")
print(missing_by_study)
```

```{r}
# Missingness by study ID
missing_by_study |> 
  ggplot(aes(x = reorder(as.factor(id_article), -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Study ID",
    x = "Study ID",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```


##########################################################################################################################################
Little's MCAR test for missingness
##########################################################################################################################################

Implications of missing.patterns:
A high number of missing patterns indicates complex missingness in your dataset, which might suggest that the data is not Missing Completely at Random (MCAR). Instead, it might be Missing at Random (MAR) or Not Missing at Random (NMAR).

```{r}
####################################################################################################################
# Prepare the data for missingness assessment
database_clean_sd_df <- database_clean_sd |> as.data.frame() |> select(-geometry) 
####################################################################################################################



# Select the variables for the test
test_data <- database_clean_sd_df %>%
  select(control_sd_merged, silvo_sd_merged, everything())  # Include control_sd_merged, silvo_sd_merged, and all variables

# Convert non-numeric columns to numeric using one-hot encoding or factor levels
test_data_numeric <- test_data %>%
  mutate(across(where(is.character), ~ as.numeric(as.factor(.)))) %>%  # Convert characters to numeric
  mutate(across(where(is.factor), as.numeric)) %>%                     # Convert factors to numeric
  select(where(~ sum(!is.na(.)) > 0))                                  # Remove columns with all missing values

# Check for problematic values
problematic_values <- test_data_numeric %>%
  summarise(across(everything(), ~ sum(is.infinite(.)) + sum(is.nan(.)) + sum(is.na(.))))

problematic_values |> glimpse()

# Exclude columns with more than 50% missing values
test_data_cleaned <- test_data_numeric %>%
  # Keep control_sd_merged and silvo_sd_merged
  select(control_sd_merged, silvo_sd_merged, response_variable, experiment_year, year_est_exp, exp_id,
         # Moderators info
         tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width) %>%  
  # Remove columns with >50% missing
  select(where(~ sum(is.na(.)) < nrow(test_data_numeric) * 0.5)) |> 
  # Convert date-time columns to numeric (e.g., extract the year)
  mutate(
    experiment_year = as.numeric(format(experiment_year, "%Y")),
    year_est_exp = as.numeric(format(year_est_exp, "%Y"))
  )

# Confirm all columns are numeric
all(sapply(test_data_cleaned, is.numeric)) 

# Check which columns are not numeric
non_numeric_cols <- sapply(test_data_cleaned, function(col) !is.numeric(col))
names(non_numeric_cols[non_numeric_cols])

# Inspect missing values after cleaning
colSums(is.na(test_data_cleaned))

# Perform Little's MCAR test on cleaned data
mcar_test <- naniar::mcar_test(test_data_cleaned)
mcar_test
```

```{r}
# Visualize missingness pattern
md.pattern(database_clean_sd_df)

# Heatmap of missing data

aggr_plot <- VIM::aggr(database_clean_sd_df, col = c('navyblue', 'red'), numbers = TRUE, sortVars = TRUE, 
                  labels = names(database_clean_sd_df), cex.axis = .7, gap = 3, ylab = c("Missingness", "Pattern"))
aggr_plot
```

```{r}
# Add missing indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd <- test_data_cleaned %>%
  mutate(
    missing_control_sd = is.na(control_sd_merged),
    missing_silvo_sd = is.na(silvo_sd_merged)
  )

# Check relationship between missingness and other variables
ggplot(test_data_cleaned_sd, aes(x = tree_age, fill = missing_control_sd)) +
  geom_histogram(position = "dodge") +
  labs(title = "Relationship Between Tree Age and Missingness in control_sd_merged")
```

Fit logistic regression models to see if missingness depends on observed variables.

```{r}
# Test if missingness depends on observed variables using logistic regression

# Add missingness indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd_test <- test_data_cleaned %>%
  mutate(
    missing_control_sd = as.numeric(is.na(control_sd_merged)),
    missing_silvo_sd = as.numeric(is.na(silvo_sd_merged))
  )
# Check levels of categorical variables
levels(test_data_cleaned_sd_test$tree_type)
levels(test_data_cleaned_sd_test$crop_type)
levels(test_data_cleaned_sd_test$age_system)
levels(test_data_cleaned_sd_test$season)
levels(test_data_cleaned_sd_test$soil_texture)
levels(test_data_cleaned_sd_test$no_tree_per_m)
levels(test_data_cleaned_sd_test$alley_width)


# Test 1: Logistic regression using specified moderators
missing_control_model_1 <- glm(
  missing_control_sd ~ tree_type + crop_type + age_system + tree_age + season + soil_texture + no_tree_per_m + tree_height + alley_width,
  data = test_data_cleaned_sd_test, family = binomial
)

missing_silvo_model_1 <- glm(
  missing_silvo_sd ~ tree_type + crop_type + age_system + tree_age + season + soil_texture + no_tree_per_m + tree_height + alley_width,
  data = test_data_cleaned_sd_test, family = binomial
)

# Summarize results for Test 1
cat("\nTest 1: Logistic regression results using specified moderators\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_1)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_1)

# Test 2: Logistic regression using response variables
missing_control_model_2 <- glm(
  missing_control_sd ~ response_variable,
  data = test_data_cleaned_sd_test, family = binomial
)

missing_silvo_model_2 <- glm(
  missing_silvo_sd ~ response_variable,
  data = test_data_cleaned_sd_test, family = binomial
)

# Summarize results for Test 2
cat("\nTest 2: Logistic regression results using response variables\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_2)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_2)

```



The updated logistic regression analysis highlights that missingness in both `control_sd` and `silvo_sd` is systematically linked to observed variables, confirming that the missing data are not random. Several factors, including tree type, crop type, season, soil texture, tree age, and tree height, significantly influence missingness patterns. Tree type plays a particularly important role, with systems involving "fruit/nut & other" trees showing increased rates of missingness, likely due to variations in experimental protocols and challenges inherent in measuring more complex systems. In contrast, simpler systems such as those involving timber trees exhibit lower missingness rates, reflecting more standardized data collection methods. Similarly, crop type is a key factor, as cereal crops consistently display lower missingness, whereas systems involving tuber or root crops often experience higher rates of missing data, potentially due to logistical or methodological complexities specific to these cropping systems.

Environmental factors such as season and soil texture further contribute to missingness patterns. Extreme seasonal conditions, such as those associated with winter or summer stress, appear to hinder consistent data collection, resulting in higher rates of missingness. Similarly, difficult soil textures, particularly clay, are associated with significant missingness, likely reflecting the logistical challenges of managing experiments in these conditions. The analysis also reveals that tree age inversely correlates with missingness. Older tree systems tend to have more complete data, likely due to their greater experimental stability and maturity, whereas younger tree systems frequently experience missing data, reflecting the challenges of monitoring developing systems over shorter study durations. Tree height, on the other hand, is positively associated with missingness, as taller trees present additional challenges for data collection, particularly in accessing upper canopy layers or quantifying their influence on understory crops.

Complex response variables, such as biodiversity and greenhouse gas emissions, are also more prone to missing data. These variables often involve indirect measurements or multi-step processes, which increases the likelihood of incomplete reporting. In contrast, simpler response variables tend to have more complete datasets, reflecting less demanding measurement protocols. The statistical analysis provides strong evidence for these patterns, with significant coefficients for tree type, crop type, season, soil texture, tree height, and response variables, confirming that missingness follows a systematic and structured pattern.

These findings underscore the validity of treating missingness as "Missing at Random" (MAR), where the probability of missing data depends on observed variables. This MAR assumption supports the use of imputation techniques that incorporate predictors such as tree type, crop type, environmental conditions, and response variables into the imputation models. By leveraging these systematic relationships, imputation approaches can reduce bias and preserve the structural integrity of the dataset. This ensures that downstream analyses remain robust and reliable, even in the context of the diverse and variable experimental settings characteristic of temperate silvoarable agroforestry systems. Understanding these mechanisms of missingness is therefore critical for addressing data gaps and maintaining the reliability of meta-analytic insights.


```{r}
# Step 1: Summarize Missingness by Tree Type and Crop Type
missing_summary_tree_crop <- test_data_cleaned_sd_test %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd, na.rm = TRUE) * 100,
    missing_silvo_sd = mean(missing_silvo_sd, na.rm = TRUE) * 100,
    .groups = "drop"
  )

# Print Summary Table
missing_summary_tree_crop
```

```{r}
# Step 2: Visualize Missingness by Tree Type and Crop Type

# Plot for Control SD Missingness
plot_control_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_control_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Control SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Control SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot for Silvo SD Missingness
plot_silvo_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_silvo_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Silvo SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Silvo SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



plot_control_missingness
plot_silvo_missingness
```


```{r}
# Step 3: Statistical Tests to Confirm Associations
# Chi-Square Test for Independence between Tree Type and Control SD Missingness
chi_sq_tree_control <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_tree_control

# Chi-Square Test for Independence between Crop Type and Control SD Missingness
chi_sq_crop_control <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_crop_control

# Chi-Square Test for Independence between Tree Type and Silvo SD Missingness
chi_sq_tree_silvo <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_tree_silvo

# Chi-Square Test for Independence between Crop Type and Silvo SD Missingness
chi_sq_crop_silvo <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_crop_silvo

# Step 4: Logistic Regression Models for Tree Type and Crop Type
# Logistic Regression for Control SD
logit_control <- glm(missing_control_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_control

# Logistic Regression for Silvo SD
logit_silvo <- glm(missing_silvo_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_silvo
```

The updated analysis confirms strong associations between missingness in both `control_sd` and `silvo_sd` and the observed variables `tree_type` and `crop_type`. Results from Pearson's Chi-squared tests reveal significant relationships for both tree type and crop type. For `tree_type`, the chi-square statistic is extremely high (X² = 76.96, p < 2.2e-16), indicating a strong dependency between tree type and missingness in `control_sd` and `silvo_sd`. Similarly, the association between `crop_type` and missingness is significant, though weaker, with a chi-square statistic of X² = 9.10 and p = 0.01058. These results clearly demonstrate that missingness is not randomly distributed but is instead systematically linked to specific experimental factors.

Logistic regression models further substantiate these findings. Both tree type and crop type have positive coefficients when predicting missingness for `control_sd` and `silvo_sd`. The intercept reflects a baseline low probability of missingness, while the positive coefficients for tree type (0.083) and crop type (0.389) indicate that certain tree and crop types increase the likelihood of missing data. The residual deviance for both models is substantially reduced compared to the null deviance, demonstrating an improved model fit, with an AIC value of 999.6 for each. These statistical results highlight the structured nature of missingness, reinforcing that it is "Missing at Random" (MAR), as it depends on observable factors like tree type and crop type.

The implications of these findings are significant for the setup and interpretation of the meta-regression analysis. First, it is essential to include variables such as `tree_type` and `crop_type` as moderators in the model to account for variability linked to experimental conditions. By doing so, the analysis will better capture the systematic relationships in the data and reduce potential biases in effect size estimates. Furthermore, addressing missing data is critical to ensure reliable results. Imputation methods such as predictive mean matching or upper quartile imputation are well-suited to handle MAR scenarios, as they leverage the systematic relationships identified in the dataset to estimate plausible values for missing observations. These methods help preserve the structural integrity of the data and maintain the robustness of downstream analyses.

Given the systematic nature of missingness, additional steps are necessary to ensure the meta-regression models are robust. Sensitivity analyses should be conducted to assess the impact of imputation methods on the final results. Comparing models fitted on imputed datasets with those using only complete cases will validate the stability of findings. Furthermore, the inclusion of tree and crop type as moderators may introduce complex interactions with other variables, necessitating the exploration of potential effect modifications. Testing for heterogeneity across studies by incorporating random effects or interaction terms is also crucial to accurately capture variability within the dataset.

Finally, diagnostic evaluations, including tests for publication bias and model performance metrics, must be incorporated to ensure the reliability and validity of the results. The systematic associations between missingness and observed variables underscore the importance of carefully handling missing data and refining model specifications. These steps will support a robust and interpretable meta-regression analysis, enabling meaningful insights into the relationships driving variability in temperate silvoarable agroforestry systems.


```{r}
# Correctly aggregate missingness percentages by tree_type and crop_type
missingness_distribution_corrected <- database_clean_sd_df %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = sum(missing_control_sd_merged, na.rm = TRUE) / n() * 100,
    missing_silvo_sd = sum(missing_silvo_sd_merged, na.rm = TRUE) / n() * 100,
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(missing_control_sd, missing_silvo_sd),
    names_to = "Variable",
    values_to = "Percent_Missing"
  )

# Re-generate plots with corrected aggregation
missingness_tree_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = tree_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Tree Type",
    x = "Tree Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_crop_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = crop_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Crop Type",
    x = "Crop Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the corrected plots
print(missingness_tree_plot_corrected)
print(missingness_crop_plot_corrected)
```



The updated visualizations highlight the percentage of missing values in `control_sd` and `silvo_sd` across tree type and crop type categories. For tree type, missingness patterns reveal that "fruit/nut & other" exhibits the highest proportion of missing values, exceeding 60% for both variables. In contrast, "biomass" shows moderate missingness, with rates around 40%, while "timber" has the lowest missingness, approximately 20%. These findings indicate that missingness is strongly dependent on tree type, with "fruit/nut & other" particularly affected, possibly due to measurement challenges or variability in experimental setups.

Similarly, crop type exhibits a pronounced influence on missingness rates. Cereal crops demonstrate minimal missingness, with percentages below 20%, suggesting standardized or easier measurement practices for this crop type. In contrast, legumes exhibit moderate missingness, averaging 30-40%, while tuber/root crops face the highest rates, exceeding 60% for both variables. This substantial variability underscores that specific crop types, like tuber/root crops, may present greater challenges in data collection or experimental consistency.

These patterns reinforce the importance of tailoring imputation strategies to account for category-specific influences. For example, tree type and crop type should be included as key predictors in imputation models to address the observed disparities. Additionally, the significantly higher missingness in "fruit/nut & other" tree types and tuber/root crops indicates that these categories warrant particular attention to mitigate biases introduced by missing data. Further validation through statistical testing can refine these insights and guide the application of targeted imputation techniques to preserve data integrity across diverse categories.

















#############
# STEP 4
##########################################################################################################################################
HANDELING OF MISSING VALUES IN THE DATASET - IMPUTATION
##########################################################################################################################################

Perform imputation on  silvo_se, control_se using 
"mice" (Multivariate Imputation by Chained Equations), 
Upper Quartile, 
Mean Imputation,
Bayesian
Linear regression imputation (norm.predict)


```{r}
database_clean_sd |> glimpse()
```

The imputation process below does not explicitly ensure that imputation only occurs when both se and sd are missing (NA or FALSE, respectively). This is because the code primarily focuses on imputing se values based on the method specified (e.g., mean_imputation, pmm, etc.), and no condition is explicitly set to check whether both se and sd are missing before proceeding. To implement the condition that imputation should only occur when both se and sd are missing, we would need to modify the imputation logic. Specifically, by adding a condition that checks for e.g. NA or FALSE in both columns before imputing se. 


```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Start time tracking
start.time <- Sys.time()

#######################################################################################
# Step 1: Check and enforce correct data types
#######################################################################################
col_for_impute <- database_clean_sd |> 
  as.data.frame() |> 
  select(-geometry) |> 
  select(
    # Columns that need to be imputed
    silvo_se, control_se, 
    # Columns that are used by mice to impute values
    tree_age, crop_type, tree_type, bioclim_sub_regions, experiment_year, alley_width, silvo_n, control_n,
    # IDs that are used to back-link imputed values to the dataset
    id_article, id_obs, treat_id, exp_id
  ) |> 
  mutate(
    silvo_se = as.numeric(silvo_se),
    control_se = as.numeric(control_se),
    silvo_n = as.numeric(silvo_n),
    control_n = as.numeric(control_n),
    tree_age = as.numeric(tree_age),
    crop_type = as.factor(crop_type),
    tree_type = as.factor(tree_type),
    bioclim_sub_regions = as.factor(bioclim_sub_regions),
    alley_width = as.factor(alley_width),
    id_article = as.numeric(id_article),
    id_obs = as.numeric(id_obs),
    treat_id = as.numeric(treat_id),
    exp_id = as.numeric(exp_id)
  )

#######################################################################################
# Step 2: Define the function for each imputation method
#######################################################################################
impute_data <- function(data, method_name) {
  if (method_name == "mean_imputation") {
    #######################################################################################
    # Mean Imputation (mean)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_se = ifelse(is.na(silvo_se), mean(silvo_se, na.rm = TRUE), silvo_se),
        control_se = ifelse(is.na(control_se), mean(control_se, na.rm = TRUE), control_se),
        silvo_n = ifelse(is.na(silvo_n), mean(silvo_n, na.rm = TRUE), silvo_n),
        control_n = ifelse(is.na(control_n), mean(control_n, na.rm = TRUE), control_n)
      )
    return(data)

  } else if (method_name == "upper_quartile") {
    #######################################################################################
    # Upper Quartile Imputation (uq)
    #######################################################################################
    upper_quartile_variance <- data %>%
      summarise(across(c(silvo_se, control_se), ~ quantile(.^2, 0.75, na.rm = TRUE))) %>%
      pivot_longer(cols = everything(), names_to = "variable", values_to = "upper_quartile")

    data <- data %>%
      mutate(
        silvo_se = ifelse(is.na(silvo_se), sqrt(upper_quartile_variance$upper_quartile[1]), silvo_se),
        control_se = ifelse(is.na(control_se), sqrt(upper_quartile_variance$upper_quartile[2]), control_se)
      )
    return(data)

  } else if (method_name == "linear_imputation") {
    #######################################################################################
    # Linear Regression Imputation (lr)
    #######################################################################################
    data <- data %>%
      mutate(
        crop_type = as.numeric(as.factor(crop_type)),
        tree_type = as.numeric(as.factor(tree_type)),
        bioclim_sub_regions = as.numeric(as.factor(bioclim_sub_regions)),
        alley_width = as.numeric(as.factor(alley_width))
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_se" = "norm.predict",   # Imputed using linear regression
      "control_se" = "norm.predict",   # Imputed using linear regression
      "silvo_n" = "",            # Not imputed
      "control_n" = "",          # Not imputed
      "tree_age" = "",           # Not imputed
      "crop_type" = "",          # Not imputed
      "tree_type" = "",          # Not imputed
      "bioclim_sub_regions" = "",# Not imputed
      "experiment_year" = "",    # Not imputed
      "alley_width" = "",        # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",             # Not imputed
      "treat_id" = "",           # Not imputed
      "exp_id" = ""              # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "bayesian") {
    #######################################################################################
    # Bayesian Imputation (by)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_se = ifelse(silvo_se < 0, 0, silvo_se),
        control_se = ifelse(control_se < 0, 0, control_se)
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_se" = "norm.nob",   # Imputed using Bayesian regression
      "control_se" = "norm.nob",   # Imputed using Bayesian regression
      "silvo_n" = "",            # Not imputed
      "control_n" = "",          # Not imputed
      "tree_age" = "",           # Not imputed
      "crop_type" = "",          # Not imputed
      "tree_type" = "",          # Not imputed
      "bioclim_sub_regions" = "",# Not imputed
      "experiment_year" = "",    # Not imputed
      "alley_width" = "",        # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",             # Not imputed
      "treat_id" = "",           # Not imputed
      "exp_id" = ""              # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "pmm") {
    #######################################################################################
    # Predictive Mean Matching (pmm)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_se" = "pmm",   # Imputed using predictive mean matching
      "control_se" = "pmm", # Imputed using predictive mean matching
      "silvo_n" = "",            # Not imputed
      "control_n" = "",          # Not imputed
      "tree_age" = "",           # Not imputed
      "crop_type" = "",          # Not imputed
      "tree_type" = "",          # Not imputed
      "bioclim_sub_regions" = "",# Not imputed
      "experiment_year" = "",    # Not imputed
      "alley_width" = "",        # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",             # Not imputed
      "treat_id" = "",           # Not imputed
      "exp_id" = ""              # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "rf") {
    #######################################################################################
    # Random Forest Imputation (rf)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_se" = "rf",   # Imputed using random forest
      "control_se" = "rf",   # Imputed using random forest
      "silvo_n" = "",            # Not imputed
      "control_n" = "",          # Not imputed
      "tree_age" = "",           # Not imputed
      "crop_type" = "",          # Not imputed
      "tree_type" = "",          # Not imputed
      "bioclim_sub_regions" = "",# Not imputed
      "experiment_year" = "",    # Not imputed
      "alley_width" = "",        # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",             # Not imputed
      "treat_id" = "",           # Not imputed
      "exp_id" = ""              # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else {
    stop("Invalid method name.")
  }
}

#######################################################################################
# Step 3: Apply each imputation method
#######################################################################################
imputation_methods <- c("mean_imputation", "upper_quartile", "linear_imputation", "bayesian", "pmm", "rf")
imputed_datasets <- list()

# Separate storage for raw mids objects
imputed_mids_pmm <- NULL
imputed_mids_rf <- NULL
imputed_mids_bayesian <- NULL
imputed_mids_linear <- NULL

# Iterate through imputation methods
for (method_name in imputation_methods) {
  cat("Applying", method_name, "imputation...\n")
  
  tryCatch({
    if (method_name %in% c("pmm", "rf", "bayesian", "linear_imputation")) {
      imputed_mids <- impute_data(col_for_impute, method_name)
      
      # Save mids objects for diagnostics
      if (method_name == "pmm") imputed_mids_pmm <- imputed_mids
      if (method_name == "rf") imputed_mids_rf <- imputed_mids
      if (method_name == "bayesian") imputed_mids_bayesian <- imputed_mids
      if (method_name == "linear_imputation") imputed_mids_linear <- imputed_mids
      
      # Store completed dataset
      imputed_datasets[[method_name]] <- mice::complete(imputed_mids)
    } else {
      # Direct dataset modification for other methods
      imputed_datasets[[method_name]] <- impute_data(col_for_impute, method_name)
    }
  }, error = function(e) {
    cat("Error applying", method_name, "imputation:", e$message, "\n")
  })
}

# Summary of results
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  if (!is.null(imputed_datasets[[method_name]])) {
    print(summary(imputed_datasets[[method_name]]))
  } else {
    cat("No data available for", method_name, "\n")
  }
}

#######################################################################################
# Step 4: Compare Results
#######################################################################################
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  print(summary(imputed_datasets[[method_name]]))
}

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, "\n")

##########################################################################
# imputed_mids_pmm and imputed_mids_linear are the raw mids objects for PMM and linear regression respectively
# imputed_datasets contains completed and capped datasets


##########################################################################
# Last run (04/01-25)
# Total time taken: 18.98046 secs

# Last run (05/01-25)
# Total time taken: 2.224936 mins 

# Last run (11/01-25)
# Total time taken: 3.70053 mins

# Last run (16/01-25)
# Total time taken: 2.12917 mins
```

```{r}
#######################################################################################
# Step 5: Extract Fitted Data and Prepare for Visualization
#######################################################################################

# Ensure consistent data types across datasets
consistent_col_types <- function(data) {
  data %>%
    mutate(
      crop_type = as.factor(crop_type),
      tree_type = as.factor(tree_type),
      bioclim_sub_regions = as.factor(bioclim_sub_regions),
      alley_width = as.factor(alley_width)
    )
}

# Apply the function to ensure consistency
col_for_impute <- consistent_col_types(col_for_impute)

for (method_name in names(imputed_datasets)) {
  imputed_datasets[[method_name]] <- consistent_col_types(imputed_datasets[[method_name]])
}

# Combine original and imputed datasets into one
visualization_data <- col_for_impute %>%
  mutate(source = "Original") %>%
  bind_rows(
    imputed_datasets[["linear_imputation"]] %>% mutate(source = "Linear Imputation"),
    imputed_datasets[["pmm"]] %>% mutate(source = "PMM"),
    imputed_datasets[["rf"]] %>% mutate(source = "Random Forest"),
    imputed_datasets[["bayesian"]] %>% mutate(source = "Bayesian"),
    imputed_datasets[["upper_quartile"]] %>% mutate(source = "Upper Quartile"),
    imputed_datasets[["mean_imputation"]] %>% mutate(source = "Mean Imputation")
  )

# Visualize imputed values against original
library(ggplot2)

# Scatterplot for silvo_se
ggplot(visualization_data, aes(x = source, y = silvo_se, color = source)) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Comparison of Imputed Values for silvo_se",
    x = "Data Source",
    y = "silvo_se"
  )

# Scatterplot for control_se
ggplot(visualization_data, aes(x = source, y = control_se, color = source)) +
  geom_jitter(width = 0.2, alpha = 0.7) +
  theme_minimal() +
  labs(
    title = "Comparison of Imputed Values for control_se",
    x = "Data Source",
    y = "control_se"
  )

```


```{r}
# Check the summary of imputed dataset list
imputed_datasets |> str()
```



```{r}
# Evaluate the imputed datasets
# Check convergence diagnostics
plot(imputed_mids_pmm)
```



```{r}
# Use stripplot to compare observed and imputed values
stripplot(imputed_mids_pmm, silvo_se + control_se ~ .imp,
  cex = c(1, 2), pch = c(20, 20), jitter = TRUE, alpha = 0.4, scales = "free")
```


```{r}
# Step 1: Summarize each imputed dataset
# Quantitative Assessment:
# Calculate summary statistics for each imputed dataset, focusing on proximity to medians (mean proximity for silvo_se and control_se).
# Incorporate additional metrics like variance, range, and RMSE for better decision-making.

imputed_summaries <- list()

for (i in 1:20) {
  data <- mice::complete(imputed_mids_pmm, i) # Extract the i-th imputed dataset

  # Calculate summary statistics for each imputation
  summary <- data %>%
    summarise(
      mean_silvo_se = mean(silvo_se, na.rm = TRUE),
      sd_silvo_se = sd(silvo_se, na.rm = TRUE),
      mean_control_se = mean(control_se, na.rm = TRUE),
      sd_control_se = sd(control_se, na.rm = TRUE),
      range_silvo_se = max(silvo_se, na.rm = TRUE) - min(silvo_se, na.rm = TRUE),
      range_control_se = max(control_se, na.rm = TRUE) - min(control_se, na.rm = TRUE)
    )

  imputed_summaries[[i]] <- summary
}

# Combine all summaries into a single data frame
imputed_summaries_df <- bind_rows(imputed_summaries, .id = "imputation")

# Calculate medians for silvo_se and control_se
median_silvo_se <- median(imputed_summaries_df$mean_silvo_se)
median_control_se <- median(imputed_summaries_df$mean_control_se)

# Add a column calculating Euclidean distance to medians
imputed_summaries_df <- imputed_summaries_df %>%
  mutate(
    distance_from_median = sqrt(
      (mean_silvo_se - median_silvo_se)^2 + (mean_control_se - median_control_se)^2
    )
  )
```

```{r}
# Step 2: Advanced Quantitative Metrics
# Root Mean Squared Error (RMSE):
# Add RMSE comparison between observed and imputed values for silvo_se and control_se.

# RMSE calculation function
calculate_rmse <- function(observed, imputed) {
  sqrt(mean((observed - imputed)^2, na.rm = TRUE))
}

# Add RMSE to imputed summaries
imputed_summaries_df <- imputed_summaries_df %>%
  rowwise() %>%
  mutate(
    rmse_silvo_se = calculate_rmse(
      col_for_impute$silvo_se[!is.na(col_for_impute$silvo_se)],
      mice::complete(imputed_mids_pmm, as.numeric(imputation))$silvo_se[is.na(col_for_impute$silvo_se)]
    ),
    rmse_control_se = calculate_rmse(
      col_for_impute$control_se[!is.na(col_for_impute$control_se)],
      mice::complete(imputed_mids_pmm, as.numeric(imputation))$control_se[is.na(col_for_impute$control_se)]
    )
  )

imputed_summaries_df
```
```{r}
# Step 3: Choose the Best Imputation
# Select the imputation based on a weighted score that combines distance to medians, RMSE, and possibly variance or range.

# Add weighted score for selection and select the top-ranked imputation
chosen_imputation <- imputed_summaries_df %>% 
  as.data.frame() |> 
  # Calculate the total_score (modify weights if necessary)
  mutate(total_score = distance_from_median + rmse_silvo_se + rmse_control_se) %>%
  # Arrange by total_score (ascending order)
  arrange(total_score) %>%
  # Select the top row with the lowest total_score
  slice(1)

# Extract the corresponding dataset
chosen_imputation_number <- as.integer(chosen_imputation$imputation)
imputed_col_data <- mice::complete(imputed_mids_pmm, chosen_imputation_number)
imputed_datasets$pmm_best <- imputed_col_data

imputed_datasets$pmm_best 
```
```{r}
# imputation_plot_data_all |> str()
# # Check if "linear" is included as a method
# unique(imputation_plot_data_all$method)
# 
# imputation_plot_data_all %>%
#     filter(method == "linear_imputation") %>%
#     filter(type == "Imputed")
# count()
```

##########################################################################################################################################
Visually examine the imputed values
##########################################################################################################################################


```{r}
# Step 4: Visual Assessment
# Density Plots for Each Method and Variable:
# Compare observed and imputed distributions for silvo_se and control_se across all imputation methods.

# Prepare data for visualization
observed_values <- list(
  silvo_se = col_for_impute$silvo_se[!is.na(col_for_impute$silvo_se)],
  control_se = col_for_impute$control_se[!is.na(col_for_impute$control_se)]
)

# Combine observed and imputed values for plotting
combined_plot_data <- list()

for (variable in c("silvo_se", "control_se")) {
  for (method_name in names(imputed_datasets)) {
    imputed_values <- imputed_datasets[[method_name]][[variable]][is.na(col_for_impute[[variable]])]

    combined_plot_data[[paste(variable, method_name, sep = "_")]] <- data.frame(
      value = c(observed_values[[variable]], imputed_values),
      type = c(rep("Original", length(observed_values[[variable]])),
               rep("Imputed", length(imputed_values))),
      method = method_name,
      variable = variable
    )
  }
}

###############################################################################
# Combine all data into one frame
imputation_plot_data_all <- bind_rows(combined_plot_data)

###############################################################################
# Remove linear imputation for better visualization
imputation_plot_data_no_linear <- 
  imputation_plot_data_all |> 
  filter(method != "linear_imputation")
```

```{r}
# Generic function to generate density plots
generate_density_plot <- function(data, title_suffix, scale_type = "linear") {
  plot <- ggplot(data, aes(x = value, fill = type)) +
    geom_density(alpha = 0.5) +
    facet_grid(variable ~ method) +
    labs(
      title = paste("Density Comparison:", title_suffix),
      x = ifelse(scale_type == "linear", "Value", "Value (Pseudo-Log Scale)"),
      y = "Density"
    ) +
    theme_minimal() +
    scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +
    theme(strip.text = element_text(size = 10, face = "bold"))
  
  if (scale_type == "pseudo_log") {
    plot <- plot + scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1)) + scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))
  }
  
  return(plot)
}

# Generate plots

plot_imputation_data_all_linear <- generate_density_plot(
  data = imputation_plot_data_all, 
  title_suffix = "Original vs. Imputed Values (Linear Scale)",
  scale_type = "linear"
)

plot_imputation_data_all_pseudo <- generate_density_plot(
  data = imputation_plot_data_all, 
  title_suffix = "Original vs. Imputed Values (Pseudo-Log Scale)",
  scale_type = "pseudo_log"
)

plot_imputation_data_no_linear_linear <- generate_density_plot(
  data = imputation_plot_data_no_linear, 
  title_suffix = "Excluding Linear Imputation (Linear Scale)",
  scale_type = "linear"
)

plot_imputation_data_no_linear_pseudo <- generate_density_plot(
  data = imputation_plot_data_no_linear, 
  title_suffix = "Excluding Linear Imputation (Pseudo-Log Scale)",
  scale_type = "pseudo_log"
)

# Print
plot_imputation_data_all_pseudo 
plot_imputation_data_all_linear 
plot_imputation_data_no_linear_linear 
plot_imputation_data_no_linear_pseudo 
```

Save the plots
```{r}
# Define the output folder path
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 30),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
plot_imputation_data_all_pseudo <- plot_imputation_data_all_pseudo + theme_custom
plot_imputation_data_all_linear <- plot_imputation_data_all_linear + theme_custom
plot_imputation_data_no_linear_linear <- plot_imputation_data_no_linear_linear + theme_custom
plot_imputation_data_no_linear_pseudo <- plot_imputation_data_no_linear_pseudo + theme_custom


# Save the plots
ggsave(
  filename = file.path(output_dir, "plot_imputation_data_all_linear.png"),
  plot = plot_imputation_data_all_linear,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "plot_imputation_data_all_pseudo.png"),
  plot = plot_imputation_data_all_pseudo,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "plot_imputation_data_no_linear_linear.png"),
  plot = plot_imputation_data_no_linear_linear,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "plot_imputation_data_no_linear_pseudo.png"),
  plot = plot_imputation_data_no_linear_pseudo,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)
```






##########################################################################################################################################
More quantitative statistical assessment
##########################################################################################################################################

```{r}
# imputed_datasets |> str()
```

```{r}
# Variable importance from a random forest model
rf_data <- na.omit(imputed_datasets$upper_quartile)

# Ensure to compute variable importance during model training
rf_model <- randomForest(silvo_se ~ . - control_se - control_n - silvo_n - id_obs - treat_id - id_article - exp_id,
                         data = rf_data,
                         importance = TRUE)

# View variable importance
randomForest::importance(rf_model)

# Plot variable importance
varImpPlot(rf_model)
```


```{r}
# a. Descriptive Statistics
# Calculate and compare mean, standard deviation, and range for key variables (e.g., silvo_se, control_se).

# a. Descriptive Statistics
# Calculate descriptive statistics for each imputation method
compare_stats <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      mean_silvo_se = mean(silvo_se, na.rm = TRUE),
      sd_silvo_se = sd(silvo_se, na.rm = TRUE),
      range_silvo_se = diff(range(silvo_se, na.rm = TRUE)),
      mean_control_se = mean(control_se, na.rm = TRUE),
      sd_control_se = sd(control_se, na.rm = TRUE),
      range_control_se = diff(range(control_se, na.rm = TRUE))
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_stats)



# b. Variance Explained
# Calculate variance for silvo_se and control_se
compare_variance <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      var_silvo_se = var(silvo_se, na.rm = TRUE),
      var_control_se = var(control_se, na.rm = TRUE)
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_variance)




# Calculate Jensen-Shannon divergence for each method - The Jensen-Shannon Divergence (JSD) is a statistical measure of similarity (or dissimilarity) between two 
# probability distributions. It quantifies how different one probability distribution is from another and is widely used in information theory, machine learning, 
# and statistics.
library(philentropy)

# Function to calculate JSD safely
calculate_jsd <- function(observed, imputed) {
  if (length(imputed) > 1 && length(observed) > 1) {
    observed_density <- density(observed)$y
    imputed_density <- density(imputed)$y
    
    # Normalize to probabilities
    observed_density <- observed_density / sum(observed_density)
    imputed_density <- imputed_density / sum(imputed_density)
    
    # Calculate JSD
    return(JSD(rbind(observed_density, imputed_density)))
  } else {
    return(NA) # Return NA if densities cannot be calculated
  }
}

# Calculate JSD for each method
compare_jsd <- lapply(imputed_datasets, function(data) {
  if (inherits(data, "mids")) {
    data <- mice::complete(data) # Handle mids objects
  }
  
  # Filter numeric columns for density calculation
  observed_silvo <- col_for_impute$silvo_se[!is.na(col_for_impute$silvo_se)]
  imputed_silvo <- data$silvo_se[is.na(col_for_impute$silvo_se)]
  
  observed_control <- col_for_impute$control_se[!is.na(col_for_impute$control_se)]
  imputed_control <- data$control_se[is.na(col_for_impute$control_se)]
  
  list(
    jsd_silvo = calculate_jsd(observed_silvo, imputed_silvo),
    jsd_control = calculate_jsd(observed_control, imputed_control)
  )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_jsd)


# Add an identifier column to each data frame and convert them to long format
compare_stats_long <- compare_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

compare_variance_long <- compare_variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

compare_jsd_long <- compare_jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine all data frames into one
combined_metrics <- bind_rows(compare_stats_long, compare_variance_long, compare_jsd_long)

# View the combined data frame
combined_metrics
```

```{r}
# Ensure `database_clean_sd` is converted to a plain data frame and the `geometry` column is removed
database_clean_sd_df <- database_clean_sd %>%
  as.data.frame() |> 
  select(-geometry)

# Recalculate the metrics for the original dataset
original_metrics <- list(
  # Descriptive statistics
  descriptive_stats = database_clean_sd_df %>%
    summarise(
      mean_silvo_se = mean(silvo_se, na.rm = TRUE),
      sd_silvo_se = sd(silvo_se, na.rm = TRUE),
      range_silvo_se = diff(range(silvo_se, na.rm = TRUE)),
      mean_control_se = mean(control_se, na.rm = TRUE),
      sd_control_se = sd(control_se, na.rm = TRUE),
      range_control_se = diff(range(control_se, na.rm = TRUE))
    ) %>%
    mutate(method = "original"),
  
  # Variance comparison
  variance = database_clean_sd_df %>%
    summarise(
      var_silvo_se = var(silvo_se, na.rm = TRUE),
      var_control_se = var(control_se, na.rm = TRUE)
    ) %>%
    mutate(method = "original"),
  
  # Jensen-Shannon divergence (JSD)
  jsd = list(
    jsd_silvo = 0, # No divergence for original dataset
    jsd_control = 0
  ) %>%
    bind_rows() %>%
    mutate(method = "original")
)

# Convert metrics to long format for visualization
original_descriptive_long <- original_metrics$descriptive_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

original_variance_long <- original_metrics$variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

original_jsd_long <- original_metrics$jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine original metrics with imputed dataset metrics
original_combined <- bind_rows(original_descriptive_long, original_variance_long, original_jsd_long)
combined_metrics_with_original <- bind_rows(combined_metrics, original_combined)
```

```{r}
prepared_data_gt <- combined_metrics_with_original %>%
  # Pivot wider to make methods the columns
  pivot_wider(names_from = method, values_from = value) %>%
  # Add absolute relative difference columns
  mutate(
    across(
      -c(metric, original, category), # Exclude non-numeric columns
      ~ ifelse(
        grepl("^jsd_", metric) & . == 0, NA,  # Set `NA` where `jsd_` metrics are 0.00
        ifelse(is.na(original) | original == 0, NA, abs((. - original) / original)) # Otherwise compute relative difference
      ),
      .names = "{.col}_relative"
    )
  ) %>%
  # Add a new column to extract the prefix (e.g., mean_, sd_, etc.)
  mutate(metric_group = sub("_.*", "", metric)) %>%
  # Sort rows first by the group (e.g., mean, sd) and then by the original metric order
  arrange(metric_group, metric)

# Display structure for verification
prepared_data_gt |> glimpse()
```


```{r}
# Create the updated plot
combined_metrics_comparison_with_original <- combined_metrics_with_original |> 
  ggplot(aes(x = method, y = value, fill = method)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.8) +
  facet_wrap(~ category + metric, scales = "free_y", ncol = 3) +
  labs(
    title = "Comparison of Imputation Methods Across Metrics (Including Original Dataset)",
    x = "Method",
    y = "Value",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  ) +
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8)  # Discrete color scale



combined_metrics_comparison_with_original
```

Save the comparison diagnostics bar chart
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as PDF

combined_metrics_comparison_with_original <- combined_metrics_comparison_with_original + theme_custom

ggsave(
  filename = file.path(output_dir, "combined_metrics_comparison_with_original.png"),
  plot = combined_metrics_comparison_with_original,
  width = 14, height = 18, dpi = 400,
  bg = "white"
)
```

```{r}
# Apply color shading to all `_relative` columns
comparison_gt <- prepared_data_gt %>%
   # Reorder the columns in the data frame before passing to gt
  select(
    metric, category, original, 
    linear_imputation,
    linear_imputation_relative,
    mean_imputation, 
    mean_imputation_relative,
    upper_quartile, 
    upper_quartile_relative, 
    bayesian,
    bayesian_relative,
    pmm, 
    pmm_relative,  
    pmm_best,  
    pmm_best_relative,
    rf,
    rf_relative
    ) |> 
  # Set `metric` as row names
  gt() %>%
  data_color(
    columns = ends_with("_relative"), # Target all _relative columns
    method = "numeric", # Use numeric method for gradient mapping
    palette = c(
    "#00FF00", # Bright Green
    "#80FF00", # Light Green
    "#A8FF00", # Lime Green
    "#FFFF00", # Yellow
    "#FFA500", # Orange
    "#FF4500", # Orange-Red
    "#FF0000", # Bright Red
    "#8B0000"  # Dark Red
),
    domain = c(0, 0.40), # Domain for relative differences
    na_color = "#f0f0f0" # Light gray for missing/NA values
  ) %>%
  tab_header(
    title = "Comparison of Imputation Methods Across Metrics",
    subtitle = "Including Original Data and Relative Differences"
  ) %>%
  cols_label(
    original = "Original",
    linear_imputation = "Linear Imputation",
    linear_imputation_relative = "Linear Imputation Relative",
    mean_imputation = "Mean Imputation",
    mean_imputation_relative = "Mean Imputation Relative",
    upper_quartile = "Upper Quartile",
    upper_quartile_relative = "Upper Quartile Relative",
    bayesian = "Bayesian",
    bayesian_relative = "Bayesian Relative",
    pmm = "PMM",
    pmm_relative = "PMM Relative",
    pmm_best = "PMM Best",
    pmm_best_relative = "PMM Best Relative",
    rf = "Random Forest",
    rf_relative = "Random Forest Relative"
    ) %>%
  fmt_number(
    columns = c(original, 
                linear_imputation,
                mean_imputation,
                upper_quartile,
                pmm, 
                pmm_best),
    decimals = 2
  ) %>%
  fmt_number(
    columns = ends_with("_relative"),
    decimals = 3
  ) %>%
  sub_missing(
    columns = ends_with("_relative"),
    missing_text = "NA"
  ) %>%
  tab_options(
    table.font.size = "small",
    column_labels.font.size = "medium"
  )

# Display the table
comparison_gt
```



The visualizations and table provide a comprehensive comparison of the imputation methods applied to silvo and control SE values, using key metrics like mean, range, standard deviation, variance, and Jensen-Shannon divergence (JSD). These metrics assess the performance of imputation methods in preserving the original data's statistical properties and minimizing relative differences.

The **upper quartile** method consistently stands out as a robust imputation technique. It achieves the most balanced performance, demonstrating minimal relative differences in means, standard deviations, and variances while maintaining low JSD values (0.90 for silvo and control SEs). This indicates that the upper quartile method effectively preserves the original data distribution and variability without introducing significant bias or distortion. Its simplicity and stability make it a compelling choice, particularly for datasets with high variability.

**RF (Random Forest)** and **PMM (Predictive Mean Matching)** methods also perform well. RF achieves the lowest relative differences in variances while maintaining competitive JSD values, making it highly effective at preserving data integrity. PMM achieves similar results but exhibits slightly higher variability in some metrics. Notably, **PMM Best**, a refined PMM approach, aligns closely with the upper quartile in most metrics, offering a balance between distributional preservation and methodological rigor.

By contrast, **Bayesian** and **Mean Imputation** methods introduce upward biases in SE means and variances. These methods deviate significantly from the original dataset, as reflected by higher relative differences and JSD scores. While Bayesian imputation excels in maintaining variance stability, it fails to preserve the original SE distributions effectively. Mean imputation, though simple, tends to overestimate SE means, resulting in noticeable divergence from the original data structure.

Overall, the **upper quartile** method emerges as the most reliable and straightforward technique, striking an optimal balance between simplicity, precision, and distributional alignment. RF and PMM are strong alternatives, particularly in scenarios requiring more sophisticated modeling. However, methods like Bayesian and Mean Imputation should be used cautiously due to their tendency to distort key statistical properties. The choice of imputation method should align with the specific analytical goals and dataset characteristics to ensure robust and interpretable results.


Save the comparison gt table
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as HTML
gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.html"))

# Save as PDF
# gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.pdf"))

```


#############
# STEP 5
##########################################################################################################################################
MERGING THE IMPUTED DATASET BACK TO THE ORIGINAL DATA AND VISUALISE
##########################################################################################################################################

```{r}
##############
# MERGING IMPUTED DATA BACK TO THE ORIGINAL DATASET AND VISUALIZING
############################################################################
# Objective:
# Combine the original dataset (`database_clean_sd`) with the imputed dataset 
# (using the PMM imputation method, selected as the most robust approach).
# This allows for a comparison of original vs. imputed values and ensures clarity by keeping columns distinct.

# Merging process
merged_data <- database_clean_sd_df %>%
  full_join(
    # Selecting the PMM imputed dataset:
    imputed_datasets$pmm %>%
      # Keep only relevant imputed columns
      select(id_article, id_obs, silvo_se, control_se), 
    # Merge based on unique identifiers
    by = c("id_article", "id_obs"), 
    # Suffix to distinguish original vs. imputed columns
    suffix = c("_original", "_imputed") 
  ) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_sd, silvo_n, silvo_sd_from_se, silvo_sd_merged, 
    control_mean, control_sd, control_n, control_sd_from_se, control_sd_merged
  )

# Preview the structure of the merged dataset to ensure the merge was successful
glimpse(merged_data)

# Dataset Summary:
# - Rows: 1,126
# - Columns: Updated based on merged dataset

# Additional Context:
# - The PMM method was selected as the most robust imputation method based on:
#   - The lowest total relative differences (31.29%) across silvo and control SEs.
#   - Strong performance in Jensen-Shannon Divergence (JSD) values, with 0.08 for control SEs and 0.44 for silvo SEs, 
#     indicating excellent alignment with the original distribution.
#   - Consistent preservation of key metrics like variance, standard deviation, and range.
#   - A balanced approach that minimizes distortion while preserving the statistical properties of the original data.


# Note:
# The evaluations/assessments of the imputation methods, including relative differences, variance comparisons, 
# and Jensen-Shannon Divergence (JSD), are performed in the subsequent sections below. These assessments 
# substantiate the selection of the PMM method as the best approach for this dataset.

# The merged dataset is now ready for further analysis and visualization, allowing for transparent comparisons between the original and imputed values.
```

```{r}
# Replace missing values in `silvo_se` and `control_se` with imputed values if originals are NA

merged_data <- merged_data %>%
  mutate(
    # For `silvo_se`, check if the original value is missing (NA)
    # If missing, use the imputed value (`silvo_se_imputed`)
    # Otherwise, retain the original value (`silvo_se_original`)
    silvo_se = ifelse(is.na(silvo_se_original), silvo_se_imputed, silvo_se_original),
    
    # For `control_se`, check if the original value is missing (NA)
    # If missing, use the imputed value (`control_se_imputed`)
    # Otherwise, retain the original value (`control_se_original`)
    control_se = ifelse(is.na(control_se_original), control_se_imputed, control_se_original)
  )

# merged_data <- merged_data %>%
#   select(-silvo_se_original, -silvo_se_imputed, -control_se_original, -control_se_imputed)
```

```{r}
# Identify rows where imputation occurred
imputation_evaluation <- merged_data %>%
  filter(
    (is.na(silvo_se_original) & !is.na(silvo_se_imputed)) |
    (is.na(control_se_original) & !is.na(control_se_imputed))
  ) %>%
  select(id_article, id_obs, exp_id) %>%
  distinct()

# Count the number of unique articles where imputation occurred
n_imputed_studies <- imputation_evaluation %>%
  distinct(id_article) %>%
  nrow()

cat("Number of unique articles with imputed values:", n_imputed_studies, "\n")
# Number of unique articles with imputed values: 11 

# Last go (16/01-2025) 
# Number of unique articles with imputed values: 20 
```


```{r}
# Calculate missing counts and proportions
missing_summary <- merged_data %>%
  summarise(
    total_obs = n(),

    # Missing counts for original dataset
    silvo_se_original_missing = sum(is.na(silvo_se_original)),
    control_se_original_missing = sum(is.na(control_se_original)),

    # Missing counts for imputed dataset
    silvo_se_imputed_missing = sum(is.na(silvo_se_imputed)),
    control_se_imputed_missing = sum(is.na(control_se_imputed))
  ) %>%
  mutate(
    # Proportions for original dataset
    silvo_se_original_proportion = silvo_se_original_missing / total_obs,
    control_se_original_proportion = control_se_original_missing / total_obs,

    # Proportions for imputed dataset
    silvo_se_imputed_proportion = silvo_se_imputed_missing / total_obs,
    control_se_imputed_proportion = control_se_imputed_missing / total_obs
  )

missing_summary
```

```{r}
original_data <- database_clean_sd_df %>%
  select(id_article, id_obs, silvo_se, control_se) %>%
  mutate(data_source = "Original")

imputed_data <- merged_data %>%
  select(id_article, id_obs, silvo_se, control_se) %>%
  mutate(data_source = "Imputed")

# Combine original and imputed data
combined_data <- bind_rows(original_data, imputed_data)
```

```{r}
# Check for duplicates
duplicates <- merged_data %>%
  group_by(id_article, id_obs) %>%
  filter(n() > 1)

# Check for rows with imputed values
imputation_check <- merged_data %>%
  filter(is.na(silvo_se_original) & !is.na(silvo_se_imputed))

# View summaries
print(duplicates)
print(imputation_check)
```


##########################################################################################################################################
VISUAL DIAGNOSTIGS OF MERGED DATA WITH SELECTED IMPUTATION METHOD
##########################################################################################################################################

```{r}
# imputed_datasets |> str()
```


```{r}
# imputation_methods <- c("pmm", "upper_quartile", "mean_imputation", "linear_imputation", "rf", "bayesian")

# Combine all imputed datasets with the original data

# Convert 'mids' objects to complete data frames
valid_imputation_methods <- imputed_datasets %>%
  keep(~ !is.null(.)) %>%
  lapply(function(dataset) {
    if (inherits(dataset, "mids")) {
      # Convert mids object to complete data frame
      complete(dataset)
    } else {
      dataset
    }
  })

# Convert the original data to a standard data frame
original_data <- database_clean_sd %>% as.data.frame()

# Combine all valid imputed datasets with the original data
se_comparison_data <- valid_imputation_methods %>%
  lapply(function(imp_data) {
    # Convert imputed data to data.frame if necessary
    imp_data <- imp_data %>%
      as.data.frame() 
    
    # Summarize the original and imputed data by response_variable or other grouping variables
    summarized_data <- original_data %>%
      full_join(
        imp_data %>% select(id_article, id_obs, silvo_se, control_se),
        by = c("id_article", "id_obs"),
        suffix = c("_original", "_imputed")
      ) %>%
      group_by(response_variable) %>%
      summarise(
        silvo_se_original_mean = mean(silvo_se_original, na.rm = TRUE),
        silvo_se_imputed_mean = mean(silvo_se_imputed, na.rm = TRUE),
        control_se_original_mean = mean(control_se_original, na.rm = TRUE),
        control_se_imputed_mean = mean(control_se_imputed, na.rm = TRUE)
      ) %>%
      mutate(
        silvo_diff = abs(silvo_se_original_mean - silvo_se_imputed_mean),
        silvo_rel_diff = if_else(silvo_se_original_mean > 0, 
                                 (silvo_diff / silvo_se_original_mean) * 100, NA_real_),
        control_diff = abs(control_se_original_mean - control_se_imputed_mean),
        control_rel_diff = if_else(control_se_original_mean > 0, 
                                   (control_diff / control_se_original_mean) * 100, NA_real_)
      )
    
    # Return the summarized data
    summarized_data
  })


# Check the structure of one of the resulting datasets
str(se_comparison_data[[1]])
se_comparison_data |> str()
```

```{r}
# Combine all the comparison data into a single dataframe for plotting
se_comparison_combined <- bind_rows(
  lapply(names(se_comparison_data), function(method) {
    se_comparison_data[[method]] %>%
      mutate(imputation_method = method)
  }),
  .id = "method"
)

# Reshape data for plotting relative differences
se_comparison_long <- se_comparison_combined %>%
  select(response_variable, imputation_method, silvo_rel_diff, control_rel_diff) %>%
  pivot_longer(cols = c(silvo_rel_diff, control_rel_diff),
               names_to = "type",
               values_to = "relative_difference")

# Plot relative differences
# Bar chart
se_comparison_plot_mods <- se_comparison_long |> 
  ggplot(aes(x = imputation_method, y = relative_difference, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ response_variable, scales = "free_y") +
  labs(
    title = "Relative Differences Between Original and Imputed SE",
    x = "Imputation Method",
    y = "Relative Difference (%)",
    fill = "SE Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot relative differences with response variables on the x-axis
se_comparison_plot_resp <- se_comparison_long |> 
  ggplot(aes(x = response_variable, y = relative_difference, fill = imputation_method)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ type, scales = "free_y") +
  labs(
    title = "Relative Differences Across Response Variables and Imputation Methods",
    x = "Response Variable",
    y = "Relative Difference (%)",
    fill = "Imputation Method"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the plots
se_comparison_plot_mods
se_comparison_plot_resp
```

Saving the plots of relative differences
```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 80),
    axis.text.x = element_text(size = 80,
                               angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
se_comparison_plot_mods <- se_comparison_plot_mods + theme_custom
se_comparison_plot_resp <- se_comparison_plot_resp + theme_custom


# Save the plots
ggsave(
  filename = file.path(output_dir, "se_comparison_plot_mods.png"),
  plot = se_comparison_plot_mods,
  width = 10, height = 8, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "se_comparison_plot_resp.png"),
  plot = se_comparison_plot_resp,
  width = 10, height = 8, dpi = 600,
  bg = "white"
)
```



```{r}
# Identify the imputation method with the least relative difference
# se_comparison_combined |> str()

# Calculate the mean relative differences for each imputation method
imp_method_summary <- se_comparison_combined %>%
  group_by(imputation_method) %>%
  summarize(
    mean_silvo_rel_diff = mean(silvo_rel_diff, na.rm = TRUE),
    mean_control_rel_diff = mean(control_rel_diff, na.rm = TRUE),
    total_rel_diff = mean_silvo_rel_diff + mean_control_rel_diff
  ) |> 
  arrange(total_rel_diff)

imp_method_summary

# A tibble:7 × 4
# imputation_method
# <chr>
# mean_silvo_rel_diff
# <dbl>
# mean_control_rel_diff
# <dbl>
# total_rel_diff
# <dbl>
# bayesian	23.516743	42.415572	65.93232	
# linear_imputation	16.330035	21.200899	37.53093	
# mean_imputation	15.642138	21.686978	37.32912	
# pmm	10.123358	5.253195	15.37655	
# pmm_best	7.750850	13.484360	21.23521	
# rf	8.349813	8.251046	16.60086	
# upper_quartile	7.409419	7.513123	14.92254	

# Identify the imputation method with the least relative difference
best_imp_method_based_on_se_rel_diff <- imp_method_summary %>%
  arrange(!total_rel_diff) %>%
  slice(1)

# Display the best method
best_imp_method_based_on_se_rel_diff
```

Generate this table as a gt table
```{r}
# imp_method_summary |> str()

# Create a publication-ready gt table
imp_method_real_diff_table <- imp_method_summary %>%
  gt() %>%
  tab_header(
    title = "Comparison of Imputation Methods",
    subtitle = "Relative Differences Across Metrics"
  ) %>%
  fmt_number(
    columns = c(mean_silvo_rel_diff, mean_control_rel_diff, total_rel_diff),
    decimals = 2
  ) %>%
  cols_label(
    imputation_method = "Imputation Method",
    mean_silvo_rel_diff = "Mean Silvo Rel. Diff (%)",
    mean_control_rel_diff = "Mean Control Rel. Diff (%)",
    total_rel_diff = "Total Rel. Diff (%)"
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "lightblue"),
      cell_text(weight = "bold")
    ),
    locations = cells_column_labels(everything())
  ) %>%
  tab_options(
    table.font.size = px(14),  # Adjust font size for readability
    table.width = pct(100)    # Adjust table width
  )

# View the table
print(imp_method_real_diff_table)
```


Based on the analysis, the **PMM (Predictive Mean Matching)** method is the most robust choice for imputing missing values. It delivers the lowest total relative difference (31.29%) by balancing silvo SE (9.54%) and control SE (21.74%) relative differences, ensuring minimal distortion and preserving the dataset's statistical integrity. PMM consistently retains the original data’s variability, as demonstrated by its strong performance across range, standard deviation, and variance metrics.

The **Upper Quartile** method is a strong alternative with a comparable total relative difference of 31.39%. It maintains a balance between silvo (15.59%) and control SE (15.80%) relative differences and excels in preserving variability while avoiding overfitting. Metrics such as range_control_se and range_silvo_se are identical to the original dataset, indicating that Upper Quartile effectively retains the statistical structure.

While **Random Forest (RF)** performs acceptably with a total relative difference of 39.44%, it introduces greater variability in variance and standard deviation metrics. This makes it less favorable compared to PMM and Upper Quartile for applications requiring minimal distortion. Methods like **Bayesian**, **Mean**, and **Linear Imputation** show significantly higher total relative differences (59.76%, 91.84%, and 75.17%, respectively). These methods substantially distort the original data, making them unsuitable for analyses where preservation of data characteristics is essential.

The table further supports PMM’s superior performance in preserving range and variance metrics while minimizing distortion. Metrics such as **var_control_se** and **var_silvo_se** highlight PMM’s alignment with the original data, outperforming more complex approaches like Bayesian Imputation. Additionally, PMM demonstrates excellent distributional alignment, validated by its strong Jensen-Shannon Divergence (JSD) values.

In conclusion, **PMM** is the recommended method due to its minimal distortion, consistency, and robust statistical preservation. The **Upper Quartile** method offers a simpler yet effective alternative, particularly for scenarios prioritizing computational efficiency. Both methods outperform more complex approaches, ensuring high-quality imputations and reliable results for this dataset.










Quality check of imputation using QQ-plot 
```{r}
# Pivot data to long format for easier plotting
qq_imp_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_se, control_se),
    names_to = "variable",
    values_to = "value"
  ) |> 
  mutate(value = ifelse(is.na(value), 0, value)) # Replace NA with 0 (or another strategy if preferred)



# Compute theoretical quantiles and prepare the data for jitter
qq_data_jitter <- qq_imp_data %>%
  group_by(variable, data_source) %>%
  mutate(
    theoretical = qnorm((rank(value, na.last = "keep") - 0.5) / sum(!is.na(value))) # Compute theoretical quantiles
  ) %>%
  ungroup() 


# Enhanced Q-Q plot for publication (with jitter)
# Enhanced Q-Q plot with different point types
qqplot_imp_combined <- qq_data_jitter %>%
  ggplot(aes(x = theoretical, y = value, color = data_source, shape = data_source)) + # Map shape to data_source
  geom_point(
    position = position_jitter(width = 0.1, height = 0.1),
    alpha = 0.9,
    size = 1
  ) + # Adjust jitter, transparency, and size
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black", size = 1) + # Reference line
  facet_wrap(~variable, scales = "free", ncol = 2) + # Adjust layout
  labs(
    title = "Q-Q Plots for Original vs. Imputed Data",
    subtitle = "Assessing Distributional Similarity with Jitter",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles",
    color = "Data Source",
    shape = "Data Source" # Add legend for shape
  ) +
  scale_color_viridis_d(
    option = "D",
    begin = 0.3,
    end = 0.9,
    name = "Data Source"
  ) +
  scale_shape_manual(
    values = c(16, 17) # Specify shapes: 16 (solid circle), 17 (triangle)
  ) +
  guides(
    color = guide_legend(override.aes = list(size = 3)), # Increase color legend point size
    shape = guide_legend(override.aes = list(size = 3))  # Increase shape legend point size
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5), # Centered title
    plot.subtitle = element_text(size = 14, face = "italic", hjust = 0.5), # Italicized subtitle
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = "bold"),
    strip.text = element_text(size = 14, face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 12)
  )


qqplot_imp_combined
```


Saving QQ-plot

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
qqplot_imp_combined <- qqplot_imp_combined + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "qqplot_imp_combined_enhanced.png"),
  plot = qqplot_imp_combined,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```



Again, checking the imputed control_se and silvo_se density distribution (imputation = upper quartile)
```{r}
# Combine the data for silvo_se and control_se into long format
density_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_se, control_se),
    names_to = "variable",
    values_to = "value"
  )

# Filter out non-positive values for log transformation
density_data_clean <- density_data %>%
  filter(value > 0) # Keep only positive values

# Improved density plot with custom x-axis labels
density_plot_clean <- density_data_clean %>%
  ggplot(aes(x = value, color = data_source, fill = data_source)) +
  geom_density(alpha = 0.4, na.rm = TRUE) + # Add density plot with transparency
  scale_x_log10(
    breaks = scales::trans_breaks("log10", function(x) 10^x), # Define breaks at log10 intervals
    labels = scales::trans_format("log10", scales::math_format(10^.x)) # Format labels as 10^x
  ) +
  labs(
    title = "Density Distribution of silvo_se and control_se (Log-Transformed)",
    x = "Value (Log Scale)",
    y = "Density",
    color = "Data Source",
    fill = "Data Source"
  ) +
  facet_wrap(~variable, scales = "free_x", ncol = 2) + # Separate plots for silvo_se and control_se
  scale_color_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "bottom"
  )

# Display the density plot
density_plot_clean
```

Save density distribution plot of imputed control_se and silvo_se

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
density_plot_clean <- density_plot_clean + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "density_plot_clean.png"),
  plot = density_plot_clean,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```











```{r}
merged_data |> glimpse()
```









#############
# STEP 6
##########################################################################################################################################
SAVING TWO VERSIONS OF PREPROCESSED DATA FOR FURTHER ANALYSIS AND VISUALIZATION - RECALCULATION OF _SD WHERE THE ORIGINAL _SD IS MISSING
##########################################################################################################################################

```{r}
# Imputed dataset where _se is imputed and then subsequently used to calculate _sd
imp_pmm_best <- merged_data |> 
  as.data.frame() |> 
  # Modify the imp_pmm_best dataset before saving
  # Remove existing columns
  select(-c(control_se, silvo_se)) |>  
  rename(
    # Rename control_sd to control_sd_original
    control_sd_original = control_sd,
    # Rename silvo_sd to silvo_sd_original
    silvo_sd_original = silvo_sd,
    # Rename control_se_imputed to control_se
    control_se_imputed = control_se_imputed, 
    # Rename silvo_se_imputed to silvo_se
    silvo_se_imputed = silvo_se_imputed      
  ) |> 
  as.data.frame()|> 
  # RECALCULATE STANDARD DEVIATION FOR IMPUTED DATASET WITH CONDITIONAL RULE
  mutate(
    # Calculate standard deviation for silvo group only if silvo_sd_merged is NA
    silvo_sd_from_imputed_se = ifelse(is.na(silvo_sd_merged), silvo_se_imputed * sqrt(silvo_n), NA),
    # Calculate standard deviation for control group only if control_sd_merged is NA
    control_sd_from_imputed_se = ifelse(is.na(control_sd_merged), control_se_imputed * sqrt(control_n), NA),
  ) |> 
   # COMBINE _sd_final AND _sd_from_imputed_se WITH _sd_final TAKING PRECEDENCE
  mutate(
    silvo_sd_combined = ifelse(is.na(silvo_sd_merged), silvo_sd_from_imputed_se, silvo_sd_merged),
    control_sd_combined = ifelse(is.na(control_sd_merged), control_sd_from_imputed_se, control_sd_merged)
  ) |> 
  # Relocate columns to the desired order 
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_n, silvo_se_original, silvo_sd_original, 
    silvo_sd_from_se, silvo_sd_merged, silvo_sd_from_imputed_se, silvo_sd_combined,
    control_mean, control_n, control_se_original, control_sd_original, 
    control_sd_from_se, control_sd_merged, control_sd_from_imputed_se, control_sd_combined, 
  )
```

```{r}
database_clean_sd |> glimpse()
```


```{r}
# Non-imputed dataset (remove geometry if necessary)
non_imp_dataset <- database_clean_sd |> 
  as.data.frame() |> 
  select(-geometry) |> 
  # Rename existing _sd columns to _sd_original
  rename(
    silvo_se_original = silvo_se,
    control_se_original = control_se,
    silvo_sd_original = silvo_sd,
    control_sd_original = control_sd
  ) |> 
  # RECALCULATE STANDARD DEVIATION USING EXISTING _se VALUES ONLY
  mutate(
    # Calculate standard deviation for silvo group only if silvo_sd_merged is NA
    silvo_sd_from_se = ifelse(is.na(silvo_sd_merged), silvo_se_original * sqrt(silvo_n), NA),
    # Calculate standard deviation for control group only if control_sd_merged is NA
    control_sd_from_se = ifelse(is.na(control_sd_merged), control_se_original * sqrt(control_n), NA)
  ) |> 
  # COMBINE _sd_merged AND _sd_CALCULATED_FROM_SE WITH _sd_merged TAKING PRECEDENCE
  mutate(
    silvo_sd_combined = ifelse(is.na(silvo_sd_merged), control_sd_from_se, silvo_sd_merged),
    control_sd_combined = ifelse(is.na(control_sd_merged), control_sd_from_se, control_sd_merged)
  ) |>  
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_n, silvo_se_original, silvo_sd_original, silvo_sd_from_se, silvo_sd_merged, silvo_sd_combined,
    control_mean, control_n, control_se_original, control_sd_original, control_sd_from_se, control_sd_merged, control_sd_combined
  )

# Preview the dataset structure silvo_sd_calculated_from_se
glimpse(non_imp_dataset)
```



```{r}
# Calculate standard deviations from standard errors and sample sizes
# Workflow for Calculating _SD with Comprehensive Conditions
```












```{r}
# Visualize differences in categorical distributions
inspect_cat(imp_pmm_best, non_imp_dataset) %>% show_plot()

# Visualize differences in numerical distributions
# Select numeric columns
imp_pmm_best_numeric <- imp_pmm_best %>% select(where(is.numeric))
non_imp_dataset_numeric <- non_imp_dataset %>% select(where(is.numeric))

# Check column counts
if (ncol(imp_pmm_best_numeric) == 0 || ncol(non_imp_dataset_numeric) == 0) {
  stop("One or both datasets have no numeric columns to compare.")
}

# Custom function to filter columns with valid variance
filter_valid_columns <- function(df) {
  df %>% select(where(~ !all(is.na(.)) && var(., na.rm = TRUE) > 0))
}

# Apply the filter to remove problematic columns
imp_pmm_best_numeric <- filter_valid_columns(imp_pmm_best_numeric)
non_imp_dataset_numeric <- filter_valid_columns(non_imp_dataset_numeric)

# Combine datasets for comparison
imp_pmm_best_numeric$dataset <- "imputed"
non_imp_dataset_numeric$dataset <- "non-imputed"
combined_data <- bind_rows(imp_pmm_best_numeric, non_imp_dataset_numeric)

# Melt into long format for ggplot
combined_long <- combined_data %>%
  pivot_longer(cols = -dataset, names_to = "variable", values_to = "value")

# Plot distributions for all variables
ggplot(combined_long, aes(x = value, fill = dataset)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~variable, scales = "free") +
  labs(title = "Density Plots for Numeric Variables", x = "Value", y = "Density") +
  theme_minimal()

# Check for column-wise similarity
inspect_cor(imp_pmm_best, non_imp_dataset) %>% show_plot()

# Missingness comparison
inspect_na(imp_pmm_best, non_imp_dataset) %>% show_plot()
```


```{r}
# SAVING TWO VERSIONS OF PREPROCESSED DATA AS RDS

# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save the non-imputed dataset as RDS
saveRDS(non_imp_dataset,
        file = file.path(output_dir, "non_imp_dataset.rds"))


# Save the best-imputed dataset as RDS
saveRDS(imp_pmm_best,
        file = file.path(output_dir, "imp_pmm_best_dataset.rds"))

# Print confirmation messages
cat("Datasets saved successfully:\n")
cat("- Non-imputed dataset: non_imp_dataset.rds\n")
cat("- Best-imputed dataset: imp_pmm_best_dataset.rds\n")
```





#############
# STEP 7
##########################################################################################################################################
CALCULATING EFFECT SIZES FOR IMPUTED AND NON-IMPUTED DATASETS
##########################################################################################################################################

Loading datasets
```{r}
# Load the non-imputed and imputed datasets
non_imp_dataset <- readRDS(file.path(output_dir, "non_imp_dataset.rds"))

# Load the imputed dataset
imp_pmm_best <- readRDS(file.path(output_dir, "imp_pmm_best_dataset.rds"))
```



```{r}
non_imp_dataset |> glimpse()
imp_pmm_best |> glimpse()
```




##########################################################################################################################################
EFFECT SIZE CALCULATION
##########################################################################################################################################

```{r}
# Function for data preparation and effect size calculation

# This function takes a dataset as input and applies several transformations
# to clean, filter, and prepare it for effect size calculation.
prep_dataset_for_rom <- function(data) {
  data %>%
    # Step 1: Filter out rows where the standard errors are zero or negative
    # - Standard errors (SE) must be positive for valid statistical calculations.
    # - Removing these rows prevents mathematical errors in subsequent calculations (e.g., division by zero).
    filter(silvo_sd_combined > 0, control_sd_combined > 0) %>%
    
    # Step 2: Adjust the sign of mean values for specific response variables
    # - For variables like "Greenhouse gas emissions," "Pests and Diseases," and "Water quality,"
    #   lower values are considered better (e.g., lower emissions or fewer pests).
    # - We negate the mean values to reflect this interpretation correctly.
    mutate(
      silvo_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"),
                          -silvo_mean, silvo_mean),
      control_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"),
                            -control_mean, control_mean)
    ) %>%
    
    # Step 3: Exclude specific response variables from analysis
    # - "Soil water content" is excluded due to inconsistent data or limited measurements.
    filter(response_variable != "Soil water content") %>%
    
    # Step 4: Remove rows with missing values in key columns
    # - Ensures that the data is complete for effect size calculation.
    # - Excludes rows where any of the following are missing: mean, sample size, or standard error for both groups.
    # filter(!is.na(silvo_mean) & !is.na(control_mean) &
    #        !is.na(silvo_n) & !is.na(control_n) &
    #        !is.na(silvo_se_original) & !is.na(control_se_original)) %>%
    
    # Step 6: Shift mean values to be positive
    # - We calculate a shift value (min_value_shift) based on the absolute minimum value
    #   of the means, ensuring all values are positive.
    # - This shift is necessary for certain transformations (e.g., log transformations),
    #   which require positive inputs.
    mutate(
      min_value_shift = abs(min(c(silvo_mean, control_mean), na.rm = TRUE)) + 1,
      # Apply the shift to the mean values for both groups
      silvo_mean = silvo_mean + min_value_shift,
      control_mean = control_mean + min_value_shift
    ) %>%
    
    # Step 6: Reorder columns for better readability and organization
    # - Places important columns (e.g., identifiers, means, SEs, SDs, sample sizes) at the front of the data frame.
    relocate(id_article, response_variable, measured_metrics, measured_unit,
             silvo_mean, silvo_n, silvo_se_original, silvo_sd_combined,
             control_mean, control_n, control_se_original, control_sd_combined) %>%
    
    # Step 7: Sort the data by article ID and response variable for consistency
    # - Sorting helps ensure that the data is organized and facilitates easier inspection and analysis.
    arrange(id_article, response_variable)
}
```

```{r}
# Apply the data preparation function to both non-imputed and imputed datasets
# - This creates cleaned and prepared datasets for effect size calculation.
non_imp_data_prep <- prep_dataset_for_rom(non_imp_dataset)
imp_data_prep <- prep_dataset_for_rom(imp_pmm_best)
```

```{r}
# Verify consistency between imputed _se and recalculated _sd
verify_sd_calculation <- function(data) {
  data <- data %>%
    mutate(
      recalculated_silvo_sd = silvo_se_original * sqrt(silvo_n),
      recalculated_control_sd = control_se_original * sqrt(control_n),
      silvo_sd_diff = abs(silvo_sd_combined - recalculated_silvo_sd),
      control_sd_diff = abs(control_sd_combined - recalculated_control_sd)
    ) %>%
    filter(silvo_sd_diff > 1e-5 | control_sd_diff > 1e-5) # Filter rows with differences

  return(data)
}

# Apply to both non-imputed and imputed datasets
non_imp_inconsistencies <- verify_sd_calculation(non_imp_data_prep)
imp_inconsistencies <- verify_sd_calculation(imp_data_prep)

# Visualize inconsistencies (if any)
list(
  non_imputed = non_imp_inconsistencies,
  imputed = imp_inconsistencies
)

```


```{r}
# Generic function for effect size calculation using `escalc()`

# This function can be applied to both imputed and non-imputed datasets.

calculate_effect_sizes <- function(data, measure = "ROM") {
  # Check if the required columns are present in the dataset
  required_columns <- c("silvo_mean", "silvo_sd_combined", "silvo_n",
                        "control_mean", "control_sd_combined", "control_n",
                        "id_article", "experiment_year")
  
  if (!all(required_columns %in% names(data))) {
    stop("The dataset is missing one or more required columns.")
  }
  
  # Calculate effect sizes using `escalc()`
  result <- escalc(
    measure = measure,           # Specify the effect size measure (default is "ROM").
    
    # Experimental group (silvo_) parameters:
    m1i = silvo_mean,            # Mean of the experimental (silvo) group.
    sd1i = silvo_sd_combined,    # Standard deviation of the experimental (silvo) group.
    n1i = silvo_n,               # Sample size of the experimental (silvo) group.
    
    # Control group (control_) parameters:
    m2i = control_mean,          # Mean of the control group.
    sd2i = control_sd_combined,  # Standard deviation of the control group.
    n2i = control_n,             # Sample size of the control group.
    
    # Study labels for identification:
    slab = paste(id_article, ", ", experiment_year, sep = ""),
    
    # The input dataset:
    data = data
  ) %>%
    as.data.frame()              # Convert the result to a data frame for easier handling.
  
  # Return the resulting data frame with calculated effect sizes
  return(result)
}
```

```{r}
# Inspect the input data to `escalc()`
imp_data_prep %>%
  select(id_article, response_variable, 
         silvo_mean, silvo_n, silvo_sd_combined, 
         control_mean,  control_n, control_sd_combined) %>%
  filter(is.na(silvo_sd_combined) | is.na(control_sd_combined) | silvo_sd_combined <= 0 | control_sd_combined <= 0)
```

```{r}
# Apply the function to both non-imputed and imputed datasets

non_imp_data_rom <- calculate_effect_sizes(non_imp_data_prep,
                                           # SMD (Standardized Mean Difference)
                                           # ROM (Log-Transformed Ratio)
                                           measure = "ROM") 

imp_data_rom <- calculate_effect_sizes(imp_data_prep,
                                       # SMD (Standardized Mean Difference)
                                       # ROM (Log-Transformed Ratio)
                                       measure = "ROM")
```

```{r}
imp_data_rom |> glimpse()
```

```{r}
# Create the boxplot for the effect size (yi)
# Order response variables by descending median effect size
imp_data_rom_reorder <- imp_data_rom %>%
  mutate(response_variable = fct_reorder(response_variable, yi, .fun = median, .desc = FALSE))

# Create the boxplot with ordered response variables
boxplot_raw_effect_size <- imp_data_rom_reorder |> 
  ggplot(aes(y = response_variable, x = yi, fill = response_variable)) +
  geom_vline(xintercept = 0, linetype = "dotted", color = "red", size = 0.8) + # Add red dotted line at x = 0
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  labs(
    title = "Raw Effect Sizes (yi) Across Response Variables",
    x = "Raw Effect Size (yi)",
    y = "Response Variable"
  ) +
  scale_x_continuous(
    trans = pseudo_log_trans(sigma = 0.1), # Apply pseudo-log transformation
    breaks = c(0, 0.1, 1, 10, 100),       # Custom breaks
    labels = c("0", "0.1", "1", "10", "100") # Relatable labels
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 12), # Adjust y-axis text size
    axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels
    legend.position = "none"
  )

boxplot_raw_effect_size

```


Save raw effect size plot of each response variable

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.position = "none",
    axis.text.x = element_text(size = 100,
                               angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
boxplot_raw_effect_size <- boxplot_raw_effect_size + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "boxplot_raw_effect_size.png"),
  plot = boxplot_raw_effect_size,
  width = 16, height = 8, dpi = 600,
  bg = "white"
)
```



```{r}
# Prepare the data for plotting
data_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(
    cols = c(control_mean, silvo_mean),
    names_to = "Group",
    values_to = "Mean"
  )

# Create the boxplot with a log-transformed y-axis
ggplot(data_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  facet_wrap(~ response_variable, scales = "free") +
  labs(
    title = "Comparison of Mean Values for Control and Silvo Groups by Response Variable (Log Scale)",
    x = "Group",
    y = "Mean Value (Log Scale)"
  ) +
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )
```

```{r}
# Boxplot comparison for control and silvo groups
imp_data_rom_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(cols = c(control_mean, silvo_mean), names_to = "Group", values_to = "Mean")

ggplot(imp_data_rom_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ response_variable, scales = "free") +  # Facet by response variable
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  labs(
    title = "Distribution of Means for Control and Silvo Groups",
    x = "Group",
    y = "Mean Value"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")
```



Identify Extreme Variances
For response variables like "Crop yield" with extreme variances, identify rows with unusually high or low values in the variance column (vi).

```{r}
# Summary statistics for variance
summary(imp_data_rom$vi)

# Identify rows with extreme variances
extreme_variance_rows <- imp_data_rom %>%
  filter(vi > quantile(vi, 0.95) #| vi < quantile(vi, 0.05)
         ) %>%
  arrange(desc(vi)) |> 
  relocate(yi, vi, id_article, response_variable,
           silvo_mean, control_mean, 
           silvo_se_original, control_se_original,
           silvo_sd_combined, control_sd_combined, 
           silvo_n, control_n)

extreme_variance_rows |> str()

# Set high and low variance thresholds (e.g., 99th and 1st percentiles)
high_variance_threshold <- quantile(imp_data_rom$vi, 0.99, na.rm = TRUE)
low_variance_threshold <- quantile(imp_data_rom$vi, 0.01, na.rm = TRUE)

# Filter rows with extreme variances
extreme_variance_articles <- imp_data_rom %>%
  filter(vi > high_variance_threshold #| vi < low_variance_threshold
         ) %>%
  summarise(
    num_obs = n(),
    avg_variance = mean(vi, na.rm = TRUE),
    max_variance = max(vi, na.rm = TRUE),
    min_variance = min(vi, na.rm = TRUE),
    response_variables = paste(unique(response_variable), collapse = ", ")
  ) %>%
  arrange(desc(avg_variance))

# Display the summary of articles with high variance
extreme_variance_articles |> str()

extreme_variance_rows
```
```{r}
# Identify high-variance observations
high_variance_rows <- imp_data_rom %>%
  filter(vi > quantile(vi, 0.99, na.rm = TRUE)) %>%
  select(yi, vi,
         id_obs, id_article, response_variable, 
         silvo_mean, control_mean, 
         silvo_se_original, control_se_original,
         silvo_sd_combined, control_sd_combined, 
         silvo_n, control_n)

high_variance_row_isolated <- high_variance_rows |> 
  relocate(yi, vi, id_article, id_obs, response_variable,
           silvo_mean, control_mean, 
           silvo_se_original, control_se_original,
           silvo_sd_combined, control_sd_combined, 
           silvo_n, control_n)

high_variance_row_isolated |> glimpse()
```

```{r}
# Define thresholds for high and non-high variance
high_variance_threshold <- stats::quantile(imp_data_rom$vi, 0.99, na.rm = TRUE)
low_variance_threshold <- stats::quantile(imp_data_rom$vi, 0.01, na.rm = TRUE)

# Create separate datasets
high_variance_data <- imp_data_rom %>%
  filter(vi > high_variance_threshold | vi < low_variance_threshold)

non_high_variance_data <- imp_data_rom %>%
  filter(!(vi > high_variance_threshold | vi < low_variance_threshold))
```

```{r}
# Plot for high variance
high_variance_plot <- ggplot(high_variance_data, aes(x = id_article, y = vi, fill = response_variable)) +
  geom_boxplot(outlier.color = "red", alpha = 0.7) +
  labs(title = "High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  # Remove legend for better visualization
  theme(legend.position = "none")

# Plot for non-high variance
non_high_variance_plot <- ggplot(non_high_variance_data, aes(x = id_article, y = vi, fill = response_variable)) +
  geom_boxplot(outlier.color = "blue", alpha = 0.7) +
  labs(title = "Non-High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Combine plots side by side
combined_plot <- high_variance_plot + non_high_variance_plot + 
  plot_layout(ncol = 2)

# Display the combined plot
print(combined_plot)
```

```{r}
# High variance plot for individual observations with increased jitter
high_variance_plot <- ggplot(high_variance_data, aes(x = as.factor(id_article), y = vi, color = response_variable)) +
  geom_point(position = position_jitter(width = 0.3, height = 0), size = 3, alpha = 0.7) +
  geom_text_repel(
    aes(label = id_obs),
    position = position_jitter(width = 0.3, height = 3),
    size = 3,
    max.overlaps = Inf
  ) +
  labs(
    title = "High Variance Observations (Individual, Jittered)",
    x = "Article ID",
    y = "Variance (vi) [pseudo log transformed]",
    color = "Response Variable"
  ) +
  scale_color_manual(values = global_palette) +
  scale_y_continuous(
    trans = pseudo_log_trans(sigma = 0.1),
    breaks = c(0, 0.1, 1, 10, 30),
    labels = c("0", "0.1", "1", "10", "30")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Non-high variance plot with aggregated boxplots
non_high_variance_plot <- ggplot(non_high_variance_data, aes(x = as.factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.color = "blue", alpha = 0.7) +
  labs(
    title = "Non-High Variance Observations (Boxplots)",
    x = "Article ID",
    y = "Variance (vi) [pseudo log transformed]",
    fill = "Response Variable"
  ) +
  scale_fill_manual(values = global_palette) +
  scale_y_continuous(
    trans = pseudo_log_trans(sigma = 0.1),
    breaks = c(0, 0.01, 0.1, 1),
    labels = c("0", "0.01", "0.1", "1")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Combine the two plots
combined_plot_high_var_plot <- high_variance_plot + non_high_variance_plot +
  plot_layout(ncol = 2, widths = c(1, 1)) &
  theme(
    plot.margin = margin(10, 10, 10, 10)
  )

# Display the combined plot
print(combined_plot_high_var_plot)
```

Save the high-variance plot
```{r}
# Saving manually from the 'Plots -> Export -> Save as image -> dimension (2000::800)'
```

```{r}
# Calculate variance contributions from SE columns
extreme_variance_analysis <- extreme_variance_rows %>%
  mutate(
    silvo_variance = silvo_se_original^2 / silvo_n,        # Variance from silvo SE
    control_variance = control_se_original^2 / control_n,  # Variance from control SE
    total_pre_escalc_variance = silvo_variance + control_variance  # Combined variance
  ) %>%
  arrange(desc(vi)) %>%  # Sort by high vi
  select(
    yi, vi, id_article, response_variable,
    silvo_mean, control_mean, 
    silvo_se_original, control_se_original, silvo_sd_combined, control_sd_combined, 
    silvo_n, control_n, total_pre_escalc_variance, silvo_variance, control_variance
  )

extreme_variance_analysis |> glimpse()
```

```{r}
discrepancies <- extreme_variance_analysis %>%
  mutate(discrepancy = vi - total_pre_escalc_variance) %>%
  arrange(desc(discrepancy))

print(discrepancies)
```
```{r}
extreme_se <- extreme_variance_analysis %>%
  filter(silvo_se_original > quantile(silvo_se_original, 0.75) | control_se_original > quantile(control_se_original, 0.75))

print(extreme_se)
```
```{r}
# Recompute vi for rows with high variance
recomputed_vi <- escalc(
  measure = "ROM", 
  m1i = silvo_mean, sd1i = silvo_sd_combined, n1i = silvo_n,
  m2i = control_mean, sd2i = control_sd_combined, n2i = control_n,
  data = extreme_variance_analysis
)

# Compare recomputed vi with original vi
comparison <- extreme_variance_analysis %>%
  mutate(recomputed_vi = recomputed_vi$vi) %>%
  select(yi, vi, recomputed_vi, total_pre_escalc_variance)

print(comparison)
```









####################################################################################################################################################

Heterogeneity Analysis
Compare the heterogeneity statistics between the meta-analyses conducted on the imputed and non-imputed datasets. This will help you understand if the imputation has influenced the heterogeneity of the studies.
####################################################################################################################################################

```{r}
# Prepare the original data
original_data_x <- non_imp_data_rom %>%
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
         silvo_se_original, control_se_original, yi, vi) |> 
  mutate(data_source = "Original") |> 
  as.data.frame() 

imputed_data_y <- imp_data_rom |> 
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
         silvo_se_imputed, control_se_imputed, yi, vi) |> 
  mutate(data_source = "Imputed") 

# Combine the original and imputed data
combined_data <- bind_rows(original_data_x, imputed_data_y)

# Join the original and imputed data to directly compare
comparison_data <- original_data_x %>%
  full_join(imputed_data_y, by = c("id_article", "exp_id", "id_obs", "response_variable"), 
            suffix = c("_original", "_imputed")) %>%
  distinct()

# Advarsel: Detected an unexpected many-to-many relationship between `x` and `y`.

comparison_data |> glimpse()
```

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################


# Fit random-effects models on both datasets
rma_non_imp <- rma(yi = yi_original, vi = vi_original, data = comparison_data)
rma_imp <- rma(yi = yi_imputed, vi = vi_imputed, data = comparison_data)

# Print heterogeneity statistics
cat("Non-Imputed Data - Heterogeneity (I^2):", rma_non_imp$I2, "\n")
cat("Non-Imputed Data - Between-study variance (tau^2):", rma_non_imp$tau2, "\n")

cat("Imputed Data - Heterogeneity (I^2):", rma_imp$I2, "\n")
cat("Imputed Data - Between-study variance (tau^2):", rma_imp$tau2, "\n")

##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
time.taken
##############################################################
# Last go (02/12-2024)
# Time difference of 4.055149 secs
# Advarsel: 186 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 10.13463 
# Non-Imputed Data - Between-study variance (tau^2): 1.468685e-06 
# Imputed Data - Heterogeneity (I^2): 99.93572 
# Imputed Data - Between-study variance (tau^2): 0.009922055 
# Time difference of 4.055149 secs

# Last go (01/01-2025)
# Time difference of 5.424392 secs
# Advarsel: 176 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.93018 
# Imputed Data - Between-study variance (tau^2): 0.01053153 
# Time difference of 5.424392 secs

# Last go (02/01-2025)
# Time difference of 6.113353 secs
# Advarsel: 177 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.93201 
# Imputed Data - Between-study variance (tau^2): 0.01083873 
# Time difference of 6.113353 secs

# Last go (04/01-2025)
# Advarsel: 212 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.89571 
# Imputed Data - Between-study variance (tau^2): 0.0174592 
# Time difference of 10.74234 secs

# Last go (04/01-2025)
# Advarsel: 184 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.93201 
# Imputed Data - Between-study variance (tau^2): 0.01006262 
# Time difference of 5.507228 secs


# Last go (12/01-2025)
# Advarsel: 184 studies with NAs omitted from model fitting.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 9.354748 
# Non-Imputed Data - Between-study variance (tau^2): 1.438406e-06 
# Imputed Data - Heterogeneity (I^2): 99.93201 
# Imputed Data - Between-study variance (tau^2): 0.01006262 
# Time difference of 3.647738 secs

# Last go (16/01-2025)
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Non-Imputed Data - Heterogeneity (I^2): 15.35531 
# Non-Imputed Data - Between-study variance (tau^2): 2.04823e-06 
# Imputed Data - Heterogeneity (I^2): 15.35531 
# Imputed Data - Between-study variance (tau^2): 2.04823e-06 
# Time difference of 0.9310322 secs
```
 
 
 
Kolmogorov-Smirnov Test
The Kolmogorov-Smirnov (KS) test can be used to compare the distributions of effect sizes.

```{r}
# Kolmogorov-Smirnov test
ks_test_result <- ks.test(non_imp_data_rom$yi, imp_data_rom$yi)
print(ks_test_result)

# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.040734, p-value = 0.4179
# alternative hypothesis: two-sided

# Last go (01/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.030426, p-value = 0.7468
# alternative hypothesis: two-sided

# Last go (02/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.031966, p-value = 0.6897
# alternative hypothesis: two-sided

# Last go (04/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.025547, p-value = 0.897
# alternative hypothesis: two-sided

# Last go (05/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.032653, p-value = 0.6621
# alternative hypothesis: two-sided

# Last go (12/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.032653, p-value = 0.6621
# alternative hypothesis: two-sided

# Last go (16/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.033209, p-value = 0.6425
# alternative hypothesis: two-sided
```

The Kolmogorov-Smirnov (KS) test was used to compare the distributions of effect sizes (ROM) between the non-imputed and imputed datasets. The test yielded a statistic \(D = 0.0332\) with a p-value of 0.6425, indicating no significant difference between the two distributions. This suggests that the imputed and non-imputed datasets share similar underlying distributions, and the null hypothesis cannot be rejected. While the warning regarding approximate p-values due to ties in the data highlights a potential limitation, the test results remain robust in confirming the alignment between the distributions.

Heterogeneity and between-study variance metrics, however, reveal substantial differences between the two datasets. The non-imputed dataset exhibited low heterogeneity (\(I^2 = 19.85\%\)) and minimal between-study variance (\(\tau^2 = 2.78 \times 10^{-6}\)), indicating limited variability among studies. Conversely, the imputed dataset showed extremely high heterogeneity (\(I^2 = 99.98\%\)) and a substantially increased between-study variance (\(\tau^2 = 0.0168\)). These results suggest that the imputation process introduced significant additional variability, altering the structure of the dataset.

The warnings about large ratios of the smallest to largest sampling variances underscore potential instability in the meta-analytic models, particularly for the imputed dataset. This issue is common in meta-analyses and emphasizes the importance of cautious interpretation, especially when variability in sampling variances is pronounced.

The KS test results confirm that the imputation process preserved the overall distribution of effect sizes. However, the sharp increase in heterogeneity and between-study variance in the imputed dataset indicates that imputation introduced considerable variability. This discrepancy highlights the need for transparency in reporting and careful sensitivity analyses to assess the potential impact of imputation on meta-analytic results.

Overall, while the imputation process successfully maintained the original distributional properties of effect sizes, the increased variability in the imputed dataset warrants careful interpretation of findings. Reporting these differences and conducting sensitivity analyses will help ensure the robustness and reliability of the conclusions drawn from the meta-analysis.
 
```{r}
# Descriptive statistics for non-imputed data
summary_non_imp <- non_imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Descriptive statistics for imputed data
summary_imp <- imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Print summaries
summary_non_imp
summary_imp

# Last go (12/01-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02767394	0.003205885	0.2501374		
# 
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02423623	0.00187394	0.2387344		

# Last go (16/01-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02767394	0.003205885	0.2501374
# 
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.0237652	0.00181963	0.2388941	
```
 
```{r}
# Density plot for non-imputed data
density_plot_non_imp <- ggplot(non_imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Density Plot: Non-Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Density plot for imputed data
density_plot_imp <- ggplot(imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Density Plot: Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Boxplot for non-imputed data
boxplot_non_imp <- ggplot(non_imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Boxplot: Non-Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Boxplot for imputed data
boxplot_imp <- ggplot(imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Boxplot: Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = pseudo_log_trans(sigma = 0.1))

# Arrange the plots in a 2x2 layout
(density_plot_non_imp | boxplot_non_imp) /
(density_plot_imp | boxplot_imp)

```


##########################################################################################################################################
ASSESSING CORRELATION BETWEEN RESPONSE VARIABLES
##########################################################################################################################################

```{r}
non_imp_data_rom |> glimpse()
imp_data_rom |> glimpse()
```

```{r}
##########################################################################
# Visual Diagnostics for Predictor Redundancy and Model Fit
##########################################################################

# Set up data
# Testing on the imputed dataset
moderators_data <- imp_data_rom %>%
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>%
  as.data.frame()

##########################################################################
# Fit a linear model with moderators
##########################################################################

lm_model <- lm(yi ~ tree_type + crop_type + age_system + season + soil_texture, 
               data = imp_data_rom)
```

```{r}
##########################################################################
# 1. Correlation Analysis
##########################################################################
# Convert categorical variables to numeric for correlation matrix
moderators_numeric <- model.matrix(~ . + 0, data = moderators_data) %>% as.data.frame()

# Calculate correlation matrix
cor_matrix <- cor(moderators_numeric, use = "pairwise.complete.obs")

# Visualize correlation matrix
corrplot::corrplot(cor_matrix, method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45, title = "Correlation Matrix of Moderators")
```

```{r}
##########################################################################
# 2. Variance Inflation Factor (VIF)
##########################################################################

# Calculate VIF for predictors
vif_values <- car::vif(lm_model)

# Print VIF values
print(vif_values)

# Plot VIF values
barplot(vif_values, main = "Variance Inflation Factors (VIF)",
        col = "blue", horiz = TRUE, las = 1, xlab = "VIF Value")
```

The Variance Inflation Factor (VIF) helps identify if predictors in a regression model are too similar or correlated with each other. When predictors are highly related, it can make it difficult to determine the individual impact of each predictor, as their effects overlap. VIF measures how much the variance of a predictor's coefficient is inflated due to this overlap.

For categorical variables with multiple levels, the Generalized VIF (GVIF) is used. GVIF adjusts for the number of levels in a categorical variable, providing a way to compare them with other predictors. A scaled version of GVIF helps interpret these adjusted values more easily.

In this analysis, the predictors all have low VIF values. The largest adjusted GVIF is 1.17 for soil texture, which is far below the commonly used thresholds of 5 or 10 for concern. This indicates there is no significant multicollinearity among the predictors, meaning they are not overly correlated with one another.

Since none of the predictors exhibit high VIF values, no corrective actions are needed, such as removing variables or combining them into fewer components. The predictors are providing independent and valuable information to the model, and the results can be interpreted without concerns about redundancy or instability.

In summary, the VIF analysis confirms that the model's predictors are sufficiently independent and do not cause issues with multicollinearity. This ensures the model's results are clear, reliable, and interpretable.






```{r}
# Convert categorical variables to factors (if not already factors)
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor))

# Create dummy variables for categorical predictors
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%  # -1 to exclude the intercept
  as.data.frame()

# Calculate pairwise correlations
correlation_matrix <- cor(predictors_numeric, use = "pairwise.complete.obs")

# Visualize the correlation matrix
corrplot::corrplot(correlation_matrix, method = "circle")

# Visualize correlations with a heatmap
heatmap(correlation_matrix, symm = TRUE)

# PCA
pca_results <- prcomp(predictors_numeric, scale. = TRUE)
summary(pca_results)
biplot(pca_results)
```

```{r}
# Convert categorical variables to factors and create dummy variables
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor))

# Create numeric predictors with dummy variables
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%
  as.data.frame()

# Ensure the response is aligned with predictors
# Keep only rows where both predictors and response are not missing
aligned_data <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width, yi) %>%
  drop_na()

# Split aligned data into predictors and response
predictors_numeric <- model.matrix(~ . - 1, data = aligned_data %>% 
                                     select(-yi)) %>% 
  as.data.frame()


response_filled <- aligned_data$yi

# Fit the Random Forest model
library(randomForest)
rf_model <- randomForest(x = predictors_numeric, y = response_filled, importance = TRUE)

# Display feature importance
varImpPlot(rf_model)
```

The results from the random forest analysis and the correlation matrix provide insight into how the predictors (tree type, crop type, age system, season, and soil texture) influence the variability in your dataset and how they relate to each other.

The random forest model was employed to evaluate the relative importance of variables considered as moderators in the meta-regression model (`rma.mv`). Random forest is particularly suitable for this purpose due to its ability to handle complex interactions and non-linear relationships between predictors, making it an effective tool for identifying which moderators most strongly influence the response variable. The model assessed the importance of these moderators using two key metrics: the percentage increase in mean squared error (%IncMSE) and increase in node purity (IncNodePurity). These metrics reflect how much each moderator improves the model's predictive power and reduces uncertainty.

###############################################

The results highlight tree age and experiment year as the most influential moderators. These variables significantly impact both %IncMSE and IncNodePurity, indicating their critical role in explaining variations in the response variable within the meta-analytic framework. Their importance suggests that temporal factors, such as the age of the tree systems and the year of the experiments, are vital in shaping the observed outcomes across studies.

Moderators related to soil texture, such as sand and silt, were also identified as moderately important, reflecting the role of soil properties in influencing the outcomes under study. Tree type and crop type, including specific categories like "Fruit, nut & other" and "Legume," were somewhat less influential but still contributed meaningfully to explaining variability in the response. Their inclusion underscores the importance of agroforestry and crop-specific characteristics as moderators in the meta-regression.

Variables like alley width and certain crop or tree types, such as tuber/root crops and timber trees, showed relatively lower importance. This indicates that their moderating effects are less pronounced in this context, suggesting they may not need to be prioritized in the meta-regression model.

The random forest results emphasize the hierarchy of moderator importance, with tree age and experiment year standing out as dominant predictors. This refined understanding can improve the meta-regression model by focusing on the most impactful moderators, simplifying the model structure while maintaining its explanatory and predictive power.

###########################################

The correlation matrix reveals the relationships between predictors. Strong correlations (shown as larger, darker circles) suggest that some predictors may overlap in the information they provide. For example, if "tree type" and "crop type" have a high positive or negative correlation, this could mean they are not entirely independent, potentially leading to redundancy in the model. This aligns with earlier findings of multicollinearity, where predictors interfere with each other.

From the PCA results, the first three principal components (PC1, PC2, and PC3) explain approximately 79% of the variance in the data. This means most of the variation in your dataset can be summarized using fewer dimensions, reducing complexity while retaining the critical patterns. The decreasing proportion of variance explained by PC4 and PC5 suggests these components add less unique information.

Overall, while "tree type" and "crop type" seem to be the most influential predictors, their high correlation with other variables might complicate the interpretation. You should consider techniques like feature selection, dimensionality reduction, or removing redundant variables to improve model clarity and performance.


###########################################


The results of the random forest analysis reveal important limitations and implications for reporting and communicating overall meta-analysis findings. By identifying tree age and experiment year as the dominant moderators, the analysis highlights a key limitation of heterogeneity within the dataset. This underscores the challenge of attributing outcomes to specific factors when a few moderators exert disproportionate influence. Such dominance may mask the contributions of less impactful moderators and complicate the interpretation of their individual roles in the meta-analysis.

One limitation lies in the reliance on moderators that capture temporal or environmental variability, such as experiment year or soil texture. These factors, while essential, may vary considerably across studies, making it difficult to disentangle their effects from study-specific conditions. Additionally, the relatively lower importance of certain moderators, such as alley width or specific tree and crop types, raises questions about whether these variables are consistently measured or reported across studies. Inconsistent data collection or reporting practices may contribute to their diminished influence, emphasizing the importance of standardized reporting in future studies.

Communicating the meta-analysis results requires careful consideration of these limitations. Overemphasis on the dominant moderators, such as tree age, may oversimplify the nuanced interactions present in agroforestry systems. Researchers and stakeholders must be cautious not to generalize findings without acknowledging the variability that less prominent moderators can introduce. This is particularly relevant when translating findings into practical recommendations, as the applicability of results to diverse settings may be constrained.

The findings also highlight the need for transparency when reporting results. Explicitly addressing the hierarchical importance of moderators, as identified by the random forest analysis, can help contextualize the results and guide readers in understanding the limitations of the analysis. Clear communication about the variability and potential biases introduced by dominant moderators is essential for ensuring that the conclusions of the meta-analysis are interpreted appropriately and applied responsibly in decision-making contexts.

###########################################


```{r}
# Prepare the data
# Convert categorical variables to factors
imp_data_rom <- imp_data_rom %>%
  mutate(across(where(is.character), as.factor))

# Define the predictors and response
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width)


response <- imp_data_rom$yi

# Combine predictors and response into a single dataset
complete_data <- cbind(predictors, response = response) %>%
  na.omit() # Remove rows with missing values to ensure compatibility


# complete_data |> str()
# 'data.frame':	808 obs. of  7 variables:
#  $ tree_age       : num  2 2 2 9 9 9 9 8 8 8 ...
#  $ crop_type      : Factor w/ 3 levels "Cereal","Legume",..: 1 1 1 1 1 1 1 1 1 1 ...
#  $ tree_type      : Factor w/ 3 levels "Biomass","Fruit,nut & other",..: 2 2 2 2 2 2 2 1 1 1 ...
#  $ soil_texture   : Factor w/ 3 levels "Clay","Sand",..: 1 1 1 1 1 1 1 3 3 3 ...
#  $ experiment_year: Date, format: "2011-01-01" "2011-01-01" "2011-01-01" "2011-01-01" ...
#  $ alley_width    : Factor w/ 2 levels "Narrow","Wide": 2 2 2 2 2 2 2 2 2 2 ...
#  $ response       : num  0.633 0.199 0.771 0.137 0.182 ...
#  - attr(*, "na.action")= 'omit' Named int [1:290] 329 330 331 332 333 334 335 336 337 338 ...
#   ..- attr(*, "names")= chr [1:290] "329" "330" "331" "332" ...

# Tidymodels Random Forest Workflow

# Step 1: Create a recipe for preprocessing
rf_recipe <- recipe(response ~ ., data = complete_data) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%  # Convert categorical predictors to dummies
  step_normalize(all_numeric_predictors())       # Normalize numeric predictors

# Step 2: Specify the Random Forest model
rf_spec <- rand_forest(
  mode = "regression",
  mtry = tune(),         # Number of predictors sampled at each split
  trees = 500,           # Number of trees
  min_n = tune()         # Minimum samples per node
) %>%
  set_engine("ranger", importance = "permutation")  # Use permutation importance

# Step 3: Define a workflow
rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_spec)

# Step 4: Create cross-validation folds
set.seed(123)

cv_splits <- vfold_cv(complete_data, v = 5)

# Step 5: Tune the model
rf_res <- tune_grid(
  rf_workflow,
  resamples = cv_splits,
  grid = 10,  # Number of parameter combinations to try
  metrics = metric_set(rmse, rsq)  # Evaluation metrics
)

# Step 6: Finalize the model with the best parameters
# Finalize the model with the best parameters
best_rf <- finalize_workflow(
  rf_workflow,
  select_best(rf_res, metric = "rmse") # Explicitly name the argument 'metric'
)

# Step 7: Fit the finalized model
final_rf_fit <- fit(best_rf, data = complete_data)

# Step 8: Compute and visualize variable importance
# Extract the fitted model
rf_final_model <- final_rf_fit %>% extract_fit_parsnip()

# Visualize Variable Importance
vip(rf_final_model) +
  ggtitle("Variable Importance from Random Forest Model") +
  theme_minimal()

```

##########################################################################
# 3. Stepwise Regression
##########################################################################

Stepwise regression iteratively adds or removes predictors from a model to optimize the Akaike Information Criterion (AIC), balancing goodness-of-fit with model complexity. Starting with an initial model, predictors are evaluated through forward selection (adding predictors) and backward elimination (removing predictors). This process identifies the most relevant variables while discarding redundant or insignificant ones, improving model interpretability and predictive performance. It mitigates multicollinearity and avoids overfitting by ensuring parsimony. However, results should be interpreted cautiously, as stepwise methods may exclude theoretically important predictors.

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################

# Set up data (imputed dataset)
moderators_data <- imp_data_rom %>%
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>%
  as.data.frame()

##########################################################################
# Fit a linear model with moderators
lm_model <- lm(yi ~ tree_type + crop_type + age_system + season + soil_texture, 
               data = imp_data_rom)

##########################################################################
# Stepwise regression using AIC
stepwise_model <- step(lm_model, direction = "both", trace = TRUE)

# Summary of the stepwise regression model
summary(stepwise_model)



##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
time.taken
##############################################################
# Last go (12/01-2025)
# Time difference of  mins
```

The stepwise regression analysis examined the influence of moderators (tree type, crop type, age system, season, and soil texture) on the response variable (\(yi\)). The final model retained all predictors, as their removal increased the AIC from its optimal value (-3130.13), indicating that each variable contributes meaningfully to the model. This underscores the importance of these moderators in explaining variations in the response variable.

**Moderator Effects:**  
- **Tree Type:** Timber trees significantly reduced the response variable (\(p = 0.016\)) compared to the reference group, highlighting their unique influence. In contrast, "Fruit, nut, and other" trees had no significant effect (\(p = 0.992\)).
- **Crop Type:** Legumes showed a positive and significant association with the response variable (\(p = 0.001\)), reflecting their potential benefits. Conversely, tuber, root, and other crops did not have a significant effect (\(p = 0.138\)).
- **Age System:** Young systems exhibited a significant positive effect on the response variable (\(p = 0.004\)), suggesting greater benefits during early stages of system development. Medium-aged systems showed no significant impact (\(p = 0.725\)).
- **Season:** Winter seasons significantly lowered the response variable (\(p = 0.028\)), indicating clear seasonal variability in effects.
- **Soil Texture:** While neither sand nor silt showed statistically significant effects, silt approached significance (\(p = 0.096\)), suggesting possible context-dependent influences.

**Model Performance:**  
The model explained 6.6% of the variance in the response variable (\(R^2 = 0.0655\)), indicating that the included moderators contribute meaningfully but leave much of the variability unexplained. The overall model was statistically significant (\(p = 4.48 \times 10^{-12}\)), demonstrating that the predictors collectively impact the response variable. However, the low \(R^2\) highlights the potential for other factors, including unmeasured moderators or interactions, to account for additional variability.

**Implications for Meta-Analysis:**  
The results highlight key moderators, such as crop type, tree type, age system, and season, as significant influencers of the response variable. These findings emphasize the importance of incorporating these variables into meta-analytic models while acknowledging that a large proportion of variability remains unexplained. Seasonal and developmental trends should be considered when interpreting the results, and future analyses should explore additional moderators, potential interactions, and non-linear relationships to better capture the complexity of the data.

In conclusion, the stepwise regression underscores the importance of specific moderators while highlighting the need for further refinement of models to address the unexplained variability and better understand the relationships within the dataset.


##########################################################################
# 4. Principal Component Analysis (PCA)
##########################################################################

```{r}
# Perform PCA on the numeric moderator data
pca_results <- prcomp(moderators_numeric, scale. = TRUE)

pca_results |> str()

screeplot(pca_results, type = "lines", main = "Scree Plot for PCA")

# Calculate proportion of variance explained
explained_variance <- (pca_results$sdev^2) / sum(pca_results$sdev^2)

# Create a scree plot
plot(explained_variance, type = "b", pch = 19, col = "blue",
     xlab = "Principal Components", ylab = "Proportion of Variance Explained",
     main = "Scree Plot for PCA")

barplot(explained_variance, names.arg = paste0("PC", 1:length(explained_variance)),
        col = "skyblue", xlab = "Principal Components", ylab = "Proportion of Variance",
        main = "Variance Explained by Principal Components")

# Biplot of the first two components
biplot(pca_results, scale = 0, main = "PCA Biplot")
```

##########################################################################
# 5. Cross-Validation
##########################################################################

```{r}
# Define predictors and response
predictors <- imp_data_rom %>% 
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>% # Convert to factors first
  mutate(across(everything(), as.numeric))   # Convert to numeric
response <- imp_data_rom$yi

# Check the structure of predictors
str(predictors)

# Remove rows with missing values in predictors or response
complete_cases <- complete.cases(predictors, response)
predictors <- predictors[complete_cases, ]
response <- response[complete_cases]

# Create a train/test split
set.seed(123)
train_index <- caret::createDataPartition(response, p = 0.8, list = FALSE)
train_data <- predictors[train_index, ]
train_response <- response[train_index]
test_data <- predictors[-train_index, ]
test_response <- response[-train_index]

# Ensure training data has no missing values
if (anyNA(train_data) || anyNA(train_response)) {
  stop("Training data contains missing values. Please clean your data.")
}

# Train a linear model with cross-validation
cv_model <- caret::train(
  x = train_data, 
  y = train_response, 
  method = "lm", 
  trControl = caret::trainControl(method = "cv", number = 10)
)

# Evaluate on test set
predictions <- predict(cv_model, newdata = test_data)
results <- caret::postResample(predictions, test_response)

# Print cross-validation results
print(cv_model)
print("Performance on test data:")
print(results)
```


The cross-validation analysis assessed the ability of the selected meta-analysis moderators—tree type, crop type, age system, season, and soil texture—to predict the variability in the response variable (**yi**). Using a dataset of 1,093 observations, cleaned of missing values, categorical moderators were numerically transformed to enable linear regression analysis. The dataset was split into training (80%) and test (20%) subsets, and 10-fold cross-validation was applied to evaluate model performance.

During cross-validation, the model achieved an RMSE (Root Mean Square Error) of **0.2321**, indicating the average prediction error relative to the observed values. The MAE (Mean Absolute Error), reflecting the average magnitude of errors regardless of direction, was **0.1201**. However, the R-squared value was only **0.0439**, suggesting that the moderators accounted for just 4.4% of the variability in **yi**. These metrics indicate a low explanatory power for the model, despite relatively small prediction errors.

Testing the model on the independent test set yielded consistent results, with an RMSE of **0.1965**, MAE of **0.1179**, and R-squared of **0.0328**. The reduction in RMSE on the test set suggests slight overfitting was avoided, but the consistently low R-squared values underscore that the included moderators collectively explain only a small fraction of the response variable’s variability.

These results highlight the limitations of the current set of moderators in explaining the observed effects. While the low RMSE and MAE values indicate reasonably accurate predictions, the very low R-squared values suggest that key drivers of variability in **yi** remain unaccounted for. This points to the need for further refinement of the meta-analysis model, potentially through the inclusion of additional moderators, exploration of interactions among existing variables, or the application of more sophisticated modeling approaches that can capture non-linear or complex relationships.

In conclusion, while the current analysis identifies some contribution of the selected moderators to the response variable, their explanatory power is limited. Future analyses should focus on expanding the scope of potential predictors and explicitly communicating these limitations to contextualize the results and ensure robust and cautious interpretation.



#############
# STEP 8
##########################################################################################################################################
SAVING FINAL PREPROCESSED META-DATASETS (IMPUTED AND NON-IMPUTED) - THESE ARE USED FOR RMA.MV() MODELLING
##########################################################################################################################################


Saving the datasets that is used for the rma.mv() modelling

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as RDS files

## NON-IMPUTED
saveRDS(non_imp_data_rom,
        file = here::here(output_dir, "non_imp_data_rom.rds"))

## IMPUTED
saveRDS(imp_data_rom,
        file = here::here(output_dir, "imp_data_rom.rds"))



# Confirmation message
cat("Files saved successfully to:", output_dir, "\n")
```

git fetch origin
git pull origin main
git push origin HEAD:refs/heads/main --force

