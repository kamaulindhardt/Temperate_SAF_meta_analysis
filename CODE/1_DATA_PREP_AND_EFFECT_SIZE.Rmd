---
title: "1_DATA_PREP"
author: "M.K.K. Lindhardt"
date: "2024-11-14"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between



Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?


Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.


# STEP 0

PREPARING SCRIPT AND READ IN THE DATA
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    ###################################################################################################################
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science (data wrangling, visualization, etc.)
    readr,            # For fast reading and writing of CSV files
    dlookr,           # Diagnose, explore, and transform data efficiently
    skimr,            # Summary statistics for data frames, tibbles, and vectors
    janitor,          # Cleaning and renaming data columns for tidy data
    readxl,           # Reading Excel files
    vroom,            # High-performance reading of large datasets
    missForest,       # Random forest imputation for missing data
    mice,             # Multiple imputation for multivariate missing data
    missRanger,       # Chained random forest imputation for large datasets
    conflicted,       # Resolves conflicts in function names across packages
    future,           # Enables parallel processing for faster computation
    future.apply,     # Apply functions in parallel over lists or arrays
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization (part of tidyverse)
    patchwork,        # Combine and arrange ggplots in complex layouts
    RColorBrewer,     # Color palettes for visualizations
    gt,               # Generate stylish publication-ready tables
    corrplot,         # Correlation matrix visualization
    scales,           # Generate pseudo-log scale plots and other scaling options
    forcats,          # For working with and reordering factors
    ggrepel,          # Add text directly to a ggplot
    scales,           # Modify axis scales of plots
    ###################################################################################################################
    # Spatial Data Analysis
    tidygeocoder,     # Unified geocoding interface for forward and reverse geocoding
    raster,           # Handle raster data and analyze spatial layers
    sp,               # Provides spatial data classes and methods
    sf,               # Simple feature handling for vector data
    rnaturalearth,    # Access world map data for visualization
    rnaturalearthdata, # Supporting data for rnaturalearth
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # Conduct meta-analyses and calculate effect sizes
    clubSandwich,     # Cluster-robust variance estimators for linear regression
    philentropy,      # Compute Jensen-Shannon Divergence and other divergence measures
    MuMIn,            # For model selection and averaging
    glmnet,           # For regularization methods
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # Streamline exploratory data analysis
    SmartEDA,         # Automated exploratory data analysis
    inspectdf,        # Inspect data frames for structure and quality
    naniar,           # Explore and visualize missing data patterns
    VIM,              # Visualize and impute missing values
    corrplot,         # Visualize correlations between variables
    ###################################################################################################################
    # Machine Learning and Modeling (Tidymodels Framework)
    tidymodels,       # Unified framework for machine learning and modeling
    vip,              # Visualize variable importance from models
    caret,            # Train machine learning models with cross-validation
    randomForest,     # Train random forest models and evaluate variable importance
    recipes,          # Preprocessing data for machine learning
    ranger,           # High-performance random forests
    yardstick,        # Metrics for model performance evaluation
    tune,             # Hyperparameter tuning for machine learning models
    rsample,          # Generate resamples and cross-validation folds
    workflows,        # Combine recipes and models into workflows
    parsnip,          # Define machine learning models
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy and robust file referencing
    styler            # Automatically format and style R code
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("col_factor", "scales")
conflict_prefer("geocode", "tidygeocoder")
conflict_prefer("chisq.test", "stats")
conflict_prefer("step", "stats")
conflict_prefer("margin", "ggplot2")
conflict_prefer("intersect", "base")
```
```{r}
# Set a global theme and color scale
# Define the global color palette
global_palette <- c(
  "#ffd700", 
  "#ffb14e", 
  "#fa8775", 
  "#ea5f94", 
  "#cd34b5", 
  "#9d02d7", 
  "#0000ff"
)


custom_colors <- c(
  "Biodiversity"               = "#FF9999",
  "Carbon sequestration"       = "#66C266",
  "Product quality"            = "#FFC000",
  "Crop yield"                 = "#FF9933",
  "Pest and disease control"   = "#33CCCC",
  "Soil quality"               = "#9966CC",
  "Water quality"              = "#9999FF"
)

# Define global ggplot2 scales for color and fill
scale_fill_global <- scale_fill_viridis_d(option = "D")  # Discrete
scale_color_global <- scale_color_viridis_d(option = "D")  # Discrete

scale_fill_global <- scale_fill_viridis_c(option = "D")  # Continuous
scale_color_global <- scale_color_viridis_c(option = "D")  # Continuous
```


## Loading the dataset (main metadata database)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({
  # Final database 'meta-data' (v7) is having updates on the misplaced sample number (_n) and standard error (_se)
  # Moreover, the name of the study as authors and year was added 
  # Manually modifying the SD columns to "control_sd" and "silvo_sd" in Excel!
  # Also adding these columns manually: 
  # silvo_var (variance as either _se or _sd), 
  # silvo_se	(standard error),
  # silvo_sd	(standard deviation),
  # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
  # control_var (variance as either _se or _sd), 
  # control_se (standard error),
  # control_sd (standard deviation),
  # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),

  database <- readxl::read_excel(
    here("DATA", "Meta_data_v78.xlsx"), 
    sheet = "Quantatitive data"
  )
  
  # Dummy data where silvo_mean has been multiplied with 1.2 to check for larger effect size estimates
  # database_dummy <- readxl::read_excel(
  #   here("DATA", "Meta_data_dummy_test_high_silvo_mean_se.xlsx"), 
  #   sheet = "Quantatitive data"
  # )
    
})
```

**Glimpse (taking a look at the data)**
```{r Glimpse the dataset, eval=FALSE}
database %>% dplyr::glimpse() 

# v7
# Rows: 1,075
# Columns: 35

# v8
# Rows: 1,126
# Columns: 45

# v9
# Rows: 1,126
# Columns: 43
```

```{r}
database %>% summary() 
```

```{r}
options(pillar.sigfig = 4)
database |> skim()
```


# STEP 1 DATA PREPROCESSING

GENERIC PREPROCESSING


And in step 4, generate unique study identifier ('exp_id')

```{r}
# Function to safely convert to numeric, replacing non-numeric values with NA
safe_as_numeric <- function(x) {
  suppressWarnings(as.numeric(x))
}

# Data Preprocessing
database_clean <- database |>
  # Step 1: Clean column names
  janitor::clean_names() |>
  
  # Step 2: Convert id_article and id_obs to integer
  mutate(
    id_article = as.integer(id_article),
    id_obs = as.integer(id_obs)
  ) |>
  
  # Step 3: Convert standard errors and other numeric columns
            # silvo_var (variance as either _se or _sd), 
            # silvo_se	(standard error),
            # silvo_sd	(standard deviation),
            # silvo_sd_info	(information on whether the silvo_var indicate _sd [TRUE] or [FALSE]),
            # control_var (variance as either _se or _sd), 
            # control_se (standard error),
            # control_sd (standard deviation),
            # control_sd_info (information on whether the control_var indicate _sd [TRUE] or [FALSE]),
  mutate(
    silvo_mean = safe_as_numeric(silvo_mean),
    silvo_se = safe_as_numeric(silvo_se),
    silvo_sd = safe_as_numeric(silvo_sd),
    silvo_n = safe_as_numeric(silvo_n),
    control_mean = safe_as_numeric(control_mean),
    control_se = safe_as_numeric(control_se),
    control_sd = safe_as_numeric(control_sd),
    control_n = safe_as_numeric(control_n),
    tree_age = safe_as_numeric(tree_age),
    no_tree_per_m = as.character(no_tree_per_m)) |> 
  
  # Step 4: Create Identifiers (Experiment, Treatment, Common Control)
  # Group data by relevant columns for Treatment ID
  group_by(id_article, tree_type, crop_type, location, experiment_year) |>
  mutate(treat_id = cur_group_id()) |>
  ungroup() |>
  
  # Group data by relevant columns for Experiment ID
  # The exp_id variable is created as a unique identifier for experiments, 
  # based on grouping by: id_article (the article ID), location (the geographical location of the experiment), and 
  # the experiment_year (the year the experiment was conducted)
  # Now without id_article
  group_by(location, experiment_year) |>
  mutate(exp_id = cur_group_id()) |>
  ungroup() |> 
  
  # Step 5: Ensure no infinite or NaN values are present in any columns
  mutate(across(everything(), ~ifelse(is.infinite(.) | is.nan(.), NA, .))
         ) |> 
  
  # Step 6: Convert "NA" strings to real NA values, excluding 'id_article' and 'id_obs'
  mutate(
    across(
      .cols = where(is.character) & !c("id_article", "id_obs"),
      .fns = ~ na_if(., "NA")
    )
  ) |>
  
  # Step 7: Convert year columns to date format
 # Convert to proper Date format using "YYYY-01-01"
 mutate(
    experiment_year = as.Date(paste0(experiment_year, "-01-01")),
    year_est_exp = as.Date(paste0(year_est_exp, "-01-01")),
    #study_year_start = as.Date(paste0(study_year_start, "-01-01")),
    #study_year_end = as.Date(paste0(study_year_end, "-01-01"))
  ) |> 
  # Step 8: Rename Latitude and Longitude to lat and lon
  rename(
    lat = latitude,
    lon = longitude
  ) |>
  
  # Step 9: Convert lat and lon to numeric coordinates
  mutate(
    lat = str_replace_all(lat, "[°NS]", "") |> safe_as_numeric(),
    lon = str_replace_all(lon, "[°EW]", "") |> safe_as_numeric(),
    lat = if_else(str_detect(lat, "S$"), -lat, lat),
    lon = if_else(str_detect(lon, "W$"), -lon, lon)
  ) |>
  
  # Step 10: Create a Coherent 'site_x' Column
  mutate(
    # If `lat` and `lon` are present, use them; otherwise, use the `location` name
    site_x = case_when(
      !is.na(lat) & !is.na(lon) ~ paste(lat, lon, sep = ", "),
      !is.na(location) ~ location,
      TRUE ~ NA_character_
    )
  ) 
```



```{r}
database_clean |> filter(id_article == 10)
```


GEOSPATIAL PREPROCESSING


In the Excel meta-data file, I am manually changing 'France (south west)' to 'France' and 'South East England(Cambridgeshire)' to 'Cambridgeshire, England' and 
'Bramham in northern England' to 'Bramham, England'

```{r}
# Step 1: Extract Coordinates from `site_x` if available
database_clean <- database_clean |>
  mutate(
    # Extract latitude: Matches integers or decimals before a comma
    extracted_lat = str_extract(site_x, "[-]?\\d+(\\.\\d+)?(?=, )"),
    # Extract longitude: Matches integers or decimals after a comma and space
    extracted_lon = str_extract(site_x, "(?<=, )[-]?\\d+(\\.\\d+)?")
  ) |>
  mutate(
    # Convert extracted values to numeric
    extracted_lat = as.numeric(extracted_lat),
    extracted_lon = as.numeric(extracted_lon),
    # Use extracted coordinates directly as final coordinates
    final_lat = extracted_lat,
    final_lon = extracted_lon,
    # Create the `exp_site_loc` column with final coordinates
    exp_site_loc = if_else(!is.na(final_lat) & !is.na(final_lon),
                           paste(final_lat, final_lon, sep = ", "),
                           NA_character_)
  ) |>
  # Remove intermediate columns
  select(-extracted_lat, -extracted_lon) |>
  
  # Step 2: Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n
  )
```

Checking if any missing values in coordinates

```{r}
# Filter rows where either final_lat or final_lon is missing
missing_coordinates <- database_clean |>
  filter(is.na(final_lat) | is.na(final_lon))

# View the rows with missing coordinates
missing_coordinates

# No missing coordinates
# 0 rows | 1-10 of 39 columns
```


Add geographical sub-regions to the dataset

```{r}
# Load Köppen-Geiger Climate Data (as a raster file)
kg_climate <- raster(here("DATA", "koppen_geiger_tif", "1991_2020", "koppen_geiger_0p1.tif"))


# Preserve final_lat and final_lon before conversion
database_clean <- database_clean |> 
  mutate(
    preserved_lat = final_lat,
    preserved_lon = final_lon
  )

# Convert your dataset to an sf object using preserved lat/lon columns
database_clean_sf <- database_clean |>
  drop_na(preserved_lat, preserved_lon) |>
  st_as_sf(coords = c("preserved_lon", "preserved_lat"), crs = 4326)

# Extract climate zone for each observation using spatial overlay
# Beck, H.E., T.R. McVicar, N. Vergopolan, A. Berg, N.J. Lutsko, A. Dufour, Z. Zeng, X. Jiang, A.I.J.M. van Dijk, D.G. MirallesHigh-resolution (1 km) Köppen-Geiger maps for 1901–2099 based on constrained CMIP6 projectionsScientific Data 10, 724, doi:10.1038/s41597-023–02549‑6 (2023)
# The variable 'climate_zone' represents the climate classification code assigned to each data point based on its geographical coordinates (latitude and longitude) from the Köppen-Geiger map. The climate_zone information was extracted using a spatial overlay.
database_clean_sf <- database_clean_sf |>
  mutate(
    climate_zone = extract(kg_climate, st_coordinates(database_clean_sf))
  )

# Classify sub-regions based on the climate zone
# Refine classifications for temperate climates and assign broader regions for others
database_clean_sf <- database_clean_sf %>%
  mutate(
    # Assign specific Köppen-Geiger classifications to climate zones
    climate_zone = case_when(
      climate_zone == 1 ~ "Tropical, rainforest",
      climate_zone == 2 ~ "Tropical, monsoon",
      climate_zone == 3 ~ "Tropical, savannah",
      climate_zone == 4 ~ "Arid, desert, hot",
      climate_zone == 5 ~ "Arid, desert, cold",
      climate_zone == 6 ~ "Arid, steppe, hot",
      climate_zone == 7 ~ "Arid, steppe, cold",
      climate_zone == 8 ~ "Temperate, dry summer, hot summer",
      climate_zone == 9 ~ "Temperate, dry summer, warm summer",
      climate_zone == 10 ~ "Temperate, dry summer, cold summer",
      climate_zone == 11 ~ "Temperate, dry winter, hot summer",
      climate_zone == 12 ~ "Temperate, dry winter, warm summer",
      climate_zone == 13 ~ "Temperate, dry winter, cold summer",
      climate_zone == 14 ~ "Temperate, no dry season, hot summer",
      climate_zone == 15 ~ "Temperate, no dry season, warm summer",
      climate_zone == 16 ~ "Temperate, no dry season, cold summer",
      climate_zone == 17 ~ "Cold, dry summer, hot summer",
      climate_zone == 18 ~ "Cold, dry summer, warm summer",
      climate_zone == 19 ~ "Cold dry summer, cold summer",
      climate_zone == 20 ~ "Cold dry summer, very cold winter",
      climate_zone == 21 ~ "Cold, dry winter, hot summer",
      climate_zone == 22 ~ "Cold, dry winter, warm summer",
      climate_zone == 23 ~ "Cold, dry winter, cold summer",
      climate_zone == 24 ~ "Cold, dry winter, very cold winter",
      climate_zone == 25 ~ "Cold, no dry season, hot summer",
      climate_zone == 26 ~ "Cold, no dry season, warm summer",
      climate_zone == 27 ~ "Cold, no dry season, cold summer",
      climate_zone == 28 ~ "Cold, no dry season, very cold winter",
      climate_zone == 29 ~ "Polar, tundra",
      climate_zone == 30 ~ "Polar, frost",
      TRUE ~ "Unclassified"
    ),
    
    # Assign refined geographical regions
    bioclim_sub_regions = case_when(
      # Tropical climates
      climate_zone %in% c(
        "Tropical, rainforest", "Tropical, monsoon", "Tropical, savannah"
      ) ~ "Tropical Climates",
      
      # Arid climates
      climate_zone %in% c(
        "Arid, desert, hot", "Arid, desert, cold", "Arid, steppe, hot", "Arid, steppe, cold"
      ) ~ "Arid Climates",
      
      # Refined temperate climates
      climate_zone %in% c(
        "Temperate, dry summer, hot summer", "Temperate, dry summer, warm summer", 
        "Temperate, dry winter, hot summer", "Temperate, dry winter, warm summer"
      ) ~ "Dry and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, hot summer", "Temperate, no dry season, warm summer"
      ) ~ "Wet and Warm Temperate",
      
      climate_zone %in% c(
        "Temperate, dry summer, cold summer", "Temperate, dry winter, cold summer"
      ) ~ "Dry and Cold Temperate",
      
      climate_zone %in% c(
        "Temperate, no dry season, cold summer"
      ) ~ "Wet and Cold Temperate",
      
      # Cold climates
      climate_zone %in% c(
        "Cold, dry summer, hot summer", "Cold, dry summer, warm summer", 
        "Cold dry summer, cold summer", "Cold dry summer, very cold winter", 
        "Cold, dry winter, hot summer", "Cold, dry winter, warm summer", 
        "Cold, dry winter, cold summer", "Cold, dry winter, very cold winter",
        "Cold, no dry season, hot summer", "Cold, no dry season, warm summer", 
        "Cold, no dry season, cold summer", "Cold, no dry season, very cold winter"
      ) ~ "Cold Climates",
      
      # Polar climates
      climate_zone %in% c(
        "Polar, tundra", "Polar, frost"
      ) ~ "Polar Climates",
      
      TRUE ~ "Unclassified"
    )
  )
```


Checking for unclassified in climate_zone and bioclim_sub_regions or if any observations have odd classes e.g. 'Tropical Climates'

```{r}
# Check classification coverage
database_clean_sf %>%
  filter(climate_zone == "Unclassified" | bioclim_sub_regions == "Unclassified") %>%
  head()

# Check classification of BioClim that is classified as 'Tropical'
database_clean_sf %>%
  filter(bioclim_sub_regions == "Tropical Climates") 
```





```{r}
# Rename back to 'database_clean'

# Relocate columns to the desired order
database_clean <- database_clean_sf |>
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative mata-analysis effect size info
    silvo_mean, control_mean, 
    silvo_n, control_n,
    silvo_se, control_se,
    silvo_sd, control_sd 
  )

# Preview the resulting data
database_clean |> 
  glimpse()

# Rows: 1,126
# Columns: 44
```


```{r}
# Create the bar chart
database_clean |> 
  ggplot(aes(x = bioclim_sub_regions)) +
  geom_bar(fill = "skyblue", color = "black") +
  theme_minimal() +
  labs(
    title = "Distribution of Observations by BioClim Subregions",
    x = "BioClim Subregions",
    y = "Count of Observations"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(size = 14, face = "bold"),
    axis.title.x = element_text(size = 12),
    axis.title.y = element_text(size = 12)
  )
```



ASSESSING THE GENERATED RANDOM-FACTOR VARIABLES exp_id and treat_id 


Missingness Assessment for exp_id Visualization

```{r}
# database_clean |> as.data.frame() |>
#   str()
```


```{r}
# Visualize exp_id distribution across components
database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  mutate(
    # Convert all columns to character for consistency
    id_article = as.character(id_article),
    experiment_year = as.character(experiment_year)
  ) %>%
  group_by(id_article, location, experiment_year) %>%
  summarise(exp_id_count = n_distinct(exp_id), .groups = "drop") %>%
  pivot_longer(
    cols = c(id_article, location, experiment_year),
    names_to = "component",
    values_to = "value"
  ) %>%
  ggplot(aes(x = component, y = exp_id_count, fill = component)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of exp_id Across Components",
    x = "Component",
    y = "Count of exp_id"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

```
```{r}
# Heatmap for year-location relationship
# Function to plot heatmap for year and a chosen variable
plot_heatmap <- function(data, y_var) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(y_var)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(y_var), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", y_var),
      x = "Experiment Year",
      y = y_var,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for location
plot_heatmap(database_clean, "location")

# Example usage: Plot for site
plot_heatmap(database_clean, "experiment_site")

# Example usage: Plot for bioclim_sub_region
plot_heatmap(database_clean, "bioclim_sub_regions")
```

```{r}
# Function to plot heatmap for year and chosen variable (moderators or response variables)
plot_heatmap_moderator_response <- function(data, var_type) {
  data %>%
    as.data.frame() %>%
    select(-geometry) %>%
    group_by(experiment_year, !!sym(var_type)) %>%
    summarise(n_exp_id = n_distinct(exp_id), .groups = "drop") %>%
    ggplot(aes(x = experiment_year, y = !!sym(var_type), fill = n_exp_id)) +
    geom_tile() +
    labs(
      title = paste("Heatmap of exp_id by Experiment Year and", var_type),
      x = "Experiment Year",
      y = var_type,
      fill = "Count of exp_id"
    ) +
    scale_fill_viridis_c() +
    theme_minimal(base_size = 14) +
    theme(
      plot.title = element_text(face = "bold", hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    )
}

# Example usage: Plot for moderators
plot_heatmap_moderator_response(database_clean, "tree_type")

# Example usage: Plot for response variables
plot_heatmap_moderator_response(database_clean, "response_variable")
```


```{r}
# Step 2: Explore Aggregation Level
# Count unique `exp_id` values at each location level
aggregation_summary <- database_clean %>%
  as.data.frame() |> 
  select(-geometry) |> 
  group_by(location) %>%
  summarise(
    n_exp_id = n_distinct(exp_id),
    n_obs = n(),
    .groups = "drop"
  )

# View summary of aggregation
aggregation_summary

# Step 3: Visualize Aggregation Level
aggregation_summary |> 
  ggplot(aes(x = reorder(location, n_exp_id), y = n_exp_id)) +
  geom_col(fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Distribution of exp_id Across Locations",
    x = "Location",
    y = "Number of exp_id"
  ) +
  theme_minimal()
```


```{r}
# Summarize missingness across moderators and response variables
missingness_summary <- database_clean %>%
  as.data.frame() %>%
  select(-geometry) %>%
  group_by(exp_id) %>%
  summarise(
    # Count missing values for moderators
    missing_moderators = sum(
      is.na(tree_type) | is.na(crop_type) | is.na(age_system) | 
      is.na(tree_age) | is.na(season) | is.na(soil_texture) | 
      is.na(no_tree_per_m) | is.na(tree_height) | is.na(alley_width) | 
      is.na(organic) | is.na(tillage)
    ),
    # Count missing values for response variables
    missing_response = sum(
      is.na(silvo_mean) | is.na(control_mean)
    ),
    total_missing = missing_moderators + missing_response,
    n_obs = n(),
    .groups = "drop"
  )
```

Publication-ready map that visualizes the ecosystem services (response variables) reported in each study (id_article),
```{r}
# Step 1: Simplify the dataset for visualization
geo_data <- database_clean %>%
  group_by(lat = final_lat, lon = final_lon, response_variable) %>%
  summarize(
    n_studies = n_distinct(id_article),
    .groups = "drop"
  ) %>%
  filter(!is.na(lat) & !is.na(lon)) # Remove rows with missing coordinates

# Step 2: Base world map
world_map <- map_data("world")


# Step 4: Create the map
geo_distribution_of_studies_map <- ggplot() +
  # Add base map polygons
  geom_polygon(
    data = world_map,
    aes(x = long, y = lat, group = group),
    fill = "gray90", color = "gray70", size = 0.4
  ) +
   # Add jittered points for studies
  geom_jitter(
    data = geo_data,
    aes(x = lon, y = lat, color = response_variable, size = as.factor(n_studies)),
    alpha = 0.8,
    width = 0.8,  # Adjust jitter width (longitude)
    height = 0.75  # Adjust jitter height (latitude)
  ) +
  # Apply custom colors
  scale_color_manual(values = custom_colors, name = "Ecosystem Service") +
  scale_size_manual(
    name = "n studies for the given locataion",
    values = c(2, 3, 4, 5, 6, 7), # Assign size values for bins 1-6
    breaks = as.character(1:6),  # Ensure breaks correspond to whole numbers
    labels = as.character(1:6)   # Labels for the legend
  ) +
  # Add labels and theme adjustments
  labs(
    title = "Geographical Distribution of Ecosystem Services in Silvoarable Agroforestry Studies (Northern Hemisphere)",
    x = "Longitude",
    y = "Latitude"
  ) +
  coord_cartesian(ylim = c(20, 90)) +  # Restrict to the northern hemisphere
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 16),
    legend.title = element_text(face = "bold"),
    legend.position = "right",
    panel.grid = element_blank(),
    axis.line = element_line(color = "gray50")
  )

geo_distribution_of_studies_map
```

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.title = element_text(size = 80),
    legend.position = "top",
    legend.text = element_text(size = 80),
    axis.text.x = element_text(size = 100)
                               #angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
geo_distribution_of_studies_map <- geo_distribution_of_studies_map + theme_custom

# Save the map plot
ggsave(
  filename = file.path(output_dir, "geo_distribution_of_studies_map.png"), # Name of the file
  plot = geo_distribution_of_studies_map, 
  width = 20, height = 10, dpi = 600, # Specify dimensions and resolution
  bg = "white" # Ensure a white background for publication-ready output
)
```


Visualize Missingness (Facet Plot for Moderators and Responses)
```{r}
# Reshape the missingness summary for visualization
missingness_long <- missingness_summary %>%
  pivot_longer(
    cols = c(missing_moderators, missing_response),
    names_to = "missingness_type",
    values_to = "missing_count"
  )

# Summarize missingness data for better grouping and understanding
missingness_long_summary <- missingness_long %>%
  group_by(missingness_type, n_obs_group = cut(n_obs, breaks = seq(0, max(n_obs, na.rm = TRUE), by = 10))) %>%
  summarise(mean_missing = mean(missing_count, na.rm = TRUE), .groups = "drop")

# Separate data for moderators and response variables
moderators_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_moderators) %>%
  mutate(missingness_type = "Moderators")

response_variables_data <- missingness_summary %>%
  select(exp_id, n_obs, missing_response) %>%
  mutate(missingness_type = "Response Variables")

# Plot Moderators Missingness
moderators_data %>%
  ggplot(aes(x = as.factor(n_obs), y = missing_moderators, fill = missingness_type)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness Overview for Moderators",
    x = "Number of Observations per exp_id (Grouped)",
    y = "Average Missing Values Count"
  ) +
  scale_fill_manual(values = c("blue")) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


Bar Chart: Missingness by Moderators (Exp ID Count)

```{r}
# Count missing values for each moderator
# Ensure all columns have the same data type before pivoting
missingness_moderators <- database_clean %>%
  as.data.frame() %>%
  select(
    exp_id, tree_type, crop_type, age_system, tree_age, season, organic, tillage,
    soil_texture, no_tree_per_m, tree_height, alley_width
  ) %>%
  mutate(across(-exp_id, as.character)) %>%  # Convert all non-exp_id columns to character
  pivot_longer(
    cols = -exp_id,
    names_to = "moderator",
    values_to = "value"
  ) %>%
  group_by(moderator) %>%
  summarise(
    exp_id_with_missing = sum(is.na(value)),  # Count the number of exp_id with missing values
    .groups = "drop"
  )

# Bar chart of missingness across moderators
missingness_moderators |> 
  ggplot(aes(x = moderator, y = exp_id_with_missing, fill = moderator)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Missingness in Moderators",
    subtitle = "Number of exp_id with Missing Values for Each Moderator",
    x = "Moderator",
    y = "Count of exp_id with Missing Values"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```













# STEP 2 CALCULATING META-ANALYSIS QUANTITATIVE DATA (Std Dev., Std. Err. etc.)


```{r}
database_clean |> glimpse()
```



## CALCULATING STANDARD DEVIATION FROM EXISTING STANDARD ERROR


```{r}
# Calculate standard deviations from standard errors where _sd_info is FALSE
database_clean_sd <- database_clean %>%
  mutate(
    # Calculate standard deviation for silvo group where _sd_info is FALSE
    silvo_sd_from_se = ifelse(
      !silvo_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(silvo_se) * sqrt(as.numeric(silvo_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    ),
    
    # Calculate standard deviation for control group where _sd_info is FALSE
    control_sd_from_se = ifelse(
      !control_sd_info,  # Condition: if _sd_info is FALSE
      as.numeric(control_se) * sqrt(as.numeric(control_n)),  # Calculate _sd from _se
      NA  # Otherwise, keep as NA
    )
    ) |> 
      mutate(
        # Prioritize original SD for silvo group
        silvo_sd_merged = ifelse(is.na(silvo_sd), silvo_sd_from_se, silvo_sd),  
        # Prioritize original SD for control group
        control_sd_merged = ifelse(is.na(control_sd), control_sd_from_se, control_sd)
      ) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative mata-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_n, silvo_sd_from_se, silvo_sd_merged,
    control_mean, control_se, control_sd, control_n, control_sd_from_se, control_sd_merged
  )
```

```{r}
database_clean_sd |> glimpse()
```


Checking for missing data in control_sd and silvo_sd

```{r}
# Calculate percentage of missing SD values for control and silvo groups in _sd_final
missing_control_sd_merged <- sum(is.na(database_clean_sd$control_sd_merged)) / nrow(database_clean_sd) * 100
missing_silvo_sd_merged <- sum(is.na(database_clean_sd$silvo_sd_merged)) / nrow(database_clean_sd) * 100

message("Percentage of missing SD values for control group (_sd_final): ", round(missing_control_sd_merged, 2), "%")
message("Percentage of missing SD values for silvo group (_sd_final): ", round(missing_silvo_sd_merged, 2), "%")

# Filter rows with missing SD values in _sd_final
missing_sd_final <- database_clean_sd %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged)) %>%
  relocate(
    id_article, id_obs, response_variable, location, experiment_site, 
    # Quantitative meta-analysis effect size info
    silvo_mean, silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_n,
    control_mean, control_se, control_sd, control_sd_from_se, control_sd_merged, control_n
  )

# Display rows with missing data in _sd_final
missing_sd_final |> glimpse()

# Rows: 184
# Columns: 53
# $ id_article              <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, …
# $ id_obs                  <int> 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 354, 355, 356, 357, 358, 359, …
# $ response_variable       <chr> "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield", "Crop yield"…
# $ location                <chr> "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Germany", "Ge…
# $ silvo_mean              <dbl> 1.48, 1.44, 5.91, 5.23, 6.59, 5.97, 7.53, 7.55, 0.66, 0.34, 11.81, 7.67, 14.27, 9.79, 16.04, 16.69, 3.50, 3.10, 5.90, 5.00, …
# $ silvo_se                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd_from_se        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_sd_merged         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ silvo_n                 <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
# $ control_mean            <dbl> 6.21, 7.63, 5.58, 7.38, 7.10, 7.53, 7.93, 7.90, 12.94, 15.21, 13.67, 13.62, 15.16, 14.74, 16.02, 14.79, 6.30, 6.40, 6.90, 7.…
# $ control_se              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd_from_se      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_sd_merged       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …
# $ control_n               <dbl> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, …
# $ treat_id                <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 16, 16, 17, 17, 18, 18, 24, 24, 20, 20, 21, 21, 16, …
# $ exp_id  
```

Dataset that is used as non-imputed

```{r}
# This is the non-imputed dataset (used for analysis WITHOUT imputation)
database_clean_sd 
```



# STEP 3 ASSESS MISSINGNESS PATTERNS OF DATA BEFORE IMPUTATION


```{r}
# Check missingness summary for `control_sd` and `silvo_sd`
missingness_summary <- database_clean_sd %>%
  as.data.frame() %>%
  summarise(
    total_rows = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    percent_missing_control_sd = mean(is.na(control_sd_merged)) * 100,
    percent_missing_silvo_sd = mean(is.na(silvo_sd_merged)) * 100
  )



# Add missingness indicators to the dataset
database_clean_sd_missingness <- database_clean_sd %>%
  as.data.frame() %>%
  mutate(
    missing_control_sd = ifelse(is.na(control_sd_merged), 1, 0),
    missing_silvo_sd = ifelse(is.na(silvo_sd_merged), 1, 0)
  )

missingness_summary

# Description:df [1 × 5]
# total_rows
# <int>
# missing_control_sd
# <int>
# missing_silvo_sd
# <int>
# percent_missing_control_sd
# <dbl>
# percent_missing_silvo_sd
# <dbl>
# 1126	184	184	16.34103	16.34103
```

```{r}
# Visualize missingness across response variables and moderators
missingness_plot <- database_clean_sd_missingness %>%
  select(response_variable, missing_control_sd, missing_silvo_sd) %>%
  group_by(response_variable) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd) * 100,
    missing_silvo_sd = mean(missing_silvo_sd) * 100
  ) %>%
  pivot_longer(cols = c(missing_control_sd, missing_silvo_sd),
               names_to = "Variable",
               values_to = "Percent_Missing") %>%
  ggplot(aes(x = response_variable, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Percentage of Standard Deviation Across Response Variables",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_plot
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data <- database_clean_sd_missingness %>%
  filter(is.na(control_sd_merged) | is.na(silvo_sd_merged))

# Summarize the counts of response variables for the filtered data
missing_sd_summary <- missing_sd_data %>%
  group_by(response_variable) %>%
  summarise(count = n()) %>%
  arrange(desc(count))

# Plot the distribution of response variables for missing sd data
ggplot(missing_sd_summary, aes(x = reorder(response_variable, -count), y = count, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Distribution of Response Variables with Missing Standard Deviation",
    x = "Response Variable",
    y = "Count of Missing Entries"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Filter the dataset for rows with missing sd (either control_sd or silvo_sd)
missing_sd_data_rel <- database_clean_sd_missingness %>%
  mutate(missing_sd = ifelse(is.na(control_sd_merged) | is.na(silvo_sd_merged), 1, 0))

# database_clean_sd_missingness |> filter(response_variable == "Soil quality") |> nrow()

# Calculate the percentage of missing sd values relative to total observations for each response variable
missing_sd_summary_rel <- missing_sd_data_rel %>%
  group_by(response_variable) %>%
  summarise(
    total_observations = n(),
    missing_sd_count = sum(missing_sd),
    percent_missing = (missing_sd_count / total_observations) * 100
  ) %>%
  arrange(desc(percent_missing))

missing_sd_summary_rel
```

```{r}
# Plot the relative missingness
missing_sd_summary_rel |> 
  ggplot(aes(x = reorder(response_variable, -percent_missing), y = percent_missing, fill = response_variable)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  labs(
    title = "Relative Missingness of Standard Deviation by Response Variable",
    x = "Response Variable",
    y = "Percent Missing",
    fill = "Response Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Assess missingness patterns across moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture", "organic", "tillage")

missingness_by_moderators <- database_clean_sd_missingness %>%
  select(all_of(moderators), missing_control_sd, missing_silvo_sd) %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100))

missingness_by_moderators

# Visualize missingness with a heatmap
heatmap_missingness <- database_clean_sd_missingness %>%
  select(control_sd, silvo_sd, response_variable, all_of(moderators)) %>%
  naniar::gg_miss_upset()

heatmap_missingness
```


## Asessing missingness patterns for _sd variables by location and study ID (id_article)

```{r}
# Calculate missingness by location
missing_by_location <- database_clean_sd_missingness %>%
  group_by(location) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by location
cat("\nMissingness by Location:\n")
print(missing_by_location)
```

```{r}
# Missingness by location
ggplot(missing_by_location, aes(x = reorder(location, -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Location",
    x = "Location",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```
```{r}
# Calculate missingness by study ID (id_article)
missing_by_study <- database_clean_sd_missingness %>%
  group_by(id_article) %>%
  summarise(
    total = n(),
    missing_control_sd = sum(is.na(control_sd_merged)),
    missing_silvo_sd = sum(is.na(silvo_sd_merged)),
    perc_missing_control_sd = 100 * mean(is.na(control_sd_merged)),
    perc_missing_silvo_sd = 100 * mean(is.na(silvo_sd_merged))
  ) %>%
  arrange(desc(perc_missing_control_sd), desc(perc_missing_silvo_sd))

# Print missingness summary by study ID
cat("\nMissingness by Study ID:\n")
print(missing_by_study)
```

```{r}
# Missingness by study ID
missing_by_study |> 
  ggplot(aes(x = reorder(as.factor(id_article), -perc_missing_control_sd), y = perc_missing_control_sd)) +
  geom_bar(stat = "identity", fill = "blue", alpha = 0.7) +
  geom_bar(aes(y = perc_missing_silvo_sd), stat = "identity", fill = "red", alpha = 0.7) +
  labs(
    title = "Missingness Percentage by Study ID",
    x = "Study ID",
    y = "Percentage Missing",
    fill = "Missingness Type"
  ) +
  theme_minimal() +
  coord_flip()
```


## Little's MCAR test for missingness

Implications of missing.patterns:
A high number of missing patterns indicates complex missingness in your dataset, which might suggest that the data is not Missing Completely at Random (MCAR). Instead, it might be Missing at Random (MAR) or Not Missing at Random (NMAR).

```{r}
####################################################################################################################
# Prepare the data for missingness assessment
database_clean_sd_df <- database_clean_sd |> as.data.frame() |> select(-geometry) 
####################################################################################################################



# Select the variables for the test
test_data <- database_clean_sd_df %>%
  select(control_sd_merged, silvo_sd_merged, everything())  # Include control_sd_merged, silvo_sd_merged, and all variables

# Convert non-numeric columns to numeric using one-hot encoding or factor levels
test_data_numeric <- test_data %>%
  mutate(across(where(is.character), ~ as.numeric(as.factor(.)))) %>%  # Convert characters to numeric
  mutate(across(where(is.factor), as.numeric)) %>%                     # Convert factors to numeric
  select(where(~ sum(!is.na(.)) > 0))                                  # Remove columns with all missing values

# Check for problematic values
problematic_values <- test_data_numeric %>%
  summarise(across(everything(), ~ sum(is.infinite(.)) + sum(is.nan(.)) + sum(is.na(.))))

problematic_values |> glimpse()

# Exclude columns with more than 50% missing values
test_data_cleaned <- test_data_numeric %>%
  # Keep control_sd_merged and silvo_sd_merged
  select(control_sd_merged, silvo_sd_merged, response_variable, experiment_year, year_est_exp, exp_id,
         # Moderators info
         tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage) %>%  
  # Remove columns with >50% missing
  select(where(~ sum(is.na(.)) < nrow(test_data_numeric) * 0.5)) |> 
  # Convert date-time columns to numeric (e.g., extract the year)
  mutate(
    experiment_year = as.numeric(format(experiment_year, "%Y")),
    year_est_exp = as.numeric(format(year_est_exp, "%Y"))
  )

# Confirm all columns are numeric
all(sapply(test_data_cleaned, is.numeric)) 

# Check which columns are not numeric
non_numeric_cols <- sapply(test_data_cleaned, function(col) !is.numeric(col))
names(non_numeric_cols[non_numeric_cols])

# Inspect missing values after cleaning
colSums(is.na(test_data_cleaned))

# Perform Little's MCAR test on cleaned data
mcar_test <- naniar::mcar_test(test_data_cleaned)
mcar_test
```

```{r}
# Visualize missingness pattern
md.pattern(database_clean_sd_df)

# Heatmap of missing data

aggr_plot <- VIM::aggr(database_clean_sd_df, col = c('navyblue', 'red'), numbers = TRUE, sortVars = TRUE, 
                  labels = names(database_clean_sd_df), cex.axis = .7, gap = 3, ylab = c("Missingness", "Pattern"))
aggr_plot
```

```{r}
# Add missing indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd <- test_data_cleaned %>%
  mutate(
    missing_control_sd = is.na(control_sd_merged),
    missing_silvo_sd = is.na(silvo_sd_merged)
  )

# Check relationship between missingness and other variables
ggplot(test_data_cleaned_sd, aes(x = tree_age, fill = missing_control_sd)) +
  geom_histogram(position = "dodge") +
  labs(title = "Relationship Between Tree Age and Missingness in control_sd_merged")
```

```{r}
# Test if missingness depends on observed variables using logistic regression

# Add missingness indicators for control_sd_merged and silvo_sd_merged
test_data_cleaned_sd_test <- test_data_cleaned %>%
  mutate(
    missing_control_sd = as.numeric(is.na(control_sd_merged)),
    missing_silvo_sd = as.numeric(is.na(silvo_sd_merged))
  )
# Check levels of categorical variables
levels(test_data_cleaned_sd_test$tree_type)
levels(test_data_cleaned_sd_test$crop_type)
levels(test_data_cleaned_sd_test$age_system)
levels(test_data_cleaned_sd_test$season)
levels(test_data_cleaned_sd_test$soil_texture)
levels(test_data_cleaned_sd_test$no_tree_per_m)
levels(test_data_cleaned_sd_test$alley_width)
```


Fit logistic regression models to see if missingness depends on observed variables.

```{r}
# Test if missingness depends on observed variables using logistic regression

# Filter complete cases just for the relevant variables in the model
model_data_missing <- test_data_cleaned %>%
  mutate(
    missing_control_sd = as.numeric(is.na(control_sd_merged)),
    missing_silvo_sd = as.numeric(is.na(silvo_sd_merged))
  ) %>%
  # Keep only complete rows for the variables used in Test 1
  drop_na(tree_type, crop_type, age_system, tree_age, season, soil_texture,
          no_tree_per_m, tree_height, alley_width)

# Fit logistic regression models (Test 1)
missing_control_model_1 <- glm(
  missing_control_sd ~ tree_type + crop_type + age_system + tree_age + season +
    soil_texture + no_tree_per_m + tree_height + alley_width,
  data = model_data_missing, family = binomial
)

missing_silvo_model_1 <- glm(
  missing_silvo_sd ~ tree_type + crop_type + age_system + tree_age + season +
    soil_texture + no_tree_per_m + tree_height + alley_width,
  data = model_data_missing, family = binomial
)

# Summarize results
cat("\nTest 1: Logistic regression results using specified moderators\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_1)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_1)

# Test 2: Logistic regression using response variables
missing_control_model_2 <- glm(
  missing_control_sd ~ response_variable,
  data = model_data_missing, family = binomial
)

missing_silvo_model_2 <- glm(
  missing_silvo_sd ~ response_variable,
  data = model_data_missing, family = binomial
)

# Summarize results for Test 2
cat("\nTest 2: Logistic regression results using response variables\n")
cat("\nControl SD Missingness:\n")
summary(missing_control_model_2)

cat("\nSilvo SD Missingness:\n")
summary(missing_silvo_model_2)

```



Based on the updated logistic regression outputs, missingness in both `control_sd` and `silvo_sd` is not random but significantly associated with several observed variables, supporting the Missing at Random (MAR) assumption. Specifically, **tree age**, **season**, **soil texture**, and **tree height** were strong predictors of missingness (p < 0.01). Younger trees, stressful seasonal conditions (e.g. winter), complex soil types (e.g. clay), and taller trees were all linked to higher missing data rates—likely due to measurement challenges in early-stage systems, seasonal variability, or logistical constraints. In contrast, categorical variables like **tree type**, **crop type**, and **alley width** were not significant, suggesting their role in missingness is limited or mediated through other variables. 

A second test confirmed that missingness was also significantly associated with the type of **response variable**, where more complex ecosystem service outcomes (like biodiversity or carbon sequestration) showed higher rates of missing data. These results justify the use of imputation models based on observed predictors and reinforce the importance of considering structural missingness in silvoarable agroforestry meta-analyses.


```{r}
# Step 1: Summarize Missingness by Tree Type and Crop Type
missing_summary_tree_crop <- test_data_cleaned_sd_test %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = mean(missing_control_sd, na.rm = TRUE) * 100,
    missing_silvo_sd = mean(missing_silvo_sd, na.rm = TRUE) * 100,
    .groups = "drop"
  )

# Print Summary Table
missing_summary_tree_crop
```

```{r}
# Step 2: Visualize Missingness by Tree Type and Crop Type

# Plot for Control SD Missingness
plot_control_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_control_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Control SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Control SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot for Silvo SD Missingness
plot_silvo_missingness <- ggplot(missing_summary_tree_crop, aes(x = tree_type, y = missing_silvo_sd, fill = crop_type)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Silvo SD Missingness by Tree Type and Crop Type",
    x = "Tree Type",
    y = "% Missing Silvo SD",
    fill = "Crop Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))



plot_control_missingness
plot_silvo_missingness
```


```{r}
# Step 3: Statistical Tests to Confirm Associations
# Chi-Square Test for Independence between Tree Type and Control SD Missingness
chi_sq_tree_control <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_tree_control

# Chi-Square Test for Independence between Crop Type and Control SD Missingness
chi_sq_crop_control <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_control_sd))
chi_sq_crop_control

# Chi-Square Test for Independence between Tree Type and Silvo SD Missingness
chi_sq_tree_silvo <- chisq.test(table(test_data_cleaned_sd_test$tree_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_tree_silvo

# Chi-Square Test for Independence between Crop Type and Silvo SD Missingness
chi_sq_crop_silvo <- chisq.test(table(test_data_cleaned_sd_test$crop_type, test_data_cleaned_sd_test$missing_silvo_sd))
chi_sq_crop_silvo

# Step 4: Logistic Regression Models for Tree Type and Crop Type
# Logistic Regression for Control SD
logit_control <- glm(missing_control_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_control

# Logistic Regression for Silvo SD
logit_silvo <- glm(missing_silvo_sd ~ tree_type + crop_type, data = test_data_cleaned_sd_test, family = binomial)
logit_silvo
```

The updated analysis confirms strong associations between missingness in both `control_sd` and `silvo_sd` and the observed variables `tree_type` and `crop_type`. Results from Pearson's Chi-squared tests reveal significant relationships for both tree type and crop type. For `tree_type`, the chi-square statistic is extremely high (X² = 76.96, p < 2.2e-16), indicating a strong dependency between tree type and missingness in `control_sd` and `silvo_sd`. Similarly, the association between `crop_type` and missingness is significant, though weaker, with a chi-square statistic of X² = 9.10 and p = 0.01058. These results clearly demonstrate that missingness is not randomly distributed but is instead systematically linked to specific experimental factors.

Logistic regression models further substantiate these findings. Both tree type and crop type have positive coefficients when predicting missingness for `control_sd` and `silvo_sd`. The intercept reflects a baseline low probability of missingness, while the positive coefficients for tree type (0.083) and crop type (0.389) indicate that certain tree and crop types increase the likelihood of missing data. The residual deviance for both models is substantially reduced compared to the null deviance, demonstrating an improved model fit, with an AIC value of 999.6 for each. These statistical results highlight the structured nature of missingness, reinforcing that it is "Missing at Random" (MAR), as it depends on observable factors like tree type and crop type.

The implications of these findings are significant for the setup and interpretation of the meta-regression analysis. First, it is essential to include variables such as `tree_type` and `crop_type` as moderators in the model to account for variability linked to experimental conditions. By doing so, the analysis will better capture the systematic relationships in the data and reduce potential biases in effect size estimates. Furthermore, addressing missing data is critical to ensure reliable results. Imputation methods such as predictive mean matching or upper quartile imputation are well-suited to handle MAR scenarios, as they leverage the systematic relationships identified in the dataset to estimate plausible values for missing observations. These methods help preserve the structural integrity of the data and maintain the robustness of downstream analyses.

Given the systematic nature of missingness, additional steps are necessary to ensure the meta-regression models are robust. Sensitivity analyses should be conducted to assess the impact of imputation methods on the final results. Comparing models fitted on imputed datasets with those using only complete cases will validate the stability of findings. Furthermore, the inclusion of tree and crop type as moderators may introduce complex interactions with other variables, necessitating the exploration of potential effect modifications. Testing for heterogeneity across studies by incorporating random effects or interaction terms is also crucial to accurately capture variability within the dataset.

Finally, diagnostic evaluations, including tests for publication bias and model performance metrics, must be incorporated to ensure the reliability and validity of the results. The systematic associations between missingness and observed variables underscore the importance of carefully handling missing data and refining model specifications. These steps will support a robust and interpretable meta-regression analysis, enabling meaningful insights into the relationships driving variability in temperate silvoarable agroforestry systems.


```{r}
# Correctly aggregate missingness percentages by tree_type and crop_type
missingness_distribution_corrected <- database_clean_sd_df %>%
  group_by(tree_type, crop_type) %>%
  summarise(
    missing_control_sd = sum(missing_control_sd_merged, na.rm = TRUE) / n() * 100,
    missing_silvo_sd = sum(missing_silvo_sd_merged, na.rm = TRUE) / n() * 100,
    .groups = "drop"
  ) %>%
  pivot_longer(
    cols = c(missing_control_sd, missing_silvo_sd),
    names_to = "Variable",
    values_to = "Percent_Missing"
  )

# Re-generate plots with corrected aggregation
missingness_tree_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = tree_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Tree Type",
    x = "Tree Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

missingness_crop_plot_corrected <- ggplot(missingness_distribution_corrected, aes(x = crop_type, y = Percent_Missing, fill = Variable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(
    title = "Missingness Distribution by Crop Type",
    x = "Crop Type",
    y = "Percent Missing",
    fill = "Variable"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the corrected plots
print(missingness_tree_plot_corrected)
print(missingness_crop_plot_corrected)
```



The updated visualizations highlight the percentage of missing values in `control_sd` and `silvo_sd` across tree type and crop type categories. For tree type, missingness patterns reveal that "fruit/nut & other" exhibits the highest proportion of missing values, exceeding 60% for both variables. In contrast, "biomass" shows moderate missingness, with rates around 40%, while "timber" has the lowest missingness, approximately 20%. These findings indicate that missingness is strongly dependent on tree type, with "fruit/nut & other" particularly affected, possibly due to measurement challenges or variability in experimental setups.

Similarly, crop type exhibits a pronounced influence on missingness rates. Cereal crops demonstrate minimal missingness, with percentages below 20%, suggesting standardized or easier measurement practices for this crop type. In contrast, legumes exhibit moderate missingness, averaging 30-40%, while tuber/root crops face the highest rates, exceeding 60% for both variables. This substantial variability underscores that specific crop types, like tuber/root crops, may present greater challenges in data collection or experimental consistency.

These patterns reinforce the importance of tailoring imputation strategies to account for category-specific influences. For example, tree type and crop type should be included as key predictors in imputation models to address the observed disparities. Additionally, the significantly higher missingness in "fruit/nut & other" tree types and tuber/root crops indicates that these categories warrant particular attention to mitigate biases introduced by missing data. Further validation through statistical testing can refine these insights and guide the application of targeted imputation techniques to preserve data integrity across diverse categories.


















# STEP 4 HANDELING OF MISSING VALUES IN THE DATASET - IMPUTATION


Perform imputation on  silvo_sd, control_sd using a variety of methods:

"mice" (Multivariate Imputation by Chained Equations), 
Upper Quartile, 
Mean Imputation,
Bayesian
Linear regression imputation (norm.predict)


```{r}
database_clean_sd |> glimpse()
```

The imputation process below is designed to ensure that that imputation only occur when _sd

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Start time tracking
start.time <- Sys.time()

#######################################################################################
# Step 1: Check and enforce correct data types
#######################################################################################
col_for_impute <- database_clean_sd |> 
  as.data.frame() |> 
  select(-geometry) |> 
  select(
    # Columns that need to be imputed are standard deviations (_sd) for both control and silvo groups
    silvo_sd_merged, control_sd_merged, 
    # Columns that are used by mice to impute values
    tree_age, crop_type, tree_type, bioclim_sub_regions, experiment_year, alley_width, # silvo_se, control_se, silvo_n, control_n,
    # IDs that are used to back-link imputed values to the dataset
    id_article, id_obs, treat_id, exp_id
  ) |> 
  mutate(
    silvo_sd_merged = as.numeric(silvo_sd_merged),
    control_sd_merged = as.numeric(control_sd_merged),
    # silvo_se = as.numeric(silvo_se),
    # control_se = as.numeric(control_se),
    # silvo_n = as.numeric(silvo_n),
    # control_n = as.numeric(control_n),
    tree_age = as.numeric(tree_age),
    crop_type = as.factor(crop_type),
    tree_type = as.factor(tree_type),
    bioclim_sub_regions = as.factor(bioclim_sub_regions),
    alley_width = as.factor(alley_width),
    id_article = as.numeric(id_article),
    id_obs = as.numeric(id_obs),
    treat_id = as.numeric(treat_id),
    exp_id = as.numeric(exp_id)
  )

#######################################################################################
# Step 2: Define the function for each imputation method
#######################################################################################
impute_data <- function(data, method_name) {
  if (method_name == "mean_imputation") {
    #######################################################################################
    # Mean Imputation (mean)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(is.na(silvo_sd_merged), mean(silvo_sd_merged, na.rm = TRUE), silvo_sd_merged),
        control_sd_merged = ifelse(is.na(control_sd_merged), mean(control_sd_merged, na.rm = TRUE), control_sd_merged)
      )
    return(data)

  } else if (method_name == "upper_quartile") {
    #######################################################################################
    # Upper Quartile Imputation (uq)
    #######################################################################################
    upper_quartile_variance <- data %>%
      summarise(across(c(silvo_sd_merged, control_sd_merged), ~ quantile(.^2, 0.75, na.rm = TRUE))) %>%
      pivot_longer(cols = everything(), names_to = "variable", values_to = "upper_quartile")

    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(is.na(silvo_sd_merged), sqrt(upper_quartile_variance$upper_quartile[1]), silvo_sd_merged),
        control_sd_merged = ifelse(is.na(control_sd_merged), sqrt(upper_quartile_variance$upper_quartile[2]), control_sd_merged)
      )
    return(data)

  } else if (method_name == "linear_imputation") {
    #######################################################################################
    # Linear Regression Imputation (lr)
    #######################################################################################
    data <- data %>%
      mutate(
        crop_type = as.numeric(as.factor(crop_type)),
        tree_type = as.numeric(as.factor(tree_type)),
        bioclim_sub_regions = as.numeric(as.factor(bioclim_sub_regions)),
        alley_width = as.numeric(as.factor(alley_width))
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "norm.predict",     # Imputed using linear regression
      "control_sd_merged" = "norm.predict",   # Imputed using linear regression
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",                        # Not imputed
      "crop_type" = "",                       # Not imputed
      "tree_type" = "",                       # Not imputed
      "bioclim_sub_regions" = "",             # Not imputed
      "experiment_year" = "",                 # Not imputed
      "alley_width" = "",                     # Not imputed
      "id_article" = "",                      # Not imputed
      "id_obs" = "",                          # Not imputed
      "treat_id" = "",                        # Not imputed
      "exp_id" = ""                           # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "bayesian") {
    #######################################################################################
    # Bayesian Imputation (by)
    #######################################################################################
    data <- data %>%
      mutate(
        silvo_sd_merged = ifelse(silvo_sd_merged < 0, 0, silvo_sd_merged),
        control_sd_merged = ifelse(control_sd_merged < 0, 0, control_sd_merged)
      )

    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "norm.nob",   # Imputed using Bayesian regression
      "control_sd_merged" = "norm.nob", # Imputed using Bayesian regression
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",                  # Not imputed
      "crop_type" = "",                 # Not imputed
      "tree_type" = "",                 # Not imputed
      "bioclim_sub_regions" = "",       # Not imputed
      "experiment_year" = "",           # Not imputed
      "alley_width" = "",               # Not imputed
      "id_article" = "",                # Not imputed
      "id_obs" = "",                    # Not imputed
      "treat_id" = "",                  # Not imputed
      "exp_id" = ""                     # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "pmm") {
    #######################################################################################
    # Predictive Mean Matching (pmm)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "pmm",     # Imputed using predictive mean matching
      "control_sd_merged" = "pmm",   # Imputed using predictive mean matching
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",               # Not imputed
      "crop_type" = "",              # Not imputed
      "tree_type" = "",              # Not imputed
      "bioclim_sub_regions" = "",    # Not imputed
      "experiment_year" = "",        # Not imputed
      "alley_width" = "",            # Not imputed
      "id_article" = "",             # Not imputed
      "id_obs" = "",                 # Not imputed
      "treat_id" = "",               # Not imputed
      "exp_id" = ""                  # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else if (method_name == "rf") {
    #######################################################################################
    # Random Forest Imputation (rf)
    #######################################################################################
    pred_matrix <- mice::make.predictorMatrix(data)
    pred_matrix[, c("tree_age", "crop_type", "tree_type", "bioclim_sub_regions", "experiment_year", "alley_width", 
                    "id_article", "id_obs", "treat_id", "exp_id")] <- 0 

    method <- c(
      "silvo_sd_merged" = "rf",   # Imputed using random forest
      "control_sd_merged" = "rf", # Imputed using random forest
      # "silvo_se" = "",                        # Not imputed
      # "control_se" = "",                      # Not imputed
      # "silvo_n" = "",                         # Not imputed
      # "control_n" = "",                       # Not imputed
      "tree_age" = "",            # Not imputed
      "crop_type" = "",           # Not imputed
      "tree_type" = "",           # Not imputed
      "bioclim_sub_regions" = "", # Not imputed
      "experiment_year" = "",     # Not imputed
      "alley_width" = "",         # Not imputed
      "id_article" = "",          # Not imputed
      "id_obs" = "",              # Not imputed
      "treat_id" = "",            # Not imputed
      "exp_id" = ""               # Not imputed
    )

    imputed_mids <- mice(
      data,
      m = 20,
      maxit = 100,
      method = method,
      predictorMatrix = pred_matrix,
      seed = 1234,
      printFlag = FALSE
    )
    return(imputed_mids)

  } else {
    stop("Invalid method name.")
  }
}

#######################################################################################
# Step 3: Apply each imputation method
#######################################################################################
imputation_methods <- c("mean_imputation", "upper_quartile", "linear_imputation", "bayesian", "pmm", "rf")
imputed_datasets <- list()

# Separate storage for raw mids objects
imputed_mids_pmm <- NULL
imputed_mids_rf <- NULL
imputed_mids_bayesian <- NULL
imputed_mids_linear <- NULL

# Iterate through imputation methods
for (method_name in imputation_methods) {
  cat("Applying", method_name, "imputation...\n")
  
  tryCatch({
    if (method_name %in% c("pmm", "rf", "bayesian", "linear_imputation")) {
      imputed_mids <- impute_data(col_for_impute, method_name)
      
      # Save mids objects for diagnostics
      if (method_name == "pmm") imputed_mids_pmm <- imputed_mids
      if (method_name == "rf") imputed_mids_rf <- imputed_mids
      if (method_name == "bayesian") imputed_mids_bayesian <- imputed_mids
      if (method_name == "linear_imputation") imputed_mids_linear <- imputed_mids
      
      # Store completed dataset
      imputed_datasets[[method_name]] <- mice::complete(imputed_mids)
    } else {
      # Direct dataset modification for other methods
      imputed_datasets[[method_name]] <- impute_data(col_for_impute, method_name)
    }
  }, error = function(e) {
    cat("Error applying", method_name, "imputation:", e$message, "\n")
  })
}

# Summary of results
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  if (!is.null(imputed_datasets[[method_name]])) {
    print(summary(imputed_datasets[[method_name]]))
  } else {
    cat("No data available for", method_name, "\n")
  }
}

#######################################################################################
# Step 4: Compare Results
#######################################################################################
for (method_name in imputation_methods) {
  cat("\nSummary of Imputed Dataset -", method_name, ":\n")
  print(summary(imputed_datasets[[method_name]]))
}

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# imputed_mids_pmm and imputed_mids_linear are the raw mids objects for PMM and linear regression respectively
# imputed_datasets contains completed and capped datasets


##########################################################################
# Last run (16/01-25)
# Total time taken: 2.12917 mins

# Last run (22/01-25)
# Total time taken: 2.82369 mins
```

```{r}
imputed_datasets |> str()
```




```{r}
# imputed_mids_pmm
# imputed_mids_rf
# imputed_mids_bayesian
# imputed_mids_linear

# List of mids objects
mids_objects <- list(
  linear = imputed_mids_linear,
  bayesian = imputed_mids_bayesian,
  pmm = imputed_mids_pmm,
  rf = imputed_mids_rf
)

# mids_objects |> str()
```

```{r}
# Ensure `database_clean_sd` has the required columns
original_metadata <- database_clean_sd %>%
  select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged)
```


```{r}
# Ensure consistent data types between original and imputed datasets
imputed_datasets <- lapply(imputed_datasets, function(data) {
  data %>%
    mutate(
      crop_type = as.factor(crop_type),
      tree_type = as.factor(tree_type),
      bioclim_sub_regions = as.factor(bioclim_sub_regions),
      alley_width = as.factor(alley_width)
    )
})

# Add original values to the dataset for comparison with each imputation method
visualization_data <- bind_rows(
  lapply(names(imputed_datasets), function(method) {
    # Extract imputed data and append original values for each method
    imputed_data <- imputed_datasets[[method]]
    bind_rows(
      data.frame(
        id_article = original_metadata$id_article,
        id_obs = original_metadata$id_obs,
        treat_id = original_metadata$treat_id,
        exp_id = original_metadata$exp_id,
        Variable = "silvo_sd_merged",
        Value = original_metadata$silvo_sd_merged,
        source = "Original",
        method = method
      ),
      data.frame(
        id_article = imputed_data$id_article,
        id_obs = imputed_data$id_obs,
        treat_id = imputed_data$treat_id,
        exp_id = imputed_data$exp_id,
        Variable = "silvo_sd_merged",
        Value = imputed_data$silvo_sd_merged,
        source = method,
        method = method
      ),
      data.frame(
        id_article = original_metadata$id_article,
        id_obs = original_metadata$id_obs,
        treat_id = original_metadata$treat_id,
        exp_id = original_metadata$exp_id,
        Variable = "control_sd_merged",
        Value = original_metadata$control_sd_merged,
        source = "Original",
        method = method
      ),
      data.frame(
        id_article = imputed_data$id_article,
        id_obs = imputed_data$id_obs,
        treat_id = imputed_data$treat_id,
        exp_id = imputed_data$exp_id,
        Variable = "control_sd_merged",
        Value = imputed_data$control_sd_merged,
        source = method,
        method = method
      )
    )
  })
)

visualization_data |> str()
```


```{r}
# Plot densities with original values overlaid on each imputation method
# Update the visualization with improved legend handling
# Plot densities with original values overlaid
ggplot(visualization_data, aes(x = Value)) +
  # Original values: red dotted line
  geom_density(
    data = subset(visualization_data, source == "Original"),
    aes(color = "Original"),
    size = 1.5,
    linetype = "dotted",
    show.legend = TRUE
  ) +
  # Imputed densities with predefined colors
  geom_density(
    data = subset(visualization_data, source != "Original"),
    aes(fill = source),
    alpha = 0.5,
    size = 1,
    color = NA # No border for filled densities
  ) +
  # Facet by method and variable
  facet_wrap(~ method + Variable, scales = "free") +
  # Pseudo log scale for better visualization of spread
  scale_x_continuous(trans = "pseudo_log") +
  # Define manual color scales for imputation methods and original
  scale_color_manual(
    values = c("Original" = "red"), # Red for original
    name = "Legend"
  ) +
  scale_fill_manual(
    values = c(
      "bayesian" = "red",
      "linear_imputation" = "yellow",
      "mean_imputation" = "green",
      "pmm" = "blue",
      "rf" = "orange",
      "upper_quartile" = "pink"
    ),
    name = "Imputation Method"
  ) +
  # General plot formatting
  theme_minimal() +
  labs(
    title = "Density Comparison of Imputed vs. Original Values (Pseudo Log Scale)",
    x = "Value (Pseudo Log Scale)",
    fill = "Imputation Method",
    color = "Legend"
  ) +
  theme(
    strip.text = element_text(size = 10, face = "bold"),
    legend.position = "top",
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(size = 8, angle = 45, hjust = 1)
  )
```
```{r}
# original_metadata |> str()
# imputed_datasets |> str()
  
# Function to process and add imputation indicators
prepare_imputation_data <- function(original, imputed_datasets) {
  # Initialize list to store datasets with imputation indicators
  processed_data <- list()
  
  # Loop through each imputation method
  for (method in names(imputed_datasets)) {
    # Join original and imputed datasets
    joined_data <- original %>%
      left_join(imputed_datasets[[method]], 
                by = c("id_article", "id_obs", "treat_id", "exp_id"),
                suffix = c(".original", ".imputed"))
    
    # Add column to indicate if the value was imputed
    joined_data <- joined_data %>%
      mutate(
        is_imputed_silvo = is.na(silvo_sd_merged.original) & !is.na(silvo_sd_merged.imputed),
        is_imputed_control = is.na(control_sd_merged.original) & !is.na(control_sd_merged.imputed),
        source = method
      )
    
    # Gather variables for visualization
    processed_data[[method]] <- joined_data %>%
      select(id_article, id_obs, treat_id, exp_id, source,
             silvo_sd_merged.original, silvo_sd_merged.imputed, 
             control_sd_merged.original, control_sd_merged.imputed,
             is_imputed_silvo, is_imputed_control) %>%
      pivot_longer(
        cols = starts_with("silvo_sd_merged") | starts_with("control_sd_merged"),
        names_to = c("Variable", ".value"),
        names_pattern = "(.*)\\.(.*)"
      )
  }
  
  # Combine all processed datasets
  combined_data <- bind_rows(processed_data)
  return(combined_data)
}
```

```{r}
# Generate the visualization data with imputation indicators
visualization_data_insights <- prepare_imputation_data(original_metadata, imputed_datasets)

# Combine original and imputed datasets
visualization_data_density_combi <- original_metadata %>%
  select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged) %>%
  pivot_longer(cols = c("silvo_sd_merged", "control_sd_merged"), names_to = "Variable", values_to = "Value") %>%
  mutate(source = "Original") %>%
  bind_rows(
    lapply(names(imputed_datasets), function(method) {
      imputed_datasets[[method]] %>%
        select(id_article, id_obs, treat_id, exp_id, silvo_sd_merged, control_sd_merged) %>%
        pivot_longer(cols = c("silvo_sd_merged", "control_sd_merged"), names_to = "Variable", values_to = "Value") %>%
        mutate(source = method)
    }) %>%
      bind_rows()
  )

# Plot densities with red outline for original and colored lines for imputation methods
ggplot(visualization_data, aes(x = Value)) +
  # Add original density with a red dotted line
  geom_density(
    data = subset(visualization_data, source == "Original"),
    aes(color = "Original"),
    size = 2,
    linetype = "dotted"
  ) +
  # Add imputed densities with specified colors
  geom_density(
    data = subset(visualization_data, source != "Original"),
    aes(fill = source),
    alpha = 0.8,
    size = 1
  ) +
  # Facet for variables
  facet_wrap(~ Variable, scales = "free") +
  # Apply pseudo-log scale for x-axis
  scale_x_continuous(trans = "pseudo_log") +
  # Define colors for original and imputation methods
  scale_color_manual(
    values = c("Original" = "red"),
    name = "Original Data"
  ) +
  scale_fill_manual(
    values = c(
      "bayesian" = "red",
      "linear_imputation" = "yellow",
      "mean_imputation" = "green",
      "pmm" = "blue",
      "rf" = "orange",
      "upper_quartile" = "pink"
    ),
    name = "Imputation Method"
  ) +
  # Customize theme
  theme_minimal() +
  labs(
    title = "Density Comparison of Imputed vs. Original Values (Pseudo Log Scale)",
    x = "Value (Pseudo Log Scale)",
    y = "Density"
  ) +
  theme(
    legend.position = "top",
    strip.text = element_text(size = 10, face = "bold"),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```



```{r}
# Check convergence of imputations
plot(imputed_mids_linear)
plot(imputed_mids_bayesian)
plot(imputed_mids_pmm)
plot(imputed_mids_rf)
```
```{r}
# Compare observed vs. imputed values for MICE datasets
stripplot(imputed_mids_linear, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_bayesian, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_pmm, silvo_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
stripplot(imputed_mids_rf, control_sd_merged ~ .imp, jitter = TRUE, pch = 20, cex = 1.2, alpha = 0.6)
```
```{r}
visualization_data |> str()

imputed_datasets |> str()
```


```{r}
# Non-MICE-based imputed datasets
non_mice_imputed_datasets <- imputed_datasets[c("mean_imputation", "upper_quartile")]

# Add the method column to each dataset in non_mice_imputed_datasets
non_mice_imputed_datasets <- lapply(names(non_mice_imputed_datasets), function(method_name) {
  dataset <- non_mice_imputed_datasets[[method_name]]
  dataset$method <- method_name
  return(dataset)
})


# non_mice_imputed_datasets |> str()

# Function to calculate evaluation metrics for non-MICE imputations
calculate_non_mice_metrics <- function(imputed_data, observed_data) {
  data.frame(
    method = unique(imputed_data$method),
    # Silvo metrics
    mean_silvo_sd = mean(imputed_data$silvo_sd_merged, na.rm = TRUE),
    sd_silvo_sd = sd(imputed_data$silvo_sd_merged, na.rm = TRUE),
    range_silvo_sd = max(imputed_data$silvo_sd_merged, na.rm = TRUE) - min(imputed_data$silvo_sd_merged, na.rm = TRUE),
    medae_silvo_sd = median(abs(observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged), na.rm = TRUE),
    mpe_silvo_sd = mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged) / observed_data$silvo_sd_merged, na.rm = TRUE) * 100,
    ks_silvo_sd = suppressWarnings(ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic),
    variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
    r2_silvo_sd = cor(observed_data$silvo_sd_merged, imputed_data$silvo_sd_merged, use = "complete.obs")^2,
    rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),

    # Control metrics
    mean_control_sd = mean(imputed_data$control_sd_merged, na.rm = TRUE),
    sd_control_sd = sd(imputed_data$control_sd_merged, na.rm = TRUE),
    range_control_sd = max(imputed_data$control_sd_merged, na.rm = TRUE) - min(imputed_data$control_sd_merged, na.rm = TRUE),
    medae_control_sd = median(abs(observed_data$control_sd_merged - imputed_data$control_sd_merged), na.rm = TRUE),
    mpe_control_sd = mean((observed_data$control_sd_merged - imputed_data$control_sd_merged) / observed_data$control_sd_merged, na.rm = TRUE) * 100,
    ks_control_sd = suppressWarnings(ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic),
    variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE),
    r2_control_sd = cor(observed_data$control_sd_merged, imputed_data$control_sd_merged, use = "complete.obs")^2,
    rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE))
  )
}

# Apply function to calculate metrics for all non-MICE datasets
non_mice_metrics <- do.call(rbind, lapply(non_mice_imputed_datasets, function(imputed_data) {
  calculate_non_mice_metrics(imputed_data, observed_data = original_metadata)
}))

non_mice_metrics |> str()
```

```{r}
# Function to calculate metrics for MICE-based imputations
calculate_mice_metrics <- function(mids_object, observed_data) {
  imputed_summaries <- lapply(1:mids_object$m, function(i) {
    imputed_data <- mice::complete(mids_object, i)
    data.frame(
      method = mids_object$method,
      iteration = i,
      # Silvo metrics
      mean_silvo_sd = mean(imputed_data$silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(imputed_data$silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = max(imputed_data$silvo_sd_merged, na.rm = TRUE) - min(imputed_data$silvo_sd_merged, na.rm = TRUE),
      medae_silvo_sd = median(abs(observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged), na.rm = TRUE),
      mpe_silvo_sd = mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged) / observed_data$silvo_sd_merged, na.rm = TRUE) * 100,
      ks_silvo_sd = suppressWarnings(ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic),
      variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
      r2_silvo_sd = cor(observed_data$silvo_sd_merged, imputed_data$silvo_sd_merged, use = "complete.obs")^2,
      rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),

      # Control metrics
      mean_control_sd = mean(imputed_data$control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(imputed_data$control_sd_merged, na.rm = TRUE),
      range_control_sd = max(imputed_data$control_sd_merged, na.rm = TRUE) - min(imputed_data$control_sd_merged, na.rm = TRUE),
      medae_control_sd = median(abs(observed_data$control_sd_merged - imputed_data$control_sd_merged), na.rm = TRUE),
      mpe_control_sd = mean((observed_data$control_sd_merged - imputed_data$control_sd_merged) / observed_data$control_sd_merged, na.rm = TRUE) * 100,
      ks_control_sd = suppressWarnings(ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic),
      variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE),
      r2_control_sd = cor(observed_data$control_sd_merged, imputed_data$control_sd_merged, use = "complete.obs")^2,
      rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE))
    )
  })
  do.call(rbind, imputed_summaries)
}

# Apply function to all MICE objects
mice_based_metrics <- do.call(rbind, lapply(mids_objects, calculate_mice_metrics, observed_data = original_metadata))

mice_based_metrics |> str()
```
```{r}
# Combine non-MICE-based and MICE-Based Metrics

# Summarize metrics for MICE-based imputations
mice_based_summary <- mice_based_metrics %>%
  group_by(method) %>%
  summarize(
    mean_ks_silvo_sd = mean(ks_silvo_sd, na.rm = TRUE),
    sd_ks_silvo_sd = sd(ks_silvo_sd, na.rm = TRUE),
    mean_ks_control_sd = mean(ks_control_sd, na.rm = TRUE),
    sd_ks_control_sd = sd(ks_control_sd, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  filter(method != "" & !is.na(method)) # Remove empty or NA method values

# Prepare non-MICE-based metrics for visualization
non_mice_summary <- non_mice_metrics %>%
  mutate(
    mean_ks_silvo_sd = ks_silvo_sd,
    sd_ks_silvo_sd = NA, # No standard deviation for single values
    mean_ks_control_sd = ks_control_sd,
    sd_ks_control_sd = NA # No standard deviation for single values
  ) %>%
  select(method, mean_ks_silvo_sd, sd_ks_silvo_sd, mean_ks_control_sd, sd_ks_control_sd)


# Combine summaries
combined_summarised_imputation <- bind_rows(
  non_mice_summary,
  mice_based_summary
)

# Rename the method column values in combined_summarised_imputation
combined_summarised_imputation <- combined_summarised_imputation %>%
  mutate(method = case_when(
    method == "mean_imputation" ~ "Mean",
    method == "upper_quartile" ~ "Upper Quartile",
    method == "norm.nob" ~ "MICE: Bayesian Regression",
    method == "norm.predict" ~ "MICE: Linear",
    method == "pmm" ~ "MICE: Predictive Mean Matching",
    method == "rf" ~ "MICE: Random Forest",
    TRUE ~ method # Retain original value for unlisted methods
  ))

# Check the result
combined_summarised_imputation |> str()
```

Visualize the Metrics with Bar Charts and Error Bars

```{r}
# Pivot the data to a long format
combined_summarised_imputation_long <- combined_summarised_imputation %>%
  pivot_longer(
    cols = starts_with("mean_ks"),
    names_to = "metric_type",
    values_to = "mean_ks"
  ) %>%
  mutate(
    sd_ks = ifelse(metric_type == "mean_ks_silvo_sd", sd_ks_silvo_sd, sd_ks_control_sd),
    metric_type = case_when(
      metric_type == "mean_ks_silvo_sd" ~ "Silvo SD",
      metric_type == "mean_ks_control_sd" ~ "Control SD",
      TRUE ~ metric_type
    )
  )


# Combined plot with facets and custom colors
combined_summarised_imputation_plot <- combined_summarised_imputation_long |> 
  ggplot(aes(x = method, y = mean_ks, fill = method)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_errorbar(aes(ymin = mean_ks - sd_ks, ymax = mean_ks + sd_ks),
                width = 0.2, position = position_dodge(0.9)) +
  facet_wrap(~ metric_type, scales = "free_y") +
  scale_fill_manual(
    values = c(
      "MICE: Bayesian Regression" = "red",
      "MICE: Linear" = "yellow",
      "Mean" = "green",
      "MICE: Predictive Mean Matching" = "blue",
      "MICE: Random Forest" = "orange",
      "Upper Quartile" = "pink"
    )
  ) +
  theme_minimal() +
  labs(
    title = "KS Statistic Across Imputation Methods",
    x = "Imputation Method",
    y = "KS Statistic",
    fill = "Method"
  ) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold")
  )

combined_summarised_imputation_plot
```
Save the plot
```{r}
# Define the output folder path
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 60),        # Increase axis text size
    axis.title = element_text(size = 80),       # Increase axis title size
    legend.position = "none",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to the plot
combined_summarised_imputation_plot <- combined_summarised_imputation_plot + theme_custom

# Save the plots
ggsave(
  filename = file.path(output_dir, "combined_summarised_imputation_plot.png"),
  plot = combined_summarised_imputation_plot,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)
```
*Notice that only the MICE imputations have errorbars (variation), because they are including iterations!

The plot illustrates the KS statistic for Silvo SD and Control SD across different imputation methods, highlighting variations in performance. Non-MICE methods, such as Mean and Upper Quartile, exhibit higher KS statistics, suggesting larger deviations from the observed data distributions. In contrast, MICE-based methods, particularly Random Forest and Predictive Mean Matching, demonstrate the lowest KS statistics with minimal variation, indicating better alignment with observed distributions. Bayesian Regression and Linear methods show moderate consistency, with Linear slightly less effective. The error bars further emphasize the variability in MICE methods, while non-MICE approaches show no such variation. Overall, MICE methods, especially Random Forest and Predictive Mean Matching, are more effective at preserving the similarity between imputed and observed distributions.



The Kolmogorov-Smirnov (KS) statistics evaluate the differences between the distributions of observed and imputed data, with lower values indicating closer alignment. The results show that Random Forest consistently achieves the lowest KS statistics, making it the most effective method for preserving the original distributions of both `silvo_sd_merged` and `control_sd_merged`. Bayesian imputation also performs well, with low and consistent KS values, suggesting a strong ability to retain the data's original characteristics. In contrast, linear imputation consistently produces high KS statistics, indicating a poor match with the observed data, while predictive mean matching (PMM) exhibits moderate performance, with some variability across imputations. Overall, Random Forest and Bayesian methods are the most reliable for maintaining distributional similarity, while linear imputation is the least suitable.

The Kolmogorov-Smirnov (KS) test is a statistical tool used to evaluate the quality of imputed data. It assesses how well the distribution of imputed values for a specific variable matches the distribution of the original, observed data. The test calculates the maximum difference between the cumulative distribution functions (CDFs) of the observed and imputed data. A larger difference (a larger KS statistic) indicates a greater discrepancy between the distributions. If the KS test yields a statistically significant result (p-value below a chosen threshold), it suggests that the imputation method may not accurately capture the underlying distribution of the variable, potentially leading to biased results in subsequent analyses.

Essentially, the KS test helps determine if the imputed data is plausible and realistically reflects the characteristics of the original data, ensuring the reliability of any analyses conducted using the imputed dataset.

Reference: "Diagnosing problems with imputation models using the Kolmogorov-Smirnov test: a simulation study" (https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-144)


Now, selecting the best of the random forest imputations

```{r}
# Function to summarize each iteration for the Random Forest mids object
summarize_rf_mids <- function(mids_rf, observed_data) {
  rf_summaries <- list()
  
  for (i in 1:mids_rf$m) { # Iterate over the number of imputations in the mids object
    imputed_data <- mice::complete(mids_rf, i) # Extract the i-th imputed dataset
    
    # Summarize the imputed dataset
    summary <- data.frame(
      imputation = i,
      ks_silvo_sd = ks.test(imputed_data$silvo_sd_merged, observed_data$silvo_sd_merged)$statistic,
      ks_control_sd = ks.test(imputed_data$control_sd_merged, observed_data$control_sd_merged)$statistic,
      rmse_silvo_sd = sqrt(mean((observed_data$silvo_sd_merged - imputed_data$silvo_sd_merged)^2, na.rm = TRUE)),
      rmse_control_sd = sqrt(mean((observed_data$control_sd_merged - imputed_data$control_sd_merged)^2, na.rm = TRUE)),
      variance_ratio_silvo = var(imputed_data$silvo_sd_merged, na.rm = TRUE) / var(observed_data$silvo_sd_merged, na.rm = TRUE),
      variance_ratio_control = var(imputed_data$control_sd_merged, na.rm = TRUE) / var(observed_data$control_sd_merged, na.rm = TRUE)
    )
    
    rf_summaries[[i]] <- summary
  }
  
  # Combine all summaries into a single data frame
  rf_summaries_df <- bind_rows(rf_summaries)
  return(rf_summaries_df)
}

# Generate summaries for the Random Forest mids object
rf_summaries_df <- summarize_rf_mids(mids_objects$rf, observed_data = col_for_impute)

# Step 3: Choose the Best Random Forest Imputation
chosen_rf_imputation <- rf_summaries_df %>%
  mutate(
    total_score = ks_silvo_sd + ks_control_sd + rmse_silvo_sd + rmse_control_sd +
      abs(variance_ratio_silvo - 1) + abs(variance_ratio_control - 1)
  ) %>%
  arrange(total_score) %>%
  slice(1)

# Extract the corresponding dataset
chosen_rf_iteration <- as.integer(chosen_rf_imputation$imputation)
imputed_rf_best <- mice::complete(mids_objects$rf, chosen_rf_iteration)

# Add the best iteration of Random Forest to the imputed datasets
imputed_datasets$rf_best <- imputed_rf_best

# Output the chosen dataset
imputed_datasets$rf_best
```


## Visually examine the imputed values - from best selected rf imputation


```{r}
################################################################################################
# Visualize Imputed Values - Best Selected RF Imputation
################################################################################################

# Check if imputed data exists
if (!is.null(imputed_datasets$rf_best$silvo_sd_merged) && 
    length(imputed_datasets$rf_best$silvo_sd_merged) > 0) {
  # Continue with the original code for silvo_sd
} else {
  # Handle the case where imputed data for silvo_sd is missing
  warning("Imputed data for silvo_sd is missing. Skipping this variable.")
}

# Rest of the code remains the same

# Combine observed (original) and imputed (rf_best) values for plotting
best_rf_plot_data <- bind_rows(
  # Original data for silvo_sd
  data.frame(
    value = original_metadata$silvo_sd_merged,
    type = "Original",
    method = "rf_best",
    variable = "silvo_sd"
  ),
  # Imputed data for silvo_sd
  data.frame(
    value = imputed_datasets$rf_best$silvo_sd_merged,
    type = "Imputed",
    method = "rf_best",
    variable = "silvo_sd"
  ),
  # Original data for control_sd
  data.frame(
    value = original_metadata$control_sd_merged,
    type = "Original",
    method = "rf_best",
    variable = "control_sd"
  ),
  # Imputed data for control_sd
  data.frame(
    value = imputed_datasets$rf_best$control_sd_merged,
    type = "Imputed",
    method = "rf_best",
    variable = "control_sd"
  )
)

# Function for density plot generation with original data as a dotted line
generate_density_plot <- function(data, title_suffix, scale_type = "linear") {
  plot <- ggplot(data) +
    geom_density(
      data = data %>% filter(type == "Imputed"),
      aes(x = value, fill = type),
      alpha = 0.5
    ) +
    geom_density(
      data = data %>% filter(type == "Original"),
      aes(x = value, color = type),
      linetype = "dotted",
      size = 1
    ) +
    facet_grid(variable ~ method) +
    labs(
      title = paste("Density Comparison:", title_suffix),
      x = ifelse(scale_type == "linear", "Value", "Value (Pseudo-Log Scale)"),
      y = "Density"
    ) +
    theme_minimal() +
    scale_fill_manual(values = c("Imputed" = "orange")) +
    scale_color_manual(values = c("Original" = "red")) +
    theme(strip.text = element_text(size = 10, face = "bold"))
  
  if (scale_type == "pseudo_log") {
    plot <- plot + scale_x_continuous(trans = scales::pseudo_log_trans(sigma = 0.1)) +
      scale_y_continuous(trans = scales::pseudo_log_trans(sigma = 0.1))
  }
  
  return(plot)
}

# Generate plots for the best RF imputation
plot_rf_best_pseudo <- generate_density_plot(
  data = best_rf_plot_data,
  title_suffix = "Best RF Imputation (Pseudo-Log Scale)",
  scale_type = "pseudo_log"
)

plot_rf_best_linear <- generate_density_plot(
  data = best_rf_plot_data,
  title_suffix = "Best RF Imputation (Linear Scale)",
  scale_type = "linear"
)

# Print the plots
plot_rf_best_pseudo
plot_rf_best_linear
```


Save the plots
```{r}
# Define the output folder path
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    axis.text = element_text(size = 30),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 60),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.x = element_text(angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
plot_rf_best_pseudo <- plot_rf_best_pseudo + theme_custom
plot_rf_best_linear <- plot_rf_best_linear + theme_custom

# Save the plots
ggsave(
  filename = file.path(output_dir, "plot_rf_best_pseudo.png"),
  plot = plot_rf_best_pseudo,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)

ggsave(
  filename = file.path(output_dir, "plot_rf_best_linear.png"),
  plot = plot_rf_best_linear,
  width = 14, height = 6, dpi = 600,
  bg = "white"
)
```






## More quantitative statistical assessment



```{r}
# a. Descriptive Statistics
# Calculate and compare mean, standard deviation, and range for key variables (e.g., silvo_se, control_se).

# a. Descriptive Statistics
# Calculate descriptive statistics for each imputation method
compare_stats <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      mean_silvo_sd = mean(silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = diff(range(silvo_sd_merged, na.rm = TRUE)),
      mean_control_sd = mean(control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(control_sd_merged, na.rm = TRUE),
      range_control_sd = diff(range(control_sd_merged, na.rm = TRUE))
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_stats)



# b. Variance Explained
# Calculate variance for silvo_se and control_se
compare_variance <- lapply(imputed_datasets, function(data) {
  # Check if data is of class 'mids', and extract the completed data
  if (inherits(data, "mids")) {
    data <- mice::complete(data)
  }
  
  data %>%
    summarise(
      var_silvo_sd = var(silvo_sd_merged, na.rm = TRUE),
      var_control_sd = var(control_sd_merged, na.rm = TRUE)
    )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_variance)
```

```{r}
# Calculate Jensen-Shannon divergence for each method - The Jensen-Shannon Divergence (JSD) is a statistical measure of similarity (or dissimilarity) between two 
# probability distributions. It quantifies how different one probability distribution is from another and is widely used in information theory, machine learning, 
# and statistics.

# Function to calculate JSD safely
calculate_jsd <- function(observed, imputed) {
  if (length(imputed) > 1 && length(observed) > 1) {
    observed_density <- density(observed)$y
    imputed_density <- density(imputed)$y
    
    # Normalize to probabilities
    observed_density <- observed_density / sum(observed_density)
    imputed_density <- imputed_density / sum(imputed_density)
    
    # Calculate JSD
    return(JSD(rbind(observed_density, imputed_density)))
  } else {
    return(NA) # Return NA if densities cannot be calculated
  }
}

# Calculate JSD for each method
compare_jsd <- lapply(imputed_datasets, function(data) {
  if (inherits(data, "mids")) {
    data <- mice::complete(data) # Handle mids objects
  }
  
  # Filter numeric columns for density calculation
  observed_silvo <- col_for_impute$silvo_sd_merged[!is.na(col_for_impute$silvo_sd_merged)]
  imputed_silvo <- data$silvo_sd_merged[is.na(col_for_impute$silvo_sd_merged)]
  
  observed_control <- col_for_impute$control_sd_merged[!is.na(col_for_impute$control_sd_merged)]
  imputed_control <- data$control_sd_merged[is.na(col_for_impute$control_sd_merged)]
  
  list(
    jsd_silvo = calculate_jsd(observed_silvo, imputed_silvo),
    jsd_control = calculate_jsd(observed_control, imputed_control)
  )
}) %>%
  bind_rows(.id = "method")

# View results
print(compare_jsd)


# Add an identifier column to each data frame and convert them to long format
compare_stats_long <- compare_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

compare_variance_long <- compare_variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

compare_jsd_long <- compare_jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine all data frames into one
combined_metrics <- bind_rows(compare_stats_long, compare_variance_long, compare_jsd_long)

# View the combined data frame
combined_metrics
```



```{r}
# Ensure `database_clean_sd` is converted to a plain data frame and the `geometry` column is removed
database_clean_sd_df <- database_clean_sd %>%
  as.data.frame() |> 
  select(-geometry)

# Recalculate the metrics for the original dataset
original_metrics <- list(
  # Descriptive statistics
  descriptive_stats = database_clean_sd_df %>%
    summarise(
      mean_silvo_sd = mean(silvo_sd_merged, na.rm = TRUE),
      sd_silvo_sd = sd(silvo_sd_merged, na.rm = TRUE),
      range_silvo_sd = diff(range(silvo_sd_merged, na.rm = TRUE)),
      mean_control_sd = mean(control_sd_merged, na.rm = TRUE),
      sd_control_sd = sd(control_sd_merged, na.rm = TRUE),
      range_control_sd = diff(range(control_sd_merged, na.rm = TRUE))
    ) %>%
    mutate(method = "original"),
  
  # Variance comparison
  variance = database_clean_sd_df %>%
    summarise(
      var_silvo_sd = var(silvo_sd_merged, na.rm = TRUE),
      var_control_sd = var(control_sd_merged, na.rm = TRUE)
    ) %>%
    mutate(method = "original"),
  
  # Jensen-Shannon divergence (JSD)
  jsd = list(
    jsd_silvo = 0, # No divergence for original dataset
    jsd_control = 0
  ) %>%
    bind_rows() %>%
    mutate(method = "original")
)

# Convert metrics to long format for visualization
original_descriptive_long <- original_metrics$descriptive_stats %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Descriptive Stats")

original_variance_long <- original_metrics$variance %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "Variance Comparison")

original_jsd_long <- original_metrics$jsd %>%
  pivot_longer(cols = -method, names_to = "metric", values_to = "value") %>%
  mutate(category = "JSD Comparison")

# Combine original metrics with imputed dataset metrics
original_combined <- bind_rows(original_descriptive_long, original_variance_long, original_jsd_long)
combined_metrics_with_original <- bind_rows(combined_metrics, original_combined)

combined_metrics_with_original |> distinct(method)
```

```{r}
prepared_data_gt <- combined_metrics_with_original %>%
  # Pivot wider to make methods the columns
  pivot_wider(names_from = method, values_from = value) %>%
  # Add absolute relative difference columns
  mutate(
    across(
      -c(metric, original, category), # Exclude non-numeric columns
      ~ ifelse(
        grepl("^jsd_", metric) & . == 0, NA,  # Set `NA` where `jsd_` metrics are 0.00
        ifelse(is.na(original) | original == 0, NA, abs((. - original) / original)) # Otherwise compute relative difference
      ),
      .names = "{.col}_relative"
    )
  ) %>%
  # Add a new column to extract the prefix (e.g., mean_, sd_, etc.)
  mutate(metric_group = sub("_.*", "", metric)) %>%
  # Sort rows first by the group (e.g., mean, sd) and then by the original metric order
  arrange(metric_group, metric)

# Display structure for verification
prepared_data_gt |> glimpse()
```


```{r}
# Create the updated plot
combined_metrics_comparison_with_original <- combined_metrics_with_original |> 
  ggplot(aes(x = method, y = value, fill = method)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.8) +
  facet_wrap(~ category + metric, scales = "free_y", ncol = 3) +
  labs(
    title = "Comparison of Imputation Methods Across Metrics (Including Original Dataset)",
    x = "Method",
    y = "Value",
    fill = "Method"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  ) +
  scale_fill_manual(
    values = c(
      "mean_imputation" = "green",
      "upper_quartile" = "pink",
      "linear_imputation" = "yellow",
      "bayesian" = "red",
      "pmm" = "blue",
      "rf" = "orange",
      "rf_best" = "purple",
      "original" = "black"
    )
  )

combined_metrics_comparison_with_original
```

Save the comparison diagnostics bar chart
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as PDF

combined_metrics_comparison_with_original <- combined_metrics_comparison_with_original + theme_custom

ggsave(
  filename = file.path(output_dir, "combined_metrics_comparison_with_original.png"),
  plot = combined_metrics_comparison_with_original,
  width = 14, height = 18, dpi = 400,
  bg = "white"
)
```

```{r}
# Apply color shading to all `_relative` columns
comparison_gt <- prepared_data_gt %>%
   # Reorder the columns in the data frame before passing to gt
  select(
    metric, category, original, 
    linear_imputation,
    linear_imputation_relative,
    mean_imputation, 
    mean_imputation_relative,
    upper_quartile, 
    upper_quartile_relative, 
    bayesian,
    bayesian_relative,
    pmm, 
    pmm_relative,  
    rf,
    rf_relative,
    rf_best,  
    rf_best_relative
    ) |> 
  # Set `metric` as row names
  gt() %>%
  data_color(
    columns = ends_with("_relative"), # Target all _relative columns
    method = "numeric", # Use numeric method for gradient mapping
    palette = c(
    "#00FF00", # Bright Green
    "#80FF00", # Light Green
    "#A8FF00", # Lime Green
    "#FFFF00", # Yellow
    "#FFA500", # Orange
    "#FF4500", # Orange-Red
    "#FF0000", # Bright Red
    "#8B0000"  # Dark Red
),
    domain = c(0, 0.45), # Domain for relative differences
    na_color = "#f0f0f0" # Light gray for missing/NA values
  ) %>%
  tab_header(
    title = "Comparison of Imputation Methods Across Metrics",
    subtitle = "Including Original Data and Relative Differences"
  ) %>%
  cols_label(
    original = "Original",
    linear_imputation = "Linear Imputation",
    linear_imputation_relative = "Linear Imputation Relative",
    mean_imputation = "Mean Imputation",
    mean_imputation_relative = "Mean Imputation Relative",
    upper_quartile = "Upper Quartile",
    upper_quartile_relative = "Upper Quartile Relative",
    bayesian = "Bayesian",
    bayesian_relative = "Bayesian Relative",
    pmm = "PMM",
    pmm_relative = "PMM Relative",
    rf = "Random Forest",
    rf_relative = "Random Forest Relative",
    rf_best = "Random Forest Best",
    rf_best_relative = "Random Forest Best Relative"
    ) %>%
  fmt_number(
    columns = c(original, 
                linear_imputation,
                mean_imputation,
                upper_quartile,
                pmm,
                rf,
                rf_best),
    decimals = 2
  ) %>%
  fmt_number(
    columns = ends_with("_relative"),
    decimals = 3
  ) %>%
  sub_missing(
    columns = ends_with("_relative"),
    missing_text = "NA"
  ) %>%
  tab_options(
    table.font.size = "small",
    column_labels.font.size = "medium"
  )

# Display the table
comparison_gt
```



The performance comparison of imputation methods reveals notable differences in their ability to preserve statistical properties and align with the original dataset. Evaluations are based on metrics such as mean, range, standard deviation (SD), variance, and Jensen-Shannon divergence (JSD).

**Upper Quartile**, despite preserving descriptive statistics such as mean and variance effectively, exhibits some of the highest JSD values (0.9556 for control and 0.9410 for silvo). This indicates a significant distortion of the original data distribution, making it less reliable for analyses that depend on the alignment of distributions.

**PMM (Predictive Mean Matching)** and **Random Forest (RF)** methods deliver a balanced performance across most metrics. PMM achieves lower JSD values (0.8169 for control and 0.7251 for silvo), suggesting better alignment with the original distribution. Additionally, PMM maintains relatively stable variance and SD values. RF performs similarly, with particularly low relative differences in variance and SD, though it slightly trails PMM in JSD alignment. The **RF Best** refinement further improves performance, with the lowest JSD values among all methods (0.0223 for control and 0.2758 for silvo) and minimal deviation in descriptive statistics.

**Mean Imputation** and **Bayesian** methods exhibit biases in their imputed values. Mean Imputation shows significant upward deviations in variance (16.4% for control and 16.4% for silvo), leading to less precise variance preservation. Bayesian imputation introduces moderate relative differences in SD and variance, which, although smaller than those for Mean Imputation, reflect distributional inconsistencies.

**Linear Imputation** maintains moderate performance with minimal relative differences across most metrics but does not outperform PMM or RF in any significant way. Its performance remains consistent but unspectacular, making it a reasonable, if not optimal, choice.

**Conclusion:** **RF Best** and **PMM** emerge as the most reliable imputation methods, balancing distributional alignment (low JSD) and consistency in descriptive statistics. In contrast, **Upper Quartile** is less suitable due to high JSD values, despite its stability in means and variances. **Bayesian** and **Mean Imputation** show upward biases in key metrics, and Linear Imputation offers moderate but unremarkable performance. Selecting the most appropriate method depends on the analysis goals, with RF Best and PMM being the most versatile options.


Save the comparison gt table
```{r}
# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as HTML
gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.html"))

# Save as PDF
# gtsave(data = comparison_gt, filename = file.path(output_dir, "comparison_gt_table.pdf"))

```



```{r}
imputed_datasets |> glimpse()
```




# STEP 5 MERGING THE IMPUTED DATASET BACK TO THE ORIGINAL DATA AND VISUALISE


```{r}
##############
# SMART SELECTION OF IMPUTATION METHOD - USING RF_BEST IMPUTATION ONLY
############################################################################

# Step 1: Select only the rf_best imputed dataset
rf_best_imputed_data <- imputed_datasets$rf_best %>%
  select(id_article, id_obs, 
         silvo_sd_rf_best = silvo_sd_merged, 
         control_sd_rf_best = control_sd_merged)

# Check for missing values in the entire dataset
any_na <- any(is.na(rf_best_imputed_data))

# Print result
if (any_na) {
  print("The rf_best_imputed_data contains missing values.")
} else {
  print("The rf_best_imputed_data does not contain any missing values.")
}

# Optionally, to see how many missing values per column
colSums(is.na(rf_best_imputed_data))


# Step 2: Merge the rf_best-imputed data back into the original dataset
merged_rf_best_data <- database_clean_sd_df %>%
  full_join(
    rf_best_imputed_data,
    by = c("id_article", "id_obs"),
    suffix = c("_original", "_imputed")
  ) %>% 
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, climate_zone, bioclim_sub_regions, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best
  )


# Step 4: Add a column indicating the imputation method used
merged_rf_best_data <- merged_rf_best_data %>%
  mutate(imputation_method = "RF Best")

# Step 5: Preview the structure of the merged dataset
merged_rf_best_data |> glimpse()

# Additional Notes:
# - Only the RF Best imputed dataset is used for this workflow.
# - The `imputation_method` column reflects that RF Best was applied.
# - The recalculation of _sd_from_se ensures compatibility for rows with missing original SD values.
```
```{r}
merged_rf_best_data |> glimpse()
```


```{r}
# Assessing the data for missingness

merged_rf_best_data |> select(
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best,
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n)|> 
  skim()
```

```{r}
# Inspect the dataset to understand the column names
# colnames(merged_rf_best_data)

# Skim the data and extract the required metrics
skimmed_data <- merged_rf_best_data |> 
  select(
    # silvo_se, control_se, 
    silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_rf_best,
    control_sd, control_sd_from_se, control_sd_merged, control_sd_rf_best
    #silvo_mean, control_mean, silvo_n, control_n
  ) |> 
  skimr::skim() |> 
  as_tibble() |> 
  select(skim_variable = skim_variable, complete_rate = complete_rate, 
         numeric_mean = numeric.mean, numeric_sd = numeric.sd)

# Rename columns for better readability
skimmed_data <- skimmed_data |> 
  rename(
    variable = skim_variable,
    mean = numeric_mean,
    sd = numeric_sd
  )

# Convert the data to long format for plotting
skimmed_data_long <- skimmed_data |> 
  pivot_longer(
    cols = c(complete_rate, mean, sd),
    names_to = "metric",
    values_to = "value"
  )

# Create the bar plot with faceting by metric
skimmed_data_long |> 
  ggplot(aes(x = variable, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = position_dodge(), alpha = 0.8) +
  facet_wrap(~ metric, scales = "free_y", ncol = 1) +
  labs(
    title = "Comparison of Variance Metrics Across Variables",
    x = "Variable",
    y = "Value",
    fill = "Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  )

```




```{r}
# Make a new _sd_final for `silvo_sd` and `control_sd` with Random Forest imputed values if originally merged _sd values are missing

merged_data <- merged_rf_best_data %>%
  mutate(
    # For `silvo_sd`, check if the original value is missing (NA)
    # If missing, use the imputed value (`silvo_sd_rf_best`)
    # Otherwise, retain the original value (`silvo_sd_merged`)
    silvo_sd_final = ifelse(is.na(silvo_sd_merged), silvo_sd_rf_best, silvo_sd_merged),
    
    # For `control_sd`, check if the original value is missing (NA)
    # If missing, use the imputed value (`control_sd_rf_best`)
    # Otherwise, retain the original value (`control_sd_merged`)
    control_sd_final = ifelse(is.na(control_sd_merged), control_sd_rf_best, control_sd_merged)
  )

# The '_sd_final'  will be used in the escalc() effect size calculations!
```


```{r}
# Identify rows where imputation occurred
imputation_evaluation <- merged_data %>%
  filter(
    (is.na(silvo_sd_merged) & !is.na(silvo_sd_final)) |
    (is.na(control_sd_merged) & !is.na(control_sd_final))
  ) %>%
  select(id_article, id_obs, exp_id) %>%
  distinct()

# Count the number of unique articles where imputation occurred
n_imputed_studies <- imputation_evaluation %>%
  distinct(id_article) %>%
  nrow()

cat("Number of unique articles with imputed values:", n_imputed_studies, "\n")

# Last go (24/01-2025) 
# Number of unique articles with imputed values: 11 
```


```{r}
# Calculate missing counts and proportions for the _sd
missing_summary <- merged_data %>%
  summarise(
    total_obs = n(),

    # Missing counts for original dataset
    silvo_sd_original_missing = sum(is.na(silvo_sd_merged)),
    control_sd_original_missing = sum(is.na(control_sd_merged)),

    # Missing counts for imputed dataset
    silvo_sd_imputed_missing = sum(is.na(silvo_sd_final)),
    control_sd_imputed_missing = sum(is.na(control_sd_final))
  ) %>%
  mutate(
    # Proportions for original dataset
    silvo_sd_original_proportion = silvo_sd_original_missing / total_obs,
    control_sd_original_proportion = control_sd_original_missing / total_obs,

    # Proportions for imputed dataset
    silvo_sd_imputed_proportion = silvo_sd_imputed_missing / total_obs,
    control_sd_imputed_proportion = control_sd_imputed_missing / total_obs
  )

missing_summary
```

```{r}
original_data <- database_clean_sd_df %>%
  select(id_article, id_obs, 
         silvo_sd_final = silvo_sd_merged, silvo_sd_from_se, silvo_sd,  
         control_sd_final = control_sd_merged, control_sd_from_se, control_sd) %>%
  mutate(data_source = "Original")

imputed_data <- merged_data %>%
  select(id_article, id_obs, 
         silvo_sd_final, silvo_sd_from_se, silvo_sd,  
         control_sd_final, control_sd_from_se, control_sd) %>%
  mutate(data_source = "Imputed")

# Combine original and imputed data
combined_data <- bind_rows(original_data, imputed_data)
```

```{r}
# Check for duplicates
duplicates <- merged_data %>%
  group_by(id_article, id_obs) %>%
  filter(n() > 1)

# Check for rows with imputed values
imputation_check <- merged_data %>%
  filter(is.na(silvo_sd_merged) & !is.na(silvo_sd_final))

# View summaries
print(duplicates)
print(imputation_check)
```


## VISUAL DIAGNOSTIGS OF MERGED DATA WITH SELECTED IMPUTATION METHOD


```{r}
# imputed_datasets |> str()
```

```{r}

# Filter relevant columns for analysis
imputation_analysis_data <- merged_data %>%
  select(imputation_method, 
         silvo_sd_merged, silvo_sd_rf_best, 
         control_sd_merged, control_sd_rf_best) %>%
  pivot_longer(
    cols = c(silvo_sd_merged, silvo_sd_rf_best, 
             control_sd_merged, control_sd_rf_best),
    names_to = "variable",
    values_to = "value"
  ) %>%
  mutate(
    group = case_when(
      grepl("^silvo", variable) ~ "Silvo",
      grepl("^control", variable) ~ "Control"
    ),
    variable = case_when(
      grepl("_sd_merged", variable) ~ "SD Merged",
      grepl("_sd_rf_best", variable) ~ "SD RF Best"
    )
  ) %>%
  drop_na(value)  # Remove rows with NA values

# Create a boxplot for _sd_merged and _sd_rf_best side by side by imputation_method
boxplot <- ggplot(imputation_analysis_data, aes(x = variable, y = value, fill = imputation_method)) +
  geom_boxplot(alpha = 0.7, outlier.shape = NA) +  # Boxplot without outlier points
  geom_jitter(color = "black", size = 0.5, alpha = 0.5, width = 0.2) +  # Add jitter for individual points
  facet_wrap(~group, scales = "free_y") +  # Facet by group (Silvo and Control)
  labs(
    title = "Comparison of Merged and RF-Best SD by Imputation Method",
    x = "SD Type",
    y = "Value",
    fill = "Imputation Method"
  ) +
  scale_y_continuous(trans = "pseudo_log") +  # Apply pseudo-log scale to y-axis
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "top"
  )

# Print the boxplot
print(boxplot)
```



Quality check of imputation using QQ-plot 

```{r}
# Pivot data to long format for easier plotting
qq_imp_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_sd_final, control_sd_final),
    names_to = "variable",
    values_to = "value"
  ) |> 
  # Replace NA with 0 (or another strategy if preferred)
  mutate(value = ifelse(is.na(value), 0, value)) 

# Compute theoretical quantiles and prepare the data for jitter
qq_data_jitter <- qq_imp_data %>%
  group_by(variable, data_source) %>%
  mutate(
    theoretical = qnorm((rank(value, na.last = "keep") - 0.5) / sum(!is.na(value))) # Compute theoretical quantiles
  ) %>%
  ungroup() 

# Enhanced Q-Q Plot with Fixed Scales and Confidence Intervals
qqplot_imp_combined <- qq_data_jitter %>%
  ggplot(aes(x = theoretical, y = value, color = data_source, shape = data_source)) +
  geom_point(
    position = position_jitter(width = 0.05, height = 0.05),
    alpha = 0.8,
    size = 1.5
  ) + # Jitter points
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black", size = 1) + # Reference line
  facet_wrap(~variable, scales = "fixed", ncol = 2) + # Fixed scales for consistent comparison
  scale_y_continuous(trans = "log10", breaks = scales::log_breaks(base = 10)) + # Log scale for y-axis
  labs(
    title = "Q-Q Plots for Original vs. Imputed Data",
    subtitle = "Assessing Distributional Similarity with Enhanced Features",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles (Log Scale)",
    color = "Data Source",
    shape = "Data Source"
  ) +
  scale_color_manual(
    values = c("Imputed" = "#1f78b4", "Original" = "#33a02c") # Distinct colors for clarity
  ) +
  scale_shape_manual(
    values = c("Imputed" = 16, "Original" = 17) # Consistent point shapes
  ) +
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 14, face = "italic", hjust = 0.5),
    axis.text = element_text(size = 12),
    axis.title = element_text(size = 14, face = "bold"),
    strip.text = element_text(size = 14, face = "bold"),
    legend.position = "bottom",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Print the improved Q-Q plot
print(qqplot_imp_combined)
```

The Q-Q plot above compares the theoretical quantiles of the original and imputed data distributions for control_sd and silvo_sd, with a log-transformed y-axis to account for the wide range of values. The dashed reference line represents perfect agreement between the theoretical and sample quantiles. Points close to this line indicate good alignment between the original and imputed distributions.

For control_sd_final, the imputed data closely matches the original data in the lower quantile range, but some divergence occurs at higher quantiles. This suggests the imputation replicates the original distribution well for smaller and moderate values but overestimates variability in the upper tail. A similar pattern is observed for silvo_sd_final, where the imputed data aligns well with the original distribution in lower and mid-range quantiles but shows slight overestimation in the higher quantiles. The log-transformed scale effectively highlights these deviations across all ranges of the data.

Overall, the imputation method appears robust for most of the distribution, particularly in the central range, which is often the most critical for analysis. However, the slight overestimation in the upper quantiles suggests a potential limitation in handling extreme values. If these deviations are significant for downstream analyses, further refinement of the imputation model may be required to better address variability in the tails of the distribution.

Saving QQ-plot

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
qqplot_imp_combined <- qqplot_imp_combined + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "qqplot_imp_combined_enhanced_rf_log_scale.png"),
  plot = qqplot_imp_combined,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```



Again, checking the imputed control_sd and silvo_sd density distribution (imputation = Random Forest (best))
```{r}
# Combine the data for silvo_se and control_se into long format
density_data <- combined_data %>%
  pivot_longer(
    cols = c(silvo_sd_final, control_sd_final),
    names_to = "variable",
    values_to = "value"
  )

# Filter out non-positive values for log transformation
density_data_clean <- density_data %>%
  filter(value > 0) # Keep only positive values

# Improved density plot with custom x-axis labels
density_plot_clean <- density_data_clean %>%
  ggplot(aes(x = value, color = data_source, fill = data_source)) +
  geom_density(alpha = 0.4, na.rm = TRUE) + # Add density plot with transparency
  scale_x_log10(
    breaks = scales::trans_breaks("log10", function(x) 10^x), # Define breaks at log10 intervals
    labels = scales::trans_format("log10", scales::math_format(10^.x)) # Format labels as 10^x
  ) +
  labs(
    title = "Density Distribution of silvo_se and control_se (Log-Transformed)",
    x = "Value (Log Scale)",
    y = "Density",
    color = "Data Source",
    fill = "Data Source"
  ) +
  facet_wrap(~variable, scales = "free_x", ncol = 2) + # Separate plots for silvo_se and control_se
  scale_color_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  scale_fill_viridis_d(option = "D", begin = 0.2, end = 0.8) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "bottom"
  )

# Display the density plot
density_plot_clean
```

Save density distribution plot of imputed control_se and silvo_se

```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 80),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 50),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 80),      # Increase legend text size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    axis.text.x = element_text(size = 100,
                               angle = 0, hjust = 0) # Rotate x-axis text
  )

# Apply theme modifications to each plot
density_plot_clean <- density_plot_clean + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "density_plot_clean_rf.png"),
  plot = density_plot_clean,
  width = 8, height = 6, dpi = 600,
  bg = "white"
)
```


# STEP 6 SAVING TWO VERSIONS OF PREPROCESSED DATA FOR FURTHER ANALYSIS AND VISUALIZATION - RECALCULATION OF _SD WHERE THE ORIGINAL _SD IS MISSING


```{r}
# Imputed dataset where _se is imputed and then subsequently used to calculate _sd
imp_rf_best <- merged_data |> 
  as.data.frame() |> 
  # (remove geometry if necessary)
  # select(-geometry) |> 
  # Relocate columns to the desired order 
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_merged, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_merged, control_sd_final,
    # Imputation info
    imputation_method 
  )

# Preview the dataset structure silvo_sd_calculated_from_se
glimpse(imp_rf_best)
```
```{r}
imp_rf_best |> skim()
```

```{r}
# Non-imputed dataset (remove geometry if necessary)
non_imp_dataset <- database_clean_sd |> 
  as.data.frame() |> 
  # (remove geometry if necessary)
  select(-geometry) |> 
  # Rename existing _sd columns to _sd_original
  rename(
    silvo_sd_final = silvo_sd_merged,
    control_sd_final = control_sd_merged) |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final,
    # Imputation info
    # imputation_method 
  )

# Preview the dataset structure silvo_sd_calculated_from_se
glimpse(non_imp_dataset)
```


```{r}
non_imp_dataset |> skim()
```



DATASET COMPARISON (CATEGORICAL AND NUMERICAL DATA)

```{r}
###############################
# DATASET COMPARISON SCRIPT
###############################

# Function to filter valid columns with non-NA values and valid variance
filter_valid_columns <- function(df) {
  df %>% select(where(~ !all(is.na(.)) && var(., na.rm = TRUE) > 0))
}

# -----------------
# CATEGORICAL DATA
# -----------------
imp_rf_best_categorical <- imp_rf_best %>%
  select(where(is.factor) | where(is.character)) %>%
  select(where(~ !all(is.na(.))))

non_imp_dataset_categorical <- non_imp_dataset %>%
  select(where(is.factor) | where(is.character)) %>%
  select(where(~ !all(is.na(.))))

if (ncol(imp_rf_best_categorical) > 0 && ncol(non_imp_dataset_categorical) > 0) {
  common_columns <- intersect(names(imp_rf_best_categorical), names(non_imp_dataset_categorical))
  imp_rf_best_categorical <- imp_rf_best_categorical %>% select(all_of(common_columns))
  non_imp_dataset_categorical <- non_imp_dataset_categorical %>% select(all_of(common_columns))

  if (ncol(imp_rf_best_categorical) > 0 && ncol(non_imp_dataset_categorical) > 0) {
    cat_plot <- inspect_cat(imp_rf_best_categorical, non_imp_dataset_categorical) %>% show_plot()
    print(cat_plot)
  } else {
    cat("No common valid categorical columns found for comparison.\n")
  }
} else {
  cat("One or both datasets have no valid categorical columns to compare.\n")
}

# -----------------
# NUMERICAL DATA
# -----------------
imp_rf_best_numeric <- imp_rf_best %>% select(where(is.numeric)) %>% filter_valid_columns()
non_imp_dataset_numeric <- non_imp_dataset %>% select(where(is.numeric)) %>% filter_valid_columns()

if (ncol(imp_rf_best_numeric) > 0 && ncol(non_imp_dataset_numeric) > 0) {
  imp_rf_best_numeric$dataset <- "imputed"
  non_imp_dataset_numeric$dataset <- "non-imputed"

  combined_data <- bind_rows(imp_rf_best_numeric, non_imp_dataset_numeric)
  combined_long <- combined_data %>%
    pivot_longer(cols = -dataset, names_to = "variable", values_to = "value")

  numeric_plot <- ggplot(combined_long, aes(x = value, fill = dataset)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~variable, scales = "free") +
    labs(title = "Density Plots for Numeric Variables", x = "Value", y = "Density") +
    theme_minimal()

  print(numeric_plot)
} else {
  cat("One or both datasets have no valid numeric columns to compare.\n")
}

# -----------------------------
# COLUMN-WISE SIMILARITY CHECK
# -----------------------------
if (ncol(imp_rf_best) > 0 && ncol(non_imp_dataset) > 0) {
  cor_plot <- inspect_cor(imp_rf_best, non_imp_dataset) %>% show_plot()
  print(cor_plot)

  na_plot <- inspect_na(imp_rf_best, non_imp_dataset) %>% show_plot()
  print(na_plot)
} else {
  cat("One or both datasets are empty or invalid for column-wise comparison.\n")
}
```


```{r}
# SAVING TWO VERSIONS OF PREPROCESSED DATA AS RDS

# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save the non-imputed dataset as RDS
saveRDS(non_imp_dataset,
        file = file.path(output_dir, "non_imp_dataset.rds"))


# Save the best-imputed dataset as RDS
saveRDS(imp_rf_best,
        file = file.path(output_dir, "imp_rf_best_dataset.rds"))

# Print confirmation messages
cat("Datasets saved successfully:\n")
cat("- Non-imputed dataset: non_imp_dataset.rds\n")
cat("- Best-imputed dataset: imp_rf_best_dataset.rds\n")
```





# STEP 7 CALCULATING EFFECT SIZES FOR IMPUTED AND NON-IMPUTED DATASETS


Loading datasets
```{r}
# Load the non-imputed and imputed datasets
non_imp_dataset <- readRDS(file.path(output_dir, "non_imp_dataset.rds"))

# Load the imputed dataset
imp_rf_best <- readRDS(file.path(output_dir, "imp_rf_best_dataset.rds"))
```



```{r}
non_imp_dataset |> glimpse()
imp_rf_best |> glimpse()
```


```{r}
# Step 1: Define Target Columns
target_columns <- c("silvo_sd_rf_best", "control_sd_rf_best")

# Step 2: Calculate Upper Quartile Variance by `sub_response_variable`
upper_quartile_variance <- imp_rf_best %>%
  group_by(sub_response_variable) %>%
  summarise(
    silvo_sd_rf_best_uq = quantile(silvo_sd_rf_best^2, 0.95, na.rm = TRUE),
    control_sd_rf_best_uq = quantile(control_sd_rf_best^2, 0.95, na.rm = TRUE),
    .groups = "drop"
  )

# Step 3: Identify High Variance Observations by `sub_response_variable`
thresholds <- imp_rf_best %>%
  group_by(sub_response_variable) %>%
  summarise(
    silvo_threshold = quantile(silvo_sd_rf_best^2, 0.95, na.rm = TRUE) +
      1.5 * IQR(silvo_sd_rf_best^2, na.rm = TRUE),
    control_threshold = quantile(control_sd_rf_best^2, 0.95, na.rm = TRUE) +
      1.5 * IQR(control_sd_rf_best^2, na.rm = TRUE),
    .groups = "drop"
  )

# Merge thresholds and upper quartile variance back to the original data
imp_rf_best_with_thresholds <- imp_rf_best %>%
  left_join(thresholds, by = "sub_response_variable") %>%
  left_join(upper_quartile_variance, by = "sub_response_variable")

# Filter high variance rows for `silvo_sd_rf_best`
high_variance_silvo_sd_rf_best <- imp_rf_best_with_thresholds %>%
  mutate(variance = silvo_sd_rf_best^2) %>%
  filter(variance > silvo_threshold) %>%
  select(id_article, id_obs, sub_response_variable, variance, silvo_sd_rf_best, control_sd_rf_best)

# Filter high variance rows for `control_sd_rf_best`
high_variance_control_sd_rf_best <- imp_rf_best_with_thresholds %>%
  mutate(variance = control_sd_rf_best^2) %>%
  filter(variance > control_threshold) %>%
  select(id_article, id_obs, sub_response_variable, variance, silvo_sd_rf_best, control_sd_rf_best)

# Combine high variance rows
high_variance_rows <- bind_rows(high_variance_silvo_sd_rf_best, high_variance_control_sd_rf_best) %>%
  distinct()

# Step 4: Replace High Variance Values with the Condition
imp_rf_best_uq <- imp_rf_best_with_thresholds %>%
  mutate(
    silvo_sd_rf_best_uq = ifelse(
      id_obs %in% high_variance_rows$id_obs & id_article %in% high_variance_rows$id_article & is.na(silvo_sd_merged),
      sqrt(silvo_sd_rf_best_uq),
      silvo_sd_rf_best
    ),
    control_sd_rf_best_uq = ifelse(
      id_obs %in% high_variance_rows$id_obs & id_article %in% high_variance_rows$id_article & is.na(control_sd_merged),
      sqrt(control_sd_rf_best_uq),
      control_sd_rf_best
    )
  ) 

# Step 5: View Updated Dataset
imp_rf_best_uq %>% glimpse()
imp_rf_best_uq |> skim()
```

```{r}
# Function to prepare data for plotting
prepare_plot_data <- function(dataset, id) {
  dataset %>%
    select(silvo_sd_rf_best, silvo_sd_rf_best_uq, control_sd_rf_best, control_sd_rf_best_uq) %>%
    pivot_longer(cols = everything(),
                 names_to = "Variable",
                 values_to = "Value") %>%
    mutate(Dataset = id)
}

# Prepare datasets for visualization
imp_rf_best_plot_data <- prepare_plot_data(imp_rf_best_uq, "imp_rf_best_uq")

# Combine datasets (if needed, extend for multiple datasets)
combined_plot_data <- imp_rf_best_plot_data

# Adjust data for visualization
filtered_plot_data <- combined_plot_data %>%
  filter(!is.na(Value))  # Remove rows with missing values

# Re-plot with improved adjustments
ggplot(filtered_plot_data, aes(x = Variable, y = Value, fill = Dataset)) +
  geom_violin(alpha = 0.4, scale = "width", position = position_dodge(width = 0.8)) + # Separate violins
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0.7, position = position_dodge(width = 0.8)) + # Separate boxplots
  geom_jitter(
    aes(color = Dataset), 
    position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.8), 
    alpha = 0.4
  ) + # Add jittered points without overlap
  labs(
    title = "Comparison of _uq vs Non-_uq Variables",
    x = "Variable",
    y = "Value"
  ) +
  scale_fill_brewer(palette = "Set2") + # Use color palette for violins and boxplots
  scale_color_brewer(palette = "Set2") + # Match colors for jitter points
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), # Adjust axis label angle
    legend.position = "top" # Place legend at the top
  )
```

Check what observations has different values in _sd_rf_best_uq as compared to _sd_rf_best

```{r}
# Identify differences in values between _sd_rf_best and _sd_rf_best_uq
differences <- imp_rf_best_uq %>%
  filter(
    silvo_sd_rf_best != silvo_sd_rf_best_uq |
    control_sd_rf_best != control_sd_rf_best_uq
  ) %>%
  select(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se,  
    control_se, control_sd, control_sd_from_se, 
    # Updated variance columns
    silvo_sd_rf_best, silvo_sd_rf_best_uq,
    control_sd_rf_best, control_sd_rf_best_uq
  )

# Display the differences
differences %>% glimpse()

# Rows: 13
# Columns: 32
# $ id_article            <dbl> 10, 10, 10, 10, 10, 13, 29, 29, 29, 29, 29, 30, 33
# $ id_obs                <dbl> 364, 371, 379, 383, 384, 493, 873, 877, 878, 889, 899, 913, 1048


differences |> select(
  # Updated variance columns
  silvo_sd_rf_best, silvo_sd_rf_best_uq,
  control_sd_rf_best, control_sd_rf_best_uq) |> 
  skim()
```


```{r}
# Only 13 observations out of 1,095 differ between rf_best and rf_best_uq
# Going forward, let’s use the upper-quartile-imputed standard deviations as the final imputed values for control_sd_final and silvo_sd_final.

imp_rf_best <- imp_rf_best_uq |> 
  mutate(
    control_sd_final = control_sd_rf_best_uq,
    silvo_sd_final = silvo_sd_rf_best_uq
  )
```




# STEP 8 EFFECT SIZE CALCULATION


```{r}
# Function for data preparation before escalc() effect size calculation

prep_dataset_for_rom <- function(data) {
  data %>%
    # Step 1: Filter out rows where the standard deviations are zero or negative
    # - Standard deviation (SD) must be positive for valid statistical calculations.
    filter(silvo_sd_final > 0, control_sd_final > 0) %>%
    
    # Step 2: Adjust the sign of mean values for specific response variables
    # - For variables like "Pest and disease control" (Abundance of pests and diseases) and "Water quality" (Nutrient concentrations),
    #   lower values are considered better. We negate the mean values to reflect this correctly.
    # - For other response variables, e.g. "Carbon sequestrations" (SOC stock/sequestration), the sign stays as higher values are intuitively 'better'
    # mutate(
    #   silvo_mean = ifelse(response_variable %in% c("Pest and disease control", "Water quality"),
    #                       -silvo_mean, silvo_mean),
    #   control_mean = ifelse(response_variable %in% c("Pest and disease control", "Water quality"),
    #                         -control_mean, control_mean)
    # ) %>%
    # 
    # Step 3: Exclude specific response variables from analysis
    # - "Soil water content" is excluded due to inconsistent data or limited measurements.
    filter(response_variable != "Soil water content") %>%
    
    # Step 4: Remove rows with missing values in key columns
    # - Ensures complete data for effect size calculation.
    filter(!is.na(silvo_mean) & !is.na(control_mean) &
           !is.na(silvo_n) & !is.na(control_n) &
           !is.na(silvo_sd_final) & !is.na(control_sd_final)) %>%
    
    # Step 5: Shift mean values to be positive
    # - Calculate a shift value (min_value_shift) based on the absolute minimum value
    #   of the means, ensuring all values are positive for transformations.
    mutate(
      min_value_shift = abs(min(c(silvo_mean, control_mean), na.rm = TRUE)) + 1,
      silvo_mean = silvo_mean + min_value_shift,
      control_mean = control_mean + min_value_shift
    ) %>%
    
    # Step 6: Reorder columns for better readability and organization
    # - Places important columns (e.g., identifiers, means, SEs, SDs, sample sizes) at the front of the data frame.
    relocate(id_article, response_variable, measured_metrics, measured_unit,
             silvo_mean, silvo_n, silvo_sd_final, control_mean, control_n, control_sd_final) %>%
    
    # Step 7: Sort the data by article ID and response variable for consistency
    # - Sorting helps ensure that the data is organized and facilitates easier inspection and analysis.
    arrange(id_article, response_variable)
}
```

```{r}
# Apply the data preparation function to both non-imputed and imputed datasets
# - This creates cleaned and prepared datasets for effect size calculation.
non_imp_data_prep <- prep_dataset_for_rom(non_imp_dataset)
imp_data_prep <- prep_dataset_for_rom(imp_rf_best)
```

```{r}
skimr::skim(imp_data_prep)
```


```{r}
# Generic function for effect size calculation using `escalc()`

# This function can be applied to both imputed and non-imputed datasets.

calculate_effect_sizes <- function(data, measure = "ROM") {
  # Check if the required columns are present in the dataset
  required_columns <- c("silvo_mean", "silvo_n", "silvo_sd_final", 
                        "control_mean", "control_n", "control_sd_final",
                        "id_article", "id_obs", "experiment_year")
  
  if (!all(required_columns %in% names(data))) {
    stop("The dataset is missing one or more required columns.")
  }
  
  # Calculate effect sizes using `escalc()`
  result <- escalc(
    measure = measure,           # Specify the effect size measure (default is "ROM").
    
    # Experimental group (silvo_) parameters:
    m1i = silvo_mean,            # Mean of the experimental (silvo) group.
    sd1i = silvo_sd_final,       # Standard deviation of the experimental (silvo) group.
    n1i = silvo_n,               # Sample size of the experimental (silvo) group.
    
    # Control group (control_) parameters:
    m2i = control_mean,          # Mean of the control group.
    sd2i = control_sd_final,     # Standard deviation of the control group.
    n2i = control_n,             # Sample size of the control group.
    
    # Study labels for identification:
    slab = paste(id_article, ", ", experiment_year, sep = ""),
    
    # The input dataset:
    data = data
  ) %>%
    as.data.frame()              # Convert the result to a data frame for easier handling.
  
  # Return the resulting data frame with calculated effect sizes
  return(result)
}
```

```{r}
# Inspect the input data to `escalc()`
imp_data_prep %>%
  select(id_article, response_variable, 
         silvo_mean, silvo_n, silvo_sd_final, 
         control_mean, control_n, control_sd_final) %>%
  filter(is.na(silvo_sd_final) | is.na(control_sd_final) | silvo_sd_final <= 0 | control_sd_final <= 0)
```


```{r}
# Apply the function to both non-imputed and imputed datasets

################################################################################################################

# function for effect size calculation using `escalc()`
non_imp_data_rom <- calculate_effect_sizes(non_imp_data_prep,
                                           # SMD (Standardized Mean Difference)
                                           # ROM (Log-Transformed Ratio)
                                           measure = "ROM") |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage, 
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )


################################################################################################################

# function for effect size calculation using `escalc()`
imp_data_rom <- calculate_effect_sizes(imp_data_prep,
                                       # SMD (Standardized Mean Difference)
                                       # ROM (Log-Transformed Ratio)
                                       measure = "ROM") |> 
  # Relocate columns to the desired order
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, experiment_site, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width, organic, tillage, 
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )
```

```{r}
imp_data_rom |> glimpse()
```
```{r}
skimr::skim(imp_data_rom)
```
## Flipping direction of selected response variables

```{r}
# Define which response variables need direction flipping
reverse_effects <- c("Pest and disease control", "Water quality") # "Carbon sequestration"

# Flip the direction of yi for those specific response variables
imp_data_rom <- imp_data_rom %>%
  mutate(
    yi = ifelse(response_variable %in% reverse_effects, -yi, yi),
    # Optionally tag flipped rows
    effect_flipped = response_variable %in% reverse_effects
  )
```

## Boxplot for the raw effect size (yi)

```{r}
# Create the boxplot for the effect size (yi)
# Order response variables by descending median effect size

# Install the scales package if it is not already installed
#install.packages("scales")


# Reorder response variables by descending median effect size
imp_data_rom_reorder <- imp_data_rom %>%
  mutate(response_variable = fct_reorder(response_variable, yi, .fun = median, .desc = FALSE))

# Create the boxplot styled like a forest plot
boxplot_raw_effect_size <- imp_data_rom_reorder |> 
  ggplot(aes(y = response_variable, x = yi, fill = response_variable)) +
  geom_vline(xintercept = 0, linetype = "solid", color = "black", size = 0.8) + # Solid black line at x = 0 (center)
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  labs(
    title = "Raw Effect Sizes (yi) Across Response Variables",
    x = "Raw Effect Size",  # Label x-axis
    y = "Response Variable"      # Label y-axis
  ) +
  scale_x_continuous(
    limits = c(-1, 1),                # Set x-axis limits symmetrically around 0
    breaks = seq(-1, 0.8, by = 0.2),    # Custom breaks for better granularity
    labels = seq(-1, 0.8, by = 0.2)     # Corresponding labels
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),           # Remove background grids
    axis.line = element_line(color = "black"),  # Add axis lines
    axis.text.y = element_text(size = 12),  # Adjust y-axis text size
    axis.text.x = element_text(angle = 0, hjust = 0.5), # Keep x-axis labels horizontal
    legend.position = "none"                # Remove legend
  )



# Display the plot
print(boxplot_raw_effect_size)
```


```{r}
# Create the boxplot for the raw effect size (yi)
# Order response variables by descending median effect size
imp_data_rom_reorder <- imp_data_rom %>%
  mutate(response_variable = fct_reorder(response_variable, yi, .fun = median, .desc = FALSE))

# Create the boxplot with ordered response variables
boxplot_raw_effect_size <- imp_data_rom_reorder |> 
  ggplot(aes(y = response_variable, x = yi, fill = response_variable)) +
  geom_vline(xintercept = 0, linetype = "dotted", color = "red", size = 0.8) +
  geom_boxplot(alpha = 0.7, outlier.size = 0.8, width = 0.6) +
  geom_jitter(height = 0.1, width = 0.001, alpha = 0.3, size = 0.8) +  # Optional: visualize raw points
  labs(
    title = "Raw Effect Sizes (yi) Across Response Variables",
    x = "Raw Effect Size (yi)",
    y = "Response Variable"
  ) +
  scale_x_continuous(
    breaks = seq(-1.15, 1.15, by = 0.1),
    labels = scales::label_number(accuracy = 0.01)
  ) +
  coord_cartesian(xlim = c(-1.15, 1.15)) +  # Zoom in tightly
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 12),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

boxplot_raw_effect_size
```


Save raw effect size plot of each response variable

```{r eval=FALSE}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 30) + 
  theme(
    plot.title = element_text(size = 120),        # Increase title size
    plot.subtitle = element_text(size = 70),
    axis.text = element_text(size = 50),        # Increase axis text size
    axis.title = element_text(size = 100),       # Increase axis title size
    strip.text = element_text(size = 50),       # Increase facet text size
    axis.text.y = element_text(size = 100),
    legend.position = "none",
    axis.text.x = element_text(size = 100,
                               angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
boxplot_raw_effect_size <- boxplot_raw_effect_size + theme_custom


# Save the enhanced plot
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")
ggsave(
  filename = file.path(output_dir, "boxplot_raw_effect_size.png"),
  plot = boxplot_raw_effect_size,
  width = 16, height = 8, dpi = 600,
  bg = "white"
)
```



```{r}
# Prepare the data for plotting
data_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(
    cols = c(control_mean, silvo_mean),
    names_to = "Group",
    values_to = "Mean"
  )

# Create the boxplot with a log-transformed y-axis
ggplot(data_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7, outlier.size = 1) +
  facet_wrap(~ response_variable, scales = "free") +
  labs(
    title = "Comparison of Mean Values for Control and Silvo Groups by Response Variable (Log Scale)",
    x = "Group",
    y = "Mean Value (Log Scale)"
  ) +
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )
```



```{r}
# Boxplot comparison for control and silvo groups
imp_data_rom_long <- imp_data_rom %>%
  select(response_variable, control_mean, silvo_mean) %>%
  pivot_longer(cols = c(control_mean, silvo_mean), names_to = "Group", values_to = "Mean")

ggplot(imp_data_rom_long, aes(x = Group, y = Mean, fill = Group)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ response_variable, scales = "free") +  # Facet by response variable
  scale_y_log10() +  # Logarithmic transformation for the y-axis
  labs(
    title = "Distribution of Means for Control and Silvo Groups",
    x = "Group",
    y = "Mean Value"
  ) +
  theme_minimal(base_size = 14) +
  theme(legend.position = "none")
```


```{r}
# Step 1: Define high variance threshold per `sub_response_variable`
high_variance_thresholds <- imp_data_rom %>%
  group_by(sub_response_variable) %>%
  summarise(
    high_threshold = quantile(vi, 0.95, na.rm = TRUE),
    low_threshold = quantile(vi, 0.05, na.rm = TRUE),
    .groups = "drop"
  )

# Step 2: Merge thresholds back to the main dataset
imp_data_rom_with_thresholds <- imp_data_rom %>%
  left_join(high_variance_thresholds, by = "sub_response_variable")

# Step 3: Filter high and low variance observations
extreme_variance_rows <- imp_data_rom_with_thresholds %>%
  filter(vi > high_threshold | vi < low_threshold) %>%
  arrange(desc(vi)) %>%
  select(
    # Relevant columns
    id_article, id_obs, sub_response_variable, response_variable, measured_metrics,
    yi, vi, silvo_mean, control_mean, 
    silvo_n, control_n, silvo_se, control_se, 
    silvo_sd_final, control_sd_final,
    silvo_sd_from_se, control_sd_from_se,
    silvo_sd_merged, control_sd_merged
  )

# Step 4: Summarize extreme variance observations (taking into account that it might be sub_response_variable dependent)
extreme_variance_summary <- extreme_variance_rows %>%
  group_by(id_article, sub_response_variable) %>%
  summarise(
    num_extreme_obs = n(),
    avg_variance = mean(vi, na.rm = TRUE),
    max_variance = max(vi, na.rm = TRUE),
    min_variance = min(vi, na.rm = TRUE),
    response_variables = paste(unique(response_variable), collapse = ", "),
    .groups = "drop"
  ) %>%
  arrange(desc(avg_variance))

# Step 5: Isolate unique articles with high variance
unique_high_variance_articles <- extreme_variance_rows %>%
  distinct(id_article, sub_response_variable) %>%
  arrange(id_article)

# Step 6: Optional Export to CSV
# write.csv(extreme_variance_rows, "extreme_variance_rows.csv", row.names = FALSE)
# write.csv(extreme_variance_summary, "extreme_variance_summary.csv", row.names = FALSE)
# write.csv(unique_high_variance_articles, "unique_high_variance_articles.csv", row.names = FALSE)

# View Results
list(
  extreme_rows = extreme_variance_rows,
  summary = extreme_variance_summary,
  unique_articles = unique_high_variance_articles
)
```


```{r}
# Step 1: Define thresholds for high and low variance per `sub_response_variable`
variance_thresholds <- imp_data_rom %>%
  group_by(sub_response_variable) %>%
  summarise(
    high_variance_threshold = quantile(vi, 0.95, na.rm = TRUE),
    low_variance_threshold = quantile(vi, 0.05, na.rm = TRUE),
    .groups = "drop"
  )

# Step 2: Merge thresholds back to the original data
imp_data_rom_with_thresholds <- imp_data_rom %>%
  left_join(variance_thresholds, by = "sub_response_variable")

# Step 3: Filter high and non-high variance observations
high_variance_data <- imp_data_rom_with_thresholds %>%
  filter(vi > high_variance_threshold)

non_high_variance_data <- imp_data_rom_with_thresholds %>%
  filter(!(vi > high_variance_threshold))
```


```{r}
# Plot for high variance
high_variance_plot <- high_variance_data %>%
  ggplot(aes(x = factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, width = 0.6) +  # Remove default outliers
  geom_jitter(
    aes(color = response_variable), 
    position = position_jitter(width = 0.1, height = 0), 
    alpha = 0.8, size = 2
  ) +  # Add jittered points
  labs(title = "High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

# Plot for non-high variance
non_high_variance_plot <- non_high_variance_data %>%
  ggplot(aes(x = factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7, width = 0.6) +  # Remove default outliers
  geom_jitter(
    aes(color = response_variable), 
    position = position_jitter(width = 0.1, height = 0), 
    alpha = 0.8, size = 2
  ) +  # Add jittered points
  labs(title = "Non-High Variance Observations", x = "Article ID", y = "Variance (vi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Combine plots side by side
combined_plot <- high_variance_plot + non_high_variance_plot + 
  plot_layout(ncol = 2)

# Display the combined plot
print(combined_plot)
```

## High variance plot for individual observations

```{r}
# High variance plot for individual observations with increased jitter

# High variance plot for individual observations with increased jitter
high_variance_plot <- ggplot(high_variance_data, aes(x = as.factor(id_article), y = vi, color = response_variable)) +
  geom_point(position = position_jitter(width = 0.3, height = 0), size = 3, alpha = 0.7) +  # Jittered points
  geom_text_repel(
    aes(label = id_obs),
    position = position_jitter(width = 0.3, height = 3),  # Adjust label positioning
    size = 3,
    max.overlaps = Inf
  ) +
  labs(
    title = "High Variance Observations (Individual, Jittered)",
    x = "Article ID",
    y = "Variance (vi) [Pseudo Log Transformed]",
    color = "Response Variable"
  ) +
  scale_color_manual(values = global_palette) +  # Use predefined color palette
  scale_y_continuous(
    trans = scales::pseudo_log_trans(sigma = 0.1),  # Pseudo log transformation
    breaks = c(0, 0.1, 1, 10, 30),
    labels = c("0", "0.1", "1", "10", "30")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Non-high variance plot with aggregated boxplots
non_high_variance_plot <- ggplot(non_high_variance_data, aes(x = as.factor(id_article), y = vi, fill = response_variable)) +
  geom_boxplot(outlier.color = "blue", alpha = 0.7, outlier.size = 2) +  # Boxplots with adjusted outlier color and size
  geom_jitter(
    aes(color = response_variable),
    position = position_jitter(width = 0.2, height = 0),  # Add jittered points to boxplots
    alpha = 0.6, size = 2
  ) +
  labs(
    title = "Non-High Variance Observations (Boxplots + Points)",
    x = "Article ID",
    y = "Variance (vi) [Pseudo Log Transformed]",
    fill = "Response Variable",
    color = "Response Variable"
  ) +
  scale_fill_manual(values = global_palette) +  # Use predefined color palette
  scale_color_manual(values = global_palette) +  # Match jitter points to boxplot fill
  scale_y_continuous(
    trans = scales::pseudo_log_trans(sigma = 0.1),  # Pseudo log transformation
    breaks = c(0, 0.01, 0.1, 1),
    labels = c("0", "0.01", "0.1", "1")
  ) +
  theme_minimal(base_size = 16) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "top",
    legend.title = element_text(size = 14, face = "bold"),
    legend.text = element_text(size = 12)
  )

# Combine the two plots
combined_plot_high_var_plot <- high_variance_plot + non_high_variance_plot +
  plot_layout(ncol = 2, widths = c(1, 1)) &
  theme(
    plot.margin = margin(10, 10, 10, 10)
  )

# Display the combined plot
print(combined_plot_high_var_plot)
```

Save the high-variance plot
```{r}
# Saving manually from the 'Plots -> Export -> Save as image -> dimension (2000::800)'
```



# STEP 9 HETEROGENEITY ANALYSIS

## 0. Heterogeneity Analysis

Compare the heterogeneity statistics between the meta-analyses conducted on the imputed and non-imputed datasets. This will help you understand if the imputation has influenced the heterogeneity of the studies.


```{r}
# Prepare the original data
original_data_x <- non_imp_data_rom %>%
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
         silvo_sd_final, control_sd_final, 
         yi, vi) |> 
  mutate(data_source = "Original") |> 
  as.data.frame() 

imputed_data_y <- imp_data_rom |> 
  select(id_article, id_obs, exp_id, id_obs, response_variable, 
          silvo_sd_final, control_sd_final, 
         yi, vi) |> 
  mutate(data_source = "Imputed") 

# Combine the original and imputed data
combined_data <- bind_rows(original_data_x, imputed_data_y)

# Join the original and imputed data to directly compare
comparison_data <- original_data_x %>%
  full_join(imputed_data_y, by = c("id_article", "exp_id", "id_obs", "response_variable"), 
            suffix = c("_original", "_imputed")) %>%
  distinct()

# Advarsel: Detected an unexpected many-to-many relationship between `x` and `y`.

comparison_data |> glimpse()
```


```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################


# Step 1: Remove rows with missing values in the columns used
# Step 2: Fit random-effects models
rma_non_imp <- rma(
  yi = yi_original,
  vi = vi_original,
  data = comparison_data,
  subset = !is.na(yi_original) & !is.na(vi_original)
)

rma_imp <- rma(
  yi = yi_imputed,
  vi = vi_imputed,
  data = comparison_data,
  subset = !is.na(yi_imputed) & !is.na(vi_imputed)
)

# Step 3: Print heterogeneity stats
cat("Non-Imputed Data - Heterogeneity (I^2):", rma_non_imp$I2, "\n")
cat("Non-Imputed Data - Between-study variance (tau^2):", rma_non_imp$tau2, "\n")

cat("Imputed Data - Heterogeneity (I^2):", rma_imp$I2, "\n")
cat("Imputed Data - Between-study variance (tau^2):", rma_imp$tau2, "\n")

##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##############################################################
# Last go (25/03-2025)
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Non-Imputed Data - Heterogeneity (I^2): 20.68326 
# Non-Imputed Data - Between-study variance (tau^2): 1.234911e-10 
# Imputed Data - Heterogeneity (I^2): 99.99889 
# Imputed Data - Between-study variance (tau^2): 4.177027e-05  
# Total time taken: 4.124935 secs 

# Last go (01/04-2025)
# Total time taken: 36.42266 secs
```
 
 
 
## 1. Kolmogorov-Smirnov Test

The Kolmogorov-Smirnov (KS) test can be used to compare the distributions of effect sizes.

```{r}
# Kolmogorov-Smirnov test
ks_test_result <- ks.test(non_imp_data_rom$yi, imp_data_rom$yi)
print(ks_test_result)

# Last go (24/01-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.031708, p-value = 0.6984
# alternative hypothesis: two-sided

# Last go (01/04-2025)
# Advarsel: p-value will be approximate in the presence of ties
# 	Asymptotic two-sample Kolmogorov-Smirnov test
# 
# data:  non_imp_data_rom$yi and imp_data_rom$yi
# D = 0.051477, p-value = 0.1426
# alternative hypothesis: two-sided
```


The Kolmogorov-Smirnov (KS) test compared the distributions of effect sizes (ROM) between the non-imputed and imputed datasets. 
The result (D = 0.0133), (p = 1) indicates no statistically significant difference, suggesting that the imputation process preserved the overall distribution of effect sizes. Although a warning was issued about approximate p-values due to ties, the extremely high p-value strongly supports the null hypothesis of no difference between the two distributions.

However, a notable divergence arises in the heterogeneity metrics. The non-imputed dataset shows low heterogeneity (I^2 = 20.7%) and an almost negligible between-study variance (tau^2 = 1.23 times 10^{-10}), indicating consistent effects across studies. In contrast, the imputed dataset shows extreme heterogeneity (I^2 = 99.99%) and a sharp increase in between-study variance (tau^2 = 4.18 times 10^{-5}), implying the imputation introduced substantial variability. This may reflect the uncertainty embedded in the imputed standard deviations and variances.

Additionally, warnings about the extreme ratio of the largest to smallest sampling variances signal potential instability in the meta-analytic models—particularly for the imputed data. Such variance imbalances are known to reduce model reliability and inflate heterogeneity metrics.

In summary, while the imputation preserved the overall distribution of effect sizes, it significantly altered the internal variance structure of the dataset. This highlights the importance of conducting sensitivity analyses, transparently reporting changes, and interpreting imputed meta-analytic results with caution.


 
```{r}
# Descriptive statistics for non-imputed data
summary_non_imp <- non_imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Descriptive statistics for imputed data
summary_imp <- imp_data_rom %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    median_yi = median(yi, na.rm = TRUE),
    sd_yi = sd(yi, na.rm = TRUE)
  )

# Print summaries
summary_non_imp
summary_imp

# Last go (24/01-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02631194	0.003205885	0.2468501	
# 
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.02328872	0.001916168	0.2360473

# Last go (01/04-2025)
# Description:df [1 × 3]
# mean_yi
# <dbl>
# median_yi
# <dbl>
# sd_yi
# <dbl>
# 0.05939467	0.00373367	0.4808079
```
 
 
```{r}
# Density plot for non-imputed data
density_plot_non_imp <- ggplot(non_imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Density Plot: Non-Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = scales::pseudo_log_trans(sigma = 0.1))

# Density plot for imputed data
density_plot_imp <- ggplot(imp_data_rom, aes(x = yi)) +
  geom_density(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Density Plot: Imputed Data",
       x = "Effect Size (yi)", y = "Density") +
  theme_minimal() +
  # Use pseudo-log transformation for x-axis
  scale_x_continuous(trans = scales::pseudo_log_trans(sigma = 0.1))

# Boxplot for non-imputed data
boxplot_non_imp <- ggplot(non_imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#0072B2", alpha = 0.5) +
  labs(title = "Boxplot: Non-Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = scales::pseudo_log_trans(sigma = 0.1))

# Boxplot for imputed data
boxplot_imp <- ggplot(imp_data_rom, aes(y = yi)) +
  geom_boxplot(fill = "#E69F00", alpha = 0.5) +
  labs(title = "Boxplot: Imputed Data",
       y = "Effect Size (yi)") +
  theme_minimal() +
  # Use pseudo-log transformation for y-axis
  scale_y_continuous(trans = scales::pseudo_log_trans(sigma = 0.1))

# Arrange the plots in a 2x2 layout
(density_plot_non_imp | boxplot_non_imp) /
(density_plot_imp | boxplot_imp)

```



## 2. Assessing correlation between response variables


```{r}
non_imp_data_rom |> glimpse()
imp_data_rom |> glimpse()
```

```{r}
##########################################################################
# Visual Diagnostics for Predictor Redundancy and Model Fit
##########################################################################

# Set up data
# Testing on the imputed dataset
# Step 1: Prepare data for linear model
model_data <- imp_data_rom %>%
  select(yi, tree_type, crop_type, age_system, season, soil_texture, organic, tillage) %>%
  drop_na() %>%  # Drop rows with any missing values in these columns
  mutate(across(-yi, as.factor))  # Ensure all moderators are factors

##########################################################################
# Fit a linear model with moderators
##########################################################################

# Step 2: Fit the linear model
lm_model <- lm(yi ~ tree_type + crop_type + age_system + season + soil_texture + organic + tillage, 
               data = model_data)

# Step 3 (Optional): Check model summary
summary(lm_model)
```

```{r}
##########################################################################
# 1. Correlation Analysis
##########################################################################
model_data <- imp_data_rom %>%
  select(yi, tree_type, crop_type, age_system, season, soil_texture) %>%
  drop_na() %>%  # Drop rows with any missing values in these columns
  mutate(across(-yi, as.factor))  # Ensure all moderators are factors

moderators_data <- model_data |> as.data.frame() |>  
  # Drop rows with any missing values in these columns
  drop_na()

# Convert categorical variables to numeric for correlation matrix
moderators_numeric <- model.matrix(~ . + 0, data = moderators_data)

# Calculate correlation matrix
cor_matrix <- cor(moderators_numeric, use = "pairwise.complete.obs")

# Visualize correlation matrix
corrplot::corrplot(cor_matrix, method = "circle", type = "upper",
         tl.col = "black", tl.srt = 45, title = "Correlation Matrix of Moderators")
```

```{r}
##########################################################################
# 2. Variance Inflation Factor (VIF)
##########################################################################

# Calculate VIF for predictors
vif_values <- car::vif(lm_model)

# Print VIF values
print(vif_values)

# Plot VIF values
barplot(vif_values, main = "Variance Inflation Factors (VIF)",
        col = "blue", horiz = TRUE, las = 1, xlab = "VIF Value")
```


The Generalized Variance Inflation Factor (GVIF) assesses how much each predictor in a regression model is correlated with the others. High correlation between predictors—known as multicollinearity—can make it difficult to isolate the individual effects of each variable. GVIF is especially useful for categorical predictors with multiple levels, as it adjusts for the number of degrees of freedom (i.e., categories).

To make GVIF values comparable across predictors, we use the scaled version: GVIF^(1/(2*Df)). Values near 1 indicate low correlation with other predictors, while values above 5 (or more conservatively, above 2.5) can indicate problematic multicollinearity.

In this case, all scaled GVIF values are low:
- **Soil texture** has the highest adjusted GVIF at **1.18**
- All other predictors (tree type, crop type, age system, and season) range between **1.09 and 1.15**

These values are well below any threshold of concern. This confirms that **none of the predictors are strongly correlated** with one another.

As a result, there’s no need to remove or combine predictors. Each contributes independently to the model, and the results can be interpreted with confidence that multicollinearity is not inflating variance or undermining model stability.

**Conclusion:**  
The VIF diagnostics show that the predictors in the model are sufficiently independent. This supports the reliability and interpretability of the regression results.





```{r}
# Convert categorical variables to factors (if not already factors)
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor)) |>
  # Drop rows with any missing values in these columns
  drop_na()

# Create dummy variables for categorical predictors
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%  # -1 to exclude the intercept
  as.data.frame()

# Calculate pairwise correlations
correlation_matrix <- cor(predictors_numeric, use = "pairwise.complete.obs")

# Visualize the correlation matrix
corrplot::corrplot(correlation_matrix, method = "circle")

# Visualize correlations with a heatmap
heatmap(correlation_matrix, symm = TRUE)

# PCA
pca_results <- prcomp(predictors_numeric, scale. = TRUE)
summary(pca_results)
biplot(pca_results)
```

```{r}
# Convert categorical variables to factors and create dummy variables
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width) %>%
  mutate(across(where(is.character), as.factor)) |>
  # Drop rows with any missing values in these columns
  drop_na()

# Create numeric predictors with dummy variables
predictors_numeric <- model.matrix(~ . - 1, data = predictors) %>%
  as.data.frame()

# Ensure the response is aligned with predictors
# Keep only rows where both predictors and response are not missing
aligned_data <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width, yi) %>%
  drop_na()

# Split aligned data into predictors and response
predictors_numeric <- model.matrix(~ . - 1, data = aligned_data %>% 
                                     select(-yi)) %>% 
  as.data.frame()


response_filled <- aligned_data$yi

# Fit the Random Forest model

rf_model <- randomForest(x = predictors_numeric, y = response_filled, importance = TRUE)

# Display feature importance
varImpPlot(rf_model)
```

The results from the random forest analysis and the correlation matrix provide insight into how the predictors (tree type, crop type, age system, season, and soil texture) influence the variability in your dataset and how they relate to each other.

The random forest model was employed to evaluate the relative importance of variables considered as moderators in the meta-regression model (`rma.mv`). Random forest is particularly suitable for this purpose due to its ability to handle complex interactions and non-linear relationships between predictors, making it an effective tool for identifying which moderators most strongly influence the response variable. The model assessed the importance of these moderators using two key metrics: the percentage increase in mean squared error (%IncMSE) and increase in node purity (IncNodePurity). These metrics reflect how much each moderator improves the model's predictive power and reduces uncertainty.



The results highlight tree age and experiment year as the most influential moderators. These variables significantly impact both %IncMSE and IncNodePurity, indicating their critical role in explaining variations in the response variable within the meta-analytic framework. Their importance suggests that temporal factors, such as the age of the tree systems and the year of the experiments, are vital in shaping the observed outcomes across studies.

Moderators related to soil texture, such as sand and silt, were also identified as moderately important, reflecting the role of soil properties in influencing the outcomes under study. Tree type and crop type, including specific categories like "Fruit, nut & other" and "Legume," were somewhat less influential but still contributed meaningfully to explaining variability in the response. Their inclusion underscores the importance of agroforestry and crop-specific characteristics as moderators in the meta-regression.

Variables like alley width and certain crop or tree types, such as tuber/root crops and timber trees, showed relatively lower importance. This indicates that their moderating effects are less pronounced in this context, suggesting they may not need to be prioritized in the meta-regression model.

The random forest results emphasize the hierarchy of moderator importance, with tree age and experiment year standing out as dominant predictors. This refined understanding can improve the meta-regression model by focusing on the most impactful moderators, simplifying the model structure while maintaining its explanatory and predictive power.



The correlation matrix reveals the relationships between predictors. Strong correlations (shown as larger, darker circles) suggest that some predictors may overlap in the information they provide. For example, if "tree type" and "crop type" have a high positive or negative correlation, this could mean they are not entirely independent, potentially leading to redundancy in the model. This aligns with earlier findings of multicollinearity, where predictors interfere with each other.

From the PCA results, the first three principal components (PC1, PC2, and PC3) explain approximately 79% of the variance in the data. This means most of the variation in your dataset can be summarized using fewer dimensions, reducing complexity while retaining the critical patterns. The decreasing proportion of variance explained by PC4 and PC5 suggests these components add less unique information.

Overall, while "tree type" and "crop type" seem to be the most influential predictors, their high correlation with other variables might complicate the interpretation. You should consider techniques like feature selection, dimensionality reduction, or removing redundant variables to improve model clarity and performance.





The results of the random forest analysis reveal important limitations and implications for reporting and communicating overall meta-analysis findings. By identifying tree age and experiment year as the dominant moderators, the analysis highlights a key limitation of heterogeneity within the dataset. This underscores the challenge of attributing outcomes to specific factors when a few moderators exert disproportionate influence. Such dominance may mask the contributions of less impactful moderators and complicate the interpretation of their individual roles in the meta-analysis.

One limitation lies in the reliance on moderators that capture temporal or environmental variability, such as experiment year or soil texture. These factors, while essential, may vary considerably across studies, making it difficult to disentangle their effects from study-specific conditions. Additionally, the relatively lower importance of certain moderators, such as alley width or specific tree and crop types, raises questions about whether these variables are consistently measured or reported across studies. Inconsistent data collection or reporting practices may contribute to their diminished influence, emphasizing the importance of standardized reporting in future studies.

Communicating the meta-analysis results requires careful consideration of these limitations. Overemphasis on the dominant moderators, such as tree age, may oversimplify the nuanced interactions present in agroforestry systems. Researchers and stakeholders must be cautious not to generalize findings without acknowledging the variability that less prominent moderators can introduce. This is particularly relevant when translating findings into practical recommendations, as the applicability of results to diverse settings may be constrained.

The findings also highlight the need for transparency when reporting results. Explicitly addressing the hierarchical importance of moderators, as identified by the random forest analysis, can help contextualize the results and guide readers in understanding the limitations of the analysis. Clear communication about the variability and potential biases introduced by dominant moderators is essential for ensuring that the conclusions of the meta-analysis are interpreted appropriately and applied responsibly in decision-making contexts.




```{r}
# Prepare the data
# Convert categorical variables to factors
imp_data_rom <- imp_data_rom %>%
  mutate(across(where(is.character), as.factor))

# Define the predictors and response
predictors <- imp_data_rom %>%
  select(tree_age, crop_type, tree_type, soil_texture, experiment_year, alley_width)


response <- imp_data_rom$yi

# Combine predictors and response into a single dataset
complete_data <- cbind(predictors, response = response) %>%
  na.omit() # Remove rows with missing values to ensure compatibility


# complete_data |> str()
# 'data.frame':	808 obs. of  7 variables:
#  $ tree_age       : num  2 2 2 9 9 9 9 8 8 8 ...
#  $ crop_type      : Factor w/ 3 levels "Cereal","Legume",..: 1 1 1 1 1 1 1 1 1 1 ...
#  $ tree_type      : Factor w/ 3 levels "Biomass","Fruit,nut & other",..: 2 2 2 2 2 2 2 1 1 1 ...
#  $ soil_texture   : Factor w/ 3 levels "Clay","Sand",..: 1 1 1 1 1 1 1 3 3 3 ...
#  $ experiment_year: Date, format: "2011-01-01" "2011-01-01" "2011-01-01" "2011-01-01" ...
#  $ alley_width    : Factor w/ 2 levels "Narrow","Wide": 2 2 2 2 2 2 2 2 2 2 ...
#  $ response       : num  0.633 0.199 0.771 0.137 0.182 ...
#  - attr(*, "na.action")= 'omit' Named int [1:290] 329 330 331 332 333 334 335 336 337 338 ...
#   ..- attr(*, "names")= chr [1:290] "329" "330" "331" "332" ...

# Tidymodels Random Forest Workflow

# Step 1: Create a recipe for preprocessing
rf_recipe <- recipe(response ~ ., data = complete_data) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%  # Convert categorical predictors to dummies
  step_normalize(all_numeric_predictors())       # Normalize numeric predictors

# Step 2: Specify the Random Forest model
rf_spec <- rand_forest(
  mode = "regression",
  mtry = tune(),         # Number of predictors sampled at each split
  trees = 500,           # Number of trees
  min_n = tune()         # Minimum samples per node
) %>%
  set_engine("ranger", importance = "permutation")  # Use permutation importance

# Step 3: Define a workflow
rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_spec)

# Step 4: Create cross-validation folds
set.seed(123)

cv_splits <- vfold_cv(complete_data, v = 5)

# Step 5: Tune the model
rf_res <- tune_grid(
  rf_workflow,
  resamples = cv_splits,
  grid = 10,  # Number of parameter combinations to try
  metrics = metric_set(rmse, rsq)  # Evaluation metrics
)

# Step 6: Finalize the model with the best parameters
# Finalize the model with the best parameters
best_rf <- finalize_workflow(
  rf_workflow,
  select_best(rf_res, metric = "rmse") # Explicitly name the argument 'metric'
)

# Step 7: Fit the finalized model
final_rf_fit <- fit(best_rf, data = complete_data)

# Step 8: Compute and visualize variable importance
# Extract the fitted model
rf_final_model <- final_rf_fit %>% extract_fit_parsnip()

# Visualize Variable Importance
vip(rf_final_model) +
  ggtitle("Variable Importance from Random Forest Model") +
  theme_minimal()

```

## 3. Stepwise Regression


Stepwise regression iteratively adds or removes predictors from a model to optimize the Akaike Information Criterion (AIC), balancing goodness-of-fit with model complexity. Starting with an initial model, predictors are evaluated through forward selection (adding predictors) and backward elimination (removing predictors). This process identifies the most relevant variables while discarding redundant or insignificant ones, improving model interpretability and predictive performance. It mitigates multicollinearity and avoids overfitting by ensuring parsimony. However, results should be interpreted cautiously, as stepwise methods may exclude theoretically important predictors.


OBS! Takes a long time ~ 1 hour!

```{r eval=FALSE}
# Moderator Model Selection Workflow using step() and lm()
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################

# 1. Filter for complete cases
model_data <- imp_data_rom %>%
  # Full set of moderators: tree_type, crop_type, age_system, season, soil_texture, tree_height, alley_width, no_tree_per_m --- # organic, tillage 
  # Reduced set of moderators: tree_type, crop_type, age_system, season, soil_texture
  select(yi, tree_type, crop_type, age_system, season, soil_texture, tree_height, alley_width, no_tree_per_m, organic, tillage) |> 
  # Make sure the response variable is numeric
  mutate(yi = as.numeric(yi)) |> 
  # Make sure predictors are factors
  mutate(across(-yi, as.factor)) |> 
  drop_na()

##########################################################################
# 2. Fit a linear model with moderators (removing intercept with '-1')
# Full set of moderators: tree_type + crop_type + age_system + season + soil_texture + tree_height + alley_width + no_tree_per_m, --- # organic, tillage 
# Reduced set of moderators: tree_type + crop_type + age_system + season + soil_texture,
lm_model <- lm(yi ~ -1 + tree_type * crop_type * age_system * season * soil_texture * tree_height * alley_width * no_tree_per_m, organic, tillage
               data = model_data)

# 3. Run stepwise regression
stepwise_model <- step(lm_model, direction = "both", trace = TRUE)

##########################################################################

# Summary of the stepwise regression model
summary(stepwise_model)



##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##############################################################
# Last go (23/03-2025)
# Total time taken: 46.53044 mins 

# Call:
# lm(formula = yi ~ tree_type + crop_type + age_system + soil_texture + 
#     tree_height + no_tree_per_m + tree_type:crop_type + tree_type:age_system + 
#     crop_type:age_system + tree_type:soil_texture + crop_type:soil_texture + 
#     age_system:soil_texture + crop_type:tree_height - 1, data = model_data)
# 
# Residuals:
#       Min        1Q    Median        3Q       Max 
# -0.312021 -0.000641 -0.000052  0.000561  0.096369 
# 
# Coefficients: (5 not defined because of singularities)
#                                                            Estimate Std. Error t value Pr(>|t|)    
# tree_typeBiomass                                         -9.330e-02  1.080e-02  -8.635  < 2e-16 ***
# tree_typeFruit,nut & other                                6.393e-04  1.094e-02   0.058 0.953430    
# tree_typeTimber                                          -4.277e-03  2.991e-02  -0.143 0.886337    
# crop_typeLegume                                           6.809e-05  6.290e-03   0.011 0.991367    
# crop_typeTuber,root and other                            -1.472e-03  2.116e-02  -0.070 0.944562    
# age_systemMedium                                          9.314e-02  1.595e-02   5.841 9.05e-09 ***
# age_systemYoung                                           3.569e-04  7.663e-03   0.047 0.962875    
# soil_textureSand                                          1.194e-01  1.616e-02   7.391 5.67e-13 ***
# soil_textureSilt                                          8.805e-02  1.752e-02   5.026 6.87e-07 ***
# tree_heightTall                                          -9.326e-02  1.351e-02  -6.904 1.44e-11 ***
# no_tree_per_mLow                                          9.334e-02  8.611e-03  10.839  < 2e-16 ***
# tree_typeFruit,nut & other:crop_typeLegume               -6.865e-02  1.064e-02  -6.454 2.45e-10 ***
# tree_typeTimber:crop_typeLegume                           9.305e-02  2.098e-02   4.436 1.12e-05 ***
# tree_typeFruit,nut & other:crop_typeTuber,root and other  1.132e-04  1.421e-02   0.008 0.993647    
# tree_typeTimber:crop_typeTuber,root and other                    NA         NA      NA       NA    
# tree_typeFruit,nut & other:age_systemMedium              -9.309e-02  2.503e-02  -3.718 0.000222 ***
# tree_typeTimber:age_systemMedium                         -8.840e-02  2.784e-02  -3.175 0.001582 ** 
# tree_typeFruit,nut & other:age_systemYoung                       NA         NA      NA       NA    
# tree_typeTimber:age_systemYoung                          -8.608e-02  3.587e-02  -2.400 0.016735 *  
# crop_typeLegume:age_systemMedium                         -9.349e-02  2.683e-02  -3.485 0.000533 ***
# crop_typeTuber,root and other:age_systemMedium           -1.394e-03  2.257e-02  -0.062 0.950782    
# crop_typeLegume:age_systemYoung                                  NA         NA      NA       NA    
# crop_typeTuber,root and other:age_systemYoung             9.448e-02  2.709e-02   3.487 0.000528 ***
# tree_typeFruit,nut & other:soil_textureSand              -1.219e-01  1.683e-02  -7.239 1.59e-12 ***
# tree_typeTimber:soil_textureSand                         -3.250e-02  4.573e-02  -0.711 0.477634    
# tree_typeFruit,nut & other:soil_textureSilt              -9.433e-02  1.577e-02  -5.981 4.07e-09 ***
# tree_typeTimber:soil_textureSilt                         -9.355e-02  1.983e-02  -4.718 3.05e-06 ***
# crop_typeLegume:soil_textureSand                          9.300e-02  3.062e-02   3.037 0.002506 ** 
# crop_typeTuber,root and other:soil_textureSand            2.464e-03  1.719e-02   0.143 0.886083    
# crop_typeLegume:soil_textureSilt                          5.028e-04  1.890e-02   0.027 0.978785    
# crop_typeTuber,root and other:soil_textureSilt            3.307e-03  2.572e-02   0.129 0.897748    
# age_systemMedium:soil_textureSand                        -2.125e-01  2.935e-02  -7.240 1.58e-12 ***
# age_systemYoung:soil_textureSand                         -1.180e-01  3.704e-02  -3.187 0.001524 ** 
# age_systemMedium:soil_textureSilt                        -8.860e-02  1.357e-02  -6.531 1.53e-10 ***
# age_systemYoung:soil_textureSilt                                 NA         NA      NA       NA    
# crop_typeLegume:tree_heightTall                           9.320e-02  2.310e-02   4.034 6.28e-05 ***
# crop_typeTuber,root and other:tree_heightTall                    NA         NA      NA       NA    
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.02164 on 532 degrees of freedom
# Multiple R-squared:  0.254,	Adjusted R-squared:  0.2091 
# F-statistic:  5.66 on 32 and 532 DF,  p-value: < 2.2e-16
# Total time taken: 46.53044 mins 

# Last go (01/01-2025)
```

```{r}
# Advanced Moderator Model Selection Workflow using glmnet and MuMIn
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################

# Step 1: Prepare data with only complete cases
model_data <- imp_data_rom %>%
  select(yi, tree_type, crop_type, age_system, season, soil_texture, tree_height, alley_width, no_tree_per_m, organic, tillage) %>%
  mutate(yi = as.numeric(yi)) %>%
  mutate(across(-yi, as.factor)) %>%
  drop_na()

# Step 2: Fit full linear model with all moderators (and selected interactions)
full_model <- lm(yi ~ tree_type * crop_type +
                    age_system * tree_height +
                    crop_type * no_tree_per_m +
                    season + soil_texture + alley_width,
                    # organic + tillage, # contrasts can be applied only to factors with 2 or more levels
                 data = model_data)

# Step 3: All-subsets model selection using AICc (MuMIn)
options(na.action = "na.fail")  # Required for dredge
model_set <- dredge(full_model)

# View top models within delta AICc < 4
model_set_subset <- subset(model_set, delta < 4)
print(model_set_subset)

# Step 4: Model averaging across best models
avg_model <- model.avg(model_set_subset)
summary(avg_model)

# Step 5: Regularization using LASSO (glmnet)
# Create design matrix and response
X <- model.matrix(~ tree_type + crop_type + age_system + season + soil_texture + 
                    tree_height + alley_width + no_tree_per_m, 
                  data = model_data)[, -1]  # remove intercept column

y <- model_data$yi

# Cross-validated LASSO
cv_lasso <- cv.glmnet(X, y, alpha = 1)

# Best lambda and coefficients
best_lambda <- cv_lasso$lambda.min
coef(cv_lasso, s = best_lambda)

# Step 6 (optional): Plot variable importance from model.avg()
importance_vals <- sw(avg_model)
importance_df <- data.frame(variable = names(importance_vals), importance = importance_vals)

# ggplot2 version of variable importance plot
ggplot(importance_df, aes(x = reorder(variable, importance), y = importance)) +
  geom_col(fill = "steelblue") +
  labs(title = "Variable Importance (Model Averaging)",
       x = "Moderator Variable",
       y = "Relative Importance") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##############################################################
# Last go (23/03-2025)
# Total time taken: 2.366118 secs
```


Two approaches were used to identify which moderator variables explain differences in effect sizes (\(yi\)). In the **stepwise regression** model, key moderators such as **tree type**, **age system**, **soil texture**, **tree height**, and **tree density** were retained, along with meaningful two-way interactions—particularly between **tree type and crop type**, **age and soil texture**, and **crop type and tree height**. This model showed moderate explanatory power (\(R^2_{adj} = 0.21\)). In contrast, the **model averaging approach** (MuMIn with selected interactions) focused on simpler, robust combinations. It confirmed the importance of variables like **alley width**, **legume crops**, and interactions such as **legume × low tree density** and **legume × fruit trees**, which showed strong and opposing effects. Together, these methods highlight that the effects of agroforestry systems on outcomes depend not just on individual moderators, but also on how they interact—especially between system type, crop choice, and structural traits.



Updated Interpretation of Moderator Selection and Interaction Models

Two complementary approaches were used to explore how moderator variables explain variation in effect sizes (\(yi\)) across studies.

 Method 1: Stepwise Regression with High-Order Interactions
This method used a saturated model including all moderators and their interactions (e.g., `tree_type * crop_type * age_system * season * soil_texture * ...`) and employed stepwise selection to reduce complexity. The final model retained a subset of main effects and several two-way interactions, such as:
- **Tree Type × Crop Type**
- **Tree Type × Age System**
- **Crop Type × Tree Height**
- **Age System × Soil Texture**

Significant effects included:
- **Tree type** (Biomass systems strongly negative, p < 0.001),
- **Age system (Medium)** (positive main effect, p < 0.001),
- **Tree height (Tall)** (negative, p < 0.001),
- **Soil texture (Sand and Silt)** (positive main effects, p < 0.001),
- **Tree density** (Low density associated with positive \(yi\), p < 0.001),
- And several **interactions**, notably:
  - *Tree type × Crop type* (e.g., fruit trees × legumes: strongly negative),
  - *Crop type × Tree height* (e.g., legumes × tall trees: positive interaction),
  - *Age system × Soil texture* (e.g., medium × sand: strongly negative).

Overall, this model revealed complex interdependencies among variables, with an adjusted \(R^2 = 0.21\), substantially higher than baseline models, indicating moderate explanatory power.

Method 2: All-Subsets Selection and Model Averaging (MuMIn + glmnet)
This method limited interaction depth (e.g., selected 2-way terms only) and tested all variable combinations within a reduced model space to avoid overfitting. The top models (ΔAICc < 4) were averaged, producing robust estimates. Key findings:
- Significant predictors included:
  - **Alley width** (Wide: negative effect),
  - **Crop type (Legumes)** (negative),
  - **Tree type (Fruit/nut)** (weakly negative),
  - **Crop type × Tree type** (Legumes × Fruit/nut: strong negative interaction),
  - **Crop type × Tree density** (Legumes × Low density: strong positive interaction),
  - **Age system × Tree height** (Medium × Tall: weak negative).

Model averaging and regularized regression (LASSO) confirmed the importance of these moderators and stabilized coefficient estimates. Though the adjusted \(R^2\) was slightly lower than in Method 1, the results were more generalizable due to reduced complexity.

---

**Implications for Meta-Analysis**
Both approaches underscore that **no single moderator** dominates the response variable—rather, **interactions between moderators matter**. Tree type, crop type, age, and structural system traits like height, density, and alley width interact in complex ways, influencing ecosystem service outcomes. For instance:
- **Legumes** in low-density systems or paired with specific tree types may yield higher benefits.
- **Tall trees in young systems** or **biomass-based systems** may reduce effectiveness.

Given the modest explanatory power of the models, unexplained heterogeneity likely remains, suggesting the need for future inclusion of **contextual variables** (e.g., climate, geography, management intensity) and more flexible non-linear modeling.

---



## 4. Principal Component Analysis (PCA)


```{r}
# Perform PCA on the numeric moderator data
pca_results <- prcomp(moderators_numeric, scale. = TRUE)

pca_results |> str()

screeplot(pca_results, type = "lines", main = "Scree Plot for PCA")

# Calculate proportion of variance explained
explained_variance <- (pca_results$sdev^2) / sum(pca_results$sdev^2)

# Create a scree plot
plot(explained_variance, type = "b", pch = 19, col = "blue",
     xlab = "Principal Components", ylab = "Proportion of Variance Explained",
     main = "Scree Plot for PCA")

barplot(explained_variance, names.arg = paste0("PC", 1:length(explained_variance)),
        col = "skyblue", xlab = "Principal Components", ylab = "Proportion of Variance",
        main = "Variance Explained by Principal Components")

# Biplot of the first two components
biplot(pca_results, scale = 0, main = "PCA Biplot")
```


## 5. Cross-Validation


```{r}
# Define predictors and response
predictors <- imp_data_rom %>% 
  select(tree_type, crop_type, age_system, season, soil_texture) %>%
  mutate(across(everything(), as.factor)) %>% # Convert to factors first
  mutate(across(everything(), as.numeric))   # Convert to numeric
response <- imp_data_rom$yi

# Check the structure of predictors
str(predictors)

# Remove rows with missing values in predictors or response
complete_cases <- complete.cases(predictors, response)
predictors <- predictors[complete_cases, ]
response <- response[complete_cases]

# Create a train/test split
set.seed(123)
train_index <- caret::createDataPartition(response, p = 0.8, list = FALSE)
train_data <- predictors[train_index, ]
train_response <- response[train_index]
test_data <- predictors[-train_index, ]
test_response <- response[-train_index]

# Ensure training data has no missing values
if (anyNA(train_data) || anyNA(train_response)) {
  stop("Training data contains missing values. Please clean your data.")
}

# Train a linear model with cross-validation
cv_model <- caret::train(
  x = train_data, 
  y = train_response, 
  method = "lm", 
  trControl = caret::trainControl(method = "cv", number = 10)
)

# Evaluate on test set
predictions <- predict(cv_model, newdata = test_data)
results <- caret::postResample(predictions, test_response)

# Print cross-validation results
print(cv_model)
print("Performance on test data:")
print(results)

# Last go (24/01-2025)
# 'data.frame':	1095 obs. of  5 variables:
#  $ tree_type   : num  2 2 2 2 2 2 2 1 1 1 ...
#  $ crop_type   : num  1 1 1 1 1 1 1 1 1 1 ...
#  $ age_system  : num  3 3 3 2 2 2 2 2 2 2 ...
#  $ season      : num  1 1 1 1 1 1 1 2 2 2 ...
#  $ soil_texture: num  1 1 1 1 1 1 1 3 3 3 ...
#  - attr(*, "digits")= Named num [1:9] 4 4 4 4 4 4 4 4 4
#   ..- attr(*, "names")= chr [1:9] "est" "se" "test" "pval" ...
#  - attr(*, "yi.names")= chr "yi"
#  - attr(*, "vi.names")= chr "vi"
# Linear Regression 
# 
# 865 samples
#   5 predictor
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 778, 779, 778, 779, 779, 777, ... 
# Resampling results:
# 
#   RMSE       Rsquared    MAE      
#   0.2274347  0.03785515  0.1181042
# 
# Tuning parameter 'intercept' was held constant at a value of TRUE
# [1] "Performance on test data:"
#       RMSE   Rsquared        MAE 
# 0.19616264 0.04730264 0.12006283 

# Last go (01/04-2025)
# 'data.frame':	1095 obs. of  5 variables:
#  $ tree_type   : num  2 2 2 2 2 2 2 1 1 1 ...
#  $ crop_type   : num  1 1 1 1 1 1 1 1 1 1 ...
#  $ age_system  : num  3 3 3 2 2 2 2 2 2 2 ...
#  $ season      : num  1 1 1 1 1 1 1 2 2 2 ...
#  $ soil_texture: num  1 1 1 1 1 1 1 3 3 3 ...
#  - attr(*, "digits")= Named num [1:9] 4 4 4 4 4 4 4 4 4
#   ..- attr(*, "names")= chr [1:9] "est" "se" "test" "pval" ...
#  - attr(*, "yi.names")= chr "yi"
#  - attr(*, "vi.names")= chr "vi"
# Linear Regression 
# 
# 866 samples
#   5 predictor
# 
# No pre-processing
# Resampling: Cross-Validated (10 fold) 
# Summary of sample sizes: 779, 780, 780, 779, 779, 781, ... 
# Resampling results:
# 
#   RMSE       Rsquared    MAE     
#   0.4830301  0.03055683  0.296807
# 
# Tuning parameter 'intercept' was held constant at a value of TRUE
# [1] "Performance on test data:"
#       RMSE   Rsquared        MAE 
# 0.42708159 0.02477727 0.27596067
```


The cross-validation analysis evaluated how well five selected moderators—tree type, crop type, age system, season, and soil texture—predict variation in the response variable (yi). The predictors were numerically encoded, and after removing missing data, a dataset of 1,095 observations was used. Linear regression was trained using 80% of the data with 10-fold cross-validation and tested on the remaining 20%.

During cross-validation, the model yielded a low Root Mean Square Error (RMSE = 0.1293), a small Mean Absolute Error (MAE = 0.0408), and a very low R^2 = 0.0081, indicating minimal explanatory power. On the test set, performance remained consistent with an RMSE of 0.0488, an MAE of 0.0344, and R^2 = 0.0014. These results confirm the model is not overfitting but also reveal that the selected moderators explain almost none of the variance in yi.

However, it is important to note that this analysis was conducted on the full dataset and not on subsets grouped by response variable. As a result, it does not capture potential differences in how well the moderators explain variation across different types of responses (e.g., yield, biodiversity, or carbon sequestration). A stratified analysis would be needed to assess moderator performance within each response category.

In summary, while the selected moderators contribute limited predictive insight into yi across the full dataset, the absence of response-specific analysis limits conclusions about their relative importance in explaining different outcomes. Expanding the model to include additional predictors, interaction effects, or more flexible modeling techniques may help capture the complexity of the system.


```{r}
# Define your moderators and target
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture", "organic", "tillage") 

# Create a function to perform cross-validation for each response type
run_cv_by_response <- function(data, response_type) {
  cat("\n\nRunning CV for response:", response_type, "\n")
  
  # Subset data
  data_subset <- data %>%
    filter(response_variable == response_type) %>%
    select(all_of(c("yi", moderators))) %>%
    drop_na()
  
  # Encode as numeric for modeling
  predictors <- data_subset %>%
    select(all_of(moderators)) %>%
    mutate(across(everything(), ~as.numeric(as.factor(.))))
  
  response <- data_subset$yi
  
  if (nrow(data_subset) < 30) {
    warning(paste("Too few samples for response:", response_type))
    return(tibble(response_variable = response_type, RMSE = NA, Rsquared = NA, MAE = NA))
  }
  
  # Split into training/testing
  set.seed(123)
  train_idx <- createDataPartition(response, p = 0.8, list = FALSE)
  train_x <- predictors[train_idx, ]
  train_y <- response[train_idx]
  test_x <- predictors[-train_idx, ]
  test_y <- response[-train_idx]
  
  # Fit model with CV
  cv_model <- train(
    x = train_x,
    y = train_y,
    method = "lm",
    trControl = trainControl(method = "cv", number = 10)
  )
  
  # Predict and evaluate
  test_preds <- predict(cv_model, newdata = test_x)
  test_metrics <- postResample(test_preds, test_y)
  
  return(tibble(
    response_variable = response_type,
    RMSE = test_metrics[["RMSE"]],
    Rsquared = test_metrics[["Rsquared"]],
    MAE = test_metrics[["MAE"]]
  ))
}

# Run the function over all response variable types
results_by_response <- imp_data_rom %>%
  distinct(response_variable) %>%
  pull() %>%
  map_dfr(~run_cv_by_response(imp_data_rom, .x))

# View results
print(results_by_response)
```
```{r}
ggplot(results_by_response, aes(x = response_variable, y = Rsquared)) +
  geom_col(fill = "steelblue") +
  theme_minimal() +
  labs(title = "Explanatory Power of Moderators (R²) by Response Variable",
       y = "R² (Test Set)",
       x = "Response Variable") +
  geom_text(aes(label = round(Rsquared, 3)), vjust = -0.5) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```


The response-specific cross-validation analysis reveals considerable variation in how well the selected moderators — tree type, crop type, age system, season, and soil texture — explain different outcomes in the meta-analysis.

- **Carbon sequestration** stands out with the **highest predictive performance**: R^2 = 0.52 indicates that over **50% of the variation** in effect sizes can be explained by the selected moderators. The RMSE (0.00148) and MAE (0.00114) are also very low, reflecting accurate and stable predictions.

- **Water quality** and **pest and disease control** also showed moderate to strong explanatory power:  
  R^2 = 0.29 and R^2 = 0.24, respectively, suggesting that these outcomes are influenced to a fair extent by the selected moderators.

- **Product quality**, **biodiversity**, and **crop yield** fell into a more modest explanatory range, with R^2 values of 0.19, 0.17, and 0.09.  
  This implies that while some variation is captured by the moderators, a substantial portion remains unexplained.

- **Soil quality** had the weakest model performance, with an R^2 of just **0.007**, indicating that the selected moderators provide almost no predictive value for this outcome. This may suggest that other unmeasured moderators or processes are driving soil-related responses.

Overall, these findings demonstrate that **moderator explanatory power is outcome-specific**. The same set of variables can be highly informative for some outcomes (e.g., carbon, water quality) but nearly irrelevant for others (e.g., soil quality). This highlights the importance of tailoring moderator models to individual response variables rather than relying on a one-size-fits-all approach.


# STEP 8 SAVING FINAL PREPROCESSED META-DATASETS (IMPUTED AND NON-IMPUTED) - THESE ARE USED FOR RMA.MV() MODELLING



Saving the datasets that is used for the rma.mv() modelling

```{r}
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the output directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save as RDS files

## NON-IMPUTED
saveRDS(non_imp_data_rom,
        file = here::here(output_dir, "non_imp_data_rom.rds"))

## IMPUTED
saveRDS(imp_data_rom,
        file = here::here(output_dir, "imp_data_rom.rds"))    # <---------------- ! This is the dataset that is used for meta-analysis model fitting !



# Confirmation message
cat("Files saved successfully to:", output_dir, "\n")
```

git fetch origin
git pull origin main
git push origin HEAD:refs/heads/main --force

