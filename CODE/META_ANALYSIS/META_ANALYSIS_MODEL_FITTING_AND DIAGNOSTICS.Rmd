---
title: "META_ANALYSIS_MODEL_FITTING"
author: "M.K.K. Lindhardt"
date: "2024-10-26"
output: html_document
---



#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    skimr,            # Provides easy summary statistics about variables in data frames, tibbles, data tables and vectors
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    tidygeocoder,     # For geocoding addresses to latitude/longitude
    rnaturalearth,    # For accessing Natural Earth map data
    rnaturalearthdata,# Companion package to rnaturalearth providing the data
    ###################################################################################################################
    # Spatial Data
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    ###################################################################################################################
    # Soil Data
    soilDB,           # For downloading soil data from ISRIC SoilGrids
    aqp,              # For soil profile visualization and analysis
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
```



############################################################################################################################
READING THE PREPROCESSED AND FILTERED METADATA CSV
############################################################################################################################

```{r}
metdata <- readr::read_csv("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/FROM_R/filtered_meta_data_rom_v5.csv")

metdata
```

##########################################################################################################################################
CREATING A VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################

Creating a variance-covariance matrix is crucial in multivariate meta-analysis because it captures the dependencies among the effect sizes from different outcomes measured within the same study. Without accounting for these dependencies, the analysis could be biased and less efficient.

Why a Variance-Covariance Matrix is Needed
- Account for Within-Study Correlations: When multiple outcomes are reported within the same study, they are often correlated. Ignoring these correlations can lead to inaccurate estimates of the overall effect size and its variance.
- Borrowing Strength: The variance-covariance matrix allows the analysis to borrow strength across different outcomes, leading to more precise estimates.
- Improve Model Accuracy: Including the correct variance-covariance structure improves the accuracy of the random-effects model, leading to better inference.

```{r, eval = FALSE}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Create a variance-covariance matrix for each study
V_list <- list() # Initialize an empty list to store variance-covariance matrices for each study

# Loop through each unique study ID in the dataset
for (study in unique(metdata$id_article)) {
  # Subset the data for the current study
  study_data <- metdata[metdata$id_article == study, ]
  
  # Check if the current study has more than one outcome
  if (nrow(study_data) > 1) {
    # Create a diagonal matrix with the variances (vi) of the outcomes
    V <- diag(study_data$vi)
    
    # Assume a constant correlation of 0.5 between outcomes within the same study
    corr <- 0.5
    
    # Loop through the rows of the matrix to set the off-diagonal elements
    for (i in 1:nrow(V)) {
      for (j in 1:nrow(V)) {
        # Set the off-diagonal elements to the product of the correlation and the square root of the product of the corresponding variances
        if (i != j) {
          V[i, j] <- corr * sqrt(V[i, i] * V[j, j])
        }
      }
    }
    # Add the variance-covariance matrix to the list for the current study
    V_list[[as.character(study)]] <- V
  } else {
    # If there is only one outcome, the variance is just the variance of the single outcome
    V_list[[as.character(study)]] <- study_data$vi
  }
}

# Combine the matrices into a block-diagonal matrix
V_matrix <- bldiag(V_list)

##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##############################################################
# Last go: 27-10-2024
# Time difference of 0.1532838 secs

# Last go: 03-11-2024
# Time difference of 0.2153811 secs
```

```{r}
str(V_matrix)
```

SAVING THE VARIANCE-COVARIANCE MATRIX

```{r, eval = FALSE}
# Save the V_matrix object as an RDS file for future use
saveRDS(V_matrix, file = "C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/FROM_R/V_matrix_v5.rds")
```



##########################################################################################################################################
Quality Assessment of the metdata and V_matrix data 
##########################################################################################################################################

```{r}
# Check for missing values in metdata
missing_values <- sapply(metdata, function(x) sum(is.na(x)))
print("Missing Values in metdata:")
print(missing_values)
```

```{r}
# Distribution of vi
metdata |> 
  ggplot(aes(x = vi)) +
  geom_histogram(binwidth = 0.1) +
  ggtitle("Distribution of Sampling Variances (vi)") +
  scale_x_log10() +
  theme_minimal()
```

```{r}
# Check for positive definiteness of V_matrix
is_positive_definite <- function(mat) {
  eigenvalues <- eigen(mat)$values
  all(eigenvalues > 0)
}

# Summary statistics for key columns
summary_stats <- metdata %>%
  select(yi, vi, id_article, response_variable) %>%
  summary()
print("Summary Statistics for metdata:")
print(summary_stats)

# Check for positive definiteness of V_matrix
is_positive_definite <- function(mat) {
  eigenvalues <- eigen(mat)$values
  all(eigenvalues > 0)
}
```

```{r}
positive_definite_check <- is_positive_definite(V_matrix)
print(paste("V_matrix is positive definite:", positive_definite_check))
```

The code snippet provided is checking if the variance-covariance matrix (V_matrix) used in your meta-analysis model is positive definite. 

Positive Definiteness of a Matrix:
A matrix is positive definite if all its eigenvalues are positive.
Positive definiteness is a desirable property for variance-covariance matrices, ensuring that the matrix can be used in statistical models and that the calculations involving the matrix (e.g., inversions) are stable.

Ensuring the positive definiteness of the variance-covariance matrix is crucial for the integrity of statistical models, including those used in meta-analysis. A positive definite matrix guarantees that the matrix is invertible, a necessary condition for various statistical calculations, such as estimating model parameters. This property also ensures numerical stability during computations, reducing the likelihood of errors and ensuring accurate results, which is fundamental for the reliability of the model fitting process and subsequent statistical inference.

Excluding missing values from the dataset is essential to maintain data integrity and model accuracy. Missing values can lead to biased estimates and incorrect inferences if not handled appropriately. By removing rows with missing values in critical columns, we ensure that all observations used in the analysis are complete and reliable. This process simplifies the dataset, making it easier to apply statistical methods and interpret the results accurately.







##########################################################################
EXCLUDIDNG MISSING VALUES FROM THE DATASET - in case of any missing values. However, in this case there is no missing values
##########################################################################



##########################################################################################################################################
PERFORM THE META-ANALYSIS MODELLING WITH A RANDOM-EFFECTS MODEL
##########################################################################################################################################

##########################################################################
NOW RUNNING THE MODEL FITTING
##########################################################################

```{r}
metdata
```

```{r}
# Count the number of unique response variables for each study
study_response_count <- metdata %>%
  group_by(id_article) %>%
  summarize(num_response_vars = n_distinct(response_variable))

# Plot the number of response variables for each study

ggplot(study_response_count, aes(x = factor(id_article), y = num_response_vars)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Number of Response Variables per Study",
       x = "Study (id_article)",
       y = "Number of Response Variables") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability

```

```{r}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

############################################################################################################################
model_with_response_var <- rma.mv(
  # Effect size estimates (dependent variable)
  yi = yi,              
  # Variance-covariance matrix of the effect sizes
  V = V_matrix,         
  random = list(
    # Random intercept for each article to account for between-study variability
    ~ 1 | id_article,                   
    # Random intercept for each response variable within each article to account for within-study correlation
    ~ 1 | id_article/response_variable
  ),
  data = metdata,  # The dataset for the meta-analysis
  verbose = TRUE,                 # Enable verbose output to track convergence
  control = list(
    optimizer = "optim",          # Use 'optim' optimizer
    optim.method = "BFGS",        # Use BFGS optimization method
    iter.max = 1000,              # Maximum iterations
    rel.tol = 1e-8                # Normal convergence tolerance
  ),
  method = "ML"                   # Use Maximum Likelihood for model fitting
)

############################################################################################################################
model_without_response_var <- rma.mv(
  # Effect size estimates (dependent variable)
  yi = yi,              
  # Variance-covariance matrix of the effect sizes
  V = V_matrix,         
  # Only random intercept for each article to account for between-study variability
  random = ~ 1 | id_article,  
  data = metdata,  # The dataset for the meta-analysis
  verbose = TRUE,                 # Enable verbose output to track convergence
  control = list(
    optimizer = "optim",          # Use 'optim' optimizer
    optim.method = "BFGS",        # Use BFGS optimization method
    iter.max = 1000,              # Maximum iterations
    rel.tol = 1e-8                # Normal convergence tolerance
  ),
  method = "ML"                   # Use Maximum Likelihood for model fitting
)

##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##############################################################
# Last go: (25/08-24)
# Iteration 71    ll = -6040.9410   sigma2 = 0.0027  
# Iteration 72    ll = -6040.9410   sigma2 = 0.0027  
# Time difference of 1.420276 mins

# Last go: (04/11-24)
# Iteration 71    ll = -6040.9410   sigma2 = 0.0027  
# Iteration 72    ll = -6040.9410   sigma2 = 0.0027  
# Time difference of 1.537482 mins

```

```{r}
AIC(model_with_response_var, model_without_response_var)
```

```{r}
anova(model_with_response_var, model_without_response_var)
```


Full Model (with both random intercepts for article and response variable within article) is better than the Reduced Model (with only random intercept for article).



#######################################################################################################################################
ACTUAL MODEL FITTING
#######################################################################################################################################

```{r, eval = FALSE}
# Fit a random-effects model using rma.mv
# By setting "verbose = TRUE", we can obtain information on the progress of the optimization algorithm:

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Adjust the model to include study-level variance and within-study correlation

#######################################################################################################################################
# Fit the original multivariate random-effects meta-analysis model using the 'rma.mv' function
# This model accounts for study-level variance and within-study correlation

original_model <- rma.mv(
  # Effect size estimates (dependent variable)
  yi = yi,             
  # Variance-covariance matrix of the effect sizes (providing information on within-study sampling variances and covariances)
  V = V_matrix,                                      
  random = list(
    # Random intercept for each article to account for between-study variability
    ~ 1 | id_article,                   
    # Random intercept for each response variable within each article to account for within-study correlation
    ~ 1 | id_article/response_variable               
  ),
  # Data frame containing the meta-analysis data, including effect sizes and their variances 
  # The filtered data (using the filter(vi > quantile(vi, 0.950) has rows/obs: 1,007)
  data = metdata,    
  # Enable verbose output to print progress and convergence information
  verbose = TRUE,                                    
  control = list(
    # Optimizer to be used for fitting the model; 'nlminb' is robust for constrained optimization problems. 
    # Changed to 'optim' (the 08/10-24) with BFGS that can better handle complex, non-linear surfaces and is generally faster in converging. 
    # nlminb might get stuck more easily if the likelihood function is tricky or has flat areas, but it’s more robust when parameter constraints are needed.
    optimizer = "optim",  
    # Use BFGS optimization method,   
    optim.method = "BFGS",
     # Maximum number of iterations for the optimizer; increase if the model is complex or if convergence is slow
    iter.max = 1000,              
    # Relative convergence tolerance; lower values indicate stricter convergence criteria
    rel.tol = 1e-12     # with nlminb I reduced from 1e-8 to 1e-4 (the 08/10-24) to avoid non-convergence       
    # Alternatively, provide initial estimates for variance components to ease convergence
    #sigma2.init = c(0.01, 0.01, 0.01)  
  ),
  # Use Maximum Likelihood (ML) estimation for fitting the model (alternatively, REML could be used for restricted maximum likelihood)
  # Justification for using Maximum Likelihood (ML) over REML:
  # - ML allows for straightforward model comparisons, making it suitable for hypothesis testing 
  #   and model selection based on different fixed effects (e.g., adding or removing moderators).
  # - ML provides consistent estimates of fixed effects, which is essential for accurately assessing 
  #   overall effect sizes and moderator impacts in the meta-analysis.
  # - For complex models with multiple levels of random effects, ML can be more computationally 
  #   efficient and is more versatile, making it a practical choice for this analysis.
  # - Although ML might slightly underestimate variance components in small sample sizes, the primary 
  #   focus here is on hypothesis testing and the fixed effects, for which ML is well-suited.
  method = "ML"                                      
)

# Notes on the model:
# - 'yi': Represents the vector of observed effect sizes, calculated previously using escalc() function.
# - 'V': The variance-covariance matrix representing the sampling variances of effect sizes and covariances, allowing for dependencies within studies.
# - 'random': Specifies the random-effects structure. 
#     - '~ 1 | id_article': Random effect at the study level to capture between-study variance.
#     - '~ 1 | id_article/response_variable': Nested random effects to account for within-study variability across different response variables.
# - 'data': Specifies the dataset being used, which has been preprocessed to include only relevant and cleaned data points.
# - 'verbose': Provides output on the optimization process, helpful for diagnosing convergence issues.
# - 'control': Contains settings for the optimization process, including the choice of optimizer, maximum iterations, and convergence tolerance.
# - 'method': Specifies the estimation method; ML is chosen here to estimate the fixed and random effects.
#             The choice between ML and REML should be guided by the specific goals of the analysis, with ML being suitable for hypothesis testing and REML
#             offering better variance estimation properties. 

# Running this model will provide insight into both the fixed effect sizes and the random effects that account for variability within and between studies.
# It will also help in understanding how much of the total variability is due to differences between studies and how much is due to within-study correlation among response variables.
#######################################################################################################################################
##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##############################################################
# Last go: (25/08-24)

# Last go: (04/11-24)
# Iteration 110   ll = -5640.6760   sigma2 = 0.0000  0.0000  0.0038  
# Iteration 111   ll = -5640.6760   sigma2 = 0.0000  0.0000  0.0038  
# Iteration 112   ll = -5640.6760   sigma2 = 0.0000  0.0000  0.0038  
# Iteration 113   ll = -5640.6760   sigma2 = 0.0000  0.0000  0.0038  
# 
# Time difference of 1.996763 mins
```

```{r, eval = FALSE}
# Save the model object to a file
saveRDS(original_model, file = "C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/FROM_R/original_model_v5.rds")
```



TAKING A LOOK AT THE FITTED MODEL

```{r, eval = FALSE}
# Inspect the model summary to get more details
summary(original_model)

# Last go: (04/11-24)

# Multivariate Meta-Analysis Model (k = 1040; method: ML)
# 
#     logLik    Deviance         AIC         BIC        AICc   
# -5640.6760  15984.0441  11289.3520  11309.1399  11289.3906   
# 
# Variance Components:
# 
#             estim    sqrt  nlvls  fixed                        factor 
# sigma^2.1  0.0000  0.0014     36     no                    id_article 
# sigma^2.2  0.0000  0.0014     36     no                    id_article 
# sigma^2.3  0.0038  0.0614     47     no  id_article/response_variable 
# 
# Test for Heterogeneity:
# Q(df = 1039) = 2235314.6962, p-val < .0001
# 
# Model Results:
# 
# estimate      se     zval    pval    ci.lb   ci.ub    
#  -0.0043  0.0097  -0.4373  0.6619  -0.0234  0.0148    
# 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```


INTERPRETATION OF MODEL SUMMARY

Model Summary Interpretation for Database Version 5 (v5)
The aim of this multivariate meta-analysis is to estimate effect sizes for various response variables across multiple studies, while accounting for the correlations within studies and variation between studies. This model incorporates both study-level and within-study variability to provide a comprehensive picture of the observed effect sizes. Using a Maximum Likelihood (ML) estimation approach, we included 1,040 effect sizes, leading to a log-likelihood of -5640.6760, with fit indices AIC (11289.3520), BIC (11309.1399), and AICc (11289.3906). These metrics indicate how well the model fits the data and can guide comparisons with alternative model specifications, where lower values imply a better fit.

Variance Components and Their Implications
This multivariate model includes random effects at two levels to capture the structure of the data:

- Between-Study Variance (sigma^2.1 and sigma^2.2): These components represent variability across studies, accounting for the fact that studies may differ in methodologies, populations, or contexts. However, in this model, both components (0.0000) indicate negligible between-study variability. This suggests that differences between studies are not a primary driver of variability in effect sizes, and the effect sizes are fairly stable across different studies.

- Within-Study Variance (sigma^2.3): The variance component sigma^2.3 (0.0038, with a standard deviation of 0.0614) captures the within-study correlation, specifically the variability across different response variables within each study. This level of variance is notably higher than the between-study variance, indicating that the primary source of variability arises from differences in specific response variables rather than from study-level differences. This variance component is critical for capturing correlations within studies, as it allows for "borrowing strength" across response variables measured within the same study, improving the precision of estimates.

By modeling these variance components, the analysis accurately reflects the hierarchical structure of the data, balancing both the need for study-level independence and the shared information within studies. This hierarchical approach also helps to prevent bias that might occur if dependencies among within-study measurements were ignored.

Testing for Heterogeneity
The Q-test for heterogeneity yielded a very large Q-value of 2235314.6962 with a p-value < 0.0001, demonstrating substantial heterogeneity among effect sizes. This high degree of heterogeneity suggests that the observed differences in effect sizes are not merely due to random variation but are influenced by genuine differences across studies and response variables. The significant heterogeneity validates the use of a random-effects model, as it indicates that the effect sizes vary meaningfully across contexts, rather than following a single, consistent pattern.

Overall Effect Size
The model estimates an overall effect size of -0.0043 with a standard error of 0.0097. This estimate is not statistically significant (p = 0.6619), and the 95% confidence interval (-0.0234 to 0.0148) crosses zero, suggesting no significant average effect across studies. This result implies that, despite the variability across individual studies and response variables, there is no consistent overall effect detected across the dataset. The lack of a significant overall effect may be due to high variability across studies and response variables, indicating that the effects observed are context-dependent rather than universally consistent.

################################################################################################
SUMMARISED:
In summary, the model captures both study-level and within-study variability, providing a robust framework to estimate effect sizes across diverse contexts and response variables. By including random effects, it effectively accounts for the dependencies within studies and the heterogeneity across them. The observed high within-study variability emphasizes the importance of considering the individual response variables within studies. The multivariate approach enables a nuanced analysis that respects the complex structure of the data, yielding more accurate and interpretable estimates of effect sizes across studies.


```{r}
# Extract variance-covariance components
vcov_matrix <- vcov(original_model)
vcov_matrix

# Extract additional parameters if they are modeled
tau2_value <- original_model$tau2
rho_value <- original_model$rho
gamma2_value <- original_model$gamma2
phi_value <- original_model$phi

# Print additional parameters
cat("tau2:", tau2_value, "\n")
cat("rho:", rho_value, "\n")
cat("gamma2:", gamma2_value, "\n")
cat("phi:", phi_value, "\n")
```

INTERPRETATION SUMMARY

These extracted parameters suggest a model with minimal between-study variability (tau2 = 0), no apparent correlations between outcomes within studies (rho = 0), and no extra levels of random variability or overdispersion (gamma2 = 0, phi = 0). Together, these values imply that the model’s random-effects structure is sufficient to capture the complexity of the data without needing additional layers of variability. The low variance-covariance matrix value and zero for other components indicate a relatively homogeneous dataset, where most variation is within outcomes rather than across studies or contexts.










################################################################################################
FORMULATING THE NEXT STEPS IN THE MEAT-ANALYSIS
################################################

Next Steps:

1. Sensitivity Analysis:
    - Assess robustness of results by checking influence of individual studies.
      Evaluate the influence of individual studies on the overall results.
    - Check if the results change when certain studies are removed.
      Use leave-one-out analysis, detect outliers, and examine impact of large sample sizes.
    
2. Moderator Analysis:
    - Investigate if certain study characteristics (moderators) explain the heterogeneity.
      Identify sources of heterogeneity.
    - Include moderators in the model to see if they account for some of the variability.
      Conduct meta-regression using study-level covariates, analyze categorical and continuous moderators.

3. Visualization:
    - Create forest plots to visualize the effect sizes and their confidence intervals across studies.
      Enhance interpretation through visual representation.
    - Use bubble plots to show the relationship between effect sizes and study characteristics.
      Create forest plots for effect sizes, bubble plots for study characteristics, and distribution plots for effect sizes.

4. Diagnostic Plots:
    - Examine funnel plots to assess publication bias.
      Check for model assumptions and biases.
    - Use residual plots to check model assumptions.
      Use funnel plots for publication bias and residual plots for model assumptions.

Alternatives:
  Reconsider the Use of REML
    - Improve variance component estimation.
      Use REML for final variance estimation, compare with ML results to ensure robustness.
  
  Data Quality and Consistency Checks
    - Maintain reliability of data.
      Standardize measurement techniques and harmonize study protocols to reduce variability.
  
  Explore Potential Unobserved Moderators
    - Identify other factors affecting results.
      Perform qualitative review of studies and consult experts to hypothesize potential moderators.

