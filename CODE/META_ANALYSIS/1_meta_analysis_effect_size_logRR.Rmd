---
title: "logRR"
author: "Kamau Lindhardt, lbk125"
date: "2024-07-06"
output: html_document
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulae to estimate effects (and their standard errors)?




#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    tidygeocoder,     # For geocoding addresses to latitude/longitude
    rnaturalearth,    # For accessing Natural Earth map data
    rnaturalearthdata,# Companion package to rnaturalearth providing the data
    ###################################################################################################################
    # Spatial Data
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    ###################################################################################################################
    # Soil Data
    soilDB,           # For downloading soil data from ISRIC SoilGrids
    aqp,              # For soil profile visualization and analysis
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Provides several cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
```


Loading the dataset (main database)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory
#setwd("~/Library/Mobile Documents/com~apple~CloudDocs/SAF_Meta_analysis/META_ANALYSIS/R/Temperate_SAF_meta_analysis")
# here::here("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temperate_SAF_meta_analysis/DATA/META_ANALYSIS/Final_database_2024_05_17.xlsx")

# Suppress warnings to avoid clutter in the console output
suppressWarnings({
  database <- read_excel(here::here("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temperate_SAF_meta_analysis/DATA/META_ANALYSIS/Final_database_2024_05_17.xlsx"), 
                           sheet = "Quantatitive data") 
  #%>%
  #  filter(INCLUDED == TRUE) # include only data entries that have been assesed and deemed included
})
```

**Glimpse (taking a look at the data)**
```{r Glimpse the dataset, eval=FALSE}
database %>% dplyr::glimpse() 
```
```{r}
database %>% summary() 
```


#############
# STEP 1
##########################################################################################################################################
DATA PREPROCESSING
##########################################################################################################################################

```{r}
# Function to safely convert to numeric, replacing non-numeric values with NA
safe_as_numeric <- function(x) {
  suppressWarnings(as.numeric(x))
}

# Convert standard errors to numeric and handle non-numeric values
database_clean <- database |>
  # Streamlining and cleaning variable column names
  janitor::clean_names() |> 
  # Converting id_article to integer
  mutate(id_article = as.integer(id_article)) |>
  # Converting to numerical data type
  mutate(
    silvo_se = safe_as_numeric(silvo_se),
    control_se = safe_as_numeric(control_se)
  ) %>%
  # Ensure no infinite or NaN values are present in any variable columns
  mutate_all(~ifelse(is.infinite(.), NA, .)) |>
  mutate_all(~ifelse(is.nan(.), NA, .)) |>
  # Relocating variable columns to better get an overview of the data
  relocate(
    id_article, response_variable, measured_metrics, measured_unit, 
    silvo_mean, silvo_se, silvo_sd, silvo_n,
    control_mean, control_se, control_sd, control_n
  )

database_clean
```
```{r}
database_clean %>% glimpse()
```

```{r}
database_clean %>% summary()
```

##########################################################################################################################################
EXPLORATIVE DATA ANALYSIS (EDA)
##########################################################################################################################################

#############
VIEWING DATA
#############

```{r}
database_clean %>% 
  group_by(response_variable) %>%
  summarise(n_silvo = sum(silvo_n),
            n_control = sum(control_n),
            mean_silvo = mean(silvo_mean),
            mean_control = mean(control_mean))
```

###################
EDA WITH DLOOKR
###################

```{r}
# Visualize pareto chart for variables with missing value.

plot_na_pareto(database_clean)

# Indicating a high proportion of NA values in the control_se and silvo_se variables. 
# Might need imputation in order to include them in the meta-analysis
```
Missing values are found in 
- silvo_se
- control_se
- distance_tree_m

```{r}
# Visualize the combinations of missing value across cases.

plot_na_intersect(database_clean)
```
```{r}
# Filter rows with missing values in silvo_se or control_se, and select relevant columns
# omitting distance_tree_m
missing_values <- database_clean |>
  filter(is.na(silvo_se) | is.na(control_se)) |> 
         # is.na(distance_tree_m)) |>
  select(id_article, response_variable, silvo_se, control_se, distance_tree_m)

# Transform data for visualization by pivoting longer and counting missing values
missing_count <- missing_values |>
  pivot_longer(cols = c(silvo_se, control_se), names_to = "missing_type", values_to = "value") |>
  filter(is.na(value)) |>
  count(id_article, response_variable, missing_type)


# Create the bar plot to visualize missing values by article and response variable
ggplot(missing_count, aes(x = factor(id_article), y = n, fill = missing_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ response_variable, scales = "free_x") +
  labs(
    title = "Missing Values by Article and Response Variable",
    x = "Article ID",
    y = "Number of Missing Values",
    fill = "Missing Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
```{r}
# Identify rows with missing values in control_se or silvo_se
missing_values_se <- missing_values |> 
  filter(is.na(silvo_se) | is.na(control_se)) |>
  select(id_article, response_variable, silvo_se, control_se)

# Prepare data to include missing_type and id_article
missing_val_se_plot <- missing_values_se |>
  mutate(
    missing_silvo_se = ifelse(is.na(silvo_se), 1, 0),
    missing_control_se = ifelse(is.na(control_se), 1, 0)
  ) |>
  pivot_longer(cols = c(missing_silvo_se, missing_control_se), names_to = "missing_type", values_to = "n") |>
  filter(n == 1)  # Keep only the rows where there is a missing value


# Create the stacked bar plot
missing_val_se_plot |>
  ggplot(aes(x = response_variable, y = n, fill = factor(id_article))) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Number of Missing Values per Response Variable",
       x = "Response Variable",
       y = "Number of Missing Values",
       fill = "Article ID") +
  facet_wrap(~missing_type, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
Firstly, the Crop yield category stands out with the highest number of missing values for both silvo_se and control_se. This is followed by the Pest and Disease and Soil quality categories, which also show significant numbers of missing values, though they are much fewer compared to Crop yield. This indicates a particular problem with data completeness in the Crop yield category.

Secondly, within each response_variable category, the number of missing values for silvo_se and control_se appears to be comparable. This suggests a pattern where if a value is missing in one, it is likely missing in the other. For instance, both silvo_se and control_se have similar heights in the Crop yield and Pest and Disease categories, indicating consistent missing data patterns across these variables.

Furthermore, the plot shows that multiple articles contribute to the missing data, with certain articles, such as IDs 2, 3, 10, and 25, being significant contributors, especially in the Crop yield category. This spread of missing data across different studies suggests that the issue is not confined to a single source but is more widespread.

In summary, the Crop yield category is particularly problematic with a high number of missing values for both silvo_se and control_se. Several articles, particularly IDs 2, 3, and 10, appear frequently in categories with high missing values. The consistency in missing data patterns between silvo_se and control_se suggests that there might be methodological or study-specific issues contributing to the missing data. To address these issues, it is essential to investigate the high-contributing articles, review the methodologies used in the Crop yield category, and develop strategies to handle the missing data, such as imputation, especially for critical categories like Crop yield. This approach will help improve the quality and completeness of the data, leading to more reliable analyses and insights.


```{r}
# Plot density distribution for control_se with log transformation
database_clean |> 
  ggplot(aes(x = control_se)) +
  geom_density() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of control_se (Log-Transformed)") +
  theme_minimal()

# Advarsel i scale_x_log10() :
#   log-10 transformation introduced infinite values.
# Advarsel: Removed 218 rows containing non-finite outside the scale range (`stat_density()`).

# warnings indicate that some of the values in the dataset are either zero or negative, which cause issues when applying a logarithmic transformation
```
```{r}
# Plot density distribution for silvo_se with log transformation
database_clean |> 
  ggplot(aes(x = silvo_se)) +
  geom_density() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

# Advarsel i transformation$transform(x) : NaNs produced
# Advarsel i scale_x_log10() :
#   log-10 transformation introduced infinite values.
# Advarsel: Removed 212 rows containing non-finite outside the scale range (`stat_density()`).

# warnings indicate that some of the values in the dataset are either zero or negative, which cause issues when applying a logarithmic transformation
```


```{r, eval = FALSE}
eda_report_meta_analysis_SAF <- database_clean |>
  eda_paged_report(#target = "response_variable", 
                   subtitle = "Temperate SAF EDA for meta-analysis",
                   output_format = "html",
                   output_file = "EDA_SAF.html")

# Remember to open in Microsoft Edge browser. For some reason Google Chrome is not working
eda_report_meta_analysis_SAF
```



##########################################################################################################################################
CONTINUED DATA PREPROCESSING AND HANDELING OF MISSING VALUES IN THE DATASET
##########################################################################################################################################

####################################################################################
Perform imputation using "mice" (Multivariate Imputation by Chained Equations)
####################################################################################

```{r, eval = TRUE}
####################################################################################
# Extract relevant columns for imputation
col_for_impute <- database_clean %>%
  dplyr::select(silvo_se, 
                control_se)
                # omitting imputation of 
                # distance_tree_m) 

####################################################################################
# Set seed for reproducibility
set.seed(1234)

# Perform imputation using mice
# - read about mice() here: https://www.metafor-project.org/doku.php/tips:multiple_imputation_with_mice_and_metafor
# - col_for_impute: the data frame containing the columns to be imputed
# - m = 5: number of multiple imputations to perform
# - maxit = 100: maximum number of iterations to perform for each imputation
# - method = 'pmm': method to use for imputation, 'pmm' stands for predictive mean matching
# - seed = 500: random seed for reproducibility of the imputations
# - printFlag: If TRUE, mice will print history on console. Use print=FALSE for silent computation.

imputed_data <- mice::mice(col_for_impute, 
                           m = 20, 
                           maxit = 100, 
                           method = 'pmm', 
                           seed = 1234,
                           printFlag = FALSE)
```

```{r}
####################################################################################

# Check the summary of imputed data
summary(imputed_data)
```
```{r}
# Evaluate the imputed datasets
# Check convergence diagnostics
plot(imputed_data)
```
```{r}
# Compare the distribution of the observed and imputed data
densityplot(imputed_data)
```
```{r}
# Use stripplot to compare observed and imputed values
stripplot(imputed_data, pch = 20, cex = 1.2)
```
```{r}
# For an evidence-based choice, we may calculate some metrics
# Calculate the mean and standard deviation of each imputed dataset
imputed_summaries <- lapply(1:5, function(i) {
  data <- complete(imputed_data, i)
  summary <- data %>%
    summarise(
      mean_silvo_se = mean(silvo_se, na.rm = TRUE),
      sd_silvo_se = sd(silvo_se, na.rm = TRUE),
      mean_control_se = mean(control_se, na.rm = TRUE),
      sd_control_se = sd(control_se, na.rm = TRUE)
    )
  return(summary)
})

# Combine the summaries into a single data frame for comparison
imputed_summaries_df <- bind_rows(imputed_summaries, .id = "imputation")

imputed_summaries_df
```
```{r}
# Choose the imputation based on the diagnostics and summaries
# For simplicity, let's assume we choose the imputation with the median mean_silvo_se
chosen_imputation <- imputed_summaries_df %>%
  filter(mean_silvo_se == median(mean_silvo_se))

chosen_imputation
```
```{r}
# Extract the chosen imputation number
chosen_imputation_number <- chosen_imputation$imputation

# Extract the complete dataset for the chosen imputation
imputed_col_data <- complete(imputed_data, as.integer(chosen_imputation_number))

imputed_col_data
```

```{r}
####################################################################################
# Another way is simply to choose an imputation run from the iterations:
# Choose one of the multiple imputations (e.g., the first imputation)
# imputed_col_data <- complete(imputed_data, 1)
# summary(imputed_col_data)

####################################################################################
# Update the original data with imputed values
imputed_database_clean <- database_clean %>%
  mutate(
    silvo_se = imputed_col_data$silvo_se,
    control_se = imputed_col_data$control_se
    ) 

imputed_database_clean |> glimpse()
```

```{r, eval=FALSE}
imputed_database_clean %>% summary()
```
Visualising the distribution of imputed values for silvo_se and control_se together with the original data

```{r}
# Prepare the original data
original_data_x <- database_clean %>%
  select(id_article, response_variable, silvo_se, control_se) |> 
  mutate(data_source = "Original")

imputed_data_y <- imputed_database_clean |> 
  select(id_article, response_variable, silvo_se, control_se) |> 
  mutate(data_source = "Imputed")

# Combine the original and imputed data
combined_data <- bind_rows(original_data_x, imputed_data_y)

combined_data
```

```{r}
# Create density plots for silvo_se with log transformation
silvo_se_impute_original_plot <- combined_data |> 
ggplot(aes(x = silvo_se, color = data_source)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

# Create density plots for control_se with log transformation
control_se_impute_original_plot <- combined_data |> 
ggplot(aes(x = control_se, color = data_source)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

library(patchwork)

silvo_se_impute_original_plot + control_se_impute_original_plot
```


#############
# STEP 3
##########################################################################################################################################
CALCULATING EFFECT SIZE MEASURE AND GENERATING AND BUILDING RANDOM-EFFECTS MODEL
##########################################################################################################################################


################################
A) The standardized mean difference: It is necessary to standardize the results of the studies to a uniform scale before they can be combined. For effect measure in our case we can use Ratio of Means (RoM) as the ratio of means can be used in either situation, but is appropriate only when outcome measurements are strictly greater than zero.

```{r}
# New dataset to be used for mata-analysis
meta_data <- imputed_database_clean |> 
  # Filtering so that only data with outcome measurements that are greater than zero will be included
  filter(silvo_se > 0, 
         control_se > 0) |>
  # Adjust the signs for specific response variables where lower values for silvo_ vs. control_ is actually better
  # Manually changing the signs for greenhouse gas emissions and pests and diseases, as lower values in the silvo_ treatment group are considered
  # better. This ensures consistency in the interpretation of effect sizes across all outcomes. 
  mutate(
    silvo_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases"), -silvo_mean, silvo_mean),
    control_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases"), -control_mean, control_mean)
  ) |> 
  # To be 100 % sure. Filter out rows with missing values in key columns
  filter(
    !is.na(silvo_mean) & !is.na(control_mean) & !is.na(silvo_n) & 
    !is.na(control_n) & !is.na(silvo_se) & !is.na(control_se)
  ) |> 
  # Calculate standard deviations from standard errors and sample sizes
  mutate(
    # Calculate standard deviation for silvo group
    silvo_sd = silvo_se * sqrt(silvo_n),
    # Calculate standard deviation for control group
    control_sd = control_se * sqrt(control_n)
  ) |> 
  # Reorder columns for better readability and organization
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable) 


meta_data |> glimpse()
```


################################################################################################
AUTOMATIC CALCULATION OF EFFECT SIZE MEASURE USING escalc() function
################################################################################################

```{r}
# Calculate effect sizes and variances using escalc()
# - measure: Specifies the effect size measure to use, "ROM" for the log transformed ratio of means 
            # Alternative effect size measures: "MD" for the raw mean difference, "RR" for the log risk ratio, 
            # "OR" for the log odds ratio, "RD" for the risk difference, "SMD" stands for Standardized Mean Difference,
            # "AS" for the arcsine square root transformed risk difference, "PETO" for the log odds ratio estimated with Peto's method
# - m1i: Means of the experimental group (silvo_mean)
# - sd1i: Standard deviations of the experimental group (silvo_se)
# - n1i: Sample sizes of the experimental group (silvo_n)
# - m2i: Means of the control group (control_mean)
# - sd2i: Standard deviations of the control group (control_se)
# - n2i: Sample sizes of the control group (control_n)
# - slab: Optional argument to specify study labels, here combining 'id_article' and 'study_year_start'
# - data: The dataset containing all the specified columns

# "ROM" for the log transformed ratio of means
meta_data_ROM <- escalc(measure = "ROM", 
                       # experimental group (silvo_)
                       m1i = silvo_mean, sd1i = silvo_sd, n1i = silvo_n,
                       # control group (control_)
                       m2i = control_mean, sd2i = control_sd, n2i = control_n,
                       # argument to specify study labels for plotting
                       slab = paste(id_article, ", ", study_year_start, sep = ""),
                       # dataset to be used
                       data = meta_data) |> 
  as.data.frame()

# Check if the meta_data_ROM object exists and display its structure
str(meta_data_ROM)

# Advarsel: Some 'yi' and/or 'vi' values equal to +-Inf. Recoded to NAs
```
```{r}
# Identify rows where 'yi' or 'vi' are NA
problematic_data <- meta_data_ROM %>%
  filter(is.na(yi) | is.na(vi))

# Display the problematic data points
problematic_data |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)
```
The yi and vi values can become NA (or infinite before being recoded to NA) for several reasons when using the escalc() function to calculate effect sizes and variances. Here are some common causes:

Zero or Negative Values in Control or Experimental Group: If the means, standard deviations, or sample sizes in the control or experimental group are zero or negative, it can lead to undefined or infinite values when calculating the log-transformed ratio of means (ROM).



To handle problematic data points by assigning them a small value instead of excluding them, you can follow these steps:

1) Identify Problematic Data Points: Identify the data points where yi or vi are NA.
2) Assign Small Values: Replace the problematic values with a small value.
3) Recalculate Effect Sizes and Variances: Recalculate yi and vi after addressing the problematic values.


################################################################################################
RE-CALCULATION OF EFFECT SIZE MEASURE USING escalc() function
################################################################################################


```{r}
# Assign a small value to zero or negative values in the original data
small_value <- 0.0001

# Create a new dataset with small values assigned to problematic data points
adjusted_meta_data <- meta_data %>%
  mutate(
    silvo_mean = ifelse(silvo_mean <= 0, small_value, silvo_mean),
    silvo_sd = ifelse(silvo_sd <= 0, small_value, silvo_sd),
    silvo_n = ifelse(silvo_n <= 0, small_value, silvo_n),
    control_mean = ifelse(control_mean <= 0, small_value, control_mean),
    control_sd = ifelse(control_sd <= 0, small_value, control_sd),
    control_n = ifelse(control_n <= 0, small_value, control_n)
  )

# Recalculate effect sizes and variances

# "ROM" for the log transformed ratio of means
meta_data_ROM_adjusted <- escalc(measure = "ROM",
                                 # experimental group (silvo_)
                                 m1i = silvo_mean, sd1i = silvo_sd, n1i = silvo_n,
                                 # control group (control_)
                                 m2i = control_mean, sd2i = control_sd, n2i = control_n,
                                 # argument to specify study labels for plotting
                                 slab = paste(id_article, ", ", study_year_start, sep = ""),
                                 # dataset to be used
                                 data = adjusted_meta_data) |> 
  as.data.frame()

# Check if the meta_data_ROM object exists and display its structure
str(meta_data_ROM_adjusted)
```


```{r}
meta_data_ROM <- meta_data_ROM_adjusted
```







```{r}
# Display the data with re-calculated effect size measure 
as.data.frame(meta_data_ROM) |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)
```
```{r}
# Display the data with re-calculated effect size measure 
as.data.frame(meta_data_ROM) |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable) |> 
  glimpse()
```
################################################################################################
VISUAL ASSESSMENT
################################################################################################

Visual assessment of yi (effect sizes) and vi (variances) for both the silvo_ and control_ groups, faceted by each response_variable

```{r}
# Prepare the data
# Separate the data for silvo_ and control_
silvo_data <- meta_data_ROM %>%
  select(id_article, response_variable, yi, vi, silvo_mean, silvo_se, silvo_sd, silvo_n) %>%
  rename(mean = silvo_mean, se = silvo_se, sd = silvo_sd, n = silvo_n) %>%
  mutate(group = "silvo_")|> 
  as.data.frame()

control_data <- meta_data_ROM %>%
  select(id_article, response_variable, yi, vi, control_mean, control_se, control_sd, control_n) %>%
  rename(mean = control_mean, se = control_se, sd = control_sd, n = control_n) %>%
  mutate(group = "control_") |> 
  as.data.frame()

# Combine the data
combined_data <- bind_rows(silvo_data, control_data)

# Prepare data for plotting
combined_long_data <- combined_data %>%
  pivot_longer(cols = c(yi, vi), names_to = "measure", values_to = "value")

# Check the prepared data
glimpse(combined_long_data)

# Create the density plot
combined_long_data |> 
ggplot(aes(x = value, fill = group), linetype = 2) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Group",
       x = "Value",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Create the density plot for silvo_ group
combined_long_data |> 
  filter(group == "silvo_") |> 
ggplot(aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Response Variable (Silvo)",
       x = "Value",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Create the density plot for control_ group
combined_long_data |> 
  filter(group == "control_") |> 
  ggplot(aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Response Variable (Control)",
       x = "Value",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
# Get the unique response variables
response_variables <- unique(combined_long_data$response_variable)

# Create individual plots for each response variable and combine them
plots <- list()
for (rv in response_variables) {
  # Filter data for the current response variable
  data_rv <- combined_long_data %>% filter(response_variable == rv)
  
  # Determine the fixed scales for yi and vi
  yi_range <- range(data_rv %>% filter(measure == "yi") %>% pull(value), na.rm = TRUE)
  vi_range <- range(data_rv %>% filter(measure == "vi") %>% pull(value), na.rm = TRUE)
  
  # Plot for yi
  p_yi <- ggplot(data_rv %>% filter(measure == "yi"), aes(x = value, fill = group)) +
    geom_density(alpha = 0.5, linetype = "dotted") +
    scale_x_continuous(limits = yi_range) +
    labs(title = paste("Density Plot of Effect Sizes (yi) for", rv),
         x = "Effect Size (yi)",
         y = "Density",
         fill = "Group") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Plot for vi
  p_vi <- ggplot(data_rv %>% filter(measure == "vi"), aes(x = value, fill = group)) +
    geom_density(alpha = 0.5, linetype = "dotted") +
    scale_x_continuous(limits = vi_range) +
    labs(title = paste("Density Plot of Variances (vi) for", rv),
         x = "Variance (vi)",
         y = "Density",
         fill = "Group") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Combine the plots using patchwork
  combined_plot <- p_yi + p_vi + plot_layout(ncol = 1)
  
  # Store the combined plot in the list
  plots[[rv]] <- combined_plot
}

# Print the combined plots
for (rv in names(plots)) {
  print(plots[[rv]])
}
```


Interpretation of the yi and vi plots


These density plots illustrate the distributions of the effect sizes (yi) and their variances (vi) across different response variables for two groups: the silvo group and the control group. Here's a detailed interpretation:

Interpretation of the Plots
Effect Sizes (yi):

The density plots for effect sizes (yi) indicate how the observed effect sizes are distributed across different response variables.
The majority of the effect sizes seem to be centered around zero, which is typical in meta-analysis when combining results from multiple studies.
Variances (vi):

The density plots for variances (vi) show the spread of the sampling variances of the effect sizes.
For some response variables like "Biodiversity," "Crop yield," and "Pest and Disease," the variances are highly skewed with extreme values.
This broad variance indicates high variability in the effect size estimates, suggesting that the studies contributing to these effect sizes may have differing levels of precision or sample sizes.
Reasons for Broad Variance
Heterogeneity: The broad variances can be due to substantial heterogeneity among the included studies. Differences in study designs, populations, interventions, and outcomes can contribute to this.
Measurement Error: Some studies might have higher measurement errors or smaller sample sizes, leading to larger variances in their effect size estimates.
Outliers: Extreme values or outliers in the data can inflate the variance.
Addressing Broad Variance
Transformations: Consider applying transformations to stabilize the variances. For example, log transformation can sometimes help in reducing skewness.
Robust Meta-Analysis Methods: Use robust statistical methods that are less sensitive to outliers and extreme values.
Subgroup Analysis: Perform subgroup analyses to explore sources of heterogeneity. Group studies based on characteristics like study design, population, or intervention.
Meta-Regression: Use meta-regression to account for potential moderators that explain variability in effect sizes.
Trim-and-Fill Method: Use the trim-and-fill method to identify and adjust for publication bias, which can contribute to variance.



Standardizing the variance (vi) data can be helpful in addressing some of the issues with broad variance. However, it's important to understand that standardizing vi will not necessarily address the underlying heterogeneity or outliers in the data. It can make the scale of variances more comparable, but it won't change the fact that some studies have higher uncertainty than others.

Regarding the effect size measure yi, the ROM (Ratio of Means) is already a standardized effect size measure that accounts for differences in scales between studies to some extent. The broad variance you are observing is likely due to the inherent heterogeneity and differences in study quality.

Standardizing Variance (vi)
You can standardize the variances by transforming them into a common scale. One way to do this is to divide each variance by the mean variance or by some measure of central tendency (e.g., the median):


Standardizing Effect Sizes (yi) 
While the ROM effect size measure does help in standardizing the effect sizes across studies, you might still consider standardizing yi for further analyses, especially if you have different scales or units across studies:




Alternative

##########################################################################################################################################
EXCLUDE HIGH-VARIANCE OBSERVATIONS 
##########################################################################################################################################

Identify and Exclude High Variance Observations from the dataset before making the variance-covariance matrix and 
fitting the random-effects model

To avoid the previous error:
Error: Fejl: Optimizer (nlminb) did not achieve convergence (convergence = 1).

Warning: Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
The warning "Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results" indicates that there is a large disparity between the variances of your effect sizes, which can lead to instability in the model results.

```{r}
# Inspect the variances (vi)
meta_data_ROM |>
  filter(!is.na(vi)) |> 
  ggplot(aes(x = vi)) +
  geom_histogram(bins = 100) +
  #scale_y_log10() + 
  scale_x_log10() +
  ggtitle("Distribution of Sampling Variances (vi)") +
  theme_minimal() 
```
```{r}
# Identify rows with high variances

high_variance_obs <- meta_data_ROM |> 
  filter(vi > quantile(vi, 0.995)) |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)

high_variance_obs
```

```{r}
# Exclude high variance observations from the dataset

# Add a row number column to meta_data_ROM
meta_data_ROM <- meta_data_ROM |> 
  as.data.frame() |> 
  mutate(row_id = row_number())

# Identify rows with high variances
high_variance_obs <- meta_data_ROM |> 
  filter(vi > quantile(vi, 0.95, # 0.995
                       na.rm = TRUE))

# Exclude high variance observations from the dataset
filtered_meta_data_ROM <- meta_data_ROM |> 
  filter(!row_id %in% high_variance_obs$row_id)

filtered_meta_data_ROM
```

##########################################################################################################################################
CREATING A VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################

Creating a variance-covariance matrix is crucial in multivariate meta-analysis because it captures the dependencies among the effect sizes from different outcomes measured within the same study. Without accounting for these dependencies, the analysis could be biased and less efficient.

Why a Variance-Covariance Matrix is Needed
- Account for Within-Study Correlations: When multiple outcomes are reported within the same study, they are often correlated. Ignoring these correlations can lead to inaccurate estimates of the overall effect size and its variance.
- Borrowing Strength: The variance-covariance matrix allows the analysis to borrow strength across different outcomes, leading to more precise estimates.
- Improve Model Accuracy: Including the correct variance-covariance structure improves the accuracy of the random-effects model, leading to better inference.

```{r}
# Create a variance-covariance matrix for each study
V_list <- list() # Initialize an empty list to store variance-covariance matrices for each study

# Loop through each unique study ID in the dataset
for (study in unique(filtered_meta_data_ROM$id_article)) {
  # Subset the data for the current study
  study_data <- filtered_meta_data_ROM[filtered_meta_data_ROM$id_article == study, ]
  
  # Check if the current study has more than one outcome
  if (nrow(study_data) > 1) {
    # Create a diagonal matrix with the variances (vi) of the outcomes
    V <- diag(study_data$vi)
    
    # Assume a constant correlation of 0.5 between outcomes within the same study
    corr <- 0.5
    
    # Loop through the rows of the matrix to set the off-diagonal elements
    for (i in 1:nrow(V)) {
      for (j in 1:nrow(V)) {
        # Set the off-diagonal elements to the product of the correlation and the square root of the product of the corresponding variances
        if (i != j) {
          V[i, j] <- corr * sqrt(V[i, i] * V[j, j])
        }
      }
    }
    # Add the variance-covariance matrix to the list for the current study
    V_list[[as.character(study)]] <- V
  } else {
    # If there is only one outcome, the variance is just the variance of the single outcome
    V_list[[as.character(study)]] <- study_data$vi
  }
}

# Combine the matrices into a block-diagonal matrix
V_matrix <- bldiag(V_list)
```

```{r}
str(V_matrix)
```




##########################################################################################################################################
Quality Assessment of the filtered_meta_data_ROM and V_matrix data 
##########################################################################################################################################

```{r}
# Check for missing values in filtered_meta_data_ROM
missing_values <- sapply(filtered_meta_data_ROM, function(x) sum(is.na(x)))
print("Missing Values in filtered_meta_data_ROM:")
print(missing_values)
```
```{r}
# Distribution of vi
ggplot(filtered_meta_data_ROM, aes(x = vi)) +
  geom_histogram(binwidth = 0.1) +
  ggtitle("Distribution of Sampling Variances (vi)") +
  scale_x_log10() +
  theme_minimal()
```
```{r}
# Check for positive definiteness of V_matrix
is_positive_definite <- function(mat) {
  eigenvalues <- eigen(mat)$values
  all(eigenvalues > 0)
}

# Summary statistics for key columns
summary_stats <- filtered_meta_data_ROM %>%
  select(yi, vi, id_article, response_variable) %>%
  summary()
print("Summary Statistics for filtered_meta_data_ROM:")
print(summary_stats)

# Check for positive definiteness of V_matrix
is_positive_definite <- function(mat) {
  eigenvalues <- eigen(mat)$values
  all(eigenvalues > 0)
}
```
```{r}
positive_definite_check <- is_positive_definite(V_matrix)
print(paste("V_matrix is positive definite:", positive_definite_check))
```
The code snippet you provided is checking if the variance-covariance matrix (V_matrix) used in your meta-analysis model is positive definite. Here's a detailed explanation of what it means:

Positive Definiteness of a Matrix:
A matrix is positive definite if all its eigenvalues are positive.
Positive definiteness is a desirable property for variance-covariance matrices, ensuring that the matrix can be used in statistical models and that the calculations involving the matrix (e.g., inversions) are stable.

Ensuring the positive definiteness of the variance-covariance matrix is crucial for the integrity of statistical models, including those used in meta-analysis. A positive definite matrix guarantees that the matrix is invertible, a necessary condition for various statistical calculations, such as estimating model parameters. This property also ensures numerical stability during computations, reducing the likelihood of errors and ensuring accurate results, which is fundamental for the reliability of the model fitting process and subsequent statistical inference.

Excluding missing values from the dataset is essential to maintain data integrity and model accuracy. Missing values can lead to biased estimates and incorrect inferences if not handled appropriately. By removing rows with missing values in critical columns, we ensure that all observations used in the analysis are complete and reliable. This process simplifies the dataset, making it easier to apply statistical methods and interpret the results accurately.

##########################################################################
EXCLUDIDNG MISSING VALUES FROM THE DATASET - in case of any missing values. However, in this case there is no missing values
##########################################################################



##########################################################################################################################################
PERFORM THE META-ANALYSIS MODELLING WITH A RANDOM-EFFECTS MODEL
##########################################################################################################################################

##########################################################################
NOW RUNNING THE MODEL FITTING
##########################################################################

TEST

```{r}
# rma.mv(yi = yi, 
#        V = V_matrix_clean, 
#        random = ~ 1 | id_article/response_variable, 
#        data = filtered_meta_data_ROM_clean,
#        verbose = TRUE)

# Iteration 71    ll = -5945.9314   sigma2 = 0.0077  0.0190  
# 
# 
# Multivariate Meta-Analysis Model (k = 985; method: REML)
# 
# Variance Components:
# 
#             estim    sqrt  nlvls  fixed                        factor 
# sigma^2.1  0.0077  0.0876     37     no                    id_article 
# sigma^2.2  0.0190  0.1377     50     no  id_article/response_variable 
# 
# Test for Heterogeneity:
# Q(df = 984) = 16532.7158, p-val < .0001
# 
# Model Results:
# 
# estimate      se    zval    pval    ci.lb   ci.ub    
#   0.0156  0.0282  0.5530  0.5803  -0.0396  0.0708    
# 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```


ACTUAL MODEL FITTING

```{r, eval = FALSE}
# Fit a random-effects model using rma.mv
# By setting "verbose = TRUE", we can obtain information on the progress of the optimization algorithm:

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Adjust the model to include study-level variance and within-study correlation

#######################################################################################################################################
# Fit the original multivariate random-effects meta-analysis model using the 'rma.mv' function

original_model <- rma.mv(yi = yi,                                           # Effect size estimates
                         V = V_matrix,                                      # Variance-covariance matrix of the effect sizes
                         random = list(~ 1 | id_article,                    # Random intercept for each article
                                       ~ 1 | id_article/response_variable), # Random intercept for each response variable within each article
                         data = filtered_meta_data_ROM,                     # Data frame containing the meta-analysis data with effects sizes
                         verbose = TRUE,                                    # Print progress and convergence information
                         control = list(iter.max = 1000,                    # Maximum number of iterations for the optimizer
                                        rel.tol = 1e-6                      # Relative convergence tolerance for the optimizer
                                        )
                         )
#######################################################################################################################################
##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

# Time difference of 4.314359 mins - too simple! And still failing :-(
# Time difference of 1.77205 hours - with all model optimizes! And still failing :-(
# Time difference of 29.00199 secs - very simplified - but works :-)
# Time difference of 39.1189 secs

# Iteration 100   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 101   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 102   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 103   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 104   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 105   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 106   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# Iteration 107   ll = -5966.3000   sigma2 = 0.0067  0.0067  0.0237  
# 
# Time difference of 52.40915 secs
```



TAKING A LOOK AT THE FITTED MODEL

```{r}
# Inspect the model summary to get more details
summary(original_model)
```
INTERPRETATION OF MODEL SUMMARY

The multivariate meta-analysis model includes 1032 effect sizes from various studies and is implemented using the restricted maximum likelihood (REML) method. The log-likelihood value is -5966.3000, indicating the fit of the model to the data. The model's fit statistics, such as the AIC (11940.6000), BIC (11960.3531), and AICc (11940.6390), provide measures of the model's goodness of fit, with lower values indicating a better fit. These values help in comparing different models and selecting the best one.

The model accounts for variability at different levels using random effects. The variance components for the id_article level are 0.0067 (with a standard deviation of 0.0820) for both sigma^2.1 and sigma^2.2, indicating the variance attributed to individual articles. Additionally, the variance component for the id_article/response_variable level is 0.0237 (with a standard deviation of 0.1539), capturing the variance attributed to different response variables within each article. These variance components highlight the hierarchical structure of the data and the importance of considering both article-level and response variable-level variability.

The Q-test for heterogeneity reveals significant variability among the effect sizes, with a Q-value of 112909.0493 and a p-value of less than 0.0001. This significant heterogeneity indicates that the effect sizes differ more than would be expected by chance alone, suggesting that there are underlying differences between the studies that need to be accounted for in the analysis. The presence of such heterogeneity underscores the necessity of using a random-effects model to capture the between-study variability.

Despite the significant heterogeneity, the overall effect size estimate is 0.0046, with a standard error of 0.0321. However, this estimate is not statistically significant, as indicated by a p-value of 0.8865. The 95% confidence interval for the effect size ranges from -0.0583 to 0.0674, encompassing zero and further indicating the lack of a significant effect. This suggests that the effect sizes across the studies do not show a consistent trend or significant overall effect, highlighting the complexity and variability inherent in the data.


```{r}
# Extract variance-covariance components
vcov_matrix <- vcov(original_model)
vcov_matrix

# Extract additional parameters if they are modeled
tau2_value <- original_model$tau2
rho_value <- original_model$rho
gamma2_value <- original_model$gamma2
phi_value <- original_model$phi

# Print additional parameters
cat("tau2:", tau2_value, "\n")
cat("rho:", rho_value, "\n")
cat("gamma2:", gamma2_value, "\n")
cat("phi:", phi_value, "\n")
```


Next Steps:
1. Sensitivity Analysis:
    - Evaluate the influence of individual studies on the overall results.
    - Check if the results change when certain studies are removed.

2. Moderator Analysis:
    - Investigate if certain study characteristics (moderators) explain the heterogeneity.
    - Include moderators in the model to see if they account for some of the variability.

3. Visualization:
    - Create forest plots to visualize the effect sizes and their confidence intervals across studies.
    - Use bubble plots to show the relationship between effect sizes and study characteristics.

4. Diagnostic Plots:
    - Examine funnel plots to assess publication bias.
    - Use residual plots to check model assumptions.

#############
# STEP 4
##########################################################################################################################################
INFLUENCE DIAGNOSTICS AND SENSITIVITY ANALYSIS ON DATA (E.G.: MISSING OUTCOME DATA)
##########################################################################################################################################

```{r, eval = FALSE}

# Initialize a list to store the results
sensitivity_results <- list()

# Get the list of unique study IDs
unique_studies <- unique(filtered_meta_data_ROM$id_article)

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Loop through each study and fit the model excluding that study
for (study in unique_studies) {
  # Exclude the current study
  data_excluded <- filtered_meta_data_ROM[filtered_meta_data_ROM$id_article != study, ]
  
  # Fit the model
  model <- rma.mv(yi = yi, 
                  V = V_matrix[filtered_meta_data_ROM$id_article != study, filtered_meta_data_ROM$id_article != study], 
                  random = ~ 1 | id_article/response_variable, 
                  data = data_excluded,
                  method = "REML")
  
  # Store the results
  sensitivity_results[[as.character(study)]] <- list(
    estimate = model$b,
    se = model$se,
    ci.lb = model$ci.lb,
    ci.ub = model$ci.ub
  )
}

# Convert the results to a data frame
sensitivity_df <- do.call(rbind, lapply(sensitivity_results, function(x) data.frame(
  estimate = x$estimate,
  se = x$se,
  ci.lb = x$ci.lb,
  ci.ub = x$ci.ub
)))

sensitivity_df$id_article <- unique_studies

##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##################################################

# Time difference of 17.05628 mins

# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
```

##########################################################################
Use the original model fitting
##########################################################################
```{r}
# Original model results
original_estimate <- original_model$b
original_ci.lb <- original_model$ci.lb
original_ci.ub <- original_model$ci.ub

##################################################
##################################################
```


Visualize the changes
Create a plot to visualize the influence of excluding each study

```{r}
# Add the original model results to the data frame
sensitivity_df <- sensitivity_df %>%
  mutate(original_estimate = original_estimate,
         original_ci.lb = original_ci.lb,
         original_ci.ub = original_ci.ub)

# Plot the results
sensitivity_df |> 
  ggplot(aes(x = id_article, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = ci.lb, ymax = ci.ub), width = 0.2) +
  geom_hline(aes(yintercept = original_estimate), linetype = "dashed", color = "red") +
  geom_hline(aes(yintercept = original_ci.lb), linetype = "dotted", color = "blue") +
  geom_hline(aes(yintercept = original_ci.ub), linetype = "dotted", color = "blue") +
  labs(title = "Sensitivity Analysis",
       x = "Study ID",
       y = "Estimate") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) + 
  scale_x_continuous(breaks = seq(1, 40, 1))

```

Studentized Residuals:

Purpose: These residuals are used to detect outliers. They are the residuals divided by an estimate of their standard deviation, adjusted for each observation.
Interpretation: Values beyond ±2 are often considered potential outliers. The plot helps in identifying these observations visually. Points far from the center line (0) indicate observations with larger than expected residuals.




Cook's Distance:

Purpose: Cook's distance assesses the influence of each observation on the overall model. Large values indicate observations that have a significant impact on the model's parameters.
Interpretation: Typically, Cook's distance values greater than 1 may indicate influential points. In large datasets, even smaller values can be significant. Points far above the average line in the plot are considered highly influential.

*OBS! Time for running this code below is 7.75 hours*

```{r, eval = FALSE}
# Calculate influence diagnostics

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Compute Cook's Distance
cooks_d <- cooks.distance(original_model, 
                          reestimate = TRUE,
                          progbar = TRUE)

# Compute DFBETAS
dfbetas_vals <- dfbetas(original_model, 
                        progbar = TRUE)

# Compute Hat Values
hat_vals <- hatvalues(original_model)

# Compute Studentized Residuals
student_resid <- rstudent(original_model, 
                          progbar = TRUE)


##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##################################################

# Time difference of 3 hours!

#   |==================================================| 100% elapsed=01h 53m 02s
#   |==================================================| 100% elapsed=03h 25m 55s
#   |==================================================| 100% elapsed=02h 26m 29s
# Time difference of 7.757072 hours

```


Saving the data of the influence diagnostics

```{r, eval = FALSE}
##############################################################
# Cook's Distance
##############################################################
# Create a data frame for Cook's Distance
cooks_data <- data.frame(
  Observed_Outcome = seq_along(cooks_d),
  Cooks_Distance = cooks_d
)

# Save to CSV
write.csv(cooks_data, "cooks_distance.csv", row.names = FALSE)

##############################################################
# DFBETAS
##############################################################
# Convert DFBETAS to a data frame
dfbetas_data <- as.data.frame(dfbetas_vals)

# Save to CSV
write.csv(dfbetas_data, "dfbetas.csv", row.names = FALSE)

##############################################################
# Studentized Residuals
##############################################################
# Convert Studentized Residuals to a data frame
student_resid_data <- data.frame(
  Observed_Outcome = seq_along(student_resid$resid),
  Residuals = student_resid$resid,
  Standard_Errors = student_resid$se,
  Z_Values = student_resid$z
)

# Save to CSV
write.csv(student_resid_data, "studentized_residuals.csv", row.names = FALSE)
```



##########################################################################################################################################  
PLOTTING INFLUENCE DIAGNOSTICS
##########################################################################################################################################

```{r}
cooks_data <- read_csv("DATA/META_ANALYSIS/FROM_R/cooks_distance.csv")
```

```{r}
# Plot Studentized Residuals

# Create a data frame for ggplot2
residuals_data <- data.frame(
  Observed_Outcome = seq_along(student_resid$resid),
  Studentized_Residuals = student_resid$resid
)

# Create the ggplot2 plot
ggplot(residuals_data, aes(x = Observed_Outcome, y = Studentized_Residuals)) +
  geom_hline(yintercept = c(-2, 2), linetype = "dashed", color = "red") +
  geom_segment(aes(xend = Observed_Outcome, yend = 0), linetype = "solid") +
  geom_point() +
  ylim(-3, 3) +
  labs(title = "Studentized Residuals Plot", 
       x = "Observed Outcome", 
       y = "Studentized Residuals") +
  theme_minimal()
```

```{r}
# Plot Cook's Distance

# Create a data frame for ggplot2
cooks_data <- data.frame(
  Observed_Outcome = seq_along(cooks_d),
  Cooks_Distance = cooks_d
)

# Calculate the threshold for Cook's Distance
threshold <- 4 / (nrow(filtered_meta_data_ROM_clean) - length(coef(res)))

# Create the ggplot2 plot
ggplot(cooks_data, aes(x = Observed_Outcome, y = Cooks_Distance)) +
  geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
  geom_segment(aes(xend = Observed_Outcome, yend = 0), linetype = "solid") +
  geom_point() +
  labs(title = "Cook's Distance Plot", 
       x = "Observed Outcome", 
       y = "Cook's Distance") +
  theme_minimal()
```

```{r}
# Plot Hat Values

# Create a data frame for hat values
hat_values_data <- data.frame(
  Observed_Outcome = seq_along(hat_vals),
  Hat_Values = hat_vals
)

# Compute the threshold line
threshold <- 2 * mean(hat_vals)

# Plot Hat Values using ggplot2
ggplot(hat_values_data, aes(x = Observed_Outcome, y = Hat_Values)) +
  geom_segment(aes(xend = Observed_Outcome, yend = 0), color = "blue") +
  geom_hline(yintercept = threshold, linetype = "dashed", color = "red") +
  labs(title = "Hat Values Plot", x = "Observed Outcome", y = "Hat Values") +
  theme_minimal()

```

```{r}
# Plot weights of model fitting - the weights given to the observed effect sizes or outcomes during the model fitting

# Extract weights
weights_vals <- weights(original_model)

# Create a data frame for plotting
weights_data <- data.frame(
  Observed_Outcome = seq_along(weights_vals),
  Weights = weights_vals
)

# Plot the weights using ggplot2
ggplot(weights_data, aes(x = Observed_Outcome, y = Weights)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Weights for Observed Outcomes", x = "Observed Outcome", y = "Weight") +
  theme_minimal() +
  theme(panel.grid.major = element_line(colour = "grey90"),
        panel.grid.minor = element_blank())
```

```{r}
# Preparing data for Covariance Ratios plot

#################################################################################
# The function calc_cov_r takes a long time to run because it fits a new model by excluding one observation at a time for each observation in the dataset. This process involves re-fitting the model k times (where k is the number of observations), which is computationally expensive, especially for large datasets or complex models.

# Need to create a function to calculate the covariance ratios
calc_cov_r <- function(model) {
  # Extract the variance-covariance matrix of the random effects
  V <- vcov(model)
  
  # Calculate covariance ratio for each observation
  cov_r <- rep(NA, model$k)
  
  for (i in 1:model$k) {
    model_excl <- try(update(model, subset = -i), silent = TRUE)
    if (!inherits(model_excl, "try-error")) {
      V_excl <- vcov(model_excl)
      cov_r[i] <- det(V_excl) / det(V)
    }
  }
  
  return(cov_r)
}

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################

# Start time tracking
start.time <- Sys.time()

##################################################
##################################################

# Calculate covariance ratios
cov_r <- calc_cov_r(original_model)

# Create a data frame for plotting
cov_r_data <- data.frame(
  Observed_Outcome = seq_along(cov_r),
  Covariance_Ratios = cov_r
)

##################################################
##################################################

# End time tracking
end.time <- Sys.time()

##############################################################
# Calculate time taken
time.taken <- end.time - start.time
time.taken

##################################################

```

```{r}
# Plot Covariance Ratios using ggplot2

cov_r_data |> 
ggplot(aes(x = Observed_Outcome, y = Covariance_Ratios)) +
  geom_segment(aes(xend = Observed_Outcome, yend = 1), color = "blue") +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  labs(title = "Covariance Ratios Plot", x = "Observed Outcome", y = "Covariance Ratios") +
  theme_minimal() +
  theme(panel.grid.major = element_line(colour = "grey90"),
        panel.grid.minor = element_blank())
```












#############
# STEP 5
##########################################################################################################################################
SENSITIVITY ANALYSIS ON DATA (E.G.: MISSING OUTCOME DATA)
##########################################################################################################################################


CHOOSING RESPONSE VARIABLES AND PERFORM 










#############
# STEP 5
##########################################################################################################################################
ASSESS THE META-ANALYSIS RESULTS
##########################################################################################################################################




#############
# STEP 6
##########################################################################################################################################
VISUALISE THE META-ANALYSIS RESULTS
##########################################################################################################################################