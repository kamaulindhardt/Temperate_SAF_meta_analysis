---
title: "TEMP_SAF_META_ANALYSIS"
author: "M.K.K. Lindhardt"
date: "2024-10-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulae to estimate effects (and their standard errors)?




#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    skimr,            # Provides easy summary statistics about variables in data frames, tibbles, data tables and vectors
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    tidygeocoder,     # For geocoding addresses to latitude/longitude
    rnaturalearth,    # For accessing Natural Earth map data
    rnaturalearthdata,# Companion package to rnaturalearth providing the data
    ###################################################################################################################
    # Spatial Data
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    ###################################################################################################################
    # Soil Data
    soilDB,           # For downloading soil data from ISRIC SoilGrids
    aqp,              # For soil profile visualization and analysis
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
```


Loading the dataset (main database)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory
# here::here("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/Final_database_2024_05_17.xlsx")
setwd("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/CODE/META_ANALYSIS")


# Suppress warnings to avoid clutter in the console output
suppressWarnings({
  # Final_database_2024_05_17 (version v5)
  database <- readxl::read_excel(here::here("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/Final_database_2024_05_17_v5.xlsx"), 
                         sheet = "Quantatitive data") 
  #%>%
  #  filter(INCLUDED == TRUE) # include only data entries that have been assesed and deemed included
})
```

**Glimpse (taking a look at the data)**
```{r Glimpse the dataset, eval=FALSE}
database %>% dplyr::glimpse() 
```

```{r}
database %>% summary() 
```

```{r}
database |> skim()
```


#############
# STEP 1
##########################################################################################################################################
DATA PREPROCESSING
##########################################################################################################################################

Manually modifying the SD columns to "control_sd" and "silvo_sd" in Excel!

```{r}
# Function to safely convert to numeric, replacing non-numeric values with NA
safe_as_numeric <- function(x) {
  suppressWarnings(as.numeric(x))
}

# Convert standard errors to numeric and handle non-numeric values
database_clean <- database |>
  # Streamlining and cleaning variable column names
  janitor::clean_names() |> 
  # Converting id_article to integer
  mutate(id_article = as.integer(id_article)) |>
  # Converting to numerical data type
  mutate(
    silvo_se = safe_as_numeric(silvo_se),
    control_se = safe_as_numeric(control_se)
  ) %>%
  # Ensure no infinite or NaN values are present in any variable columns
  mutate_all(~ifelse(is.infinite(.), NA, .)) |>
  mutate_all(~ifelse(is.nan(.), NA, .)) |>
  # Relocating variable columns to better get an overview of the data
  relocate(
    id_article, response_variable, measured_metrics, measured_unit, 
    silvo_mean, silvo_se, silvo_sd, silvo_n,
    control_mean, control_se, control_sd, control_n
  )

database_clean
```
```{r}
database_clean %>% glimpse()
```

```{r}
database_clean %>% summary()
```



##########################################################################################################################################
EXPLORATIVE DATA ANALYSIS (EDA)
##########################################################################################################################################

#############
VIEWING DATA
#############

```{r}
database_clean %>% 
  group_by(response_variable) %>%
  summarise(n_silvo = sum(silvo_n),
            n_control = sum(control_n),
            mean_silvo = mean(silvo_mean),
            mean_control = mean(control_mean))
```

###################
EDA WITH DLOOKR
###################

```{r}
# Visualize pareto chart for variables with missing value.

plot_na_pareto(database_clean)

# Indicating a high proportion of NA values in the control_se and silvo_se variables. 
# Might need imputation in order to include them in the meta-analysis
```
Missing values are found in 
- silvo_se
- control_se
- distance_tree_m

```{r}
database_clean
```


```{r}
# Visualize the combinations of missing value across cases.

plot_na_intersect(database_clean)
```
```{r}
# Filter rows with missing values in silvo_se or control_se, and select relevant columns
# omitting distance_tree_m
missing_values <- database_clean |>
  filter(is.na(silvo_se) | is.na(control_se)) |> 
         # is.na(distance_tree_m)) |>
  select(id_article, response_variable, silvo_se, control_se, distance_tree_m)

# Transform data for visualization by pivoting longer and counting missing values
missing_count <- missing_values |>
  pivot_longer(cols = c(silvo_se, control_se), names_to = "missing_type", values_to = "value") |>
  filter(is.na(value)) |>
  count(id_article, response_variable, missing_type)


# Create the bar plot to visualize missing values by article and response variable
ggplot(missing_count, aes(x = factor(id_article), y = n, fill = missing_type)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ response_variable, scales = "free_x") +
  labs(
    title = "Missing Values by Article and Response Variable",
    x = "Article ID",
    y = "Number of Missing Values",
    fill = "Missing Type"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
```{r}
# Identify rows with missing values in control_se or silvo_se
missing_values_se <- missing_values |> 
  filter(is.na(silvo_se) | is.na(control_se)) |>
  select(id_article, response_variable, silvo_se, control_se)

# Prepare data to include missing_type and id_article
missing_val_se_plot <- missing_values_se |>
  mutate(
    missing_silvo_se = ifelse(is.na(silvo_se), 1, 0),
    missing_control_se = ifelse(is.na(control_se), 1, 0)
  ) |>
  pivot_longer(cols = c(missing_silvo_se, missing_control_se), names_to = "missing_type", values_to = "n") |>
  filter(n == 1)  # Keep only the rows where there is a missing value


# Create the stacked bar plot
missing_val_se_plot |>
  ggplot(aes(x = response_variable, y = n, fill = factor(id_article))) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Number of Missing Values per Response Variable",
       x = "Response Variable",
       y = "Number of Missing Values",
       fill = "Article ID") +
  facet_wrap(~missing_type, scales = "free_y") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Firstly, the Crop yield category stands out with the highest number of missing values for both silvo_se and control_se. This is followed by the Pest and Disease and Soil quality categories, which also show significant numbers of missing values, though they are much fewer compared to Crop yield. This indicates a particular problem with data completeness in the Crop yield category.

Secondly, within each response_variable category, the number of missing values for silvo_se and control_se appears to be comparable. This suggests a pattern where if a value is missing in one, it is likely missing in the other. For instance, both silvo_se and control_se have similar heights in the Crop yield and Pest and Disease categories, indicating consistent missing data patterns across these variables.

Furthermore, the plot shows that multiple articles contribute to the missing data, with certain articles, such as IDs 2, 3, 10, and 25, being significant contributors, especially in the Crop yield category. This spread of missing data across different studies suggests that the issue is not confined to a single source but is more widespread.

In summary, the Crop yield category is particularly problematic with a high number of missing values for both silvo_se and control_se. Several articles, particularly IDs 2, 3, and 10, appear frequently in categories with high missing values. The consistency in missing data patterns between silvo_se and control_se suggests that there might be methodological or study-specific issues contributing to the missing data. To address these issues, it is essential to investigate the high-contributing articles, review the methodologies used in the Crop yield category, and develop strategies to handle the missing data, such as imputation, especially for critical categories like Crop yield. This approach will help improve the quality and completeness of the data, leading to more reliable analyses and insights.


```{r}
# Plot density distribution for control_se with log transformation
database_clean |> 
  ggplot(aes(x = control_se)) +
  geom_density() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of control_se (Log-Transformed)") +
  theme_minimal()

# Advarsel i scale_x_log10() :
#   log-10 transformation introduced infinite values.
# Advarsel: Removed 218 rows containing non-finite outside the scale range (`stat_density()`).

# warnings indicate that some of the values in the dataset are either zero or negative, which cause issues when applying a logarithmic transformation
```
```{r}
# Plot density distribution for silvo_se with log transformation
database_clean |> 
  ggplot(aes(x = silvo_se)) +
  geom_density() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

# Advarsel i transformation$transform(x) : NaNs produced
# Advarsel i scale_x_log10() :
#   log-10 transformation introduced infinite values.
# Advarsel: Removed 212 rows containing non-finite outside the scale range (`stat_density()`).

# warnings indicate that some of the values in the dataset are either zero or negative, which cause issues when applying a logarithmic transformation
```

Studies where silvo_se or control_se data needs to be imputed

```{r}
# Check which rows that needs to be imputed and count the number of associated distinct studies
n_imp_studies <- database_clean %>% 
  select(id_article, response_variable, silvo_se, control_se) %>%
  filter(is.na(silvo_se) | is.na(control_se)) %>%  # Filter for rows where either silvo_se or control_se is NA
  distinct(id_article) %>%  # Get unique id_article entries
  n_distinct()  # Count the number of unique id_article values

n_imp_studies

# 11 studies
```


```{r, eval = FALSE}
eda_report_meta_analysis_SAF <- database_clean |>
  eda_paged_report(#target = "response_variable", 
                   subtitle = "Temperate SAF EDA for meta-analysis",
                   output_format = "html",
                   output_file = "EDA_SAF.html")

# Remember to open in Microsoft Edge browser. For some reason Google Chrome is not working
eda_report_meta_analysis_SAF
```



##########################################################################################################################################
CONTINUED DATA PREPROCESSING AND HANDELING OF MISSING VALUES IN THE DATASET
##########################################################################################################################################

####################################################################################
Perform imputation using "mice" (Multivariate Imputation by Chained Equations)
####################################################################################

```{r, eval = TRUE}
####################################################################################
# Extract relevant columns for imputation
col_for_impute <- database_clean %>%
  dplyr::select(silvo_se, 
                control_se)
                # omitting imputation of 
                # distance_tree_m) 

####################################################################################
# Set seed for reproducibility
set.seed(1234)

# Perform imputation using mice
# - read about mice() here: https://www.metafor-project.org/doku.php/tips:multiple_imputation_with_mice_and_metafor
# - col_for_impute: the data frame containing the columns to be imputed
# - m = 5: number of multiple imputations to perform
# - maxit = 100: maximum number of iterations to perform for each imputation
# - method = 'pmm': method to use for imputation, 'pmm' stands for predictive mean matching
# - seed = 500: random seed for reproducibility of the imputations
# - printFlag: If TRUE, mice will print history on console. Use print=FALSE for silent computation.

imputed_data <- mice::mice(col_for_impute, 
                           m = 20, 
                           maxit = 100, 
                           method = 'pmm', 
                           seed = 1234,
                           printFlag = FALSE)
```

```{r}
####################################################################################

# Check the summary of imputed data
summary(imputed_data)
```
```{r}
# Evaluate the imputed datasets
# Check convergence diagnostics
plot(imputed_data)
```
```{r}
# Compare the distribution of the observed and imputed data
densityplot(imputed_data)
```

```{r}
# Use stripplot to compare observed and imputed values
stripplot(imputed_data, pch = 20, cex = 1.2)
```

```{r}
# For an evidence-based choice, we may calculate some metrics
# Calculate the mean and standard deviation of each imputed dataset
imputed_summaries <- lapply(1:5, function(i) {
  data <- complete(imputed_data, i)
  summary <- data %>%
    summarise(
      mean_silvo_se = mean(silvo_se, na.rm = TRUE),
      sd_silvo_se = sd(silvo_se, na.rm = TRUE),
      mean_control_se = mean(control_se, na.rm = TRUE),
      sd_control_se = sd(control_se, na.rm = TRUE)
    )
  return(summary)
})

# Combine the summaries into a single data frame for comparison
imputed_summaries_df <- bind_rows(imputed_summaries, .id = "imputation")

imputed_summaries_df
```

```{r}
# Choose the imputation based on the diagnostics and summaries
# For simplicity, let's assume we choose the imputation with the median mean_silvo_se
chosen_imputation <- imputed_summaries_df %>%
  filter(mean_silvo_se == median(mean_silvo_se))

chosen_imputation
```

```{r}
# Extract the chosen imputation number
chosen_imputation_number <- chosen_imputation$imputation

# Extract the complete dataset for the chosen imputation
imputed_col_data <- complete(imputed_data, as.integer(chosen_imputation_number))

imputed_col_data
```

```{r}
####################################################################################
# Another way is simply to choose an imputation run from the iterations:
# Choose one of the multiple imputations (e.g., the first imputation)
# imputed_col_data <- complete(imputed_data, 1)
# summary(imputed_col_data)

####################################################################################
# Update the original data with imputed values
imputed_database_clean <- database_clean %>%
  mutate(
    silvo_se = imputed_col_data$silvo_se,
    control_se = imputed_col_data$control_se
    ) 

imputed_database_clean |> glimpse()
```

```{r, eval=FALSE}
imputed_database_clean %>% summary()
```


Visualising the distribution of imputed values for silvo_se and control_se together with the original data

```{r}
# Prepare the original data
original_data_x <- database_clean %>%
  select(id_article, response_variable, silvo_se, control_se) |> 
  mutate(data_source = "Original")

imputed_data_y <- imputed_database_clean |> 
  select(id_article, response_variable, silvo_se, control_se) |> 
  mutate(data_source = "Imputed")

# Combine the original and imputed data
combined_data <- bind_rows(original_data_x, imputed_data_y)

combined_data
```


```{r}
# Join the original and imputed data to directly compare
comparison_data <- original_data_x %>%
  left_join(imputed_data_y, by = c("id_article", "response_variable"), suffix = c("_original", "_imputed"))
# Advarsel: Detected an unexpected many-to-many relationship between `x` and `y`

# Identify rows where imputation occurred by checking if originally missing values are filled
imputation_evaluation <- comparison_data %>%
  filter(
    (is.na(silvo_se_original) & !is.na(silvo_se_imputed)) |
    (is.na(control_se_original) & !is.na(control_se_imputed))
  ) %>%
  select(id_article, response_variable) %>%
  distinct()

# Count the number of unique articles where imputation occurred
n_imputed_studies <- imputation_evaluation %>%
  distinct(id_article) %>%
  nrow()

# Output the results
imputation_evaluation
n_imputed_studies
```


```{r}
# Create density plots for silvo_se with log transformation
silvo_se_impute_original_plot <- combined_data |> 
ggplot(aes(x = silvo_se, color = data_source)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

# Create density plots for control_se with log transformation
control_se_impute_original_plot <- combined_data |> 
ggplot(aes(x = control_se, color = data_source)) +
  geom_density(alpha = 0.5) +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Density Distribution of silvo_se (Log-Transformed)") +
  theme_minimal()

library(patchwork)

silvo_se_impute_original_plot + control_se_impute_original_plot
```


#############
# STEP 3
##########################################################################################################################################
CALCULATING EFFECT SIZE MEASURE AND GENERATING AND BUILDING RANDOM-EFFECTS MODEL
##########################################################################################################################################

SOME PREPROCESSING OF THE META-DATA BEFORE CALCULATING EFFECT SIZE MEASURE

################################
A) The standardized mean difference: It is necessary to standardize the results of the studies to a uniform scale before they can be combined. For effect measure in our case we can use Ratio of Means (RoM) as the ratio of means can be used in either situation, but is appropriate only when outcome measurements are strictly greater than zero.

```{r}
# Create a new dataset for meta-analysis with shifted values for interpretation
meta_data <- imputed_database_clean |>
  # Filtering so that only data with outcome measurements that are greater than zero will be included
  # Including only data with positive standard errors ensures that the subsequent calculations (e.g., variances, effect sizes) are statistically valid and 
  # interpretable. It helps avoid mathematical errors such as division by zero or taking the square root of a negative number.
  # By excluding studies or observations with zero or negative standard errors, you might be systematically excluding certain types of data. For instance,
  # studies with less variability might be excluded, potentially skewing the overall results.
    filter(silvo_se > 0,
           control_se > 0) |>
  # Adjust the signs for specific response variables where lower values for silvo_ vs. control_ is considered 'better'
  mutate(
    silvo_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"), 
                        -silvo_mean, silvo_mean),
    control_mean = ifelse(response_variable %in% c("Greenhouse gas emissions", "Pests and Diseases", "Water quality"), 
                          -control_mean, control_mean)
  ) |> 
  # Exclude the variable soil water content due to inconsistent data from only a single measurement
  filter(response_variable != "Soil water content") |> 
  # Filter out rows with missing values in key columns to ensure data completeness
  filter(
    !is.na(silvo_mean) & !is.na(control_mean) & !is.na(silvo_n) & 
    !is.na(control_n) & !is.na(silvo_se) & !is.na(control_se)
  ) |> 
 # Calculate standard deviations from standard errors and sample sizes
  mutate(
    # Calculate standard deviation for silvo group
    silvo_sd = silvo_se * sqrt(silvo_n),
    # Calculate standard deviation for control group
    control_sd = control_se * sqrt(control_n)
  ) |> 
  # Shift values to be positive
  # Shifting values to be positive is a necessary step when using transformations that require positive inputs, like the
  # log-transformed ratio of means. It enables the inclusion of all studies, avoids mathematical errors, and standardizes data
  # across studies, ensuring the validity and reliability of the meta-analysis. Not performing this step could lead to errors,
  # exclusion of data, and potential biases in the results. However, it's important to
  # interpret the results in the context of the shift and acknowledge that absolute values have been adjusted.
  mutate(
    min_value_shift = abs(min(c(silvo_mean, control_mean), na.rm = TRUE)) + 1,
    silvo_mean = silvo_mean + min_value_shift,
    control_mean = control_mean + min_value_shift
  ) |>
  # Reorder columns for better readability and organization in the output
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           silvo_mean, silvo_se, silvo_sd, silvo_n, control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)


meta_data |> glimpse()
```


When shifting values or flipping the sign of the means, it does indeed alter the interpretation of the data and the units they represent. This process can make the original units less meaningful, and it can introduce challenges in interpreting the results. 

```{r}
meta_data |> filter(response_variable == "Water quality") |> skim()
```


################################################################################################
AUTOMATIC CALCULATION OF EFFECT SIZE MEASURE USING escalc() function
################################################################################################

```{r}
# Calculate effect sizes and variances using escalc()
# - measure: Specifies the effect size measure to use, "ROM" for the log transformed ratio of means 
            # Alternative effect size measures: "MD" for the raw mean difference, "RR" for the log risk ratio, 
            # "OR" for the log odds ratio, "RD" for the risk difference, "SMD" stands for Standardized Mean Difference,
            # "AS" for the arcsine square root transformed risk difference, "PETO" for the log odds ratio estimated with Peto's method
# - m1i: Means of the experimental group (silvo_mean)
# - sd1i: Standard deviations of the experimental group (silvo_se)
# - n1i: Sample sizes of the experimental group (silvo_n)
# - m2i: Means of the control group (control_mean)
# - sd2i: Standard deviations of the control group (control_se)
# - n2i: Sample sizes of the control group (control_n)
# - slab: Optional argument to specify study labels, here combining 'id_article' and 'study_year_start'
# - data: The dataset containing all the specified columns

# "ROM" for the log transformed ratio of means
meta_data_ROM <- escalc(measure = "ROM", 
                       # experimental group (silvo_)
                       m1i = silvo_mean, sd1i = silvo_sd, n1i = silvo_n,
                       # control group (control_)
                       m2i = control_mean, sd2i = control_sd, n2i = control_n,
                       # argument to specify study labels for plotting
                       slab = paste(id_article, ", ", study_year_start, sep = ""),
                       # dataset to be used
                       data = meta_data) |> 
  as.data.frame()

# Check if the meta_data_ROM object exists and display its structure
str(meta_data_ROM)

# After shifting the mean values, I don't see this warning below
# Advarsel: Some 'yi' and/or 'vi' values equal to +-Inf. Recoded to NAs
```

The warning message "Some 'yi' and/or 'vi' values equal to +-Inf. Recoded to NAs." means that some of the calculated effect sizes or their variances are turning into infinite values during the computation. This usually happens when the data for the experimental or control groups contain zeros or when there's a big difference between the means and standard deviations that can't be properly captured using the "ROM" (log-transformed ratio of means) effect size measure. To avoid the analysis from failing, the escalc() function replaces these infinite values with NA. Having NA values can be problematic because it means those observations will be excluded from the analysis, which might reduce the study's statistical power. If many observations are affected, it could suggest that the dataset isn't suitable for the "ROM" measure or that there are data quality issues that need addressing. If only a few data points are affected, the impact is less severe, but it's still important to understand why these values are occurring.


```{r}
# Identify rows where 'yi' or 'vi' are NA
problematic_data <- meta_data_ROM %>%
  filter(is.na(yi) | is.na(vi))

# Display the problematic data points
problematic_data |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)

# Before shifting the mean values, I got these:
# id_article	response_variable	measured_metrics	measured_unit	yi	vi	silvo_mean	silvo_se	silvo_sd	silvo_n
# <int>	<chr>	<chr>	<chr>	<dbl>	<dbl>	<dbl>	<dbl>	<dbl>	<dbl>
# 5	Water quality	NO3- concentration	ppm	NA	NA	0.0	0.006	0.03841875	41
# 6	Pest and Disease	Disease	µg/kg dry barley grain	NA	NA	0.0	3.470	25.96710226	56
# 9	Biodiversity	Plants	Species richness	NA	NA	0.5	0.900	18.70614872	432
# 9	Biodiversity	Plants	Species richness	NA	NA	1.8	0.850	8.32826513	96
# 30	Biodiversity	Airborne arthropods	Abundance	NA	NA	1.0	1.410	8.91762300	40
# 30	Biodiversity	Airborne arthropods	Abundance	NA	NA	1.0	7.300	46.16925384	40
# 30	Biodiversity	Airborne arthropods	Abundance	NA	NA	1.0	11.230	71.02475625	40
# 30	Biodiversity	Airborne arthropods	Abundance	NA	NA	0.0	138.920	878.60722510	40
# 30	Biodiversity	Airborne arthropods	Abundance	NA	NA	4.0	1.290	8.15867636	40
# 30	Pest and Disease	Abunadance of pest insects	Abundance	NA	NA	0.0	1.410	8.91762300	40

# After shifting the mean values I don't get that
# Description:df [0 × 38]
```

The yi and vi values can become NA (or infinite before being recoded to NA) for several reasons when using the escalc() function to calculate effect sizes and variances. Some common causes are:

Zero or Negative Values in Control or Experimental Group: If the means, standard deviations, or sample sizes in the control or experimental group are zero or negative, it can lead to undefined or infinite values when calculating the log-transformed ratio of means (ROM).

To handle problematic data points by assigning them a small value instead of excluding them, it is possible by following these steps:

1) Identify Problematic Data Points: Identify the data points where yi or vi are NA.
2) Assign Small Values: Replace the problematic values with a small value.
3) Recalculate Effect Sizes and Variances: Recalculate yi and vi after addressing the problematic values.


################################################################################################
RE-CALCULATION OF EFFECT SIZE MEASURE USING escalc() function
################################################################################################


```{r}
# Assign a small value to zero or negative values in the original data
small_value <- 0.001

# Create a new dataset with small values assigned to problematic data points
adjusted_meta_data <- meta_data %>%
  mutate(
    silvo_mean = ifelse(silvo_mean <= 0, small_value, silvo_mean),
    silvo_sd = ifelse(silvo_sd <= 0, small_value, silvo_sd),
    silvo_n = ifelse(silvo_n <= 0, small_value, silvo_n),
    control_mean = ifelse(control_mean <= 0, small_value, control_mean),
    control_sd = ifelse(control_sd <= 0, small_value, control_sd),
    control_n = ifelse(control_n <= 0, small_value, control_n)
  )

# Recalculate effect sizes and variances

# "ROM" for the log transformed ratio of means
meta_data_ROM_adjusted <- escalc(measure = "ROM",
                                 # experimental group (silvo_)
                                 m1i = silvo_mean, sd1i = silvo_sd, n1i = silvo_n,
                                 # control group (control_)
                                 m2i = control_mean, sd2i = control_sd, n2i = control_n,
                                 # argument to specify study labels for plotting
                                 slab = paste(id_article, ", ", study_year_start, sep = ""),
                                 # dataset to be used
                                 data = adjusted_meta_data) |> 
  as.data.frame()

# Check if the meta_data_ROM object exists and display its structure
str(meta_data_ROM_adjusted)
```

```{r}
# Display the data with re-calculated effect size measure 
meta_data_ROM_adjusted <- as.data.frame(meta_data_ROM_adjusted) |> 
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)

meta_data_ROM_adjusted
```


################################################################################################
VISUAL ASSESSMENT
################################################################################################

```{r}
# Prepare the data
# Separate the data for silvo_ and control_
silvo_data <- meta_data_ROM_adjusted %>%
  select(id_article, response_variable, yi, vi, silvo_mean, silvo_se, silvo_sd, silvo_n) %>%
  rename(mean = silvo_mean, se = silvo_se, sd = silvo_sd, n = silvo_n) %>%
  mutate(group = "silvo_")|> 
  as.data.frame()

control_data <- meta_data_ROM_adjusted %>%
  select(id_article, response_variable, yi, vi, control_mean, control_se, control_sd, control_n) %>%
  rename(mean = control_mean, se = control_se, sd = control_sd, n = control_n) %>%
  mutate(group = "control_") |> 
  as.data.frame()

#####################################

silvo_data <- meta_data_ROM_adjusted %>%
  mutate(yi = log(silvo_mean / control_mean),
         vi = (silvo_se^2 / silvo_mean^2) + (control_se^2 / control_mean^2)) %>%
  select(id_article, response_variable, yi, vi, silvo_mean, silvo_se, silvo_sd, silvo_n) %>%
  rename(mean = silvo_mean, se = silvo_se, sd = silvo_sd, n = silvo_n) %>%
  mutate(group = "silvo_")

control_data <- meta_data_ROM_adjusted %>%
  mutate(yi = log(control_mean / silvo_mean),
         vi = (control_se^2 / control_mean^2) + (silvo_se^2 / silvo_mean^2)) %>%
  select(id_article, response_variable, yi, vi, control_mean, control_se, control_sd, control_n) %>%
  rename(mean = control_mean, se = control_se, sd = control_sd, n = control_n) %>%
  mutate(group = "control_")



# Combine the data
combined_data <- bind_rows(silvo_data, 
                           control_data)
```


Visual assessment of yi (effect sizes) and vi (variances) for both the silvo_ and control_ groups, faceted by each response_variable

```{r}
# Prepare the data for visualization without reversing effect size
combined_long_data <- combined_data %>% # meta_data_ROM_adjusted
  pivot_longer(cols = c(yi, vi), names_to = "measure", values_to = "value")

# Create the density plot
combined_long_data |> 
  ggplot(aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(
    title = "Density Plot of Effect Sizes (yi) and Variances (vi) by Group",
    x = "Value",
    y = "Density",
    fill = "Group",
    color = "Group"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r}
combined_long_data |> summary()

combined_long_data %>%
  group_by(group, measure) %>%
  summarise(min_value = min(value, na.rm = TRUE), max_value = max(value, na.rm = TRUE)) %>%
  print()
```
```{r}
# Inspect the data
table(combined_long_data$group)
summary(combined_long_data$value)
```
```{r}
head(silvo_data)
head(control_data)
```
```{r}
summary(silvo_data$mean)
summary(control_data$mean)
```
```{r}
# Apply skim to your data
silvo_data$mean |> skim()
control_data$mean |> skim()
```

Visualizing with log-transformed values

```{r}
# Create the density plot with log scale
combined_long_data |> 
  ggplot(aes(x = value, fill = group, color = group)) +
  geom_density(alpha = 0.3) +
  scale_x_log10() +  # Applying log scale to x-axis
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Group (Log Scale)",
       x = "Value (Log Scale)",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Advarsel i transformation$transform(x) : NaNs produced
# Advarsel i scale_x_log10() :
#   log-10 transformation introduced infinite values.
# Advarsel: Removed 1080 rows containing non-finite outside the scale range (`stat_density()`).
```
```{r}
# Identify rows with non-positive values in 'value'
problematic_values <- combined_long_data %>%
  filter(value <= 0)
```

```{r}
# Define a small constant for shifting values
shift_constant <- abs(min(combined_long_data$value, na.rm = TRUE)) + 1

# Shift values to be positive
combined_long_data_shifted <- combined_long_data %>%
  mutate(
    value_shifted = value + shift_constant,
    shift_info = "Values shifted by a constant for log-transformed visualization"
  )

# Create the density plot with log scale using shifted values
combined_long_data_shifted |> 
  ggplot(aes(x = value_shifted, fill = group, color = group)) +
  geom_density(alpha = 0.3) +
  scale_x_log10() +  # Applying log scale to x-axis
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(
    title = "Density Plot of Effect Sizes and Variances by Group (Log Scale)",
    x = "Value (Log Scale, Shifted for Visualization)",
    y = "Density",
    fill = "Group",
    caption = "Note: Values shifted by a constant purely for visualization"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
# Create the density plot for silvo_ group
combined_long_data |> 
  filter(group == "silvo_") |> 
ggplot(aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Response Variable (Silvo)",
       x = "Value",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Create the density plot for control_ group
combined_long_data |> 
  filter(group == "control_") |> 
  ggplot(aes(x = value, fill = group)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ response_variable + measure, scales = "free") +
  labs(title = "Density Plot of Effect Sizes and Variances by Response Variable (Control)",
       x = "Value",
       y = "Density",
       fill = "Group") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
combined_long_data |> filter(response_variable == "Product quality")
combined_long_data |> filter(response_variable == "Water quality")
```

```{r}
# Get the unique response variables
response_variables <- unique(combined_long_data$response_variable)

# Create individual plots for each response variable and combine them
plots <- list()
for (rv in response_variables) {
  # Filter data for the current response variable
  data_rv <- combined_long_data %>% filter(response_variable == rv)
  
  # Determine the fixed scales for yi and vi
  yi_range <- range(data_rv %>% filter(measure == "yi") %>% pull(value), na.rm = TRUE)
  vi_range <- range(data_rv %>% filter(measure == "vi") %>% pull(value), na.rm = TRUE)
  
  # Plot for yi
  p_yi <- ggplot(data_rv %>% filter(measure == "yi"), aes(x = value, colour = group)) +
    geom_density(alpha = 0.5, linetype = "dotted", linewidth = 0.8) +
    scale_x_continuous(limits = yi_range) +
    labs(title = paste("Density Plot of Effect Sizes (yi) for", rv),
         x = "Effect Size (yi)",
         y = "Density",
         fill = "Group") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Plot for vi
  p_vi <- ggplot(data_rv %>% filter(measure == "vi"), aes(x = value, colour = group)) +
    geom_density(alpha = 0.5, linetype = "dotted", linewidth = 0.8) +
    scale_x_continuous(limits = vi_range) +
    labs(title = paste("Density Plot of Variances (vi) for", rv),
         x = "Variance (vi)",
         y = "Density",
         fill = "Group") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Combine the plots using patchwork
  combined_plot <- p_yi + p_vi + plot_layout(ncol = 1)
  
  # Store the combined plot in the list
  plots[[rv]] <- combined_plot
}

# Print the combined plots
for (rv in names(plots)) {
  print(plots[[rv]])
}
```


Interpretation of the yi and vi density plots

The visual assessment from the density plots indicates that there are very high variances (vi) in several response variables, particularly in product quality, water quality, crop yield, pest and diseases, and soil quality. This high spread in variances can significantly influence the results of the meta-analysis, leading to potential biases and less reliable estimates. Dealing with extreme variances (vi) in a meta-analysis is crucial because these 'outliers' can disproportionately influence the results, leading to unreliable conclusions. 

1. Identify Observations with Extreme Variances

To identify observations with extreme variances, it is possible to use the following approach:
  a) Calculate summary statistics for the vi values to understand their distribution.
  b) Identify outliers based on these statistics, typically using a threshold like the top 1% of vi values or using statistical        measures like IQR (Interquartile Range).






These density plots illustrate the distributions of the effect sizes (yi) and their variances (vi) across different response variables for two groups: the silvo group and the control group. 

Interpretation of the Plots

Effect Sizes (yi):
The density plots for effect sizes (yi) indicate how the observed effect sizes are distributed across different response variables. The majority of the effect sizes seem to be centered around zero, which is typical in meta-analysis when combining results from multiple studies.

Variances (vi):
The density plots for variances (vi) show the spread of the sampling variances of the effect sizes.
For some response variables like "Biodiversity," "Crop yield," and "Pest and Disease," the variances are highly skewed with extreme values. This broad variance indicates high variability in the effect size estimates, suggesting that the studies contributing to these effect sizes may have differing levels of precision or sample sizes.

Reasons for Broad Variance
Heterogeneity: The broad variances can be due to substantial heterogeneity among the included studies. Differences in study designs, populations, interventions, and outcomes can contribute to this.
Measurement Error: Some studies might have higher measurement errors or smaller sample sizes, leading to larger variances in their effect size estimates.
Outliers: Extreme values or outliers in the data can inflate the variance.

Addressing Broad Variance
Transformations: Consider applying transformations to stabilize the variances. For example, log transformation can sometimes help in reducing skewness.
Robust Meta-Analysis Methods: Use robust statistical methods that are less sensitive to outliers and extreme values.
Subgroup Analysis: Perform subgroup analyses to explore sources of heterogeneity. Group studies based on characteristics like study design, population, or intervention.
Meta-Regression: Use meta-regression to account for potential moderators that explain variability in effect sizes.
Trim-and-Fill Method: Use the trim-and-fill method to identify and adjust for publication bias, which can contribute to variance.


Standardizing the variance (vi) data can be helpful in addressing some of the issues with broad variance. However, it's important to understand that standardizing vi will not necessarily address the underlying heterogeneity or outliers in the data. It can make the scale of variances more comparable, but it won't change the fact that some studies have higher uncertainty than others.

Regarding the effect size measure yi, the ROM (Ratio of Means) is already a standardized effect size measure that accounts for differences in scales between studies to some extent. The broad variance you are observing is likely due to the inherent heterogeneity and differences in study quality.

Standardizing Variance (vi)
You can standardize the variances by transforming them into a common scale. One way to do this is to divide each variance by the mean variance or by some measure of central tendency (e.g., the median):

Standardizing Effect Sizes (yi) 
While the ROM effect size measure does help in standardizing the effect sizes across studies, you might still consider standardizing yi for further analyses, especially if you have different scales or units across studies:




Alternative

##########################################################################################################################################
EXCLUDE HIGH-VARIANCE OBSERVATIONS 
##########################################################################################################################################

Identify and Exclude High Variance Observations from the dataset before making the variance-covariance matrix and 
fitting the random-effects model

To avoid the previous error:
Error: Fejl: Optimizer (nlminb) did not achieve convergence (convergence = 1).

Warning: Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
The warning "Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results" indicates that there is a large disparity between the variances of your effect sizes, which can lead to instability in the model results.

```{r}
# Inspect the variances (vi)
meta_data_ROM_adjusted |>
  filter(!is.na(vi)) |> 
  ggplot(aes(x = vi)) +
  geom_histogram(bins = 100) +
  #scale_y_log10() + 
  scale_x_log10() +
  ggtitle("Distribution of Sampling Variances (vi)") +
  theme_minimal() 
```
```{r}
# Identify rows with high variances
# filters the dataset to keep only the rows where the variance (vi) is greater than the 95th percentile of all vi values in

high_variance_obs <- meta_data_ROM_adjusted |> 
  filter(vi > quantile(vi, 0.950)) |> # 0.995
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           silvo_mean, silvo_se, silvo_sd, silvo_n, 
           control_mean, control_se, control_sd, control_n) |> 
  arrange(id_article, response_variable)

skim(high_variance_obs)
```

```{r}
# Exclude high variance observations from the dataset

# Add a row number column to meta_data_ROM_adjusted
meta_data_ROM_adjusted <- meta_data_ROM_adjusted |> 
  as.data.frame() |> 
  mutate(row_id = row_number())

# Identify rows with high variances
high_variance_obs <- meta_data_ROM_adjusted |> 
  filter(vi > quantile(vi, 0.995, # 0.995 # 0.950
                       na.rm = TRUE))


##################################################################################################################

# Exclude high variance observations from the dataset
filtered_meta_data_ROM <- meta_data_ROM_adjusted |> 
  filter(!row_id %in% high_variance_obs$row_id)

filtered_meta_data_ROM
filtered_meta_data_ROM |> glimpse()
filtered_meta_data_ROM |> skim()

###############################################################################
```












```{r, eval = FALSE}
# Saving the preprocessed metadata as csv


##############################################################
# Save to CSV
readr::write_csv(filtered_meta_data_ROM, 
                 here::here("C:/Users/au759124/OneDrive - Aarhus universitet/Documents/Temp_SAF_meta_analysis/DATA/META_ANALYSIS/FROM_R/filtered_meta_data_rom_v5.csv"))
```


