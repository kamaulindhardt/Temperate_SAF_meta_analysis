---
title: "3_META_MODEL_FITTING"
author: "M.K.K. Lindhardt"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Load multiple add-on packages using pacman::p_load for efficiency
# pacman::p_load automatically installs missing packages and loads them
pacman::p_load(
  
  # Conflict Resolution
  conflicted,        # Resolves conflicts when functions with the same name exist in multiple packages
  
  # Data Manipulation / Transformation
  tidyverse,         # Comprehensive collection of R packages for data science (e.g., ggplot2, dplyr, readr)
  readr,             # Simplifies reading and writing of delimited text files (e.g., CSV)
  dplyr,             # A grammar of data manipulation (e.g., filter, mutate, summarise, etc.)
  skimr,             # Provides summary statistics with a more user-friendly output
  future,            # Supports parallel processing for speeding up computations
  future.apply,      # Extends the future package for parallelized versions of base R apply functions
  readxl,            # Read excel files
  
  ###################################################################################################################
  # Data Visualization
  ggplot2,           # A data visualization package for creating static and interactive graphics (part of tidyverse)
  patchwork,         # Extends ggplot2 by providing tools to combine multiple plots into one
  gridExtra,         # Arranges multiple grid-based plots (e.g., from ggplot2) into a single display
  scales,            # Adds tools for handling scale transformations and labels in visualizations
  gt,                # Stylish tables
  ggbreak,           # Breaks on axis for bar charts etc.
  ggpubr,            # Working with plots and legends library
  forcats,           # Tools for Working with Categorical Variables (Factors)
  
  ###################################################################################################################
  # Meta-Analysis
  metafor,           # For conducting meta-analyses, including calculating effect sizes and response ratios
  orchaRd,           # Provides tools for conducting and visualising meta-analyses and meta-regressions
  clubSandwich,      # Provides cluster-robust variance estimators for meta-analysis models
  mice,              # Multivariate Imputation by Chained Equations for handling missing data
  
  ###################################################################################################################
  # Exploratory Data Analysis (EDA)
  DataExplorer,      # Automates exploratory data analysis with summary statistics and visualizations
  SmartEDA,          # Automates exploratory data analysis with summary reports and visualizations
  naniar,            # Provides tools for handling and visualizing missing data
  VIM,               # Visualization and Imputation of Missing Data
  Hmisc,             # Miscellaneous functions including data summary, analysis, and visualization
  BaylorEdPsych,     # Provides tools for reliability analysis and missing data imputation
  openxlsx,          # Simplifies the the process of writing and styling Excel xlsx
  
  ###################################################################################################################
  # Project Management and Code Styling
  here,              # Simplifies file referencing by locating the root of a project directory
  styler             # Formats and styles R code to improve readability and consistency
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("summarize", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("intersect", "base")
```



#############
# STEP 1
##########################################################################################################################################
LOADING PREPARED META-DATA
##########################################################################################################################################


Loading the two datasets (imputed and non-imputed)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Define file paths
non_imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom.rds"))
imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))

# non_imp_data_rom_dummy <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom_dummy.rds"))

# Read in the non-imputed dataset
non_imp_dataset <- non_imp_data_rom %>%
  as.data.frame()|> 
  # select(-geometry) |> 
  relocate(
       # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )

# Read in the imputed dataset
imp_dataset <- imp_data_rom %>%
  as.data.frame()|> 
  relocate(
       # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )
})
```

```{r}
# Checking high observations with extreme high variance
high_variance_obs <- 
  imp_dataset|> 
  filter(vi > quantile(vi, 0.95)) |> # 0.995
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           # Quantitative meta-analysis variables - mean and no. of observations
           silvo_mean, control_mean, silvo_n, control_n,
           # Quantitative meta-analysis variables - variance info
           silvo_se, silvo_sd_from_se, silvo_sd_final, 
           control_se, control_sd_from_se, control_sd_final,
           tree_type, crop_type, age_system, season, soil_texture, no_tree_per_m, tree_height, alley_width) |> 
  arrange(id_article, response_variable)

skim(high_variance_obs)
```
```{r}
non_imp_dataset |> glimpse()
imp_dataset |> glimpse()
```

```{r}
# Select distinct id_article entries
distinct_articles <- imp_dataset %>%
  select(id_article) %>%
  distinct()

# Get the number of unique id_article entries
num_distinct_articles <- nrow(distinct_articles)

# Print the result
cat("Number of distinct id_article entries:", num_distinct_articles, "\n")
# Number of distinct id_article entries: 37 
```




##########################################################################################################################################
LISTING RESPONSE VARIABLES AND SETTING UP COSTUM COLORS
##########################################################################################################################################

```{r}
# Custom colors for response variables
custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)

# Response variables to analyze
response_variables <- names(custom_colors)
```

```{r}
# Filter dataset for specified response variables
filtered_dataset <- imp_dataset %>%
  filter(response_variable %in% response_variables)

# Calculate the Response Ratio
filtered_dataset <- filtered_dataset %>%
  mutate(
    ResponseRatio = silvo_mean / control_mean,
    log_ResponseRatio = log(ResponseRatio) # Log transformation for better interpretation
  ) |> 
  # Recalculate log ResponseRatio and add a small constant to avoid log(0)
  mutate(
    log_ResponseRatio = log(ResponseRatio + 1e-6) # Add a tiny constant for log safety
  )


# Bootstrap data for violin plot
bootstrapped_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarise(
    bootstrapped_rr = list(boot::boot(data = log_ResponseRatio, statistic = function(x, i) mean(x[i]), R = 25000)$t)
  ) %>%
  unnest(bootstrapped_rr)

# Summary statistics for plotting
summary_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarize(
    WeightedMeanRR = mean(ResponseRatio, na.rm = TRUE),
    LowerCI = mean(ResponseRatio, na.rm = TRUE) - 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    UpperCI = mean(ResponseRatio, na.rm = TRUE) + 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    RR_Less_1 = mean(ResponseRatio < 1) * 100,
    RR_Greater_1 = mean(ResponseRatio > 1) * 100,
    Studies = n_distinct(id_article),
    Observations = n(),
    .groups = "drop"
  )
```

```{r}
# Ensure consistent factor levels for response_variable
common_levels <- filtered_dataset$response_variable %>% unique() %>% sort()

filtered_dataset <- filtered_dataset %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

bootstrapped_data <- bootstrapped_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

summary_data <- summary_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

# Recreate the violin plot with proper alignment
violin_plot_response_var_lnrr <- 
  ggplot() +
  # Violin plot for bootstrapped data
  geom_violin(data = bootstrapped_data, aes(y = response_variable, x = exp(bootstrapped_rr), fill = response_variable), 
              alpha = 0.5, scale = "area") + # Use 'area' scaling for better proportional representation
  # Overlay mean and confidence intervals
  # geom_point(data = summary_data, aes(y = response_variable, x = exp(WeightedMeanRR)), color = "black", size = 3) +
  # geom_errorbarh(data = summary_data, aes(y = response_variable, xmin = exp(LowerCI), xmax = exp(UpperCI)), 
  #               height = 0.2, color = "black") +
  # Add a red vertical dotted line at x = 1
  geom_vline(xintercept = 1, linetype = "dotted", color = "red", size = 0.8) +
    # Add annotations for proportions and study counts
  geom_text(data = summary_data, aes(
    y = response_variable, x = max(summary_data$UpperCI) * 0.825, 
    label = paste0("RR<1: ", round(RR_Less_1), "%\nRR>1: ", round(RR_Greater_1), "%\n[N=", Studies, ", NO=", Observations, "]")
  ), size = 3, hjust = 0) +
  # Apply custom colors
  scale_fill_manual(values = custom_colors) +
  # Customize plot
  scale_x_continuous(limits = c(0.8, 1.6), trans = "identity", breaks = scales::pretty_breaks()) +
  labs(
    title = "Weighted Mean Response Ratio",
    subtitle = "Agroforestry vs. Non-Agroforestry Effects by Response Variable",
    x = "Response Ratio",
    y = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    legend.position = "none"
  )

# Print the plot
violin_plot_response_var_lnrr
```




 
##########################################################################################################################################
PUBLICATION-READY RIDGELINE PLOTS OF EFFECT SIZE DISTRIBUTIONS PER RESPONSE VARIABLE
##########################################################################################################################################

Ridge Plot: Shows the distribution of effect sizes for each response variable.
 
```{r}
# meta_data |> glimpse()
```
```{r}
# Extract relevant columns, including vi
# effect_size_data <- meta_data %>%
#   select(response_variable, yi, vi) %>%
#   drop_na()  # Remove missing values
```

 
 








#############
# STEP 2
##########################################################################################################################################
PERFORMING MULTIVARIATE/MULTILEVEL LINEAR (MIXED-EFFECTS) MODELLING 
##########################################################################################################################################

Assessment of Missing Data for Moderators
Imputation of Missing Values for Moderators Using mice()
Post-Imputation Assessment of Moderators
Selection of Moderators for Analysis
Fitting the Multivariate Random-Effects Model with Selected Moderators

```{r}
# Define the function for missing data assessment
assess_missing_data <- function(dataset, moderators, dataset_name = "Dataset") {
  
  cat("\nStarting missing data assessment for", dataset_name, "...\n")
  
  # Step 1: Calculate the proportion of missing values for each moderator
  missing_summary <- dataset %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_proportion")

  # Print the missing summary table
  cat("\nProportion of Missing Values for Each Moderator:\n")
  print(missing_summary)

  # Step 2: Create a basic bar chart of missing proportions
  missing_plot <- ggplot(missing_summary, aes(x = reorder(variable, -missing_proportion), y = missing_proportion)) +
    geom_bar(stat = "identity", fill = "#0072B2") +
    labs(
      title = paste("Proportion of Missing Data for Moderator Variables -", dataset_name),
      x = "Moderator Variable",
      y = "Missing Proportion"
    ) +
    scale_y_continuous(labels = scales::percent) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Step 3: Calculate missingness for each moderator by response_variable
  missing_by_response <- dataset %>%
    group_by(response_variable) %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = -response_variable, names_to = "moderator", values_to = "missing_proportion")

  # Print the summary table for missingness by response_variable
  cat("\nMissing Proportion by Response Variable for Each Moderator:\n")
  print(missing_by_response)

  # Step 4: Create a heatmap for missingness by response_variable
  missing_heatmap <- ggplot(missing_by_response, aes(x = moderator, y = response_variable, fill = missing_proportion)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "#56B1F7", high = "#132B43", na.value = "gray90", labels = percent) +
    labs(
      title = paste("Heatmap of Missing Data by Moderator and Response Variable -", dataset_name),
      x = "Moderator Variable",
      y = "Response Variable",
      fill = "Missing Proportion"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Display the plots
  print(missing_plot)
  print(missing_heatmap)
  
  cat("\nMissing data assessment completed for", dataset_name, ".\n")
}
```

```{r}
# Assessing Moderator missingness

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Assess missing data for non-imputed dataset
assess_missing_data(non_imp_dataset, moderators, "Non-Imputed Dataset")

# Assess missing data for imputed dataset
assess_missing_data(imp_dataset, moderators, "Imputed Dataset")
```






##########################################################################################################################################
CREATING A VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################


```{r}
# Variance-Covariance Matrix Calculation Function
calculate_v_matrix <- function(data, correlation = 0.5) {
  cat("\nCalculating Variance-Covariance Matrix...\n")
  
  v_list <- list()
  for (study in unique(data$id_article)) {
    study_data <- data[data$id_article == study, ]
    
    if (nrow(study_data) > 1) {
      v <- diag(study_data$vi)
      for (i in 1:nrow(v)) {
        for (j in 1:nrow(v)) {
          if (i != j) {
            v[i, j] <- correlation * sqrt(v[i, i] * v[j, j])
          }
        }
      }
      v_list[[as.character(study)]] <- v
    } else {
      v_list[[as.character(study)]] <- matrix(study_data$vi, nrow = 1, ncol = 1)
    }
  }

  v_matrix <- bldiag(v_list)
  cat("\nGenerated Variance-Covariance Matrix:\n")
  print(v_matrix)
  
  return(v_matrix)
}
```

```{r, results = 'hide'}
#########################################################################
###############################################################################
###################################################################################
########################################################################################
#############################################################################################
####################################################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset

####################################################################################################
#############################################################################################
########################################################################################
###################################################################################
###############################################################################
#########################################################################


# Directory for saving results
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Generate and save v_matrices for each response variable
v_matrices <- list()

for (response in response_variables) {
  cat("\nProcessing response variable:", response, "\n")
  
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]
  
  # Calculate the variance-covariance matrix
  v_matrix <- invisible(calculate_v_matrix(data_subset, correlation = 0.5))
  
  # Store the matrix in the list
  v_matrices[[response]] <- v_matrix
  
  # Save the matrix to an individual RDS file
  file_name <- paste0("v_matrix_", tolower(gsub(" ", "_", response)), ".rds")
  saveRDS(v_matrix, file = file.path(output_dir, file_name))
  
  cat("Saved v_matrix for response variable:", response, "to", file.path(output_dir, file_name), "\n")
}

# Also, save the entire list of v_matrices as a single file
saveRDS(v_matrices, file = file.path(output_dir, "v_matrices_by_response_variable.rds"))
cat("\nAll v_matrices saved to:", output_dir, "\n")
```




#############
# STEP 3
##########################################################################################################################################
MODEL FITTING ON EACH SUBSET DATA USING ASSOCIATED VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################

```{r}
# Load the saved v_matrices
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
v_matrices <- readRDS(file.path(output_dir, "v_matrices_by_response_variable.rds"))
```


```{r}
imp_dataset |> glimpse()
```
```{r}
# Summary of missing data by column
missing_summary <- imp_dataset %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "MissingCount")

# View variables with missing data
missing_summary <- missing_summary %>%
  filter(MissingCount > 0) %>%
  arrange(desc(MissingCount))

# Visualize missingness
gg_miss_var(imp_dataset) +
  labs(title = "Missing Data Across Variables")

# View rows with missing data
rows_with_missing <- imp_dataset %>%
  filter(!complete.cases(.))
```
```{r}
# Summary statistics for effect size (yi)
summary(imp_dataset$yi)

# Summary statistics for variance (vi)
summary(imp_dataset$vi)

# Identify rows with extreme variances on a sub_response_variable level
extreme_variance_rows <- imp_dataset %>%
  group_by(sub_response_variable) %>%
  filter(vi > quantile(vi, 0.95, na.rm = TRUE) | vi < quantile(vi, 0.05, na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(desc(vi))

extreme_variance_rows |> glimpse()

# Last go (24/01-2025)
#    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
#  0.00000  0.00019  0.00102  0.09496  0.00620 40.29043 
# Rows: 131
# Columns: 64
```


##########################################################################################################################################
FITTING MODELS (SUB-GROUP) FOR EACH RESPONSE VARIABLE USING PRECOMPUTED V_MATRICES
##########################################################################################################################################

```{r}
##########################################################################################################################################
# HIERARCHICAL COMPLEXITY APPROACH ALIGNED WITH THE CABBAGE APPROACH
##########################################################################################################################################

# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################



# Function to fit models incrementally for a response variable
fit_models_all <- function(data_subset, response_variable, v_matrix, moderators, random_effects) {
  results <- list()

  cat("\nProcessing response variable:", response_variable, "\n")

  #############################################################################################
  # Null model: Global average without moderators
  results$null_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in null model:", e$message, "\n")
    return(NULL)
  })
  ############################################################################################# 
  # Minimal random effects model
  results$minimal_random_effects <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = ~ 1,  # Intercept-only model
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in minimal random effects model:", e$message, "\n")
    return(NULL)
  })
  
  #############################################################################################
  # Incremental models for each moderator (no interaction)
  results$moderator_models <- map(moderators, ~ {
    moderator <- .x
    tryCatch({
      rma.mv(
        yi = yi,
        V = v_matrix,
        mods = as.formula(paste("~", moderator)),
        random = random_effects,
        data = data_subset,
        method = "REML",
        control = list(iter.max = 2000, rel.tol = 1e-9)
      )
    }, error = function(e) {
      cat("Error in moderator model for", moderator, ":", e$message, "\n")
      return(NULL)
    })
  })
  names(results$moderator_models) <- moderators
  
  ############################################################################################# <-------------- ! (chosen model) !
  # Full model with all moderators (no interaction)
  results$full_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = as.formula(paste("~", paste(moderators, collapse = " + "))),
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in full model:", e$message, "\n")
    return(NULL)
  })

  #############################################################################################
  # Full interaction model with all moderators
  results$interaction_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = as.formula(paste("~", paste(moderators, collapse = " * "))),
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in interaction model:", e$message, "\n")
    return(NULL)
  })

  return(results)
}

##########################################################################
# Fit Models for Each Response Variable
##########################################################################

# Initialize an empty list to store model results
model_results <- list()

# Loop through each response variable to fit models
for (response in names(v_matrices)) {
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]

  # Extract the variance-covariance matrix for the response variable
  v_matrix <- v_matrices[[response]]

  # Define the moderators to include in the model
  moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

  # Define random effects structure
  random_effects <- ~ 1 | exp_id

  # Fit models incrementally using the cabbage approach
  model_results[[response]] <- fit_models_all(
    data_subset = data_subset,
    response_variable = response,
    v_matrix = v_matrix,
    moderators = moderators,
    random_effects = random_effects
  )
}

##########################################################################
# Save All Fitted Models
##########################################################################

output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Save all models in a combined file
saveRDS(model_results, file = file.path(output_dir, "fitted_models_all_new.rds"))

# Save individual model results
for (response in names(model_results)) {
  saveRDS(model_results[[response]], file = file.path(output_dir, paste0("fitted_models_", response, "_new.rds")))
}

cat("\nAll models have been saved successfully!\n")

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (25/01-2025) 
# Total time taken: 31.73879 secs 

# Processing response variable: Biodiversity 
# Advarsel: Redundant predictors dropped from the model.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: Redundant predictors dropped from the model.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Greenhouse gas emission 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Product quality 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Crop yield 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Pest and Disease 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Soil quality 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Error in interaction model: Optimizer (nlminb) did not achieve convergence (convergence = 1). 
# 
# Processing response variable: Water quality 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.
# All models have been saved successfully!
# 
# Total time taken: 31.73879 secs 
```

Explanations of the above Multi-Model Fitting 

Descriptions of the 'Hierarchical Complexity Approach' Multi-Model Fitting for Temperate Silvoarable Agroforrestry and Ecosystem Services Meta-Analysis

In this study we decided to employ a hierarchical complexity approach for meta-analysis multi-model fitting aligned with Carrillo-Reche et al. (2023) [https://www.sciencedirect.com/science/article/pii/S0167880923002232], aka the "Cabbage approach" to evaluate the effects of silvoarable agroforestry systems across multiple response variables. Meta-analytic models were constructed using the `rma.mv` function from the **metafor** package, accounting for random effects and systematically including moderators to assess their contribution to heterogeneity reduction and effect size estimation.

Model Construction and Fitting
Models were fitted incrementally for each response variable, starting with a null model to estimate the global average effect size without moderators. A minimal random effects model introduced random variability at the experiment level (`~ 1 | exp_id`) to account for between-study differences. Moderator models were then constructed to examine the independent effects of moderators such as `tree_type`, `crop_type`, `age_system`, `season`, and `soil_texture`. A full model combined all moderators additively, while a full interaction model evaluated interaction terms between all moderators. Convergence criteria were tightened by increasing the maximum iterations (`iter.max = 2000`) and reducing the relative tolerance (`rel.tol = 1e-9`) to improve model stability.

Error and Warning Analysis
During model fitting, several warnings and errors were encountered, highlighting potential limitations in the dataset or model structure. Redundant predictors were dropped due to collinearity or lack of variability, affecting models for all response variables (see the resulting output messages from the multi-model fitting code chunk above). For instance, in cases like `tree_type` and `crop_type`, collinearity led to the exclusion of certain predictors. Observations with missing values in moderators were omitted, particularly for `Biodiversity`, where 14 rows were removed. High variance ratio warnings indicated extreme variability in sampling variances, notably for `Crop yield`, `Soil quality`, and `Water quality`, leading to unstable parameter estimates. Convergence failures occurred for the full interaction model in `Soil quality` and `Water quality`, likely due to excessive complexity and insufficient data for interaction terms.

Alternatively, we could have fitted the Full model only with selected interaction pairs of moderators?

# Full model with selected moderator interactions
  interaction_pairs <- list(
    c("tree_type", "crop_type"),
    c("age_system", "season"),
    c("season", "soil_texture")
  )

  [...]

Model Outcomes
The null and minimal random effects models were generally successful, providing baseline estimates and capturing between-study heterogeneity. However, the interaction models often failed to converge, particularly when all moderators and their interactions were included. This highlights the challenges of modeling complex interactions in datasets with limited observations or high heterogeneity.



```{r}
# Load and assess the model results from the saved file
# This script allows evaluating both higher-level and lower-level effects of moderators for each response variable and model.

# Load the combined model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

# Define a function to summarize and evaluate model results
evaluate_model <- function(models, response_variable) {
  cat("\nEvaluating models for response variable:", response_variable, "\n")
  
  # Initialize a list to store evaluation results
  evaluation_results <- list()
  
  # Evaluate the null model
  if (!is.null(models$null_model)) {
    evaluation_results$null_model <- summary(models$null_model)
    cat("\nNull model:\n", paste(capture.output(evaluation_results$null_model), collapse = "\n"), "\n")
  }
  
  # Evaluate the minimal random effects model
  if (!is.null(models$minimal_random_effects)) {
    evaluation_results$minimal_random_effects <- summary(models$minimal_random_effects)
    cat("\nMinimal random effects model:\n", paste(capture.output(evaluation_results$minimal_random_effects), collapse = "\n"), "\n")
  }
  
  # Evaluate individual moderator models
  if (!is.null(models$moderator_models)) {
    evaluation_results$moderator_models <- lapply(models$moderator_models, summary)
    cat("\nModerator models:\n")
    for (moderator in names(models$moderator_models)) {
      cat("\nModerator:", moderator, "\n")
      cat(paste(capture.output(evaluation_results$moderator_models[[moderator]]), collapse = "\n"), "\n")
    }
  }
  
  # Evaluate the full model (no interaction)
  if (!is.null(models$full_model)) {
    evaluation_results$full_model <- summary(models$full_model)
    cat("\nFull model (no interaction):\n", paste(capture.output(evaluation_results$full_model), collapse = "\n"), "\n")
  }
  
  # Evaluate the full interaction model
  if (!is.null(models$interaction_model)) {
    evaluation_results$interaction_model <- summary(models$interaction_model)
    cat("\nFull interaction model:\n", paste(capture.output(evaluation_results$interaction_model), collapse = "\n"), "\n")
  }
  
  return(evaluation_results)
}

# Loop through each response variable and evaluate model results
evaluation_results <- list()

for (response in names(model_results)) {
  evaluation_results[[response]] <- evaluate_model(models = model_results[[response]], response_variable = response)
}

cat("\nModel evaluation completed.\n")


##########################################################################
# Save evaluation results for further analysis or reporting
##########################################################################

# Save combined evaluation results
saveRDS(evaluation_results, file = here::here("DATA", "OUTPUT_FROM_R", 
                                              "MULTI_MODEL_EVALUATION_RESULTS", "evaluation_results_combined.rds"))

# Save individual evaluation results
for (response in names(evaluation_results)) {
  saveRDS(evaluation_results[[response]], file = here::here("DATA", "OUTPUT_FROM_R", 
                                                            "MULTI_MODEL_EVALUATION_RESULTS", paste0("evaluation_results_", response, ".rds")))
}

cat("\nEvaluation results of the multi-model fitting have been saved successfully!\n")
```

```{r}
evaluation_results$Biodiversity |> str()

# evaluation_results$Biodiversity
```



```{r}
##########################################################################
# Assess AIC, BIC, and LogLik from all models
##########################################################################
##########################################################################
# HIERARCHICAL COMPLEXITY APPROACH - MODEL STATISTICS EXTRACTION
##########################################################################

# Load the combined model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

##########################################################################
# Function to extract AIC, BIC, and LogLik from all models
##########################################################################
extract_model_stats <- function(models, response_variable) {
  stats <- data.frame(
    Model = character(),
    AIC = numeric(),
    BIC = numeric(),
    LogLik = numeric(),
    ResponseVariable = character(),
    stringsAsFactors = FALSE
  )

  # Helper function to safely extract stats
  get_stats <- function(model) {
    if (!is.null(model)) {
      return(c(
        AIC = tryCatch(AIC(model), error = function(e) NA),
        BIC = tryCatch(BIC(model), error = function(e) NA),
        LogLik = tryCatch(logLik(model), error = function(e) NA)
      ))
    } else {
      return(c(AIC = NA, BIC = NA, LogLik = NA))
    }
  }

  # Add model statistics if available
  if (!is.null(models$null_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Null Model",
      t(get_stats(models$null_model)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$minimal_random_effects)) {
    stats <- rbind(stats, data.frame(
      Model = "Minimal Random Effects",
      t(get_stats(models$minimal_random_effects)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$moderator_models)) {
    for (moderator in names(models$moderator_models)) {
      mod <- models$moderator_models[[moderator]]
      stats <- rbind(stats, data.frame(
        Model = paste("Moderator -", moderator),
        t(get_stats(mod)),
        ResponseVariable = response_variable
      ))
    }
  }

  if (!is.null(models$full_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Full Model",
      t(get_stats(models$full_model)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$interaction_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Interaction Model",
      t(get_stats(models$interaction_model)),
      ResponseVariable = response_variable
    ))
  }

  return(stats)
}

##########################################################################
# Extract model statistics for all response variables
##########################################################################
all_model_stats <- do.call(rbind, lapply(names(model_results), function(response) {
  extract_model_stats(models = model_results[[response]], response_variable = response)
}))

all_model_stats |> glimpse()
```

```{r}
##########################################################################
# Calculate relative AIC difference compared to Null Model for each response variable
relative_aic <- all_model_stats |> 
  group_by(ResponseVariable) |> 
  mutate(RelativeAIC = AIC - AIC[Model == "Null Model"]) |> 
  ungroup()

relative_aic


# Define the file path for saving
output_file <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "relative_aic.xlsx")
# Save the dataframe to an Excel file
write.xlsx(relative_aic, file = output_file, row.names = FALSE)
cat("The relative AIC data has been saved to:", output_file, "\n")

##########################################################################
```

```{r}
##########################################################################
# Create publication-ready visualizations for AIC with faceting - focusing on comparing across models
##########################################################################

# Plot AIC values for all models with faceting
plot_aic <- all_model_stats |> 
  ggplot(aes(x = ResponseVariable, y = AIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Model, scales = "free_y") +
  coord_flip() +
  labs(
    title = "Model AIC Values Across Response Variables",
    x = "Response Variable",
    y = "AIC",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold")
  )

plot_aic

##########################################################################
# Modify plot to use pseudo-log-scale on the y-axis with faceting
##########################################################################

plot_aic_log <- all_model_stats |> 
  ggplot(aes(x = ResponseVariable, y = log10(AIC), fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Model, scales = "free_y") +
  coord_flip() +
  labs(
    title = "Model AIC Values Across Response Variables (Log Scale)",
    x = "Response Variable",
    y = "Log10(AIC)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold")
  )

plot_aic_log
```

```{r}
##########################################################################
# Create publication-ready visualizations for AIC - focusing on comparing across response variables
##########################################################################

# Plot AIC values for all models
plot_aic_models <- all_model_stats |> 
  ggplot(aes(x = fct_reorder(Model, AIC), y = AIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ ResponseVariable, scales = "free_x") +
  labs(
    title = "Model AIC Values Across Response Variables",
    x = "Models",
    y = "AIC",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_aic_models

# Modify plot to use pseudo-log-scale on the x-axis (log-transformed AIC)
plot_aic_log_models <- all_model_stats |> 
  ggplot(aes(x = fct_reorder(Model, AIC), y = log10(AIC), fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ ResponseVariable, scales = "free_x") +
  labs(
    title = "Model AIC Values Across Response Variables (Log Scale)",
    x = "Models",
    y = "Log10(AIC)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_aic_log_models
```


```{r}
##########################################################################
# Create publication-ready visualizations - focusing specifically on relative AIC difference
##########################################################################

# Plot relative AIC values for all models
plot_relative_aic <- relative_aic |> 
  ggplot(aes(x = Model, y = RelativeAIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ResponseVariable, scales = "free_x") +
  labs(
    title = "Relative AIC Difference Across Models (Compared to Null Model)",
    x = "Models",
    y = "Relative AIC (Difference from Null Model)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_relative_aic
```

Streamlined Interpretation of AIC Values

The relative AIC values provide a comparison of model performance against the Null Model for each response variable. Negative relative AIC values indicate better model performance, while positive values indicate poorer performance. For `Product Quality` and `Water Quality`, the absolute AIC values (which were negative) require special attention, as positive relative differences in these cases reflect better model performance.

**Key Insights by Response Variable:**

1. **Biodiversity:**
   - Both the `Full Model` and `Interaction Model` demonstrate significantly better performance than the Null Model, with **relative AIC values of -656** and **-645**, respectively, underscoring the importance of moderators in explaining biodiversity outcomes.
   - The `Minimal Random Effects Model` shows no improvement over the Null Model, indicating that adding random effects alone does not enhance performance.

2. **Crop Yield:**
   - The `Interaction Model` and the `Full Model` show substantial improvements over the Null Model, with **relative AIC values of -1191** and **-894**, respectively. This highlights the critical role of both moderators and their interactions in explaining crop yield variability.
   - The `Null Model` and `Minimal Random Effects Model` perform identically, showing no added value from random effects alone.

3. **Greenhouse Gas Emissions:**
   - The `Full Model` and `Interaction Model` exhibit **exceptional improvements** over the Null Model, with **relative AIC values of -3156** and **-3150**, respectively. These results emphasize the necessity of including multiple moderators to capture the complex dynamics of emissions data.
   - Similar to crop yield, the `Minimal Random Effects Model` offers no improvement over the Null Model.

4. **Pest and Disease:**
   - Both the `Full Model` and the `Interaction Model` show improved performance, with **relative AIC values of -391** and **-392**, respectively, demonstrating the value of including moderators for pest and disease data.
   - However, interactions between moderators (captured in the `Interaction Model`) do not improve the relative AIC further, indicating that the additional complexity is unnecessary.
   - The `Minimal Random Effects Model` performs comparably to the Null Model.

5. **Product Quality:**
   - Positive relative AIC values for the `Interaction Model` (**84**) and the `Full Model` (**44**) indicate that these models outperform the Null Model in terms of absolute AIC values, contrary to initial expectations.
   - The `Interaction Model` shows the greatest improvement, indicating that capturing interactions between moderators is essential for better explaining product quality outcomes.
   - The `Minimal Random Effects Model` performs similarly to the Null Model, offering no substantial benefit.

6. **Soil Quality:**
   - The `Full Model` demonstrates a substantial improvement with a **relative AIC value of -950**, indicating that capturing high complexity significantly enhances model performance for soil quality.
   - The absence of data for the `Interaction Model` suggests potential model-fitting issues when including interactions among moderators.
   - The `Minimal Random Effects Model` adds no value compared to the Null Model.

7. **Water Quality:**
   - Positive relative AIC values for the `Interaction Model` (**19**) and the `Full Model` (**19**) suggest these models outperform the Null Model in terms of absolute AIC values, similar to product quality.
   - The additional complexity of interactions between moderators does not further improve performance, as seen in the similar relative AIC values for the `Full Model` and `Interaction Model`.
   - The `Minimal Random Effects Model` again shows no improvement over the Null Model.

**General Observations:**
- **Complex models like the Full and Interaction Models generally outperform simpler models**, especially for complex response variables such as greenhouse gas emissions, crop yield, and biodiversity.
- **Product Quality and Water Quality require attention to absolute AIC values**, as positive relative AIC values reflect better performance due to negative absolute AICs.
- Moderators play a critical role in improving model performance, but their interactions are selectively important, as shown for product quality and crop yield.

Implications:
This refined analysis confirms the importance of tailoring model complexity and moderator interactions to specific response variables. While complex models are crucial for variables with significant variability or interactions, simpler models suffice for others, provided they capture the essential dynamics.


```{r}
##########################################################################################################################################
# Add Relative BIC and Adjust Selection Criteria
##########################################################################################################################################

# Add Relative BIC to the dataset
relative_aic_with_bic <- relative_aic |> 
  group_by(ResponseVariable) |> 
  mutate(RelativeBIC = BIC - BIC[Model == "Null Model"]) |> 
  ungroup()

# Adjust relative AIC and BIC for Product Quality and Water Quality
relative_aic_bic_adjusted <- relative_aic_with_bic |> 
  mutate(
    AdjustedRelativeAIC = case_when(
      ResponseVariable %in% c("Product quality", "Water quality") ~ -RelativeAIC, # Flip sign for these variables
      TRUE ~ RelativeAIC
    ),
    AdjustedRelativeBIC = case_when(
      ResponseVariable %in% c("Product quality", "Water quality") ~ -RelativeBIC, # Flip sign for these variables
      TRUE ~ RelativeBIC
    )
  )

# Calculate mean adjusted relative AIC and BIC across all response variables for each model
model_performance_adjusted <- relative_aic_bic_adjusted |> 
  group_by(Model) |> 
  summarise(
    MeanAdjustedRelativeAIC = mean(AdjustedRelativeAIC, na.rm = TRUE),
    MeanAdjustedRelativeBIC = mean(AdjustedRelativeBIC, na.rm = TRUE)
  ) |> 
  arrange(MeanAdjustedRelativeAIC, MeanAdjustedRelativeBIC)

# Identify the overall best-performing model based on adjusted criteria
best_model_adjusted <- model_performance_adjusted |> slice(1)

# Display the adjusted performance summary
model_performance_adjusted

# Highlight the adjusted best-performing model
best_model_adjusted
```

The model performance analysis indicates that the **Interaction Model** consistently outperforms all other models, achieving the lowest mean adjusted relative AIC (-913.72) and BIC (-892.45) across all response variables. This result demonstrates that accounting for interactions among moderators is crucial for capturing the complexities of the data and delivering the most explanatory power.

The **Full Model**, which includes all main effects of moderators but excludes interactions, ranks second with a mean adjusted relative AIC of -871.91 and BIC of -861.33. While it provides substantial improvements over simpler models, it falls short of the Interaction Model due to its inability to account for nuanced interactions among variables.

Among individual moderator models, `age_system` shows the most significant improvement in performance, followed by `crop_type`, `tree_type`, and `soil_texture`. These moderators enhance explanatory power to varying degrees but remain less impactful compared to the comprehensive models. The `season` moderator provides only limited improvement, indicating its minimal relevance across the response variables.

Baseline models, including the **Minimal Random Effects Model** and the **Null Model**, perform identically and fail to capture meaningful variability. Their lack of improvement underscores the necessity of incorporating moderators and interactions for effective model performance.

Overall, the results highlight the superiority of the Interaction Model, emphasizing the importance of capturing complex relationships among moderators to explain variations across the response variables effectively. Simpler models, while informative in specific contexts, are insufficient for fully addressing the intricacies of the data.



```{r}
##########################################################################################################################################
# Function to Back-Transform log-ROM to ROM in Percentage for All Response Variables
##########################################################################################################################################

# Define the function
back_transform_logROM <- function(evaluation_results) {
  # Initialize an empty list to store back-transformed results
  back_transformed_results <- list()

  # Iterate through each response variable in evaluation_results
  for (response in names(evaluation_results)) {
    cat("Processing response variable:", response, "\n")

    # Extract models for the response variable
    models <- evaluation_results[[response]]

    # Initialize a list to store back-transformed values for this response variable
    response_results <- list()

    # Define a helper function to back-transform log-ROM values
    back_transform <- function(estimate, ci.lb, ci.ub) {
      list(
        ROM_percent = (exp(estimate) - 1) * 100,  # Convert to percentage
        ROM_lower_percent = (exp(ci.lb) - 1) * 100,
        ROM_upper_percent = (exp(ci.ub) - 1) * 100
      )
    }

    # Iterate through all models (null, minimal, moderators, full, interaction)
    for (model_name in names(models)) {
      model <- models[[model_name]]

      # Skip if the model is NULL
      if (is.null(model)) {
        response_results[[model_name]] <- NULL
        next
      }

      # Extract estimates and confidence intervals
      if (!is.null(model$b)) {
        response_results[[model_name]] <- back_transform(
          estimate = model$b[1],
          ci.lb = model$ci.lb[1],
          ci.ub = model$ci.ub[1]
        )
      } else {
        response_results[[model_name]] <- NULL
      }
    }

    # Store the back-transformed results for this response variable
    back_transformed_results[[response]] <- response_results
  }

  return(back_transformed_results)
}

##########################################################################################################################################
# Example: Apply the function to evaluation_results
##########################################################################################################################################

# Assuming evaluation_results is already loaded
back_transformed_results <- back_transform_logROM(evaluation_results)

# Inspect the back-transformed results for a specific response variable
print(back_transformed_results$Biodiversity)

##########################################################################################################################################
```
Interpretation of the back-transformed values (ROM in percentages) for all response variables


### Interpretation of Back-Transformed Values (ROM in Percentages)

The back-transformed Ratio of Means (ROM) values provide an interpretable measure of effect sizes for all response variables. These percentages allow us to assess how the system impacts different response variables compared to controls, including associated uncertainty (confidence intervals).

---

### **1. Biodiversity**
- **Null Model:** **4.42%** [CI: -1.25%, 10.42%]  
  Biodiversity is estimated to increase by **4.42%**, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **4.42%** [CI: -1.25%, 10.42%]  
  Identical to the null model, suggesting no improvement by accounting for random effects.  
- **Full Model:** **-7.28%** [CI: -57.80%, 103.74%]  
  Indicates a **7.28% decrease**, but the very wide CI reflects high uncertainty and potential overfitting.  
- **Interaction Model:** **-2.84%** [CI: -46.59%, 76.75%]  
  Shows a **2.84% decrease**, with a similarly wide and uncertain CI.

---

### **2. Greenhouse Gas Emissions**
- **Null Model:** **0.94%** [CI: 0.69%, 1.20%]  
  A minimal and statistically significant increase in emissions, reflecting consistent results across the CI.  
- **Minimal Random Effects Model:** **0.94%** [CI: 0.69%, 1.20%]  
  No improvement over the null model.  
- **Full Model:** **25.73%** [CI: 14.49%, 38.06%]  
  A large, statistically significant increase in emissions, highlighting the importance of moderators in explaining variability.  
- **Interaction Model:** **25.58%** [CI: 14.29%, 37.98%]  
  Similar to the full model, demonstrating consistency with added interactions.

---

### **3. Product Quality**
- **Null Model:** **-2.00%** [CI: -3.66%, -0.32%]  
  A small, statistically significant decrease in product quality.  
- **Minimal Random Effects Model:** **-2.00%** [CI: -3.66%, -0.32%]  
  Identical to the null model, indicating no improvement.  
- **Full Model:** **-1.71%** [CI: -6.31%, 3.13%]  
  A smaller decrease, but with a CI including zero, indicating no significant effect.  
- **Interaction Model:** **-0.80%** [CI: -5.30%, 3.92%]  
  The smallest effect with high uncertainty, suggesting minimal influence of moderator interactions.

---

### **4. Crop Yield**
- **Null Model:** **-2.28%** [CI: -4.40%, -0.11%]  
  A small but statistically significant decrease in yield.  
- **Minimal Random Effects Model:** **-2.28%** [CI: -4.40%, -0.11%]  
  Identical to the null model.  
- **Full Model:** **-1.67%** [CI: -6.34%, 3.24%]  
  A smaller decrease, but the CI includes zero, showing no significant effect.  
- **Interaction Model:** **-25.28%** [CI: -36.39%, -12.24%]  
  A large and significant decrease, highlighting the strong effect of interactions among moderators.

---

### **5. Pest and Disease**
- **Null Model:** **-8.67%** [CI: -24.89%, 11.05%]  
  A modest decrease, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **-8.67%** [CI: -24.89%, 11.05%]  
  Identical to the null model.  
- **Full Model:** **-40.47%** [CI: -64.04%, -1.46%]  
  A large, statistically significant decrease, showing the impact of moderators.  
- **Interaction Model:** **-40.47%** [CI: -64.04%, -1.46%]  
  Identical to the full model, suggesting interactions add no further value.

---

### **6. Soil Quality**
- **Null Model:** **3.37%** [CI: -1.14%, 8.08%]  
  A small increase, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **3.37%** [CI: -1.14%, 8.08%]  
  No improvement over the null model.  
- **Full Model:** **-33.61%** [CI: -54.09%, -3.98%]  
  A large and statistically significant decrease, reflecting the critical role of moderators.
- **Interaction Model:**  

---

### **7. Water Quality**
- **Null Model:** **1.56%** [CI: -1.35%, 4.56%]  
  A small increase, with the CI including zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **1.56%** [CI: -1.35%, 4.56%]  
  Identical to the null model.  
- **Full Model:** **2.69%** [CI: -10.40%, 17.68%]  
  A slightly larger increase, but the wide CI reflects high uncertainty.  
- **Interaction Model:** **2.69%** [CI: -10.40%, 17.68%]  
  Identical to the full model, suggesting interactions add no value.

---

### **General Observations**
1. **Simple Models (Null, Minimal Random Effects):** These provide consistent but limited insights, often failing to capture significant effects.
2. **Full Model:** This generally improves fit, revealing significant effects for variables like `Greenhouse Gas Emissions`, `Pest and Disease`, and `Soil Quality`.
3. **Interaction Model:** Adds minimal value beyond the full model for most variables, except for `Crop Yield`.

---

### **Conclusions**
- **Greenhouse Gas Emissions** and **Pest and Disease** see the most substantial improvements with complex models, reflecting the value of moderators.  
- **Biodiversity**, **Product Quality**, and **Water Quality** remain uncertain, with wide CIs indicating potential data limitations or overfitting.  
- Simplified models suffice for some variables, but full models are critical for uncovering nuanced effects in others.


```{r}
##########################################################################################################################################
# Combine Raw Effect Sizes and Back-Transformed Values into a Structured Data Frame
##########################################################################################################################################

# Function to create a structured data frame
combine_effect_sizes <- function(evaluation_results, back_transformed_results) {
  combined_results <- data.frame(
    ResponseVariable = character(),
    Model = character(),
    Estimate = numeric(),
    CI_Lower = numeric(),
    CI_Upper = numeric(),
    P_Value = character(),
    Significance = character(),
    ROM_Percent = numeric(),
    ROM_Lower_Percent = numeric(),
    ROM_Upper_Percent = numeric(),
    stringsAsFactors = FALSE
  )

  for (response in names(evaluation_results)) {
    models <- evaluation_results[[response]]
    back_transformed <- back_transformed_results[[response]]

    for (model_name in names(models)) {
      model <- models[[model_name]]
      if (!is.null(model) && !is.null(model$b) && !is.null(model$ci.lb) && !is.null(model$pval)) {
        p_value <- ifelse(model$pval[1] < 0.001, "<0.001", formatC(model$pval[1], format = "f", digits = 3))
        significance <- if (model$pval[1] < 0.001) {
          "***"
        } else if (model$pval[1] < 0.01) {
          "**"
        } else if (model$pval[1] < 0.05) {
          "*"
        } else if (model$pval[1] < 0.1) {
          "."
        } else {
          " "
        }

        combined_results <- rbind(combined_results, data.frame(
          ResponseVariable = response,
          Model = model_name,
          Estimate = model$b[1],
          CI_Lower = model$ci.lb[1],
          CI_Upper = model$ci.ub[1],
          P_Value = p_value,
          Significance = significance,
          ROM_Percent = back_transformed[[model_name]]$ROM_percent,
          ROM_Lower_Percent = back_transformed[[model_name]]$ROM_lower_percent,
          ROM_Upper_Percent = back_transformed[[model_name]]$ROM_upper_percent
        ))
      }
    }
  }

  return(combined_results)
}


# Apply the function
structured_results <- combine_effect_sizes(evaluation_results, back_transformed_results)


output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# Save structured_results in a combined file
saveRDS(structured_results, file = file.path(output_dir, "structured_results_all_effect_sizes.rds"))



# Inspect the structured data frame
structured_results |> glimpse()
```


```{r}
##########################################################################################################################################
# Create a Publication-Ready gt Table for Back-Transformed Values
##########################################################################################################################################


# Function to create a gt table for ROM values
create_gt_table <- function(data) {
  data |> 
    dplyr::select(ResponseVariable, Model, ROM_Percent, ROM_Lower_Percent, ROM_Upper_Percent, P_Value, Significance) |> 
    gt() |> 
    tab_header(
      title = "Back-Transformed Values (ROM in Percentages)",
      subtitle = "Includes Estimates, Confidence Intervals, P-Values, and Significance Levels"
    ) |> 
    cols_label(
      ResponseVariable = "Response Variable",
      Model = "Model",
      ROM_Percent = "ROM (%)",
      ROM_Lower_Percent = "Lower CI (%)",
      ROM_Upper_Percent = "Upper CI (%)",
      P_Value = "P-Value",
      Significance = "Significance"
    ) |> 
    fmt_number(
      columns = c(ROM_Percent, ROM_Lower_Percent, ROM_Upper_Percent),
      decimals = 2
    ) |> 
    tab_options(
      table.font.size = "small",
      heading.align = "center"
    )
}

# Create the gt table
back_transformed_table <- create_gt_table(structured_results)

# Render the table
back_transformed_table
```


```{r}
##########################################################################################################################################
# Filter for the Best-Performing Model (Interaction Model) and Create a gt Table
##########################################################################################################################################

# Filter structured results for the Interaction Model
best_model_results <- structured_results |> 
  dplyr::filter(Model == "interaction_model")

# Create the gt table for the Interaction Model
best_model_gt_table <- create_gt_table(best_model_results) |> 
  cols_hide("Model")

# Render the table
best_model_gt_table
```



##########################################################################################################################################
# SECTION 1: META-ANALYSIS DIAGNOSTICS 
##########################################################################################################################################

```{r}
# model_results |> str()
# model_results$`Crop yield` |> str()

model_results$`Crop yield`
```



```{r}
##########################################################################################################################################
# A: Extract heterogeneity statistics for each response variable
##########################################################################################################################################
extract_heterogeneity_stats <- function(model_results) {
  heterogeneity_stats <- lapply(names(model_results), function(response) {
    
    model <- model_results[[response]]$full_model    # <------------------------------- !(chosen model)!
    if (is.null(model)) return(NULL)

    # Calculate I2 manually if tau2 is 0
    QE <- model$QE
    df <- model$QEdf
    I2 <- if (QE > df) (QE - df) / QE * 100 else 0

    data.frame(
      Response_Variable = response,
      I2 = I2,
      Tau2 = model$tau2,
      QE = QE,
      QE_pval = model$QEp,
      stringsAsFactors = FALSE
    )
  })

  # Combine results into a single data frame
  do.call(rbind, heterogeneity_stats)
}

# Extract heterogeneity statistics
heterogeneity_stats <- extract_heterogeneity_stats(model_results)

# Inspect the results
heterogeneity_stats
```

Crop yield	NA	0	203339.1624	      null_model
Crop yield	NA	0	95862.5010        interaction_model
Crop yield	99.80134	0	134398.4729	full_model

The results of the heterogeneity statistics indicate the following:

1. **I² Values:**
   - The I² values range from 36% (Product quality) to 99.98% (Biodiversity), suggesting varying levels of heterogeneity across response variables.
   - High I² values (close to 100%) for most response variables (e.g., Biodiversity, Crop yield, Pest and Disease, Soil quality) indicate that a large proportion of the variability in effect sizes is due to heterogeneity rather than sampling error.
   - Moderate I² for Product quality (36.01%) suggests less heterogeneity, with sampling error accounting for most of the variability.

2. **Tau² (Between-Study Variance):**
   - All Tau² values are `0`, indicating no estimated between-study variance in the random-effects models. This could suggest either true homogeneity of effect sizes or insufficient power to detect between-study variance.

3. **QE (Cochran's Q Test):**
   - QE values are very high for most response variables, particularly for Biodiversity, Crop yield, and Soil quality, suggesting significant residual heterogeneity not explained by the model. The associated QE p-values (<0.001 for all) confirm that the observed heterogeneity is statistically significant.

4. **Implications:**
   - The high I² values, combined with significant QE tests and zero Tau², indicate that heterogeneity exists, but it is not being captured by the random-effects variance component (Tau²). This suggests that other moderators or model structures may need to be explored to better explain the variability.

5. **Recommendations:**
   - For variables with very high I² and significant QE (e.g., Biodiversity, Crop yield, Soil quality), consider including additional moderators or interaction terms in the model to account for heterogeneity.
   - For Product quality (lower I²), the model seems to explain a reasonable proportion of variability, though further exploration of moderators could still be beneficial.

In summary, while the models reveal significant heterogeneity across most response variables, the lack of between-study variance (Tau² = 0) suggests that additional moderators or refinements to model specifications may be required to better account for the observed variability.

# 2a: Extract influence of higher-level and sub-level moderators

# 2b: Evaluate the proportion of heterogeneity explained by each moderator


 
 


#############
# STEP 
##########################################################################################################################################
PROPORTION OF EFFECT SIZE DIRECTION AS NUMBER OF POSITIVE, NEUTRAL, AND NEGATIVE
##########################################################################################################################################

Based on the minimal_random_effects model

```{r}
imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))
```

```{r}
# Step 1: Calculate Z-score, p-value, and categorize effect sizes
imp_data_rom_calc <- imp_data_rom %>%
  mutate(
    Z = yi / sqrt(vi),  # Calculate Z-score
    Pval = 2 * (1 - pnorm(abs(Z))),  # Two-tailed p-value
    category = case_when(
      Pval < 0.05 & yi > 0 ~ "Positive",  # Significant positive effect
      Pval < 0.05 & yi < 0 ~ "Negative",  # Significant negative effect
      TRUE ~ "Neutral"  # Non-significant or neutral effect
    )
  )

# Step 2: Count effect sizes per category for each response variable
summary_data_for_eff_calc <- imp_data_rom_calc %>%
  count(response_variable, category, name = "count") %>%  # More efficient than group_by() + summarise(n())
  group_by(response_variable) %>%
  mutate(
    total_count = sum(count),  # Total effect sizes per response variable
    percentage = (count / total_count) * 100  # Compute proportion
  ) %>%
  ungroup()  # Remove grouping after calculation

# Step 3: Ensure response variables are ordered by total effect sizes
summary_data_for_eff_calc <- summary_data_for_eff_calc %>%
  mutate(response_variable = fct_reorder(response_variable, total_count, .fun = sum))

# Step 4: Create stacked bar plot for effect size proportions
stacked_barplot <- ggplot(summary_data_for_eff_calc, aes(x = response_variable, y = percentage, fill = category)) +
  geom_bar(stat = "identity", position = "stack") +
  scale_fill_manual(values = c("Positive" = "#1b9e77", "Negative" = "#d95f02", "Neutral" = "#757575")) +
  labs(
    title = "Percentage of Effect Sizes by Response Variable",
    x = "Response Variable",
    y = "Percentage of Effect Sizes",
    fill = "Effect Size Category"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),
    axis.text.y = element_text(size = 12),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12),
    panel.grid.major.y = element_line(color = "gray", linewidth = 0.5),  # Keep only y-axis grid lines
    panel.grid.major.x = element_blank(),  # Remove x-axis grid lines
    panel.grid.minor = element_blank(),  # Remove minor grid lines
    axis.line = element_line(linewidth = 0.5)  # Keep axis lines visible
  ) +
  scale_y_continuous(
    limits = c(0, 100),  # Y-axis fixed between 0 and 100%
    breaks = seq(0, 100, by = 20)  # Set breaks at 20% intervals
  )

# Step 5: Display the plot
print(stacked_barplot)

```
 
 
 
 
 
 
 
#############
# STEP 
##########################################################################################################################################
EXTRACT MODEL WEIGHTS PER RESPONSE VARIABLE 
##########################################################################################################################################

 
 
##########################################################################################################################################
SAVING DATASETS AND MODEL OBJECTS
##########################################################################################################################################

 
 

Improvements and Adjustments
To address collinearity, pre-analysis checks such as variance inflation factors (VIF) or pairwise correlation matrices should be performed. Moderators with high collinearity or sparse data should be excluded or merged. Missing data can be handled using imputation methods or treated as a separate category. Log-transforming or standardizing `yi` and moderators could stabilize models with high variance ratios, while robust variance estimators, such as Knapp-Hartung adjustments, may improve reliability. Reducing the complexity of interaction models by focusing on key moderator pairs (e.g., `tree_type * crop_type`) rather than all interactions could improve convergence.

Model Diagnostics and Reporting
For each response variable, heterogeneity was assessed using statistics such as `I²` and `τ²`, and model fits were compared using AIC and BIC. Funnel plots, Egger’s test, and leave-one-out sensitivity analyses were conducted to evaluate publication bias and model robustness. Failed models were documented to ensure transparency, and systematic adjustments were reported to improve reproducibility. This approach balances explanatory power and interpretability, ensuring that the hierarchical complexity of moderators is appropriately captured.








