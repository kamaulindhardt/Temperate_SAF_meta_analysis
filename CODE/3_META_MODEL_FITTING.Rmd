---
title: "3_META_MODEL_FITTING"
author: "M.K.K. Lindhardt"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Load multiple add-on packages using pacman::p_load for efficiency
# pacman::p_load automatically installs missing packages and loads them
pacman::p_load(
  
  # Conflict Resolution
  conflicted,        # Resolves conflicts when functions with the same name exist in multiple packages
  
  # Data Manipulation / Transformation
  tidyverse,         # Comprehensive collection of R packages for data science (e.g., ggplot2, dplyr, readr)
  readr,             # Simplifies reading and writing of delimited text files (e.g., CSV)
  dplyr,             # A grammar of data manipulation (e.g., filter, mutate, summarise, etc.)
  skimr,             # Provides summary statistics with a more user-friendly output
  future,            # Supports parallel processing for speeding up computations
  future.apply,      # Extends the future package for parallelized versions of base R apply functions
  readxl,            # Read excel files
  
  ###################################################################################################################
  # Data Visualization
  ggplot2,           # A data visualization package for creating static and interactive graphics (part of tidyverse)
  patchwork,         # Extends ggplot2 by providing tools to combine multiple plots into one
  gridExtra,         # Arranges multiple grid-based plots (e.g., from ggplot2) into a single display
  scales,            # Adds tools for handling scale transformations and labels in visualizations
  gt,                # Stylish tables
  ggbreak,           # Breaks on axis for bar charts etc.
  ggpubr,            # Working with plots and legends library
  forcats,           # Tools for Working with Categorical Variables (Factors)
  
  ###################################################################################################################
  # Meta-Analysis
  metafor,           # For conducting meta-analyses, including calculating effect sizes and response ratios
  orchaRd,           # Provides tools for conducting and visualising meta-analyses and meta-regressions
  clubSandwich,      # Provides cluster-robust variance estimators for meta-analysis models
  mice,              # Multivariate Imputation by Chained Equations for handling missing data
  
  ###################################################################################################################
  # Exploratory Data Analysis (EDA)
  DataExplorer,      # Automates exploratory data analysis with summary statistics and visualizations
  SmartEDA,          # Automates exploratory data analysis with summary reports and visualizations
  naniar,            # Provides tools for handling and visualizing missing data
  VIM,               # Visualization and Imputation of Missing Data
  Hmisc,             # Miscellaneous functions including data summary, analysis, and visualization
  BaylorEdPsych,     # Provides tools for reliability analysis and missing data imputation
  openxlsx,          # Simplifies the the process of writing and styling Excel xlsx
  
  ###################################################################################################################
  # Project Management and Code Styling
  here,              # Simplifies file referencing by locating the root of a project directory
  styler             # Formats and styles R code to improve readability and consistency
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("summarize", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("intersect", "base")
```



#############
# STEP 1
##########################################################################################################################################
LOADING PREPARED META-DATA
##########################################################################################################################################


Loading the two datasets (imputed and non-imputed)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Define file paths
non_imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom.rds"))
imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))

# non_imp_data_rom_dummy <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom_dummy.rds"))

# Read in the non-imputed dataset
non_imp_dataset <- non_imp_data_rom %>%
  as.data.frame()|> 
  # select(-geometry) |> 
  relocate(
       # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )

# Read in the imputed dataset
imp_dataset <- imp_data_rom %>%
  as.data.frame()|> 
  relocate(
       # Overall ID info
    id_article, id_obs, treat_id, exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )
})
```

```{r}
# Checking high observations with extreme high variance
high_variance_obs <- 
  imp_dataset|> 
  filter(vi > quantile(vi, 0.95)) |> # 0.995
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           # Quantitative meta-analysis variables - mean and no. of observations
           silvo_mean, control_mean, silvo_n, control_n,
           # Quantitative meta-analysis variables - variance info
           silvo_se, silvo_sd_from_se, silvo_sd_final, 
           control_se, control_sd_from_se, control_sd_final,
           tree_type, crop_type, age_system, season, soil_texture, no_tree_per_m, tree_height, alley_width) |> 
  arrange(id_article, response_variable)

skim(high_variance_obs)
```
```{r}
non_imp_dataset |> glimpse()
imp_dataset |> glimpse()
```

```{r}
# Select distinct id_article entries
distinct_articles <- imp_dataset %>%
  select(id_article) %>%
  distinct()

# Get the number of unique id_article entries
num_distinct_articles <- nrow(distinct_articles)

# Print the result
cat("Number of distinct id_article entries:", num_distinct_articles, "\n")
# Number of distinct id_article entries: 37 
```




##########################################################################################################################################
LISTING RESPONSE VARIABLES AND SETTING UP COSTUM COLORS
##########################################################################################################################################

```{r}
# Custom colors for response variables
custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)

# Response variables to analyze
response_variables <- names(custom_colors)
```

```{r}
# Filter dataset for specified response variables
filtered_dataset <- imp_dataset %>%
  filter(response_variable %in% response_variables)

# Calculate the Response Ratio
filtered_dataset <- filtered_dataset %>%
  mutate(
    ResponseRatio = silvo_mean / control_mean,
    log_ResponseRatio = log(ResponseRatio) # Log transformation for better interpretation
  ) |> 
  # Recalculate log ResponseRatio and add a small constant to avoid log(0)
  mutate(
    log_ResponseRatio = log(ResponseRatio + 1e-6) # Add a tiny constant for log safety
  )


# Bootstrap data for violin plot
bootstrapped_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarise(
    bootstrapped_rr = list(boot::boot(data = log_ResponseRatio, statistic = function(x, i) mean(x[i]), R = 25000)$t)
  ) %>%
  unnest(bootstrapped_rr)

# Summary statistics for plotting
summary_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarize(
    WeightedMeanRR = mean(ResponseRatio, na.rm = TRUE),
    LowerCI = mean(ResponseRatio, na.rm = TRUE) - 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    UpperCI = mean(ResponseRatio, na.rm = TRUE) + 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    RR_Less_1 = mean(ResponseRatio < 1) * 100,
    RR_Greater_1 = mean(ResponseRatio > 1) * 100,
    Studies = n_distinct(id_article),
    Observations = n(),
    .groups = "drop"
  )
```

```{r}
# Ensure consistent factor levels for response_variable
common_levels <- filtered_dataset$response_variable %>% unique() %>% sort()

filtered_dataset <- filtered_dataset %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

bootstrapped_data <- bootstrapped_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

summary_data <- summary_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

# Recreate the violin plot with proper alignment
violin_plot_response_var_lnrr <- 
  ggplot() +
  # Violin plot for bootstrapped data
  geom_violin(data = bootstrapped_data, aes(y = response_variable, x = exp(bootstrapped_rr), fill = response_variable), 
              alpha = 0.5, scale = "area") + # Use 'area' scaling for better proportional representation
  # Overlay mean and confidence intervals
  # geom_point(data = summary_data, aes(y = response_variable, x = exp(WeightedMeanRR)), color = "black", size = 3) +
  # geom_errorbarh(data = summary_data, aes(y = response_variable, xmin = exp(LowerCI), xmax = exp(UpperCI)), 
  #               height = 0.2, color = "black") +
  # Add a red vertical dotted line at x = 1
  geom_vline(xintercept = 1, linetype = "dotted", color = "red", size = 0.8) +
    # Add annotations for proportions and study counts
  geom_text(data = summary_data, aes(
    y = response_variable, x = max(summary_data$UpperCI) * 0.825, 
    label = paste0("RR<1: ", round(RR_Less_1), "%\nRR>1: ", round(RR_Greater_1), "%\n[N=", Studies, ", NO=", Observations, "]")
  ), size = 3, hjust = 0) +
  # Apply custom colors
  scale_fill_manual(values = custom_colors) +
  # Customize plot
  scale_x_continuous(limits = c(0.8, 1.6), trans = "identity", breaks = scales::pretty_breaks()) +
  labs(
    title = "Weighted Mean Response Ratio",
    subtitle = "Agroforestry vs. Non-Agroforestry Effects by Response Variable",
    x = "Response Ratio",
    y = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    legend.position = "none"
  )

# Print the plot
violin_plot_response_var_lnrr
```













#############
# STEP 2
##########################################################################################################################################
PERFORMING MULTIVARIATE/MULTILEVEL LINEAR (MIXED-EFFECTS) MODELLING 
##########################################################################################################################################

Assessment of Missing Data for Moderators
Imputation of Missing Values for Moderators Using mice()
Post-Imputation Assessment of Moderators
Selection of Moderators for Analysis
Fitting the Multivariate Random-Effects Model with Selected Moderators

```{r}
# Define the function for missing data assessment
assess_missing_data <- function(dataset, moderators, dataset_name = "Dataset") {
  
  cat("\nStarting missing data assessment for", dataset_name, "...\n")
  
  # Step 1: Calculate the proportion of missing values for each moderator
  missing_summary <- dataset %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_proportion")

  # Print the missing summary table
  cat("\nProportion of Missing Values for Each Moderator:\n")
  print(missing_summary)

  # Step 2: Create a basic bar chart of missing proportions
  missing_plot <- ggplot(missing_summary, aes(x = reorder(variable, -missing_proportion), y = missing_proportion)) +
    geom_bar(stat = "identity", fill = "#0072B2") +
    labs(
      title = paste("Proportion of Missing Data for Moderator Variables -", dataset_name),
      x = "Moderator Variable",
      y = "Missing Proportion"
    ) +
    scale_y_continuous(labels = scales::percent) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Step 3: Calculate missingness for each moderator by response_variable
  missing_by_response <- dataset %>%
    group_by(response_variable) %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = -response_variable, names_to = "moderator", values_to = "missing_proportion")

  # Print the summary table for missingness by response_variable
  cat("\nMissing Proportion by Response Variable for Each Moderator:\n")
  print(missing_by_response)

  # Step 4: Create a heatmap for missingness by response_variable
  missing_heatmap <- ggplot(missing_by_response, aes(x = moderator, y = response_variable, fill = missing_proportion)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "#56B1F7", high = "#132B43", na.value = "gray90", labels = percent) +
    labs(
      title = paste("Heatmap of Missing Data by Moderator and Response Variable -", dataset_name),
      x = "Moderator Variable",
      y = "Response Variable",
      fill = "Missing Proportion"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Display the plots
  print(missing_plot)
  print(missing_heatmap)
  
  cat("\nMissing data assessment completed for", dataset_name, ".\n")
}
```

```{r}
# Assessing Moderator missingness

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Assess missing data for non-imputed dataset
assess_missing_data(non_imp_dataset, moderators, "Non-Imputed Dataset")

# Assess missing data for imputed dataset
assess_missing_data(imp_dataset, moderators, "Imputed Dataset")
```






##########################################################################################################################################
CREATING A VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################


```{r}
# Variance-Covariance Matrix Calculation Function
calculate_v_matrix <- function(data, correlation = 0.5) {
  cat("\nCalculating Variance-Covariance Matrix...\n")
  
  v_list <- list()
  for (study in unique(data$id_article)) {
    study_data <- data[data$id_article == study, ]
    
    if (nrow(study_data) > 1) {
      v <- diag(study_data$vi)
      for (i in 1:nrow(v)) {
        for (j in 1:nrow(v)) {
          if (i != j) {
            v[i, j] <- correlation * sqrt(v[i, i] * v[j, j])
          }
        }
      }
      v_list[[as.character(study)]] <- v
    } else {
      v_list[[as.character(study)]] <- matrix(study_data$vi, nrow = 1, ncol = 1)
    }
  }

  v_matrix <- bldiag(v_list)
  cat("\nGenerated Variance-Covariance Matrix:\n")
  print(v_matrix)
  
  return(v_matrix)
}
```

```{r, results = 'hide'}
# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset




# Directory for saving results
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Generate and save v_matrices for each response variable
v_matrices <- list()

for (response in response_variables) {
  cat("\nProcessing response variable:", response, "\n")
  
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]
  
  # Calculate the variance-covariance matrix
  v_matrix <- calculate_v_matrix(data_subset, correlation = 0.5)
  
  # Store the matrix in the list
  v_matrices[[response]] <- v_matrix
  
  # Save the matrix to an individual RDS file
  file_name <- paste0("v_matrix_", tolower(gsub(" ", "_", response)), ".rds")
  saveRDS(v_matrix, file = file.path(output_dir, file_name))
  
  cat("Saved v_matrix for response variable:", response, "to", file.path(output_dir, file_name), "\n")
}

# Also, save the entire list of v_matrices as a single file
saveRDS(v_matrices, file = file.path(output_dir, "v_matrices_by_response_variable.rds"))
cat("\nAll v_matrices saved to:", output_dir, "\n")
```




#############
# STEP 3
##########################################################################################################################################
MODEL FITTING ON EACH SUBSET DATA USING ASSOCIATED VARIANCE-COVARIANCE MATRIX
##########################################################################################################################################

```{r}
# Load the saved v_matrices
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
v_matrices <- readRDS(file.path(output_dir, "v_matrices_by_response_variable.rds"))
```


```{r}
imp_dataset |> glimpse()
```
```{r}
# Summary of missing data by column
missing_summary <- imp_dataset %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "MissingCount")

# View variables with missing data
missing_summary <- missing_summary %>%
  filter(MissingCount > 0) %>%
  arrange(desc(MissingCount))

# Visualize missingness
gg_miss_var(imp_dataset) +
  labs(title = "Missing Data Across Variables")

# View rows with missing data
rows_with_missing <- imp_dataset %>%
  filter(!complete.cases(.))
```
```{r}
# Summary statistics for effect size (yi)
summary(imp_dataset$yi)

# Summary statistics for variance (vi)
summary(imp_dataset$vi)

# Identify rows with extreme variances on a sub_response_variable level
extreme_variance_rows <- imp_dataset %>%
  group_by(sub_response_variable) %>%
  filter(vi > quantile(vi, 0.95, na.rm = TRUE) | vi < quantile(vi, 0.05, na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(desc(vi))

extreme_variance_rows |> glimpse()

# Last go (24/01-2025)
#    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
#  0.00000  0.00019  0.00102  0.09496  0.00620 40.29043 
# Rows: 131
# Columns: 64
```


##########################################################################################################################################
FITTING MODELS (SUB-GROUP) FOR EACH RESPONSE VARIABLE USING PRECOMPUTED V_MATRICES
##########################################################################################################################################

```{r}
##########################################################################################################################################
# HIERARCHICAL COMPLEXITY APPROACH ALIGNED WITH THE CABBAGE APPROACH
##########################################################################################################################################

# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################



# Function to fit models incrementally for a response variable
fit_models_all <- function(data_subset, response_variable, v_matrix, moderators, random_effects) {
  results <- list()

  cat("\nProcessing response variable:", response_variable, "\n")

  #############################################################################################
  # Null model: Global average without moderators
  results$null_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in null model:", e$message, "\n")
    return(NULL)
  })
  ############################################################################################# ---------- ! (chosen model) !
  # Minimal random effects model
  results$minimal_random_effects <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = ~ 1,  # Intercept-only model
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in minimal random effects model:", e$message, "\n")
    return(NULL)
  })
  
  #############################################################################################
  # Incremental models for each moderator (no interaction)
  results$moderator_models <- map(moderators, ~ {
    moderator <- .x
    tryCatch({
      rma.mv(
        yi = yi,
        V = v_matrix,
        mods = as.formula(paste("~", moderator)),
        random = random_effects,
        data = data_subset,
        method = "REML",
        control = list(iter.max = 2000, rel.tol = 1e-9)
      )
    }, error = function(e) {
      cat("Error in moderator model for", moderator, ":", e$message, "\n")
      return(NULL)
    })
  })
  names(results$moderator_models) <- moderators
  
  #############################################################################################
  # Full model with all moderators (no interaction)
  results$full_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = as.formula(paste("~", paste(moderators, collapse = " + "))),
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in full model:", e$message, "\n")
    return(NULL)
  })

  #############################################################################################
  # Full interaction model with all moderators
  results$interaction_model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = as.formula(paste("~", paste(moderators, collapse = " * "))),
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    cat("Error in interaction model:", e$message, "\n")
    return(NULL)
  })

  return(results)
}

##########################################################################
# Fit Models for Each Response Variable
##########################################################################

# Initialize an empty list to store model results
model_results <- list()

# Loop through each response variable to fit models
for (response in names(v_matrices)) {
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]

  # Extract the variance-covariance matrix for the response variable
  v_matrix <- v_matrices[[response]]

  # Define the moderators to include in the model
  moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

  # Define random effects structure
  random_effects <- ~ 1 | exp_id

  # Fit models incrementally using the cabbage approach
  model_results[[response]] <- fit_models_all(
    data_subset = data_subset,
    response_variable = response,
    v_matrix = v_matrix,
    moderators = moderators,
    random_effects = random_effects
  )
}

##########################################################################
# Save All Fitted Models
##########################################################################

output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Save all models in a combined file
saveRDS(model_results, file = file.path(output_dir, "fitted_models_all_new.rds"))

# Save individual model results
for (response in names(model_results)) {
  saveRDS(model_results[[response]], file = file.path(output_dir, paste0("fitted_models_", response, "_new.rds")))
}

cat("\nAll models have been saved successfully!\n")

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (25/01-2025) 
# Total time taken: 31.73879 secs 

# Processing response variable: Biodiversity 
# Advarsel: Redundant predictors dropped from the model.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: Redundant predictors dropped from the model.Advarsel: 14 rows with NAs omitted from model fitting.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Greenhouse gas emission 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Product quality 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Crop yield 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Pest and Disease 
# Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.Advarsel: Redundant predictors dropped from the model.
# Processing response variable: Soil quality 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Error in interaction model: Optimizer (nlminb) did not achieve convergence (convergence = 1). 
# 
# Processing response variable: Water quality 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Advarsel: Redundant predictors dropped from the model.
# All models have been saved successfully!
# 
# Total time taken: 31.73879 secs 
```

Explanations of the above Multi-Model Fitting 

Descriptions of the 'Hierarchical Complexity Approach' Multi-Model Fitting for Temperate Silvoarable Agroforrestry and Ecosystem Services Meta-Analysis

In this study we decided to employ a hierarchical complexity approach for meta-analysis multi-model fitting aligned with Carrillo-Reche et al. (2023) [https://www.sciencedirect.com/science/article/pii/S0167880923002232], aka the "Cabbage approach" to evaluate the effects of silvoarable agroforestry systems across multiple response variables. Meta-analytic models were constructed using the `rma.mv` function from the **metafor** package, accounting for random effects and systematically including moderators to assess their contribution to heterogeneity reduction and effect size estimation.

Model Construction and Fitting
Models were fitted incrementally for each response variable, starting with a null model to estimate the global average effect size without moderators. A minimal random effects model introduced random variability at the experiment level (`~ 1 | exp_id`) to account for between-study differences. Moderator models were then constructed to examine the independent effects of moderators such as `tree_type`, `crop_type`, `age_system`, `season`, and `soil_texture`. A full model combined all moderators additively, while a full interaction model evaluated interaction terms between all moderators. Convergence criteria were tightened by increasing the maximum iterations (`iter.max = 2000`) and reducing the relative tolerance (`rel.tol = 1e-9`) to improve model stability.

Error and Warning Analysis
During model fitting, several warnings and errors were encountered, highlighting potential limitations in the dataset or model structure. Redundant predictors were dropped due to collinearity or lack of variability, affecting models for all response variables (see the resulting output messages from the multi-model fitting code chunk above). For instance, in cases like `tree_type` and `crop_type`, collinearity led to the exclusion of certain predictors. Observations with missing values in moderators were omitted, particularly for `Biodiversity`, where 14 rows were removed. High variance ratio warnings indicated extreme variability in sampling variances, notably for `Crop yield`, `Soil quality`, and `Water quality`, leading to unstable parameter estimates. Convergence failures occurred for the full interaction model in `Soil quality` and `Water quality`, likely due to excessive complexity and insufficient data for interaction terms.

Alternatively, we could have fitted the Full model only with selected interaction pairs of moderators?

# Full model with selected moderator interactions
  interaction_pairs <- list(
    c("tree_type", "crop_type"),
    c("age_system", "season"),
    c("season", "soil_texture")
  )

  [...]

Model Outcomes
The null and minimal random effects models were generally successful, providing baseline estimates and capturing between-study heterogeneity. However, the interaction models often failed to converge, particularly when all moderators and their interactions were included. This highlights the challenges of modeling complex interactions in datasets with limited observations or high heterogeneity.



```{r}
# Load and assess the model results from the saved file
# This script allows evaluating both higher-level and lower-level effects of moderators for each response variable and model.

# Load the combined model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

# Define a function to summarize and evaluate model results
evaluate_model <- function(models, response_variable) {
  cat("\nEvaluating models for response variable:", response_variable, "\n")
  
  # Initialize a list to store evaluation results
  evaluation_results <- list()
  
  # Evaluate the null model
  if (!is.null(models$null_model)) {
    evaluation_results$null_model <- summary(models$null_model)
    cat("\nNull model:\n", paste(capture.output(evaluation_results$null_model), collapse = "\n"), "\n")
  }
  
  # Evaluate the minimal random effects model
  if (!is.null(models$minimal_random_effects)) {
    evaluation_results$minimal_random_effects <- summary(models$minimal_random_effects)
    cat("\nMinimal random effects model:\n", paste(capture.output(evaluation_results$minimal_random_effects), collapse = "\n"), "\n")
  }
  
  # Evaluate individual moderator models
  if (!is.null(models$moderator_models)) {
    evaluation_results$moderator_models <- lapply(models$moderator_models, summary)
    cat("\nModerator models:\n")
    for (moderator in names(models$moderator_models)) {
      cat("\nModerator:", moderator, "\n")
      cat(paste(capture.output(evaluation_results$moderator_models[[moderator]]), collapse = "\n"), "\n")
    }
  }
  
  # Evaluate the full model (no interaction)
  if (!is.null(models$full_model)) {
    evaluation_results$full_model <- summary(models$full_model)
    cat("\nFull model (no interaction):\n", paste(capture.output(evaluation_results$full_model), collapse = "\n"), "\n")
  }
  
  # Evaluate the full interaction model
  if (!is.null(models$interaction_model)) {
    evaluation_results$interaction_model <- summary(models$interaction_model)
    cat("\nFull interaction model:\n", paste(capture.output(evaluation_results$interaction_model), collapse = "\n"), "\n")
  }
  
  return(evaluation_results)
}

# Loop through each response variable and evaluate model results
evaluation_results <- list()

for (response in names(model_results)) {
  evaluation_results[[response]] <- evaluate_model(models = model_results[[response]], response_variable = response)
}

cat("\nModel evaluation completed.\n")


##########################################################################
# Save evaluation results for further analysis or reporting
##########################################################################

# Save combined evaluation results
saveRDS(evaluation_results, file = here::here("DATA", "OUTPUT_FROM_R", 
                                              "MULTI_MODEL_EVALUATION_RESULTS", "evaluation_results_combined.rds"))

# Save individual evaluation results
for (response in names(evaluation_results)) {
  saveRDS(evaluation_results[[response]], file = here::here("DATA", "OUTPUT_FROM_R", 
                                                            "MULTI_MODEL_EVALUATION_RESULTS", paste0("evaluation_results_", response, ".rds")))
}

cat("\nEvaluation results of the multi-model fitting have been saved successfully!\n")
```

```{r}
evaluation_results$Biodiversity |> str()

# evaluation_results$Biodiversity
```



```{r}
##########################################################################
# Assess AIC, BIC, and LogLik from all models
##########################################################################
##########################################################################
# HIERARCHICAL COMPLEXITY APPROACH - MODEL STATISTICS EXTRACTION
##########################################################################

# Load the combined model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

##########################################################################
# Function to extract AIC, BIC, and LogLik from all models
##########################################################################
extract_model_stats <- function(models, response_variable) {
  stats <- data.frame(
    Model = character(),
    AIC = numeric(),
    BIC = numeric(),
    LogLik = numeric(),
    ResponseVariable = character(),
    stringsAsFactors = FALSE
  )

  # Helper function to safely extract stats
  get_stats <- function(model) {
    if (!is.null(model)) {
      return(c(
        AIC = tryCatch(AIC(model), error = function(e) NA),
        BIC = tryCatch(BIC(model), error = function(e) NA),
        LogLik = tryCatch(logLik(model), error = function(e) NA)
      ))
    } else {
      return(c(AIC = NA, BIC = NA, LogLik = NA))
    }
  }

  # Add model statistics if available
  if (!is.null(models$null_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Null Model",
      t(get_stats(models$null_model)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$minimal_random_effects)) {
    stats <- rbind(stats, data.frame(
      Model = "Minimal Random Effects",
      t(get_stats(models$minimal_random_effects)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$moderator_models)) {
    for (moderator in names(models$moderator_models)) {
      mod <- models$moderator_models[[moderator]]
      stats <- rbind(stats, data.frame(
        Model = paste("Moderator -", moderator),
        t(get_stats(mod)),
        ResponseVariable = response_variable
      ))
    }
  }

  if (!is.null(models$full_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Full Model",
      t(get_stats(models$full_model)),
      ResponseVariable = response_variable
    ))
  }

  if (!is.null(models$interaction_model)) {
    stats <- rbind(stats, data.frame(
      Model = "Interaction Model",
      t(get_stats(models$interaction_model)),
      ResponseVariable = response_variable
    ))
  }

  return(stats)
}

##########################################################################
# Extract model statistics for all response variables
##########################################################################
all_model_stats <- do.call(rbind, lapply(names(model_results), function(response) {
  extract_model_stats(models = model_results[[response]], response_variable = response)
}))

all_model_stats |> glimpse()
```

```{r}
##########################################################################
# Calculate relative AIC difference compared to Null Model for each response variable
relative_aic <- all_model_stats |> 
  group_by(ResponseVariable) |> 
  mutate(RelativeAIC = AIC - AIC[Model == "Null Model"]) |> 
  ungroup()

relative_aic


# Define the file path for saving
output_file <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "relative_aic.xlsx")
# Save the dataframe to an Excel file
write.xlsx(relative_aic, file = output_file, row.names = FALSE)
cat("The relative AIC data has been saved to:", output_file, "\n")

##########################################################################
```

```{r}
##########################################################################
# Create publication-ready visualizations for AIC with faceting - focusing on comparing across models
##########################################################################

# Plot AIC values for all models with faceting
plot_aic <- all_model_stats |> 
  ggplot(aes(x = ResponseVariable, y = AIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Model, scales = "free_y") +
  coord_flip() +
  labs(
    title = "Model AIC Values Across Response Variables",
    x = "Response Variable",
    y = "AIC",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold")
  )

plot_aic

##########################################################################
# Modify plot to use pseudo-log-scale on the y-axis with faceting
##########################################################################

plot_aic_log <- all_model_stats |> 
  ggplot(aes(x = ResponseVariable, y = log10(AIC), fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ Model, scales = "free_y") +
  coord_flip() +
  labs(
    title = "Model AIC Values Across Response Variables (Log Scale)",
    x = "Response Variable",
    y = "Log10(AIC)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16),
    strip.text = element_text(face = "bold")
  )

plot_aic_log
```

```{r}
##########################################################################
# Create publication-ready visualizations for AIC - focusing on comparing across response variables
##########################################################################

# Plot AIC values for all models
plot_aic_models <- all_model_stats |> 
  ggplot(aes(x = fct_reorder(Model, AIC), y = AIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ ResponseVariable, scales = "free_x") +
  labs(
    title = "Model AIC Values Across Response Variables",
    x = "Models",
    y = "AIC",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_aic_models

# Modify plot to use pseudo-log-scale on the x-axis (log-transformed AIC)
plot_aic_log_models <- all_model_stats |> 
  ggplot(aes(x = fct_reorder(Model, AIC), y = log10(AIC), fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ ResponseVariable, scales = "free_x") +
  labs(
    title = "Model AIC Values Across Response Variables (Log Scale)",
    x = "Models",
    y = "Log10(AIC)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_aic_log_models
```


```{r}
##########################################################################
# Create publication-ready visualizations - focusing specifically on relative AIC difference
##########################################################################

# Plot relative AIC values for all models
plot_relative_aic <- relative_aic |> 
  ggplot(aes(x = Model, y = RelativeAIC, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  coord_flip() +
  facet_wrap(~ResponseVariable, scales = "free_x") +
  labs(
    title = "Relative AIC Difference Across Models (Compared to Null Model)",
    x = "Models",
    y = "Relative AIC (Difference from Null Model)",
    fill = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(face = "bold", size = 16)
  )

plot_relative_aic
```

Streamlined Interpretation of AIC Values

The relative AIC values provide a comparison of model performance against the Null Model for each response variable. Negative relative AIC values indicate better model performance, while positive values indicate poorer performance. For `Product Quality` and `Water Quality`, the absolute AIC values (which were negative) require special attention, as positive relative differences in these cases reflect better model performance.

**Key Insights by Response Variable:**

1. **Biodiversity:**
   - Both the `Full Model` and `Interaction Model` demonstrate significantly better performance than the Null Model, with **relative AIC values of -656** and **-645**, respectively, underscoring the importance of moderators in explaining biodiversity outcomes.
   - The `Minimal Random Effects Model` shows no improvement over the Null Model, indicating that adding random effects alone does not enhance performance.

2. **Crop Yield:**
   - The `Interaction Model` and the `Full Model` show substantial improvements over the Null Model, with **relative AIC values of -1191** and **-894**, respectively. This highlights the critical role of both moderators and their interactions in explaining crop yield variability.
   - The `Null Model` and `Minimal Random Effects Model` perform identically, showing no added value from random effects alone.

3. **Greenhouse Gas Emissions:**
   - The `Full Model` and `Interaction Model` exhibit **exceptional improvements** over the Null Model, with **relative AIC values of -3156** and **-3150**, respectively. These results emphasize the necessity of including multiple moderators to capture the complex dynamics of emissions data.
   - Similar to crop yield, the `Minimal Random Effects Model` offers no improvement over the Null Model.

4. **Pest and Disease:**
   - Both the `Full Model` and the `Interaction Model` show improved performance, with **relative AIC values of -391** and **-392**, respectively, demonstrating the value of including moderators for pest and disease data.
   - However, interactions between moderators (captured in the `Interaction Model`) do not improve the relative AIC further, indicating that the additional complexity is unnecessary.
   - The `Minimal Random Effects Model` performs comparably to the Null Model.

5. **Product Quality:**
   - Positive relative AIC values for the `Interaction Model` (**84**) and the `Full Model` (**44**) indicate that these models outperform the Null Model in terms of absolute AIC values, contrary to initial expectations.
   - The `Interaction Model` shows the greatest improvement, indicating that capturing interactions between moderators is essential for better explaining product quality outcomes.
   - The `Minimal Random Effects Model` performs similarly to the Null Model, offering no substantial benefit.

6. **Soil Quality:**
   - The `Full Model` demonstrates a substantial improvement with a **relative AIC value of -950**, indicating that capturing high complexity significantly enhances model performance for soil quality.
   - The absence of data for the `Interaction Model` suggests potential model-fitting issues when including interactions among moderators.
   - The `Minimal Random Effects Model` adds no value compared to the Null Model.

7. **Water Quality:**
   - Positive relative AIC values for the `Interaction Model` (**19**) and the `Full Model` (**19**) suggest these models outperform the Null Model in terms of absolute AIC values, similar to product quality.
   - The additional complexity of interactions between moderators does not further improve performance, as seen in the similar relative AIC values for the `Full Model` and `Interaction Model`.
   - The `Minimal Random Effects Model` again shows no improvement over the Null Model.

**General Observations:**
- **Complex models like the Full and Interaction Models generally outperform simpler models**, especially for complex response variables such as greenhouse gas emissions, crop yield, and biodiversity.
- **Product Quality and Water Quality require attention to absolute AIC values**, as positive relative AIC values reflect better performance due to negative absolute AICs.
- Moderators play a critical role in improving model performance, but their interactions are selectively important, as shown for product quality and crop yield.

Implications:
This refined analysis confirms the importance of tailoring model complexity and moderator interactions to specific response variables. While complex models are crucial for variables with significant variability or interactions, simpler models suffice for others, provided they capture the essential dynamics.


```{r}
##########################################################################################################################################
# Add Relative BIC and Adjust Selection Criteria
##########################################################################################################################################

# Add Relative BIC to the dataset
relative_aic_with_bic <- relative_aic |> 
  group_by(ResponseVariable) |> 
  mutate(RelativeBIC = BIC - BIC[Model == "Null Model"]) |> 
  ungroup()

# Adjust relative AIC and BIC for Product Quality and Water Quality
relative_aic_bic_adjusted <- relative_aic_with_bic |> 
  mutate(
    AdjustedRelativeAIC = case_when(
      ResponseVariable %in% c("Product quality", "Water quality") ~ -RelativeAIC, # Flip sign for these variables
      TRUE ~ RelativeAIC
    ),
    AdjustedRelativeBIC = case_when(
      ResponseVariable %in% c("Product quality", "Water quality") ~ -RelativeBIC, # Flip sign for these variables
      TRUE ~ RelativeBIC
    )
  )

# Calculate mean adjusted relative AIC and BIC across all response variables for each model
model_performance_adjusted <- relative_aic_bic_adjusted |> 
  group_by(Model) |> 
  summarise(
    MeanAdjustedRelativeAIC = mean(AdjustedRelativeAIC, na.rm = TRUE),
    MeanAdjustedRelativeBIC = mean(AdjustedRelativeBIC, na.rm = TRUE)
  ) |> 
  arrange(MeanAdjustedRelativeAIC, MeanAdjustedRelativeBIC)

# Identify the overall best-performing model based on adjusted criteria
best_model_adjusted <- model_performance_adjusted |> slice(1)

# Display the adjusted performance summary
model_performance_adjusted

# Highlight the adjusted best-performing model
best_model_adjusted
```

The model performance analysis indicates that the **Interaction Model** consistently outperforms all other models, achieving the lowest mean adjusted relative AIC (-913.72) and BIC (-892.45) across all response variables. This result demonstrates that accounting for interactions among moderators is crucial for capturing the complexities of the data and delivering the most explanatory power.

The **Full Model**, which includes all main effects of moderators but excludes interactions, ranks second with a mean adjusted relative AIC of -871.91 and BIC of -861.33. While it provides substantial improvements over simpler models, it falls short of the Interaction Model due to its inability to account for nuanced interactions among variables.

Among individual moderator models, `age_system` shows the most significant improvement in performance, followed by `crop_type`, `tree_type`, and `soil_texture`. These moderators enhance explanatory power to varying degrees but remain less impactful compared to the comprehensive models. The `season` moderator provides only limited improvement, indicating its minimal relevance across the response variables.

Baseline models, including the **Minimal Random Effects Model** and the **Null Model**, perform identically and fail to capture meaningful variability. Their lack of improvement underscores the necessity of incorporating moderators and interactions for effective model performance.

Overall, the results highlight the superiority of the Interaction Model, emphasizing the importance of capturing complex relationships among moderators to explain variations across the response variables effectively. Simpler models, while informative in specific contexts, are insufficient for fully addressing the intricacies of the data.



```{r}
##########################################################################################################################################
# Function to Back-Transform log-ROM to ROM in Percentage for All Response Variables
##########################################################################################################################################

# Define the function
back_transform_logROM <- function(evaluation_results) {
  # Initialize an empty list to store back-transformed results
  back_transformed_results <- list()

  # Iterate through each response variable in evaluation_results
  for (response in names(evaluation_results)) {
    cat("Processing response variable:", response, "\n")

    # Extract models for the response variable
    models <- evaluation_results[[response]]

    # Initialize a list to store back-transformed values for this response variable
    response_results <- list()

    # Define a helper function to back-transform log-ROM values
    back_transform <- function(estimate, ci.lb, ci.ub) {
      list(
        ROM_percent = (exp(estimate) - 1) * 100,  # Convert to percentage
        ROM_lower_percent = (exp(ci.lb) - 1) * 100,
        ROM_upper_percent = (exp(ci.ub) - 1) * 100
      )
    }

    # Iterate through all models (null, minimal, moderators, full, interaction)
    for (model_name in names(models)) {
      model <- models[[model_name]]

      # Skip if the model is NULL
      if (is.null(model)) {
        response_results[[model_name]] <- NULL
        next
      }

      # Extract estimates and confidence intervals
      if (!is.null(model$b)) {
        response_results[[model_name]] <- back_transform(
          estimate = model$b[1],
          ci.lb = model$ci.lb[1],
          ci.ub = model$ci.ub[1]
        )
      } else {
        response_results[[model_name]] <- NULL
      }
    }

    # Store the back-transformed results for this response variable
    back_transformed_results[[response]] <- response_results
  }

  return(back_transformed_results)
}

##########################################################################################################################################
# Example: Apply the function to evaluation_results
##########################################################################################################################################

# Assuming evaluation_results is already loaded
back_transformed_results <- back_transform_logROM(evaluation_results)

# Inspect the back-transformed results for a specific response variable
print(back_transformed_results$Biodiversity)

##########################################################################################################################################
```
Interpretation of the back-transformed values (ROM in percentages) for all response variables


### Interpretation of Back-Transformed Values (ROM in Percentages)

The back-transformed Ratio of Means (ROM) values provide an interpretable measure of effect sizes for all response variables. These percentages allow us to assess how the system impacts different response variables compared to controls, including associated uncertainty (confidence intervals).

---

### **1. Biodiversity**
- **Null Model:** **4.42%** [CI: -1.25%, 10.42%]  
  Biodiversity is estimated to increase by **4.42%**, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **4.42%** [CI: -1.25%, 10.42%]  
  Identical to the null model, suggesting no improvement by accounting for random effects.  
- **Full Model:** **-7.28%** [CI: -57.80%, 103.74%]  
  Indicates a **7.28% decrease**, but the very wide CI reflects high uncertainty and potential overfitting.  
- **Interaction Model:** **-2.84%** [CI: -46.59%, 76.75%]  
  Shows a **2.84% decrease**, with a similarly wide and uncertain CI.

---

### **2. Greenhouse Gas Emissions**
- **Null Model:** **0.94%** [CI: 0.69%, 1.20%]  
  A minimal and statistically significant increase in emissions, reflecting consistent results across the CI.  
- **Minimal Random Effects Model:** **0.94%** [CI: 0.69%, 1.20%]  
  No improvement over the null model.  
- **Full Model:** **25.73%** [CI: 14.49%, 38.06%]  
  A large, statistically significant increase in emissions, highlighting the importance of moderators in explaining variability.  
- **Interaction Model:** **25.58%** [CI: 14.29%, 37.98%]  
  Similar to the full model, demonstrating consistency with added interactions.

---

### **3. Product Quality**
- **Null Model:** **-2.00%** [CI: -3.66%, -0.32%]  
  A small, statistically significant decrease in product quality.  
- **Minimal Random Effects Model:** **-2.00%** [CI: -3.66%, -0.32%]  
  Identical to the null model, indicating no improvement.  
- **Full Model:** **-1.71%** [CI: -6.31%, 3.13%]  
  A smaller decrease, but with a CI including zero, indicating no significant effect.  
- **Interaction Model:** **-0.80%** [CI: -5.30%, 3.92%]  
  The smallest effect with high uncertainty, suggesting minimal influence of moderator interactions.

---

### **4. Crop Yield**
- **Null Model:** **-2.28%** [CI: -4.40%, -0.11%]  
  A small but statistically significant decrease in yield.  
- **Minimal Random Effects Model:** **-2.28%** [CI: -4.40%, -0.11%]  
  Identical to the null model.  
- **Full Model:** **-1.67%** [CI: -6.34%, 3.24%]  
  A smaller decrease, but the CI includes zero, showing no significant effect.  
- **Interaction Model:** **-25.28%** [CI: -36.39%, -12.24%]  
  A large and significant decrease, highlighting the strong effect of interactions among moderators.

---

### **5. Pest and Disease**
- **Null Model:** **-8.67%** [CI: -24.89%, 11.05%]  
  A modest decrease, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **-8.67%** [CI: -24.89%, 11.05%]  
  Identical to the null model.  
- **Full Model:** **-40.47%** [CI: -64.04%, -1.46%]  
  A large, statistically significant decrease, showing the impact of moderators.  
- **Interaction Model:** **-40.47%** [CI: -64.04%, -1.46%]  
  Identical to the full model, suggesting interactions add no further value.

---

### **6. Soil Quality**
- **Null Model:** **3.37%** [CI: -1.14%, 8.08%]  
  A small increase, but the CI includes zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **3.37%** [CI: -1.14%, 8.08%]  
  No improvement over the null model.  
- **Full Model:** **-33.61%** [CI: -54.09%, -3.98%]  
  A large and statistically significant decrease, reflecting the critical role of moderators.

---

### **7. Water Quality**
- **Null Model:** **1.56%** [CI: -1.35%, 4.56%]  
  A small increase, with the CI including zero, indicating no significant effect.  
- **Minimal Random Effects Model:** **1.56%** [CI: -1.35%, 4.56%]  
  Identical to the null model.  
- **Full Model:** **2.69%** [CI: -10.40%, 17.68%]  
  A slightly larger increase, but the wide CI reflects high uncertainty.  
- **Interaction Model:** **2.69%** [CI: -10.40%, 17.68%]  
  Identical to the full model, suggesting interactions add no value.

---

### **General Observations**
1. **Simple Models (Null, Minimal Random Effects):** These provide consistent but limited insights, often failing to capture significant effects.
2. **Full Model:** This generally improves fit, revealing significant effects for variables like `Greenhouse Gas Emissions`, `Pest and Disease`, and `Soil Quality`.
3. **Interaction Model:** Adds minimal value beyond the full model for most variables, except for `Crop Yield`.

---

### **Conclusions**
- **Greenhouse Gas Emissions** and **Pest and Disease** see the most substantial improvements with complex models, reflecting the value of moderators.  
- **Biodiversity**, **Product Quality**, and **Water Quality** remain uncertain, with wide CIs indicating potential data limitations or overfitting.  
- Simplified models suffice for some variables, but full models are critical for uncovering nuanced effects in others.


```{r}
##########################################################################################################################################
# Combine Raw Effect Sizes and Back-Transformed Values into a Structured Data Frame
##########################################################################################################################################

# Function to create a structured data frame
combine_effect_sizes <- function(evaluation_results, back_transformed_results) {
  combined_results <- data.frame(
    ResponseVariable = character(),
    Model = character(),
    Estimate = numeric(),
    CI_Lower = numeric(),
    CI_Upper = numeric(),
    P_Value = character(),
    Significance = character(),
    ROM_Percent = numeric(),
    ROM_Lower_Percent = numeric(),
    ROM_Upper_Percent = numeric(),
    stringsAsFactors = FALSE
  )

  for (response in names(evaluation_results)) {
    models <- evaluation_results[[response]]
    back_transformed <- back_transformed_results[[response]]

    for (model_name in names(models)) {
      model <- models[[model_name]]
      if (!is.null(model) && !is.null(model$b) && !is.null(model$ci.lb) && !is.null(model$pval)) {
        p_value <- ifelse(model$pval[1] < 0.001, "<0.001", formatC(model$pval[1], format = "f", digits = 3))
        significance <- if (model$pval[1] < 0.001) {
          "***"
        } else if (model$pval[1] < 0.01) {
          "**"
        } else if (model$pval[1] < 0.05) {
          "*"
        } else if (model$pval[1] < 0.1) {
          "."
        } else {
          " "
        }

        combined_results <- rbind(combined_results, data.frame(
          ResponseVariable = response,
          Model = model_name,
          Estimate = model$b[1],
          CI_Lower = model$ci.lb[1],
          CI_Upper = model$ci.ub[1],
          P_Value = p_value,
          Significance = significance,
          ROM_Percent = back_transformed[[model_name]]$ROM_percent,
          ROM_Lower_Percent = back_transformed[[model_name]]$ROM_lower_percent,
          ROM_Upper_Percent = back_transformed[[model_name]]$ROM_upper_percent
        ))
      }
    }
  }

  return(combined_results)
}

# Apply the function
structured_results <- combine_effect_sizes(evaluation_results, back_transformed_results)

# Inspect the structured data frame
structured_results |> glimpse()
```


```{r}
##########################################################################################################################################
# Create a Publication-Ready gt Table for Back-Transformed Values
##########################################################################################################################################


# Function to create a gt table for ROM values
create_gt_table <- function(data) {
  data |> 
    dplyr::select(ResponseVariable, Model, ROM_Percent, ROM_Lower_Percent, ROM_Upper_Percent, P_Value, Significance) |> 
    gt() |> 
    tab_header(
      title = "Back-Transformed Values (ROM in Percentages)",
      subtitle = "Includes Estimates, Confidence Intervals, P-Values, and Significance Levels"
    ) |> 
    cols_label(
      ResponseVariable = "Response Variable",
      Model = "Model",
      ROM_Percent = "ROM (%)",
      ROM_Lower_Percent = "Lower CI (%)",
      ROM_Upper_Percent = "Upper CI (%)",
      P_Value = "P-Value",
      Significance = "Significance"
    ) |> 
    fmt_number(
      columns = c(ROM_Percent, ROM_Lower_Percent, ROM_Upper_Percent),
      decimals = 2
    ) |> 
    tab_options(
      table.font.size = "small",
      heading.align = "center"
    )
}

# Create the gt table
back_transformed_table <- create_gt_table(structured_results)

# Render the table
back_transformed_table
```


```{r}
##########################################################################################################################################
# Filter for the Best-Performing Model (Interaction Model) and Create a gt Table
##########################################################################################################################################

# Filter structured results for the Interaction Model
best_model_results <- structured_results |> 
  dplyr::filter(Model == "interaction_model")

# Create the gt table for the Interaction Model
best_model_gt_table <- create_gt_table(best_model_results) |> 
  cols_hide("Model")

# Render the table
best_model_gt_table
```



##########################################################################################################################################
# SECTION 1: META-ANALYSIS DIAGNOSTICS 
##########################################################################################################################################

```{r}
# model_results |> str()
# model_results$`Crop yield` |> str()

model_results$`Crop yield`
```



```{r}
##########################################################################################################################################
# A: Extract heterogeneity statistics for each response variable
##########################################################################################################################################
extract_heterogeneity_stats <- function(model_results) {
  heterogeneity_stats <- lapply(names(model_results), function(response) {
    
    model <- model_results[[response]]$full_model   # <------------------------------- !(chosen model)!
    if (is.null(model)) return(NULL)

    # Calculate I2 manually if tau2 is 0
    QE <- model$QE
    df <- model$QEdf
    I2 <- if (QE > df) (QE - df) / QE * 100 else 0

    data.frame(
      Response_Variable = response,
      I2 = I2,
      Tau2 = model$tau2,
      QE = QE,
      QE_pval = model$QEp,
      stringsAsFactors = FALSE
    )
  })

  # Combine results into a single data frame
  do.call(rbind, heterogeneity_stats)
}

# Extract heterogeneity statistics
heterogeneity_stats <- extract_heterogeneity_stats(model_results)

# Inspect the results
heterogeneity_stats
```

Crop yield	NA	0	203339.1624	      null_model
Crop yield	NA	0	95862.5010        interaction_model
Crop yield	99.80134	0	134398.4729	full_model

The results of the heterogeneity statistics indicate the following:

1. **I² Values:**
   - The I² values range from 36% (Product quality) to 99.98% (Biodiversity), suggesting varying levels of heterogeneity across response variables.
   - High I² values (close to 100%) for most response variables (e.g., Biodiversity, Crop yield, Pest and Disease, Soil quality) indicate that a large proportion of the variability in effect sizes is due to heterogeneity rather than sampling error.
   - Moderate I² for Product quality (36.01%) suggests less heterogeneity, with sampling error accounting for most of the variability.

2. **Tau² (Between-Study Variance):**
   - All Tau² values are `0`, indicating no estimated between-study variance in the random-effects models. This could suggest either true homogeneity of effect sizes or insufficient power to detect between-study variance.

3. **QE (Cochran's Q Test):**
   - QE values are very high for most response variables, particularly for Biodiversity, Crop yield, and Soil quality, suggesting significant residual heterogeneity not explained by the model. The associated QE p-values (<0.001 for all) confirm that the observed heterogeneity is statistically significant.

4. **Implications:**
   - The high I² values, combined with significant QE tests and zero Tau², indicate that heterogeneity exists, but it is not being captured by the random-effects variance component (Tau²). This suggests that other moderators or model structures may need to be explored to better explain the variability.

5. **Recommendations:**
   - For variables with very high I² and significant QE (e.g., Biodiversity, Crop yield, Soil quality), consider including additional moderators or interaction terms in the model to account for heterogeneity.
   - For Product quality (lower I²), the model seems to explain a reasonable proportion of variability, though further exploration of moderators could still be beneficial.

In summary, while the models reveal significant heterogeneity across most response variables, the lack of between-study variance (Tau² = 0) suggests that additional moderators or refinements to model specifications may be required to better account for the observed variability.


```{r}
##########################################################################################################################################
# B: Assess publication bias using funnel plots and Egger's test
##########################################################################################################################################
assess_publication_bias <- function(model_results) {
  publication_bias <- lapply(names(model_results), function(response) {
    
    model <- model_results[[response]]$interaction_model  # <------------------------------- !(chosen model)!
    if (is.null(model)) return(NULL)

    # Perform Egger's test
    egger_test <- tryCatch({
      regtest(model, model = "lm")
    }, error = function(e) {
      return(NULL)
    })

    # Generate funnel plot
    funnel_plot <- tryCatch({
      funnel(model)
    }, error = function(e) {
      return(NULL)
    })

    list(
      Response_Variable = response,
      Egger_p_value = if (!is.null(egger_test)) sprintf("%.3f", egger_test$pval) else NA,
      Funnel_Plot = funnel_plot
    )
  })

  # Combine into a data frame for easier inspection
  publication_bias_summary <- do.call(rbind, lapply(publication_bias, function(x) {
    if (!is.null(x)) {
      data.frame(
        Response_Variable = x$Response_Variable,
        Egger_p_value = x$Egger_p_value
      )
    }
  }))

  list(Summary = publication_bias_summary, Full_Results = publication_bias)
}

# Assess publication bias
publication_bias_results <- assess_publication_bias(model_results)
```

```{r}
##########################################################################################################################################
# C: Conduct leave-one-out sensitivity analysis
##########################################################################################################################################
conduct_sensitivity_analysis <- function(model_results) {
  sensitivity_analysis <- lapply(names(model_results), function(response) {
    
    model <- model_results[[response]]$interaction_model  # <------------------------------- !(chosen model)!
    if (is.null(model)) return(NULL)

    # Perform leave-one-out sensitivity analysis
    leave_one_out <- tryCatch({
      leave1out(model)
    }, error = function(e) {
      return(NULL)
    })

    list(
      Response_Variable = response,
      Leave_One_Out_Results = leave_one_out
    )
  })

  # Combine into a data frame for easier inspection
  sensitivity_summary <- do.call(rbind, lapply(sensitivity_analysis, function(x) {
    if (!is.null(x)) {
      data.frame(
        Response_Variable = x$Response_Variable,
        Leave_One_Out_Count = if (!is.null(x$Leave_One_Out_Results)) nrow(x$Leave_One_Out_Results) else 0
      )
    }
  }))

  list(Summary = sensitivity_summary, Full_Results = sensitivity_analysis)
}

# Conduct sensitivity analysis
sensitivity_analysis_results <- conduct_sensitivity_analysis(model_results)
```


```{r}
##########################################################################################################################################
# Combine All Diagnostics Results
##########################################################################################################################################
meta_analysis_diagnostics <- list(
  Heterogeneity_Stats = heterogeneity_stats,
  Publication_Bias_Summary = publication_bias_results$Summary,
  Sensitivity_Analysis_Summary = sensitivity_analysis_results$Summary,
  Publication_Bias_Details = publication_bias_results$Full_Results,
  Sensitivity_Analysis_Details = sensitivity_analysis_results$Full_Results
)

# Inspect results
meta_analysis_diagnostics$Heterogeneity_Stats
meta_analysis_diagnostics$Publication_Bias_Summary
meta_analysis_diagnostics$Sensitivity_Analysis_Summary
```



















```{r}
##########################################################################################################################################
# SECTION 2: INFLUENCE OF SILVOARABLE AGROFORESTRY CHARACTERISTICS (MODERATORS)
##########################################################################################################################################

# 2a: Extract influence of higher-level and sub-level moderators
moderator_effects <- lapply(names(model_results), function(response) {
  lapply(model_results[[response]]$moderator_models, function(model, moderator) {
    if (is.null(model)) return(NULL)

    # Extract coefficients, confidence intervals, and p-values
    summary_stats <- summary(model)
    data.frame(
      Response_Variable = response,
      Moderator = moderator,
      Effect_Size = summary_stats$beta,
      CI_Lower = summary_stats$ci.lb,
      CI_Upper = summary_stats$ci.ub,
      P_Value = summary_stats$pval
    )
  }, names(model_results[[response]]$moderator_models)) %>% bind_rows()
}) %>% bind_rows()

# 2b: Evaluate the proportion of heterogeneity explained by each moderator
heterogeneity_reduction <- lapply(names(model_results), function(response) {
  lapply(model_results[[response]]$moderator_models, function(model, moderator) {
    if (is.null(model)) return(NULL)

    # Extract heterogeneity metrics
    summary_stats <- summary(model)
    i2 <- summary_stats$I2
    tau2 <- summary_stats$tau2

    data.frame(
      Response_Variable = response,
      Moderator = moderator,
      I2 = i2,
      Tau2 = tau2
    )
  }, names(model_results[[response]]$moderator_models)) %>% bind_rows()
}) %>% bind_rows()

##########################################################################################################################################
# SAVE AND REPORT RESULTS
##########################################################################################################################################

# Save results to CSV files
write.csv(overall_effects, "overall_effects.csv", row.names = FALSE)
write.csv(heterogeneity_stats, "heterogeneity_stats.csv", row.names = FALSE)
write.csv(moderator_effects, "moderator_effects.csv", row.names = FALSE)
write.csv(heterogeneity_reduction, "heterogeneity_reduction.csv", row.names = FALSE)

# Print outputs for verification
list(
  Overall_Effects = overall_effects,
  Heterogeneity_Stats = heterogeneity_stats,
  Publication_Bias = publication_bias,
  Sensitivity_Analysis = sensitivity_analysis,
  Moderator_Effects = moderator_effects,
  Heterogeneity_Reduction = heterogeneity_reduction
)
```




























```{r}
# Extracting and displaying model summaries
model_summaries <- lapply(model_results, function(response_models) {
  # Create a summary for each model
  lapply(response_models, function(model) {
    if (!is.null(model)) {
      summary(model)  # Summarize the model
    }
  })
})

# To view summaries for a specific model, you can access like this:
print(model_summaries[["Biodiversity"]][["A_null"]])  # Example for a model summary

# To save the summary outputs as a list, you can also save them to files if needed
# For instance, for "Biodiversity" response models:
# write.csv(as.data.frame(model_summaries[["Biodiversity"]]), file = "biodiversity_model_summary.csv")
```

```{r}
# Model Summaries for A_null (Intercept-only model)

model_summaries$`Crop yield`$A_null                        # Crop Yield Model
model_summaries$Biodiversity$A_null                        # Biodiversity Model
model_summaries$`Greenhouse gas emission`$A_null           # Greenhouse Gas Emission Model
model_summaries$`Product quality`$A_null                   # Product Quality Model
model_summaries$`Pest and Disease`$A_null                  # Pest and Disease Model
model_summaries$`Soil quality`$A_null                      # Soil Quality Model
model_summaries$`Water quality`$A_null                     # Water Quality Model


# Model Summaries for B_minimal_random_incremental (Minimal random effects model)

model_summaries$`Crop yield`$B_minimal_random_incremental   # Crop Yield Model
model_summaries$Biodiversity$B_minimal_random_incremental   # Biodiversity Model
model_summaries$`Greenhouse gas emission`$B_minimal_random_incremental  # Greenhouse Gas Emission Model
model_summaries$`Product quality`$B_minimal_random_incremental    # Product Quality Model
model_summaries$`Pest and Disease`$B_minimal_random_incremental   # Pest and Disease Model
model_summaries$`Soil quality`$B_minimal_random_incremental       # Soil Quality Model
model_summaries$`Water quality`$B_minimal_random_incremental      # Water Quality Model


# # Model Summaries for C_incremental_no_random_incremental (Incremental model without random effects)
# 
# model_summaries$`Crop yield`$C_incremental_no_random_incremental   # Crop Yield Model
# model_summaries$Biodiversity$C_incremental_no_random_incremental   # Biodiversity Model
# model_summaries$`Greenhouse gas emission`$C_incremental_no_random_incremental  # Greenhouse Gas Emission Model
# model_summaries$`Product quality`$C_incremental_no_random_incremental    # Product Quality Model
# model_summaries$`Pest and Disease`$C_incremental_no_random_incremental   # Pest and Disease Model
# model_summaries$`Soil quality`$C_incremental_no_random_incremental       # Soil Quality Model
# model_summaries$`Water quality`$C_incremental_no_random_incremental      # Water Quality Model
# 
# 
# # Model Summaries for D_incremental_random_incremental (Incremental model with random effects)
# 
# model_summaries$`Crop yield`$D_incremental_random_incremental          # Crop Yield Model
# model_summaries$Biodiversity$D_incremental_random_incremental          # Biodiversity Model
# model_summaries$`Greenhouse gas emission`$D_incremental_random_incremental  # Greenhouse Gas Emission Model
# model_summaries$`Product quality`$D_incremental_random_incremental     # Product Quality Model
# model_summaries$`Pest and Disease`$D_incremental_random_incremental    # Pest and Disease Model
# model_summaries$`Soil quality`$D_incremental_random_incremental        # Soil Quality Model
# model_summaries$`Water quality`$D_incremental_random_incremental       # Water Quality Model


# Model Summaries for E_intercept_fixed_random_incremental (Intercept-fixed with random effects)

model_summaries$`Crop yield`$E_intercept_fixed_random_incremental      # Crop Yield Model
model_summaries$Biodiversity$E_intercept_fixed_random_incremental      # Biodiversity Model
model_summaries$`Greenhouse gas emission`$E_intercept_fixed_random_incremental # Greenhouse Gas Emission Model
model_summaries$`Product quality`$E_intercept_fixed_random_incremental # Product Quality Model
model_summaries$`Pest and Disease`$E_intercept_fixed_random_incremental # Pest and Disease Model
model_summaries$`Soil quality`$E_intercept_fixed_random_incremental    # Soil Quality Model
model_summaries$`Water quality`$E_intercept_fixed_random_incremental   # Water Quality Model
```

```{r}
logLik_ml <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$fit.stats$ML
logLik_reml <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$fit.stats$REML

k <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$parms

n <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$data$id_article
sample_size <- length(unique(n))  # Or directly use n if it's stored elsewhere


# For AIC (Maximum Likelihood or REML)
AIC_ml <- 2 * k - 2 * logLik_ml
AIC_reml <- 2 * k - 2 * logLik_reml

# For BIC (Maximum Likelihood or REML)
BIC_ml <- log(sample_size) * k - 2 * logLik_ml
BIC_reml <- log(sample_size) * k - 2 * logLik_reml

logLik_ml <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$fit.stats$ML
logLik_reml <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$fit.stats$REML
k <- model_summaries$`Water quality`$E_intercept_fixed_random_incremental$parms
n <- length(model_summaries$`Water quality`$E_intercept_fixed_random_incremental$data$id_article)

# Calculate AIC and BIC for both ML and REML
AIC_ml <- 2 * k - 2 * logLik_ml
AIC_reml <- 2 * k - 2 * logLik_reml

BIC_ml <- log(n) * k - 2 * logLik_ml
BIC_reml <- log(n) * k - 2 * logLik_reml

# Display AIC and BIC for both methods
list(AIC_ml = AIC_ml, AIC_reml = AIC_reml, BIC_ml = BIC_ml, BIC_reml = BIC_reml)

```
```{r}
# Define the function
extract_model_metrics <- function(model_summaries, response_vars, models = c("A_null", "B_minimal_random_incremental", "E_intercept_fixed_random_incremental")) {
  
  # Initialize an empty list to store metrics
  metrics_list <- list()

  # Loop over all response variables and models
  for (response in response_vars) {
    metrics_list[[response]] <- list()  # Create an entry for each response variable

    for (model in models) {
      model_key <- paste(response, model, sep = "$")
      
      # Extract necessary components from model summaries
      logLik_ml <- model_summaries[[response]][[model]]$fit.stats$ML
      logLik_reml <- model_summaries[[response]][[model]]$fit.stats$REML
      k <- model_summaries[[response]][[model]]$parms
      n <- length(model_summaries[[response]][[model]]$data$id_article)
      
      # Calculate AIC and BIC for both ML and REML
      AIC_ml <- 2 * k - 2 * logLik_ml
      AIC_reml <- 2 * k - 2 * logLik_reml
      BIC_ml <- log(n) * k - 2 * logLik_ml
      BIC_reml <- log(n) * k - 2 * logLik_reml

      # Store the metrics in the response model entry
      metrics_list[[response]][[model]] <- list(
        AIC_ml = AIC_ml,
        AIC_reml = AIC_reml,
        BIC_ml = BIC_ml,
        BIC_reml = BIC_reml
      )
    }
  }
  
  return(metrics_list)
}

# Example usage:
response_vars <- c("Biodiversity", "Greenhouse gas emission", "Product quality", "Crop yield", "Pest and Disease", "Soil quality", "Water quality")

# Call the function with your model summaries
model_metrics <- extract_model_metrics(model_summaries, response_vars)

model_metrics
```
```{r}
# Create an empty dataframe to store the results
metrics_df <- data.frame(
  Category = character(),
  Model = character(),
  AIC_ml_first = numeric(),
  AIC_reml_first = numeric(),
  BIC_ml_first = numeric(),
  BIC_reml_first = numeric(),
  stringsAsFactors = FALSE
)

# Define the categories to extract
categories <- c("Biodiversity", "Greenhouse gas emission", "Product quality", 
                "Crop yield", "Pest and Disease", "Soil quality", "Water quality")

# Loop through each category to extract the first number of each metric
for (category in categories) {
  # Access the nested metrics within each category
  category_metrics <- model_metrics[[category]]
  
  # Loop through each model within the category
  for (model_name in names(category_metrics)) {
    # Extract the first number for each metric
    AIC_ml_first <- category_metrics[[model_name]]$AIC_ml[1]
    AIC_reml_first <- category_metrics[[model_name]]$AIC_reml[1]
    BIC_ml_first <- category_metrics[[model_name]]$BIC_ml[1]
    BIC_reml_first <- category_metrics[[model_name]]$BIC_reml[1]
    
    # Add the extracted values along with the model name to the dataframe
    metrics_df <- rbind(metrics_df, data.frame(
      Category = category,
      Model = model_name,
      AIC_ml_first = AIC_ml_first,
      AIC_reml_first = AIC_reml_first,
      BIC_ml_first = BIC_ml_first,
      BIC_reml_first = BIC_reml_first
    ))
  }
}

metrics_df <- metrics_df |> 
  mutate(Response = Category,
         Model_Type = Model,
         AIC = AIC_reml_first,
         BIC = BIC_reml_first) |> 
  relocate(Response, Model_Type) |> 
  select(!c(Category, Model, AIC_reml_first, BIC_reml_first, BIC_ml_first, AIC_ml_first))

# View the resulting dataframe
print(metrics_df)

metrics_df |> str()
```


```{r}
# Initialize an empty list to store the model metrics
model_metrics <- list()

# Loop through the different response variables
response_vars <- c("Biodiversity", "Greenhouse gas emission", "Product quality", "Crop yield", "Pest and Disease", "Soil quality", "Water quality")  # Adjust as needed)

# Loop through response variables and models
for (response in response_vars) {
  
  # C_incremental_no_random_incremental models
  for (i in 1:length(model_results[[response]]$C_incremental_no_random_incremental)) {
    model <- model_results[[response]]$C_incremental_no_random_incremental[[i]]
    
    # Extract logLik, AIC, BIC
    logLik_val <- logLik(model)
    AIC_val <- AIC(model)
    BIC_val <- BIC(model)
    
    # Manually calculate AIC and BIC
    n <- length(model$yi)  # Assuming model$yi is the response variable vector
    k <- length(coef(model))  # Number of parameters
    AIC_calc <- 2 * k - 2 * logLik_val
    BIC_calc <- k * log(n) - 2 * logLik_val
    
    # Store the results in the list
    model_metrics[[length(model_metrics) + 1]] <- data.frame(
      Model = paste(response, "C", i, sep = "_"),
      Response = response,
      Model_Type = "C_incremental_no_random_incremental",
      AIC = AIC_val,
      BIC = BIC_val,
      AIC_Manual = AIC_calc,
      BIC_Manual = BIC_calc
    )
  }
  
  # D_incremental_random_incremental models
  for (i in 1:length(model_results[[response]]$D_incremental_random_incremental)) {
    model <- model_results[[response]]$D_incremental_random_incremental[[i]]
    
    # Extract logLik, AIC, BIC
    logLik_val <- logLik(model)
    AIC_val <- AIC(model)
    BIC_val <- BIC(model)
    
    # Manually calculate AIC and BIC
    n <- length(model$yi)  # Assuming model$yi is the response variable vector
    k <- length(coef(model))  # Number of parameters
    AIC_calc <- 2 * k - 2 * logLik_val
    BIC_calc <- k * log(n) - 2 * logLik_val
    
    # Store the results in the list
    model_metrics[[length(model_metrics) + 1]] <- data.frame(
      Model = paste(response, "D", i, sep = "_"),
      Response = response,
      Model_Type = "D_incremental_random_incremental",
      AIC = AIC_val,
      BIC = BIC_val,
      AIC_Manual = AIC_calc,
      BIC_Manual = BIC_calc
    )
  }
}

model_metrics_df <- model_metrics_df |> 
  select(!c(Model, AIC_Manual, BIC_Manual)) |> 
    relocate(Response, Model_Type)

# Combine all results into a single dataframe
model_metrics_df <- do.call(rbind, model_metrics)

# View the dataframe
model_metrics_df |> str()
```

```{r}
# Perform a full join to merge the datasets based on Response and Model_Type
merged_df <- merge(model_metrics_df, 
                   metrics_df, 
                   by = c("Response", "Model_Type"), 
                   all = TRUE)

# Check the structure of the merged dataframe
str(merged_df)


# Create a new dataframe with combined AIC and BIC columns
final_merged_df <- merged_df %>%
  mutate(
    AIC = coalesce(AIC.x, AIC.y),   # Combine AIC columns, prefer non-NA values
    BIC = coalesce(BIC.x, BIC.y)    # Combine BIC columns, prefer non-NA values
  ) %>%
  select(Response, Model_Type, AIC, BIC)  # Keep only the necessary columns

# Check the structure of the new dataframe
str(final_merged_df)

# View the first few rows of the final dataframe
final_merged_df
```
```{r}
# Reshape the data from wide to long format for easier plotting
final_df_long <- final_merged_df |> 
  pivot_longer(cols = c("AIC", "BIC"), 
               names_to = "Metric", 
               values_to = "Value")


custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)


# Create a ggplot with bar chart for AIC and BIC metrics
ggplot(final_df_long, aes(x = Model_Type, y = Value, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +  # Change to bar chart
  facet_wrap(~ Response, scales = "free_y") +  # facet by Response and free y-axis
  labs(
    title = "AIC and BIC Metrics by Response and Model Type",
    x = "Model Type",
    y = "Metric Value"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +  # Rotate x-axis labels
  scale_fill_manual(values = custom_colors)  # Apply custom colors for Response
```






```{r}
# Calculate average AIC and BIC for each Model_Type across all response variables
average_metrics <- final_merged_df %>%
  group_by(Model_Type) %>%
  summarise(
    Average_AIC = mean(AIC, na.rm = TRUE),
    Average_BIC = mean(BIC, na.rm = TRUE)
  ) %>%
  arrange(Average_AIC)

# Create a named vector to map old model names to meaningful names
model_rename_map <- c(
  "D_incremental_random_incremental" = "Incremental Model with Random Effects",
  "B_minimal_random_incremental" = "Minimal Random Effects Model",
  "E_intercept_fixed_random_incremental" = "Intercept with Fixed and Random Effects Model",
  "C_incremental_no_random_incremental" = "Incremental Model without Random Effects",
  "A_null" = "Null Model"
)

# Rename the model types in the average_metrics dataframe
average_metrics <- average_metrics %>%
  mutate(Model_Type = recode(Model_Type, !!!model_rename_map))

# View the calculated averages
average_metrics |> str()
```

```{r}
# Create a publication-ready gt table
model_comparison_gt_table <- average_metrics %>%
  gt() %>%
  tab_header(
    title = "Model Comparison: Average AIC and BIC Values",
    subtitle = "Average AIC and BIC for each model type across all response variables"
  ) %>%
  cols_label(
    Model_Type = "Model Type",
    Average_AIC = "Average AIC",
    Average_BIC = "Average BIC"
  ) %>%
  fmt_number(
    columns = vars(Average_AIC, Average_BIC),
    decimals = 2
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_column_labels(everything())
  ) %>%
  tab_options(
    table.font.size = 14,
    heading.title.font.size = 20,
    heading.subtitle.font.size = 16
  ) %>%
  opt_table_font(
    font = list(
      google_font("Lato"),
      default_fonts()
    )
  )

# View the table
model_comparison_gt_table
```

Model Comparison Interpretation:

The model comparison assesses the impact of increasing complexity on explaining variability across different response variables. The models range from the simplest (null model) to more complex models that incorporate random effects and fixed effects. The metrics used to balance model fit and complexity are AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion), with lower values indicating better performance.

Null Model (A_null): The null model serves as the baseline and consistently underperforms across all response variables, with the highest AIC (134,882.43) and BIC (134,885.34). This suggests that the null model offers poor explanatory power, confirming the need for more sophisticated models to capture variability in the data.

Minimal Random Effects Model (B_minimal_random_incremental): Introducing random effects through the minimal random effects model significantly improves the model fit, reducing the AIC to 9,795.85 and the BIC to 9,805.82. This model captures some variability across experiments, showing its superiority over the null model.

Intercept with Fixed and Random Effects Model (E_intercept_fixed_random_incremental): Adding moderators with both fixed and random effects results in the same AIC and BIC values (9,879.92 and 9,885.74, respectively) as the minimal random effects model. This suggests that, in this case, adding fixed effects did not provide a significant improvement in model fit, likely due to the complexity already captured by random effects.

Incremental Model without Random Effects (C_incremental_no_random_incremental): This model, which does not incorporate random effects, has a notably higher AIC (103,759.01) and BIC (103,766.10), indicating a significant reduction in model fit compared to models that include random effects. This suggests that random effects are important in capturing variability across the experiments.

Incremental Model with Random Effects (D_incremental_random_incremental): This model, which incorporates random effects, provides an improved fit compared to the models without random effects. It shows a substantial reduction in both AIC (9,795.85) and BIC (9,805.82), demonstrating its capacity to capture the complexity in the data without introducing unnecessary complexity.

Conclusion: The model comparison highlights that more complex models, especially those that incorporate random effects, provide better model fit and explanatory power. The minimal random effects model offers a good balance of complexity and performance, while models that do not include random effects (like the Incremental Model without Random Effects) are far less effective in explaining variability. For datasets with high variability and complexity, such as those involving multiple experiments, random effects are crucial for improving model performance. The results underscore the importance of selecting the right model complexity based on the dataset at hand, ensuring robust and interpretable insights.



We now focus on the Incremental Model with Random Effects (D_incremental_random_incremental):
Because it shows the best AIC. Now We need to look into the random effects:

################################################################################################################################################################
RANDOM EFFECTS 
################################################################################################################################################################

```{r}
# Initialize an empty dataframe to store the random effects
combined_random_effects <- data.frame(
  model = character(),
  sigma2 = numeric(),
  sqrt = numeric(),
  nlvls = integer(),
  fixed = character(),
  factor = character(),
  stringsAsFactors = FALSE
)

# Define a function to extract random effects
extract_random_effects <- function(model, model_name, factor_name = "exp_id") {
  if (!is.null(model$sigma2)) {
    # Extract the unique levels of exp_id or other factors from the data
    unique_levels <- length(unique(model$data[[factor_name]]))
    random_effects <- data.frame(
      model = model_name,
      sigma2 = model$sigma2,
      sqrt = sqrt(model$sigma2),
      nlvls = unique_levels,  # Use unique levels of exp_id
      fixed = "no",
      factor = factor_name
    )
    return(random_effects)
  }
  return(NULL)
}

# Extract random effects from model_b_minimal_random_incremental
model_b_minimal_random <- model_results$`Crop yield`$B_minimal_random_incremental
random_effects_b <- extract_random_effects(model_b_minimal_random, "B_minimal_random_incremental")
if (!is.null(random_effects_b)) {
  combined_random_effects <- rbind(combined_random_effects, random_effects_b)
}

# Extract random effects from model_d_incremental_random_incremental
model_d_incremental_random <- model_results$`Crop yield`$D_incremental_random_incremental
moderator_names <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")  # Assuming these are the moderators
for (i in 1:length(model_d_incremental_random)) {
  model_level <- model_d_incremental_random[[i]]
  random_effects_d <- extract_random_effects(model_level, paste("D_incremental_random_incremental_", moderator_names[i], sep = ""))
  if (!is.null(random_effects_d)) {
    combined_random_effects <- rbind(combined_random_effects, random_effects_d)
  }
}

# Extract random effects from model_e_intercept_fixed_random_incremental
model_e_intercept_fixed_random <- model_results$`Crop yield`$E_intercept_fixed_random_incremental
random_effects_e <- extract_random_effects(model_e_intercept_fixed_random, "E_intercept_fixed_random_incremental")
if (!is.null(random_effects_e)) {
  combined_random_effects <- rbind(combined_random_effects, random_effects_e)
}

# View the combined random effects dataframe
print(combined_random_effects)
```







#############
# STEP 5
##########################################################################################################################################
MODEL DIAGNOSTICS ON EACH SUBSET MODEL FITTING 
##########################################################################################################################################


```{r}
####################################################################################################################################################
# Load and Inspect Saved Meta-Analysis Models
####################################################################################################################################################

# Define output directory where models are saved
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load all models into a list
model_results <- readRDS(file.path(output_dir, "fitted_models_all_incremental.rds"))

# model_results |> str()
```

 
##########################################################################################################################################
Variance Components (Tau2) and Heterogeneity (I²)
##########################################################################################################################################

```{r}
str(model_results$Biodiversity$A_null)
```
```{r}
# Check sigma2 for problematic models
model_results$Biodiversity$C_incremental_no_random_incremental
model_results$Biodiversity$D_incremental_random_incremental
```
```{r}
model_results$Biodiversity$D_incremental_random_incremental

model_bio_d <- model_results$Biodiversity$D_incremental_random_incremental[[1]]
model_bio_d |> str()
```


```{r}
# Initialize an empty data frame to store the heterogeneity and variance results
heterogeneity_results <- data.frame(
  response = character(),
  model = character(),
  sigma2 = numeric(),
  tau2 = numeric(),
  rho = numeric(),
  gamma2 = numeric(),
  phi = numeric(),
  QE = numeric(),
  QM = numeric(),
  Qp = numeric(),
  k = integer(),
  stringsAsFactors = FALSE
)

# Loop through each response variable and extract heterogeneity components for all models
for (response in names(model_results)) {
  cat("\nProcessing response variable:", response, "\n")
  
  # Loop through each model in the current response
  for (model_name in names(model_results[[response]])) {
    model <- model_results[[response]][[model_name]]
    
    # Check if model is valid and contains necessary fields
    if (!is.null(model)) {
      # Safely extract variance components, handle NULLs gracefully
      sigma2 <- ifelse(!is.null(model$sigma2), model$sigma2, NA)
      tau2 <- ifelse(!is.null(model$tau2), model$tau2, NA)
      rho <- ifelse(!is.null(model$rho), model$rho, NA)
      gamma2 <- ifelse(!is.null(model$gamma2), model$gamma2, NA)
      phi <- ifelse(!is.null(model$phi), model$phi, NA)
      
      # Safely extract heterogeneity test results, handle NULLs gracefully
      QE <- ifelse(!is.null(model$QE), model$QE, NA)
      QM <- ifelse(!is.null(model$QM), model$QM, NA)
      Qp <- ifelse(!is.null(model$QMp), model$QMp, NA)
      k <- ifelse(!is.null(model$k), model$k, NA)
      
      # Append the model data to the heterogeneity_results
      heterogeneity_results <- rbind(heterogeneity_results, data.frame(
        response = response,  # Add the response variable dynamically here
        model = model_name,
        sigma2 = sigma2,
        tau2 = tau2,
        rho = rho,
        gamma2 = gamma2,
        phi = phi,
        QE = QE,
        QM = QM,
        Qp = Qp,
        k = k
      ))
    }
  }

  # Extract the variance components for D_incremental_random_incremental for each response
  model_d <- model_results[[response]]$D_incremental_random_incremental[[1]]  # Extract the first model in the list
  
  # Extract the variance components for D_incremental_random_incremental
  sigma2_d <- ifelse(!is.null(model_d$sigma2), model_d$sigma2, NA)
  tau2_d <- ifelse(!is.null(model_d$tau2), model_d$tau2, NA)
  rho_d <- ifelse(!is.null(model_d$rho), model_d$rho, NA)
  gamma2_d <- ifelse(!is.null(model_d$gamma2), model_d$gamma2, NA)
  phi_d <- ifelse(!is.null(model_d$phi), model_d$phi, NA)

  # Heterogeneity and model fit stats for D_incremental_random_incremental
  QE_d <- ifelse(!is.null(model_d$QE), model_d$QE, NA)
  QM_d <- ifelse(!is.null(model_d$QM), model_d$QM, NA)
  Qp_d <- ifelse(!is.null(model_d$QMp), model_d$QMp, NA)
  k_d <- ifelse(!is.null(model_d$k), model_d$k, NA)

  # Manually add the results for D_incremental_random_incremental
  heterogeneity_results <- rbind(heterogeneity_results, data.frame(
    response = response,  # Add the response variable dynamically here
    model = "D_incremental_random_incremental",
    sigma2 = sigma2_d,
    tau2 = tau2_d,
    rho = rho_d,
    gamma2 = gamma2_d,
    phi = phi_d,
    QE = QE_d,
    QM = QM_d,
    Qp = Qp_d,
    k = k_d
  ))
}

# View the updated heterogeneity results
print(heterogeneity_results)
heterogeneity_results |> str()

```

```{r}
# Melt the heterogeneity results to make it long-format for ggplot
long_data <- melt(heterogeneity_results, id.vars = "model", 
                  measure.vars = c("sigma2", "tau2", "rho", "gamma2", "phi", "QE", "QM", "Qp", "k"))

# Plotting the data with facets for each metric
ggplot(long_data, aes(x = model, y = value, fill = variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Heterogeneity and Variance Results Across Models",
       x = "Model",
       y = "Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none") +
  facet_wrap(~ variable, scales = "free_y")  # Facet for each metric
  
```


##########################################################################
Model Diagnostics: Heterogeneity also called Residual Heterogeneity Partitioning
##########################################################################




#############
# STEP 7
##########################################################################################################################################
PUBLICATION-READY PLOTS AND TABLES OF EFFECT SIZE IMPACTS ON RESPONSE VARIABLES OF TEMPERATE SAF FOR EACH SUBSET MODEL FITTING 
##########################################################################################################################################



Forest Plot: Visualizes effect sizes and confidence intervals for response variables.
Ridge Plot: Shows the distribution of effect sizes for each response variable.
Variance Plot: Compares variance components (Tau²) and heterogeneity (I²).
Combined Plot: Combines the forest and ridge plots into a single figure for publication.

##########################################################################################################################################
FOREST PLOT
##########################################################################################################################################

```{r}
# Loop through the different response variables
response_vars <- c("Biodiversity", "Greenhouse gas emission", "Product quality", "Crop yield", "Pest and Disease", "Soil quality", "Water quality")  # Adjust as needed)
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

# Extract data for forest plot
model_results$Biodiversity$D_incremental_random_incremental
```
```{r}
meta_data |> glimpse()
```


```{r}
##########################################################################################################################################
# RE-FITTING MODEL D_incremental_random_incremental
##########################################################################################################################################

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################

# Function to fit models with one moderator at a time
fit_model_incremental <- function(data_subset, response_variable, v_matrix, moderator, random_effects = NULL, intercept = TRUE) {
  # Print progress message
  cat("\nFitting model for response variable:", response_variable, "with moderator:", moderator, "...\n")

  # Build the formula for the moderator
  moderator_formula <- if (!is.null(moderator)) {
    if (intercept) {
      as.formula(paste("yi ~", moderator))  # Include global intercept
    } else {
      as.formula(paste("yi ~", moderator, "- 1"))  # Exclude global intercept
    }
  } else {
    ~ 1  # Intercept-only model
  }

  # Fit the model
  model <- tryCatch({
    rma.mv(
      yi = yi,
      V = v_matrix,
      mods = moderator_formula,
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = list(
        optimizer = "optim",
        optim.method = "BFGS",
        iter.max = 1000,
        rel.tol = 1e-8
      )
    )
  }, error = function(e) {
    cat("Error in model fitting for", response_variable, "with moderator", moderator, ":", e$message, "\n")
    return(NULL)
  })

  # Return fitted model or NULL if fitting failed
  if (!is.null(model)) {
    cat("Model fitting completed for response variable:", response_variable, "with moderator:", moderator, ".\n")
    return(model)
  } else {
    return(NULL)
  }
}

##########################################################################################################################################
# Fit Models for Each Response Variable with Incremental Moderator Inclusion
##########################################################################################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset
#############################################################

# Initialize an empty list to store model results
selected_model_results <- list()

# Loop through each response variable to fit models
for (response in names(v_matrices)) {
  # Display the response variable being processed
  cat("\nProcessing response variable:", response, "\n")

  # Subset the metadata to include only rows relevant to the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]

  # Extract the corresponding variance-covariance matrix for the response variable
  v_matrix <- v_matrices[[response]]

  # Define the list of moderators to be included in the model
  moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

  # Fit models step-by-step for the response variable
  selected_model_results[[response]] <- list(
    

    # Incremental model with random effects: Adds moderators incrementally
    D_refit_incremenal_random = lapply(moderators, function(moderator) {
      fit_model_incremental(
        data_subset = data_subset,
        response_variable = response,
        v_matrix = v_matrix,
        moderator = moderator,             # Add one moderator
        random_effects = ~ 1 | exp_id,     # Random effect at the experiment level
        intercept = FALSE                  # Do not include intercept - making it easier to compare moderator levels
      )
    })

  )
}

##########################################################################################################################################
# Save All Fitted Model
##########################################################################################################################################

# Directory for saving results
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Save the results for each response variable under the name D_refit_incremenal_random_no_intercept
save_selected_models <- function(model_results, output_dir) {
  # Save the model results as an RDS file
  saveRDS(model_results, file = file.path(output_dir, "D_refit_incremenal_random_no_intercept.rds"))
  cat("Model results saved successfully!\n")
}

# Save the results
save_selected_models(selected_model_results, output_dir)

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (19/01-2025)
# Total time taken: 19.15765  mins
```
```{r}
# Specify the output directory where the model was saved
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load the model results
selected_model_results <- readRDS(file.path(dir, "D_refit_incremenal_random_no_intercept.rds"))
```
```{r}
# Example of refitting a model (for the "Crop yield" response variable and one moderator)
# str(selected_model_results$`Crop yield`$D_refit_incremenal_random)

model_res_data_crop_yield <- selected_model_results$`Crop yield`$D_refit_incremenal_random  # Take the first model as an example
model_res_data_crop_yield
```


```{r}
# Initialize an empty data frame to store forest plot data for all response variables
forest_plot_data_all <- data.frame(
  Study = character(),
  EffectSize = numeric(),
  CI_Lower = numeric(),
  CI_Upper = numeric(),
  ResponseVariable = character(),
  stringsAsFactors = FALSE
)

# Loop through each response variable to extract data for the forest plot
for (response in names(selected_model_results)) {
  
  # Extract the model data for each response variable
  model_data <- selected_model_results[[response]]$D_refit_incremenal_random[[1]]
  
  # Extract the effect sizes (yi) and variances (vi)
  effect_sizes <- model_data$yi
  variances <- model_data$vi
  
  # Calculate confidence intervals
  ci_lower <- effect_sizes - 1.96 * sqrt(variances)
  ci_upper <- effect_sizes + 1.96 * sqrt(variances)
  
  # Create a data frame for the current response variable's forest plot data
  forest_plot_data <- data.frame(
    Study = model_data$slab,  # Assuming slab is the study identifier
    EffectSize = effect_sizes,
    CI_Lower = ci_lower,
    CI_Upper = ci_upper,
    ResponseVariable = response  # Add the response variable name
  )
  
  # Append the data for the current response variable to the overall data frame
  forest_plot_data_all <- rbind(forest_plot_data_all, forest_plot_data)
}

# Check the combined data
forest_plot_data_all |> glimpse()
```

```{r}
# Calculate the global mean for each response variable
global_mean_data <- forest_plot_data_all %>%
  group_by(ResponseVariable) %>%
  summarise(
    overall_effect = mean(EffectSize, na.rm = TRUE),
    lower_ci = mean(CI_Lower, na.rm = TRUE),
    upper_ci = mean(CI_Upper, na.rm = TRUE),
    .groups = "drop"
  )

# Merge the global mean data with the forest plot data
forest_plot_data_all_with_mean <- forest_plot_data_all %>%
  left_join(global_mean_data, by = "ResponseVariable")

# Now create the forest plot with the global mean effect size added as a line
forest_plot_mean_response <- forest_plot_data_all_with_mean |> 
  ggplot(aes(x = EffectSize, y = Study)) +
  # Points for effect sizes
  geom_point(size = 3) +
  # Confidence intervals
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2) +
  # Add vertical line at 0
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  # Add a line for the global mean effect size per response variable
  geom_vline(aes(xintercept = overall_effect), color = "blue", linetype = "solid", size = 1) +
  # Customize labels
  labs(
    title = "Forest Plot for All Response Variables",
    x = "Effect Size (Overall)",
    y = "Study"
  ) +
  # Focus on the area around 0
  xlim(-2, 2) +  # Adjust this range based on your needs
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    strip.text = element_text(size = 12, face = "bold")  # Bold facet labels
  ) +
  facet_wrap(~ ResponseVariable, scales = "free_y", ncol = 1) +  # Facet by response variable
  theme(strip.background = element_rect(fill = "lightgray", color = "black"))

forest_plot_mean_response
```



```{r}
# Ensure custom_colors are applied directly to the mean dots
forest_plot_mean_response_scaled <- forest_plot_data_all_with_mean |> 
  ggplot(aes(x = EffectSize, y = Study)) +
  # Points for individual observations
  geom_point(color = "gray40", size = 3, alpha = 0.8) +  # Gray for all other points
  # Confidence intervals
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2, alpha = 0.7, color = "gray40") +
  # Add a dot for the global mean effect size per response variable
  geom_point(
    data = forest_plot_data_all_with_mean %>% 
      group_by(ResponseVariable) %>% 
      summarize(overall_mean = mean(EffectSize, na.rm = TRUE), Study = 0),  # Calculate mean data
    aes(x = overall_mean, y = Study),  # Map coordinates
    color = "black",  # Ensure a black outline for visibility
    size = 5, shape = 21,  # Filled circle
    fill = forest_plot_data_all_with_mean %>%
      pull(ResponseVariable) %>%
      unique() %>%
      purrr::map_chr(~ custom_colors[.])  # Map custom colors directly
  ) +
  # Customize labels
  labs(
    title = "Improved Forest Plot with Robust Mean Dot Colors",
    x = "Effect Size (Pseudo-Log Scale)",
    y = "Observation",
    fill = "Response Variable"
  ) +
  # Apply pseudo-log scale transformation to x-axis
  scale_x_continuous(
    trans = pseudo_log_scale, 
    breaks = c(-2, -1, 0, 1, 2), 
    labels = scales::number_format(accuracy = 0.01)
  ) +
  # Facet by response variable with synchronized strip background colors
  ggh4x::facet_wrap2(
    ~ ResponseVariable, 
    scales = "free_y", 
    ncol = 1, 
    strip = ggh4x::strip_themed(
      background_x = list(
        Biodiversity = element_rect(fill = custom_colors["Biodiversity"], color = "black"),
        `Greenhouse gas emission` = element_rect(fill = custom_colors["Greenhouse gas emission"], color = "black"),
        `Product quality` = element_rect(fill = custom_colors["Product quality"], color = "black"),
        `Crop yield` = element_rect(fill = custom_colors["Crop yield"], color = "black"),
        `Pest and Disease` = element_rect(fill = custom_colors["Pest and Disease"], color = "black"),
        `Soil quality` = element_rect(fill = custom_colors["Soil quality"], color = "black"),
        `Water quality` = element_rect(fill = custom_colors["Water quality"], color = "black")
      )
    )
  ) +
  # Add slim dotted vertical line at x = 0 for all facets
  geom_vline(xintercept = 0, linetype = "dotted", color = "red", alpha = 0.6, size = 0.8) +
  # Enhance theme for readability
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    strip.text = element_text(size = 12, face = "bold"),
    legend.position = "right",
    panel.border = element_rect(color = "black", fill = NA, size = 1)  # Black border for each panel
  )

# Display the corrected plot
print(forest_plot_mean_response_scaled)
```

Saving the forest_plot_mean_response_scaled 
```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 10) + 
  theme(
    plot.title = element_text(size = 10),        # Increase title size
    axis.text = element_text(size = 10),        # Increase axis text size
    axis.title = element_text(size = 10),       # Increase axis title size
    legend.position = "top",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 10),      # Increase legend text size
    strip.text = element_text(size = 10),       # Increase facet text size
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10,
                               angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
forest_plot_mean_response_scaled <- forest_plot_mean_response_scaled + theme_custom


# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}


# Save the plots
ggsave(
  filename = file.path(output_dir, "forest_plot_mean_response_scaled.png"),
  plot = forest_plot_mean_response_scaled,
  width = 16, height = 8, dpi = 600,
  bg = "white"
)
```

Further enhanced plot
```{r}
forest_plot_data_all_with_mean |> glimpse()

# Calculate the variance and confidence intervals for overall means
mean_summary <- forest_plot_data_all_with_mean %>%
  group_by(ResponseVariable) %>%
  summarize(
    overall_mean = mean(EffectSize, na.rm = TRUE),
    mean_variance = mean(VarEffectSize, na.rm = TRUE),
    central_y = mean(range(Study)),  # Center y-coordinate
    lower_ci = overall_mean - 1.96 * sqrt(mean_variance),  # Lower confidence interval
    upper_ci = overall_mean + 1.96 * sqrt(mean_variance)   # Upper confidence interval
  )

mean_summary |> glimpse()
```

```{r}
# Updated plot with error bars for mean dots
forest_plot_mean_response_scaled_v4 <- ggplot(forest_plot_data_all_with_mean, aes(x = EffectSize, y = Study)) +
  # Points for individual observations
  geom_point(color = "gray40", size = 3, alpha = 0.8) +  
  # Confidence intervals for individual observations
  geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2, alpha = 0.7, color = "gray40") +
  # Add a dot for the global mean effect size per response variable, centered vertically
  geom_point(
    data = mean_summary,
    mapping = aes(x = overall_mean, y = central_y, color = ResponseVariable),
    size = 5, shape = 16, inherit.aes = FALSE
  ) +
  # Add error bars for the global mean dots
  geom_errorbarh(
    data = mean_summary,
    mapping = aes(xmin = lower_ci, xmax = upper_ci, y = central_y, color = ResponseVariable),
    height = 0.5, size = 0.8, alpha = 0.8, inherit.aes = FALSE
  ) +
  # Add slim dotted vertical line at x = 0 for all facets
  geom_vline(xintercept = 0, linetype = "dotted", color = "red", alpha = 0.6, size = 0.8) +
  # Customize labels
  labs(
    title = "Improved Forest Plot with Centered Mean Dots and Error Bars per Response Variable",
    x = "Effect Size (Pseudo-Log Scale)",
    y = "Observation",
    color = "Response Variable"
  ) +
  # Apply pseudo-log scale transformation to x-axis
  scale_x_continuous(
    trans = pseudo_log_scale, 
    breaks = c(-2, -1, 0, 1, 2), 
    labels = scales::number_format(accuracy = 0.01)
  ) +
  # Apply custom colors to ResponseVariable for mean dots
  scale_color_manual(values = custom_colors) +
  # Facet by response variable with custom strip background colors
  facet_wrap(~ ResponseVariable, scales = "free_y", ncol = 1) +
  theme_minimal(base_size = 14) +
  # Enhance theme for readability and custom facet colors
  theme(
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    strip.text = element_text(size = 12, face = "bold"),
    strip.background = element_rect(fill = "white", color = "black"),
    legend.position = "none",
    panel.border = element_rect(color = "black", fill = NA, size = 1)
  )

# Display the updated plot
forest_plot_mean_response_scaled_v4
```
Saving the forest_plot_mean_response_scaled_v4 
```{r}
# Increase base text size and adjust all styling for the plots
theme_custom <- theme_minimal(base_size = 10) + 
  theme(
    plot.title = element_text(size = 10),        # Increase title size
    axis.text = element_text(size = 10),        # Increase axis text size
    axis.title = element_text(size = 10),       # Increase axis title size
    legend.position = "none",                    # Place legend at the top
    legend.title = element_blank(),             # Remove legend title
    legend.text = element_text(size = 10),      # Increase legend text size
    strip.text = element_text(size = 10),       # Increase facet text size
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 10)
                              # angle = 45, hjust = 1) # Rotate x-axis text
  )

# Apply theme modifications to each plot
forest_plot_mean_response_scaled_v4 <- forest_plot_mean_response_scaled_v4 + theme_custom


# Specify the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "FIGURES")

# Ensure the directory exists (optional step)
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}


# Save the plots
ggsave(
  filename = file.path(output_dir, "forest_plot_mean_response_scaled_v4.png"),
  plot = forest_plot_mean_response_scaled_v4,
  width = 20, height = 8, dpi = 600,
  bg = "white"
)
```


#############
# STEP 6
##########################################################################################################################################
KEY VARIANCE EXPLANATION FOR EACH RESPONSE VARIABLE AND MODERATOR - MODEL FITTING 
##########################################################################################################################################

```{r}
# selected_model_results |> str()
```
```{r}
print(selected_model_results[[1]]$D_refit_incremenal_random[[1]]) 
```


```{r}
# Initialize an empty data frame to store the summary table results
summary_table <- data.frame(
  Aspect = character(),
  Moderator = character(),
  Estimate = numeric(),
  SE = numeric(),
  Z_value = numeric(),
  P_value = numeric(),
  CI_Lower = numeric(),
  CI_Upper = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each response variable to extract and summarize results
for (response in names(selected_model_results)) {
  
  # Extract the model data for each response variable
  model_data_list <- selected_model_results[[response]]$D_refit_incremenal_random
  
  # Loop through each moderator for the current response variable
  for (moderator_index in seq_along(model_data_list)) {
    
    # Extract the model fit for the current moderator
    model_data <- model_data_list[[moderator_index]]
    
    # Check if the model fitting was successful and contains necessary data
    if (!is.null(model_data) && !is.null(model_data$beta)) {
      
      # Extract the relevant statistics for each moderator (e.g., 'beta', 'se', 'zval', 'pval', etc.)
      estimates <- model_data$beta  # The effect estimates (beta coefficients)
      standard_errors <- model_data$se  # Standard errors of the estimates
      z_values <- model_data$zval  # Z-values
      p_values <- model_data$pval  # P-values
      ci_lower <- model_data$ci.lb  # Lower bound of the confidence intervals
      ci_upper <- model_data$ci.ub  # Upper bound of the confidence intervals
      
      # Check if estimates have more than 0 entries
      if (length(estimates) > 0) {
        # Loop through each effect size estimate for the current moderator
        for (i in 1:length(estimates)) {
          # Ensure the current moderator has valid data
          if (!is.na(estimates[i]) && !is.na(standard_errors[i]) && !is.na(z_values[i]) && !is.na(p_values[i])) {
            # Store each result in the summary table
            summary_table <- rbind(summary_table, data.frame(
              Aspect = response,  # Use response variable as the aspect
              Moderator = rownames(estimates)[i],  # Moderator name (from row names)
              Estimate = estimates[i],
              SE = standard_errors[i],
              Z_value = z_values[i],
              P_value = p_values[i],
              CI_Lower = ci_lower[i],
              CI_Upper = ci_upper[i]
            ))
          }
        }
      }
    }
  }
}

summary_table |> glimpse()
```

```{r}
# Format the p-values for significance with appropriate asterisks
summary_table$P_value_formatted <- ifelse(summary_table$P_value < 0.001, 
                                           paste0("< 0.001", "***"),  # Three asterisks for p < 0.001
                                           ifelse(summary_table$P_value < 0.01, 
                                                  paste0(round(summary_table$P_value, 3), "**"),  # Two asterisks for p < 0.01
                                                  ifelse(summary_table$P_value < 0.05, 
                                                         paste0(round(summary_table$P_value, 3), "*"),  # One asterisk for p < 0.05
                                                         ifelse(summary_table$P_value < 0.10, 
                                                                paste0(round(summary_table$P_value, 3), "·"),  # One dot for p < 0.10
                                                                round(summary_table$P_value, 3)))))  # No asterisks for p ≥ 0.05

# Create a new column for neatly rounded p-values without extra characters
summary_table <- summary_table %>%
  mutate(
    P_value_simple = round(P_value, 3)  # Round p-values to 3 decimals
  )

# Step 1: Format the p-values and create significance columns
summary_table <- summary_table %>%
  mutate(
    P_value_simple = round(P_value, 3),  # Rounded p-values without any special symbols
    # Create formatted p-values based on P_value
    P_value_formatted = case_when(
      P_value < 0.001 ~ paste0("< 0.001", "***"),  # Three asterisks for p < 0.001
      P_value < 0.01  ~ paste0(round(P_value, 3), "**"),  # Two asterisks for p < 0.01
      P_value < 0.05  ~ paste0(round(P_value, 3), "*"),   # One asterisk for p < 0.05
      P_value < 0.10  ~ paste0(round(P_value, 3), "·"),   # One dot for p < 0.10
      TRUE ~ paste0(round(P_value, 3))  # No asterisks for p ≥ 0.05 (ensure it's treated as a string)
    ),
    
    # Create significance level column for each response variable
    significance = case_when(
      P_value < 0.001 ~ "***",  # Three asterisks for p < 0.001
      P_value < 0.01  ~ "**",   # Two asterisks for p < 0.01
      P_value < 0.05  ~ "*",    # One asterisk for p < 0.05
      P_value < 0.10  ~ "·",   # One dot for p < 0.10
      TRUE ~ "NS"  # Non-significant for p ≥ 0.05
    )
  ) |> 
  # Convert P_value_simple = 0.000 to < 0.001
  mutate(P_value_simple = ifelse(P_value_simple == 0, "< 0.001", P_value_simple))


# Check the result to ensure columns are correctly formatted
summary_table |> glimpse()
```

```{r}
summary_table_split <- summary_table %>%
  mutate(Response_variable = Aspect) %>%  # Copy 'Aspect' to 'Response_variable' for clarity
  # Separate "Moderator" using a regular expression to handle cases like "seasonSummer"
  mutate(Moderator_type = gsub("(.*?)([A-Z].*)", "\\1", Moderator),  # Capture the first part before the capitalized word
         Moderator_type_level = gsub(".*?([A-Z].*)", "\\1", Moderator)) %>%  # Capture the second part after the first capitalized word
  # Clean the "Moderator_type_level" column by removing unnecessary prefixes (e.g., "type", "system")
  mutate(Moderator_type_level = gsub("type", "", Moderator_type_level),
         Moderator_type_level = gsub("system", "", Moderator_type_level)) %>%
  # Format 'Moderator_type' and 'Moderator_type_level' with appropriate typography
  mutate(Moderator_type = gsub("_", " ", Moderator_type),  # Replace underscores with spaces
         Moderator_type = tools::toTitleCase(Moderator_type),  # Capitalize each word
         Moderator_type_level = gsub("_", " ", Moderator_type_level),  # Replace underscores with spaces
         Moderator_type_level = tools::toTitleCase(Moderator_type_level)) %>%  # Capitalize each word
    # Modify the specific case of "Tuber,root and Other" & "Fruit,nut & Other"
  mutate(Moderator_type_level = gsub("Tuber,root and Other", "Tuber, root and other crops", Moderator_type_level),
         Moderator_type_level = gsub("Fruit,nut & Other", "Fruit, nut and other trees", Moderator_type_level)) %>%
   # Filter out rows where Moderator = "intrcpt"
  filter(Moderator != "intrcpt") %>%
  relocate(Response_variable, Moderator, Moderator_type, Moderator_type_level)  # Reorder columns for better readability


# Check the result
summary_table_split |> glimpse()
```
 

```{r}
# Prepare the GT table using the split Moderator structure
summary_table_gt <- summary_table_split %>%
  mutate(row_id = row_number()) %>%  # Add row_id column for alternating row colors
  gt() %>%
  tab_header(
    title = "Summary of Moderator Effects on Key Response Variables"
  ) %>%
  fmt_number(
    columns = c("Estimate", "P_value_simple"),
    decimals = 3
  ) %>%
  tab_spanner(
    label = "Statistics",
    columns = c("Estimate", "P_value_simple", "significance")
  ) %>%
  # Apply bold for significant values in the 'significance' column
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(
      columns = "significance",
      rows = significance %in% c("***", "**", "*")  # Bold for significant results
    )
  ) %>%
  # Apply normal weight for non-significant results in the 'significance' column
  tab_style(
    style = cell_text(weight = "normal"),
    locations = cells_body(
      columns = "significance",
      rows = significance == "NS"  # Normal weight for non-significant results
    )
  ) %>%
  # Apply alternating row colors for readability (odd/even rows)
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(color = "black")
    ),
    locations = cells_body(
      columns = everything(),
      rows = row_id %% 2 != 0  # Odd rows
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#f2f2f2"),  # Light gray for alternating rows
      cell_text(color = "black")
    ),
    locations = cells_body(
      columns = everything(),
      rows = row_id %% 2 == 0  # Even rows
    )
  ) %>%
  # Add column spacing for better readability
  tab_options(
    table.width = pct(100),  # Set width to 100% of the container
    column_labels.font.size = 12,  # Adjust font size of column labels
    row.striping.include_table_body = TRUE,  # Enable row striping in the table body
    data_row.padding = px(5)  # Padding between data rows for readability
  ) %>%
  # Remove row_id column for the final table display
  cols_hide(columns = "row_id") |> 
  cols_hide(columns = "Moderator") |> 
  cols_hide(columns = "Aspect") |> 
  cols_hide(columns = "P_value_formatted") |> 
  cols_hide(columns = "P_value") 

# Print the GT table without the row_id column
summary_table_gt
```


```{r}
summary_table_selected_condenced <- summary_table_split |> 
  select(Response_variable, Moderator_type, Moderator_type_level, Estimate, P_value_simple, significance)
  
summary_table_selected_condenced |> glimpse() 
```

```{r}
selected_model_results$Biodiversity$D_refit_incremenal_random[[3]]$k.eff
```


Study level data to add to the summary table

```{r}
################################################################################
# Number of observations for each 

# Define response variables and moderators
response_vars <- c("Biodiversity", "Greenhouse gas emission", "Product quality", "Crop yield", "Pest and Disease", "Soil quality", "Water quality")
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

# Initialize an empty data frame to store the summary of number of observations
study_summary <- data.frame(
  Response_variable = character(),
  Moderator = character(),
  Num_observations = integer(),
  stringsAsFactors = FALSE
)

# Loop through each response variable
for (response in response_vars) {
  
  # Extract the model data for each response variable
  model_data_list <- selected_model_results[[response]]$D_refit_incremenal_random
  
  # Loop through each moderator for the current response variable
  for (moderator_index in seq_along(moderators)) {
    
    # Check if the current moderator exists in the model data
    moderator_name <- moderators[moderator_index]
    moderator_data <- model_data_list[[moderator_index]]
    
    # Check if the moderator data contains the necessary field (k.eff) and is not null or empty
    if (!is.null(moderator_data$k.eff)) {
      num_observations <- moderator_data$k.eff  # Extract the number of observations (k.eff)
      
      # Append the result to the summary table
      study_summary <- rbind(study_summary, data.frame(
        Response_variable = response,
        Moderator = moderator_name,
        Num_observations = num_observations
      ))
    } else {
      # If k.eff is missing, print a debug message
      cat("Missing data for:", response, "Moderator:", moderator_name, "\n")
    }
  }
}

# Check the resulting summary of observations
study_summary |> glimpse()
```


```{r}
# meta_data |> glimpse()

# Define response variables and moderators
response_vars <- c("Biodiversity", "Greenhouse gas emission", "Product quality", "Crop yield", "Pest and Disease", "Soil quality", "Water quality")
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

# Initialize an empty list to store the summary data
study_obs_summary <- data.frame()

# Loop through each response variable
for (response in unique(meta_data$response_variable)) {
  # Loop through each moderator
  for (moderator in moderators) {
    # Filter data for the specific response and moderator
    filtered_data <- meta_data %>%
      filter(response_variable == response, !is.na(get(moderator)))
    
    # Calculate the number of unique observations and studies
    num_observations <- filtered_data %>%
      select(id_obs) %>%
      distinct() %>%
      nrow()
    
    num_studies <- filtered_data %>%
      select(id_article) %>%
      distinct() %>%
      nrow()

    # Calculate the average yi and vi for the specific combination
    avg_yi <- filtered_data %>%
      summarise(mean_yi = mean(yi, na.rm = TRUE)) %>%
      pull(mean_yi)
    
    avg_vi <- filtered_data %>%
      summarise(mean_vi = mean(vi, na.rm = TRUE)) %>%
      pull(mean_vi)

    # Get the list of unique studies (id_article) for this combination
    unique_studies <- filtered_data %>%
      select(id_article) %>%
      distinct() %>%
      pull(id_article)

    # Store the result in the summary data frame
    study_obs_summary <- rbind(study_obs_summary, data.frame(
      Response_variable = response,
      Moderator = moderator,
      Num_observations = num_observations,
      Num_studies = num_studies,
      Avg_yi = avg_yi,
      Avg_vi = avg_vi,
      Unique_studies = I(list(unique_studies))  # Storing the list of unique studies
    ))
  }
}

# Standardize column names in dataframe

# In study_obs_summary, rename 'Moderator' to 'Moderator_type' 
# and 'Unique_studies' column to be more descriptive
study_obs_summary <- study_obs_summary %>%
  rename(
    Moderator_type = Moderator,
    n_obs = Num_observations,
    n_studies = Num_studies
  ) |> 
  # Modify the specific case of "Tuber,root and Other" & "Fruit,nut & Other"
  mutate(Moderator_type = gsub("tree_type", "Tree Type", Moderator_type),
         Moderator_type = gsub("crop_type", "Crop Type", Moderator_type),
         Moderator_type = gsub("age_system", "Age System", Moderator_type),
         Moderator_type = gsub("season", "Season", Moderator_type),
         Moderator_type = gsub("soil_texture", "Soil Texture", Moderator_type)
  )


# Display the summary with additional information
study_obs_summary |> glimpse()

# study_obs_summary$Unique_studies
```



Merging with the model summary statistics

```{r}
# summary_table_selected_condenced |> glimpse() 


# Perform the left join
merged_summary <- study_obs_summary %>%
  full_join(
    summary_table_selected_condenced,
    by = c("Response_variable", "Moderator_type")
  ) |> 
   # Reorder columns for better readability
  relocate(Response_variable, Moderator_type, Moderator_type_level, n_studies, n_obs, Estimate, P_value_simple, significance, Avg_yi, Avg_vi, Unique_studies) 

# View the merged dataset
merged_summary |>  glimpse()
```

```{r}
# Prepare the GT table from merged_summary
merged_summary_gt <- merged_summary %>%
  mutate(row_id = row_number()) %>%  # Add row_id column for alternating row colors
  gt() %>%
  tab_header(
    title = "Summary of Moderator Effects on Key Response Variables"
  ) %>%
  fmt_number(
    columns = c("Estimate", "Avg_yi", "Avg_vi"),
    decimals = 3
  ) %>%
  fmt_number(
    columns = "P_value_simple",
    decimals = 3
  ) %>%
  tab_spanner(
    label = "Statistics",
    columns = c("Estimate", "P_value_simple", "significance", "Avg_yi", "Avg_vi")
  ) %>%
  cols_label(
    Response_variable = "Response Variable",
    Moderator_type = "Moderator Type",
    Moderator_type_level = "Moderator Level",
    n_studies = "n studies",
    n_obs = "n observations",
    Estimate = "Estimate",
    P_value_simple = "P-Value",
    significance = "Significance",
    Avg_yi = "Avg. Effect Size (yi)",
    Avg_vi = "Avg. Variance (vi)"
  ) %>%
  tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(
      columns = "significance",
      rows = significance %in% c("***", "**", "*")  # Bold for significant results
    )
  ) %>%
  tab_style(
    style = cell_text(weight = "normal"),
    locations = cells_body(
      columns = "significance",
      rows = significance == "NS"  # Normal weight for non-significant results
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "white"),
      cell_text(color = "black")
    ),
    locations = cells_body(
      rows = row_id %% 2 != 0  # Odd rows
    )
  ) %>%
  tab_style(
    style = list(
      cell_fill(color = "#f2f2f2"),  # Light gray for alternating rows
      cell_text(color = "black")
    ),
    locations = cells_body(
      rows = row_id %% 2 == 0  # Even rows
    )
  ) %>%
  tab_options(
    table.width = pct(100),  # Full-width table
    column_labels.font.size = 12,  # Font size for column labels
    data_row.padding = px(5)  # Padding for rows
  ) %>%
  cols_hide(columns = "row_id") %>%  # Hide row_id column
  cols_hide(columns = "Avg_yi") |>   # Hide Avg_yi column
  cols_hide(columns = "Avg_vi")      # Hide Avg_vi column

# Print the table
merged_summary_gt
```




























```{r}
# Step 2: Select the relevant columns and pivot the table
summary_table_condensed <- summary_table_split %>%
  select(Response_variable, Moderator_type, Moderator_type_level, Estimate, P_value_simple, significance)  # Ensure 'significance' is included

# Pivot the table with response variables as columns
summary_table_pivoted <- summary_table_condensed %>%
  pivot_wider(names_from = Moderator_type_level, values_from = c(Estimate, P_value_simple, significance))

# Step 3: Rename the columns for clarity
summary_table_pivoted <- summary_table_pivoted %>%
  rename_with(~ gsub("Estimate_", "Effect Estimate: ", .), starts_with("Estimate")) %>%
  rename_with(~ gsub("P_value_simple_", "P-value (simple): ", .), starts_with("P_value_simple")) %>%
  rename_with(~ gsub("significance_", "Significance: ", .), starts_with("significance"))

summary_table_pivoted |> glimpse()
```

 
 
 
 
 
 
##########################################################################################################################################
PUBLICATION-READY RIDGELINE PLOTS OF EFFECT SIZE DISTRIBUTIONS PER RESPONSE VARIABLE
##########################################################################################################################################

Ridge Plot: Shows the distribution of effect sizes for each response variable.
 
```{r}
meta_data |> glimpse()
```
```{r}
# Extract relevant columns, including vi
effect_size_data <- meta_data %>%
  select(response_variable, yi, vi) %>%
  drop_na()  # Remove missing values
```

 
 
 
 
 
 

Improvements and Adjustments
To address collinearity, pre-analysis checks such as variance inflation factors (VIF) or pairwise correlation matrices should be performed. Moderators with high collinearity or sparse data should be excluded or merged. Missing data can be handled using imputation methods or treated as a separate category. Log-transforming or standardizing `yi` and moderators could stabilize models with high variance ratios, while robust variance estimators, such as Knapp-Hartung adjustments, may improve reliability. Reducing the complexity of interaction models by focusing on key moderator pairs (e.g., `tree_type * crop_type`) rather than all interactions could improve convergence.

Model Diagnostics and Reporting
For each response variable, heterogeneity was assessed using statistics such as `I²` and `τ²`, and model fits were compared using AIC and BIC. Funnel plots, Egger’s test, and leave-one-out sensitivity analyses were conducted to evaluate publication bias and model robustness. Failed models were documented to ensure transparency, and systematic adjustments were reported to improve reproducibility. This approach balances explanatory power and interpretability, ensuring that the hierarchical complexity of moderators is appropriately captured.








##########################################################################################################################################
SAVING DATASETS AND MODEL OBJECTS
##########################################################################################################################################

