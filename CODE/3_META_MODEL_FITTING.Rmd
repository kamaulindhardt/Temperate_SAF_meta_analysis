---
title: "3_META_MODEL_FITTING"
author: "M.K.K. Lindhardt"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between



Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?


Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.


# STEP 0 PREPARING SCRIPT AND READ IN THE DATA


```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Load multiple add-on packages using pacman::p_load for efficiency
# pacman::p_load automatically installs missing packages and loads them
pacman::p_load(
  
  # Conflict Resolution
  conflicted,        # Resolves conflicts when functions with the same name exist in multiple packages
  
  # Data Manipulation / Transformation
  tidyverse,         # Comprehensive collection of R packages for data science (e.g., ggplot2, dplyr, readr)
  readr,             # Simplifies reading and writing of delimited text files (e.g., CSV)
  dplyr,             # A grammar of data manipulation (e.g., filter, mutate, summarise, etc.)
  skimr,             # Provides summary statistics with a more user-friendly output
  future,            # Supports parallel processing for speeding up computations
  future.apply,      # Extends the future package for parallelized versions of base R apply functions
  furrr,             # Provides a simple and consistent way to work with futures and parallel processing
  readxl,            # Read excel files
  
  ###################################################################################################################
  # Data Visualization
  ggplot2,           # A data visualization package for creating static and interactive graphics (part of tidyverse)
  patchwork,         # Extends ggplot2 by providing tools to combine multiple plots into one
  gridExtra,         # Arranges multiple grid-based plots (e.g., from ggplot2) into a single display
  scales,            # Adds tools for handling scale transformations and labels in visualizations
  gt,                # Stylish tables
  ggbreak,           # Breaks on axis for bar charts etc.
  ggpubr,            # Working with plots and legends library
  forcats,           # Tools for Working with Categorical Variables (Factors)
  
  ###################################################################################################################
  # Meta-Analysis
  metafor,           # For conducting meta-analyses, including calculating effect sizes and response ratios
  orchaRd,           # Provides tools for conducting and visualising meta-analyses and meta-regressions
  clubSandwich,      # Provides cluster-robust variance estimators for meta-analysis models
  mice,              # Multivariate Imputation by Chained Equations for handling missing data
  
  ###################################################################################################################
  # Exploratory Data Analysis (EDA)
  DataExplorer,      # Automates exploratory data analysis with summary statistics and visualizations
  SmartEDA,          # Automates exploratory data analysis with summary reports and visualizations
  naniar,            # Provides tools for handling and visualizing missing data
  VIM,               # Visualization and Imputation of Missing Data
  Hmisc,             # Miscellaneous functions including data summary, analysis, and visualization
  BaylorEdPsych,     # Provides tools for reliability analysis and missing data imputation
  openxlsx,          # Simplifies the the process of writing and styling Excel xlsx
  
  ###################################################################################################################
  # Project Management and Code Styling
  here,              # Simplifies file referencing by locating the root of a project directory
  styler             # Formats and styles R code to improve readability and consistency
)
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("summarize", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("intersect", "base")
```



# STEP 1 LOADING PREPARED META-DATA


## Loading the two datasets (imputed and non-imputed)

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())

# Suppress warnings to avoid clutter in the console output
suppressWarnings({

# Define file paths
non_imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom.rds"))
imp_data_rom <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))

# non_imp_data_rom_dummy <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom_dummy.rds"))

# Read in the non-imputed dataset
non_imp_dataset <- non_imp_data_rom %>%
  as.data.frame()|> 
  # select(-geometry) |> 
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, #exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )

# Read in the imputed dataset
imp_dataset <- imp_data_rom %>%
  as.data.frame()|> 
  relocate(
    # Overall ID info
    id_study, id_article, id_obs, treat_id, #exp_id,
    # Effect size calculation and variance
    yi, vi,
    # Response variable info
    response_variable, sub_response_variable,
    # Geographic and temporal info
    location, final_lat, final_lon, exp_site_loc, experiment_year,
    # Moderators info
    tree_type, crop_type, age_system, tree_age, season, soil_texture, no_tree_per_m, tree_height, alley_width,
    # Quantitative meta-analysis variables - mean and no. of observations
    silvo_mean, control_mean, silvo_n, control_n,
    # Quantitative meta-analysis variables - variance info
    silvo_se, silvo_sd, silvo_sd_from_se, silvo_sd_final, 
    control_se, control_sd, control_sd_from_se, control_sd_final
  )
})
```

```{r}
# Checking high observations with extreme high variance
high_variance_obs <- 
  imp_dataset|> 
  filter(vi > quantile(vi, 0.95)) |> # 0.995
  # Reorder columns for better readability
  relocate(id_article, response_variable, measured_metrics, measured_unit, 
           yi, vi,
           # Quantitative meta-analysis variables - mean and no. of observations
           silvo_mean, control_mean, silvo_n, control_n,
           # Quantitative meta-analysis variables - variance info
           silvo_se, silvo_sd_from_se, silvo_sd_final, 
           control_se, control_sd_from_se, control_sd_final,
           tree_type, crop_type, age_system, season, soil_texture, no_tree_per_m, tree_height, alley_width) |> 
  arrange(id_article, response_variable)

skim(high_variance_obs)
```
```{r}
non_imp_dataset |> glimpse()
imp_dataset |> glimpse()
```

```{r}
# Select distinct id_article entries
distinct_articles <- imp_dataset %>%
  select(id_article) %>%
  distinct()

# Get the number of unique id_article entries
num_distinct_articles <- nrow(distinct_articles)

# Print the result
cat("Number of distinct id_article entries:", num_distinct_articles, "\n")
# Number of distinct id_article entries: 37 
```

```{r}
skimr::skim(imp_dataset)
```




## Listing response variables and setting up costum colors

```{r}
# Custom colors for response variables
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Carbon sequestration"     = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC",
  "Water quality"            = "#9999FF"
)

# Response variables to analyze
response_variables <- names(custom_colors)
```

```{r}
# Filter dataset for specified response variables
filtered_dataset <- imp_dataset %>%
  filter(response_variable %in% response_variables)

# Calculate the Response Ratio
filtered_dataset <- filtered_dataset %>%
  mutate(
    ResponseRatio = silvo_mean / control_mean,
    log_ResponseRatio = log(ResponseRatio) # Log transformation for better interpretation
  ) |> 
  # Recalculate log ResponseRatio and add a small constant to avoid log(0)
  mutate(
    log_ResponseRatio = log(ResponseRatio + 1e-6) # Add a tiny constant for log safety
  )


# Bootstrap data for violin plot
bootstrapped_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarise(
    bootstrapped_rr = list(boot::boot(data = log_ResponseRatio, statistic = function(x, i) mean(x[i]), R = 25000)$t)
  ) %>%
  unnest(bootstrapped_rr)

# Summary statistics for plotting
summary_data <- filtered_dataset %>%
  group_by(response_variable) %>%
  summarize(
    WeightedMeanRR = mean(ResponseRatio, na.rm = TRUE),
    LowerCI = mean(ResponseRatio, na.rm = TRUE) - 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    UpperCI = mean(ResponseRatio, na.rm = TRUE) + 1.96 * sd(ResponseRatio, na.rm = TRUE) / sqrt(n()),
    RR_Less_1 = mean(ResponseRatio < 1) * 100,
    RR_Greater_1 = mean(ResponseRatio > 1) * 100,
    Studies = n_distinct(id_article),
    Observations = n(),
    .groups = "drop"
  )
```

```{r}
# Ensure consistent factor levels for response_variable
common_levels <- filtered_dataset$response_variable %>% unique() %>% sort()

filtered_dataset <- filtered_dataset %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

bootstrapped_data <- bootstrapped_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

summary_data <- summary_data %>%
  mutate(response_variable = factor(response_variable, levels = common_levels))

# Recreate the violin plot with proper alignment
violin_plot_response_var_lnrr <- 
  ggplot() +
  # Violin plot for bootstrapped data
  geom_violin(data = bootstrapped_data, aes(y = response_variable, x = exp(bootstrapped_rr), fill = response_variable), 
              alpha = 0.5, scale = "area") + # Use 'area' scaling for better proportional representation
  # Overlay mean and confidence intervals
  # geom_point(data = summary_data, aes(y = response_variable, x = exp(WeightedMeanRR)), color = "black", size = 3) +
  # geom_errorbarh(data = summary_data, aes(y = response_variable, xmin = exp(LowerCI), xmax = exp(UpperCI)), 
  #               height = 0.2, color = "black") +
  # Add a red vertical dotted line at x = 1
  geom_vline(xintercept = 1, linetype = "dotted", color = "red", size = 0.8) +
    # Add annotations for proportions and study counts
  geom_text(data = summary_data, aes(
    y = response_variable, x = max(summary_data$UpperCI) * 0.825, 
    label = paste0("RR<1: ", round(RR_Less_1), "%\nRR>1: ", round(RR_Greater_1), "%\n[N=", Studies, ", NO=", Observations, "]")
  ), size = 3, hjust = 0) +
  # Apply custom colors
  scale_fill_manual(values = custom_colors) +
  # Customize plot
  scale_x_continuous(limits = c(0.8, 1.6), trans = "identity", breaks = scales::pretty_breaks()) +
  labs(
    title = "Weighted Mean Response Ratio",
    subtitle = "Agroforestry vs. Non-Agroforestry Effects by Response Variable",
    x = "Response Ratio",
    y = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    legend.position = "none"
  )

# Print the plot
violin_plot_response_var_lnrr
```




 
## Publication-ready ridgeline plots of effect size distributions per response variable


Ridge Plot: Shows the distribution of effect sizes for each response variable.
 
```{r}
# meta_data |> glimpse()
```

```{r}
# Extract relevant columns, including vi
# effect_size_data <- meta_data %>%
#   select(response_variable, yi, vi) %>%
#   drop_na()  # Remove missing values
```

 
 








# STEP 2 PERFORMING MULTIVARIATE/MULTILEVEL LINEAR (MIXED-EFFECTS) MODELLING 


Assessment of Missing Data for Moderators
Imputation of Missing Values for Moderators Using mice()
Post-Imputation Assessment of Moderators
Selection of Moderators for Analysis
Fitting the Multivariate Random-Effects Model with Selected Moderators

```{r}
# Define the function for missing data assessment
assess_missing_data <- function(dataset, moderators, dataset_name = "Dataset") {
  
  cat("\nStarting missing data assessment for", dataset_name, "...\n")
  
  # Step 1: Calculate the proportion of missing values for each moderator
  missing_summary <- dataset %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = everything(), names_to = "variable", values_to = "missing_proportion")

  # Print the missing summary table
  cat("\nProportion of Missing Values for Each Moderator:\n")
  print(missing_summary)

  # Step 2: Create a basic bar chart of missing proportions
  missing_plot <- ggplot(missing_summary, aes(x = reorder(variable, -missing_proportion), y = missing_proportion)) +
    geom_bar(stat = "identity", fill = "#0072B2") +
    labs(
      title = paste("Proportion of Missing Data for Moderator Variables -", dataset_name),
      x = "Moderator Variable",
      y = "Missing Proportion"
    ) +
    scale_y_continuous(labels = scales::percent) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Step 3: Calculate missingness for each moderator by response_variable
  missing_by_response <- dataset %>%
    group_by(response_variable) %>%
    summarise(across(all_of(moderators), ~ mean(is.na(.), na.rm = TRUE))) %>%
    pivot_longer(cols = -response_variable, names_to = "moderator", values_to = "missing_proportion")

  # Print the summary table for missingness by response_variable
  cat("\nMissing Proportion by Response Variable for Each Moderator:\n")
  print(missing_by_response)

  # Step 4: Create a heatmap for missingness by response_variable
  missing_heatmap <- ggplot(missing_by_response, aes(x = moderator, y = response_variable, fill = missing_proportion)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "#56B1F7", high = "#132B43", na.value = "gray90", labels = scales::percent) +
    labs(
      title = paste("Heatmap of Missing Data by Moderator and Response Variable -", dataset_name),
      x = "Moderator Variable",
      y = "Response Variable",
      fill = "Missing Proportion"
    ) +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Display the plots
  print(missing_plot)
  print(missing_heatmap)
  
  cat("\nMissing data assessment completed for", dataset_name, ".\n")
}
```

```{r}
# Assessing Moderator missingness

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Assess missing data for non-imputed dataset
assess_missing_data(non_imp_dataset, moderators, "Non-Imputed Dataset")

# Assess missing data for imputed dataset
assess_missing_data(imp_dataset, moderators, "Imputed Dataset")
```






## Creating a variance-covariance matrix



```{r}
# Variance-Covariance Matrix Calculation Function
calculate_v_matrix <- function(data, correlation = 0.5) {
  cat("\nCalculating Variance-Covariance Matrix...\n")
  
  v_list <- list()
  for (study in unique(data$id_article)) {
    study_data <- data[data$id_article == study, ]
    
    if (nrow(study_data) > 1) {
      v <- diag(study_data$vi)
      for (i in 1:nrow(v)) {
        for (j in 1:nrow(v)) {
          if (i != j) {
            v[i, j] <- correlation * sqrt(v[i, i] * v[j, j])
          }
        }
      }
      v_list[[as.character(study)]] <- v
    } else {
      v_list[[as.character(study)]] <- matrix(study_data$vi, nrow = 1, ncol = 1)
    }
  }

  v_matrix <- bldiag(v_list)
  cat("\nGenerated Variance-Covariance Matrix:\n")
  print(v_matrix)
  
  return(v_matrix)
}
```

```{r results = 'hide'}
#########################################################################
###############################################################################
###################################################################################
########################################################################################
#############################################################################################
####################################################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset

####################################################################################################
#############################################################################################
########################################################################################
###################################################################################
###############################################################################
#########################################################################


# Directory for saving results
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
if (!dir.exists(output_dir)) dir.create(output_dir, recursive = TRUE)

# Generate and save v_matrices for each response variable
v_matrices <- list()

for (response in response_variables) {
  cat("\nProcessing response variable:", response, "\n")
  
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]
  
  # Calculate the variance-covariance matrix
  v_matrix <- invisible(calculate_v_matrix(data_subset, correlation = 0.5))
  
  # Store the matrix in the list
  v_matrices[[response]] <- v_matrix
  
  # Save the matrix to an individual RDS file
  file_name <- paste0("v_matrix_", tolower(gsub(" ", "_", response)), ".rds")
  saveRDS(v_matrix, file = file.path(output_dir, file_name))
  
  cat("Saved v_matrix for response variable:", response, "to", file.path(output_dir, file_name), "\n")
}

# Also, save the entire list of v_matrices as a single file
saveRDS(v_matrices, file = file.path(output_dir, "v_matrices_by_response_variable.rds"))
cat("\nAll v_matrices saved to:", output_dir, "\n")
```

# STEP 4 TESTING DIFFERENT RANDOM EFFECTS STRUCTURES FOR THE CHOSEN MODEL (MINIMAL RANDOM EFFECTS MODEL)


```{r}
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset

# Define the 4 random effects structures to test
random_effect_structures <- list(
 # study_exp = list(~ 1 | id_article / exp_id),
  study_year         = list(~ 1 | id_article / experiment_year),
  study_loc_year     = list(~ 1 | id_article / location * experiment_year),  # <------- ! Chosen Random Effects Structure !
  study_and_loc_year = list(~ 1 | id_article,
                            ~ 1 | location / experiment_year
  )
)

# Define moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Run model comparisons for each response variable under each random effect structure
model_comparison_results <- list()

for (response in names(v_matrices)) {
  cat("\n================= Testing random effects for:", response, "=================\n")
  
  data_subset <- meta_data %>% filter(response_variable == response) %>%
    mutate(across(all_of(moderators), as.factor))
  v_matrix <- v_matrices[[response]]

  response_results <- list()

  for (re_name in names(random_effect_structures)) {
    cat("\n--- Using random effects:", re_name, "---\n")

    tryCatch({
      model_fit <- rma.mv(
        yi = yi,
        V = v_matrix,
        mods = ~ 1,
        random = random_effect_structures[[re_name]],
        data = data_subset,
        method = "REML",
        control = control_params
      )
      
      response_results[[re_name]] <- list(
        AIC = AIC(model_fit),
        BIC = BIC(model_fit),
        logLik = logLik(model_fit),
        tau2 = model_fit$tau2,
        model = model_fit
      )
    }, error = function(e) {
      cat("\u274c Error for", re_name, ":", e$message, "\n")
      response_results[[re_name]] <- NULL
    })
  }

  model_comparison_results[[response]] <- response_results
}

# Summarize results into a data frame
extract_summary <- function(results, response) {
  tibble::tibble(
    response_variable = response,
    random_structure = names(results),
    AIC = purrr::map_dbl(results, ~ if (!is.null(.x)) .x$AIC else NA_real_),
    BIC = purrr::map_dbl(results, ~ if (!is.null(.x)) .x$BIC else NA_real_),
    logLik = purrr::map_dbl(results, ~ if (!is.null(.x)) .x$logLik else NA_real_),
    total_tau2 = purrr::map_dbl(results, ~ if (!is.null(.x$tau2)) sum(.x$tau2) else NA_real_))}
  


# Compile all
model_re_structures_summary <- purrr::map2_dfr(model_comparison_results, names(model_comparison_results), extract_summary)

# View ordered by AIC
model_re_structures_summary %>%
  arrange(response_variable, AIC)

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (04/02-2025) 
# Total time taken: 6.676552 mins 
# Last go (25/03-2025) 
# Total time taken: 17.43763 mins 
```
## Best Random Effects Structure Per Response Variable (based on AIC)

```{r}
best_random_structure_by_response <- model_re_structures_summary %>%
  group_by(response_variable) %>%
  arrange(AIC, .by_group = TRUE) %>%
  slice(1) %>%
  ungroup()

# Mean AIC per Random Effects Structure Grouped by Response Variable
mean_aic_by_response <- model_re_structures_summary %>%
  group_by(response_variable, random_structure) %>%
  summarise(mean_AIC = mean(AIC, na.rm = TRUE), .groups = "drop") %>%
  arrange(response_variable, mean_AIC)

mean_aic_by_response
```

## Overall Best Random Effects Structure (across all responses)

```{r}
# Count how many times each structure performed best
overall_best_random_structure <- best_random_structure_by_response %>%
  count(random_structure, sort = TRUE)

# Overall Mean AIC per Random Effects Structure
mean_aic_overall <- model_re_structures_summary %>%
  group_by(random_structure) %>%
  summarise(mean_AIC = mean(AIC, na.rm = TRUE), .groups = "drop") %>%
  arrange(mean_AIC)

mean_aic_overall
```

## Visualising Mean AIC per Random Effects Structure Grouped by Response Variable

```{r}
# Plot: Mean AIC per Random Effects Structure Grouped by Response Variable
mean_aic_by_response |> 
ggplot(aes(x = reorder(random_structure, mean_AIC), y = mean_AIC, fill = random_structure)) +
  geom_col(show.legend = FALSE, width = 0.6) +
  facet_wrap(~response_variable, scales = "free_y") +
  labs(
    title = "Mean AIC per Random Effects Structure (by Response Variable)",
    x = "Random Effects Structure",
    y = "Mean AIC"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(color = "grey80"),
    panel.spacing = unit(1, "lines")
  )

# Plot: Overall Mean AIC per Random Effects Structure (Summarized)
mean_aic_overall |> 
  ggplot(aes(x = reorder(random_structure, mean_AIC), y = mean_AIC, fill = random_structure)) +
  geom_col(width = 0.5, show.legend = FALSE) +
  labs(
    title = "Overall Mean AIC Across All Response Variables",
    x = "Random Effects Structure",
    y = "Mean AIC"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    panel.grid.major.y = element_line(color = "grey80")
  )

# Plot: AIC of All Random Structures by Response Variable
model_re_structures_summary |> 
  ggplot(aes(x = random_structure, y = AIC, fill = random_structure)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.6, show.legend = FALSE) +
  labs(
    title = "AIC of Random Effects Structures per Response Variable",
    x = "Random Effects Structure",
    y = "AIC"
  ) +
  facet_grid(. ~ response_variable, scales = "free_y", space = "free_x") +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 12, face = "bold"),
    panel.grid.major.y = element_line(color = "grey85"),
    panel.spacing.x = unit(1.5, "lines")
  ) +
  scale_fill_brewer(palette = "Set2")
```






# STEP 5 MODEL FITTING ON EACH SUBSET DATA USING ASSOCIATED VARIANCE-COVARIANCE MATRIX


## Loading variance-covariance matrix 

```{r}
# Load the saved v_matrices
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
v_matrices <- readRDS(file.path(dir, "v_matrices_by_response_variable.rds"))
```


## Double checking missingness of data before model fitting

```{r eval=FALSE}
imp_dataset |> glimpse()
```

```{r eval=FALSE}
# Summary of missing data by column
missing_summary <- imp_dataset %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "MissingCount")

# View variables with missing data
missing_summary <- missing_summary %>%
  filter(MissingCount > 0) %>%
  arrange(desc(MissingCount))

# Visualize missingness
gg_miss_var(imp_dataset) +
  labs(title = "Missing Data Across Variables")

# View rows with missing data
rows_with_missing <- imp_dataset %>%
  filter(!complete.cases(.))
```

```{r eval=FALSE}
# Summary statistics for effect size (yi)
summary(imp_dataset$yi)

# Summary statistics for variance (vi)
summary(imp_dataset$vi)

# Identify rows with extreme variances on a sub_response_variable level
extreme_variance_rows <- imp_dataset %>%
  group_by(sub_response_variable) %>%
  filter(vi > quantile(vi, 0.95, na.rm = TRUE) | vi < quantile(vi, 0.05, na.rm = TRUE)) %>%
  ungroup() %>%
  arrange(desc(vi))

extreme_variance_rows |> glimpse()

# Last go (24/01-2025)
#    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
#  0.00000  0.00019  0.00102  0.09496  0.00620 40.29043 
# Rows: 131
# Columns: 64
```


## Fitting models (sub-group) for each response variable using precomputed v_matrices

```{r}
meta_data |> skimr::skim()
```

```{r}
##########################################################################################################################################
# HIERARCHICAL COMPLEXITY APPROACH ALIGNED WITH THE CABBAGE APPROACH
##########################################################################################################################################

# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################


# Global control parameters for optimization
control_params <- list(
  optimizer = "optim",
  method = "BFGS",
  iter.max = 10000,
  rel.tol = 1e-12
)

# Explicitly Convert all moderators to factors
data_subset <- data_subset %>%
  mutate(across(c(age_system, crop_type, tree_type, season, soil_texture,
                  no_tree_per_m, tree_height, alley_width), as.factor))


# Transparent and reproducible 'cabbage-style' meta-analysis moderator testing
fit_meta_analysis_moderator_models <- function(data_subset, response_variable, v_matrix, random_effects) {
  cat("\n--- Processing response variable:", response_variable, "---\n")
  
  results <- list()

  # ------------------------------------------------------------------------------------------------
  # Base multilevel model (intercept only)
  # ------------------------------------------------------------------------------------------------
  results$base_model <- tryCatch({                                        
    rma.mv(                                                                           # Baseline model (iterated on each response variable)
      yi = yi,
      V = v_matrix,
      mods = ~1,
      random = random_effects,
      data = data_subset,
      method = "REML",
      control = control_params
    )
  }, error = function(e) {
    cat("\u274c Error in base model:", e$message, "\n")
    NULL
  })
  # ------------------------------------------------------------------------------------------------
  # Explicit one-by-one moderator models
  # ------------------------------------------------------------------------------------------------
  results$tree_type <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + tree_type, random = random_effects,        # Tree Type
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$crop_type <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + crop_type, random = random_effects,        # Crop Type
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$age_system <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + age_system, random = random_effects,       # Age System
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$season <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + season, random = random_effects,           # Season
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$soil_texture <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + soil_texture, random = random_effects,     # Soil Texture
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$no_tree_per_m <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + no_tree_per_m, random = random_effects,     # Number of Trees per m2
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$tree_height <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + tree_height, random = random_effects,       # Tree Height
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  results$alley_width <- tryCatch({
    rma.mv(yi, V = v_matrix, mods = ~ -1 + alley_width, random = random_effects,       # Alley Width
           data = data_subset, method = "REML", control = control_params)
  }, error = function(e) NULL)

  # ------------------------------------------------------------------------------------------------
  # Two-way interaction models between selected pairs
  # ------------------------------------------------------------------------------------------------
  interaction_pairs <- list(                                                         # Selected two-way interactions 
    c("tree_type", "crop_type"),
    c("tree_type", "age_system"),
    c("crop_type", "season"),
    c("soil_texture", "age_system"),
    c("tree_height", "alley_width"),
    c("tillage", "organic"),
     c("crop_type", "tree_height", "alley_width")
    # organic (1 = organic, 0 = conventional)
    # tillage (1 = tillage, 0 = no tillage)
  )

  for (pair in interaction_pairs) {
    # Include -1 to remove the intercept
    mod_formula <- as.formula(paste("~ -1 +", paste(pair, collapse = " * ")))
    model_name <- paste(pair, collapse = "_x_")
    results[[model_name]] <- tryCatch({
      rma.mv(
        yi = yi,
        V = v_matrix,
        mods = mod_formula,
        random = random_effects,
        data = data_subset,
        method = "REML",
        control = control_params
      )
    }, error = function(e) {
      cat("\u274c Error in interaction model for", model_name, ":", e$message, "\n")
      NULL
    })
  }

  return(results)
}

# ------------------------------------------------------------------------------------------------
# ------------------------------------------------------------------------------------------------
# Loop over each response variable to fit cabbage-style models
model_results <- list()

for (response in names(v_matrices)) {
  data_subset <- meta_data[meta_data$response_variable == response, ]
  v_matrix <- v_matrices[[response]]
  
  random_effects <- list(~ 1 | id_article / location * experiment_year)
  # random_effects <- list(~ 1 | id_article / experiment_year)
  # random_effects <- list(~ 1 | id_article,
  #                        ~ 1 |location/experiment_year)
  
  model_results[[response]] <- fit_meta_analysis_moderator_models(
    data_subset = data_subset,
    response_variable = response,
    v_matrix = v_matrix,
    random_effects = random_effects
  )
}


##########################################################################
# Save All Fitted Models
##########################################################################

# Save all model results to disk
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Save all models in a single RDS file
saveRDS(model_results, file = file.path(output_dir, "fitted_models_all_new.rds"))

# Save individual model results per response variable
for (response in names(model_results)) {
  saveRDS(model_results[[response]],
          file = file.path(output_dir, paste0("fitted_models_", response, "_new.rds")))
}

cat("\nAll models have been saved successfully!\n")

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (27/03-2025) 
# Total time taken: 1.374625 mins 
```


The meta-analysis model testing successfully fitted intercept-only and one-by-one moderator models across all response variables, providing a reproducible structure for interpreting silvoarable effects. However, several two-way interaction models failed, primarily due to missing values, single-level factors, or factors with only one valid level, which prevents contrast estimation. Warnings about extreme variance ratios suggest caution in interpreting models with highly imbalanced sampling precision. Despite these issues, most models ran as expected and were saved successfully. Future runs should filter incomplete combinations and ensure all interaction moderators have at least two levels and sufficient non-missing data across response variables.

```{r}
# Cross-checking data
# table(meta_data$id_article, meta_data$location, meta_data$experiment_year)
# table(meta_data$location, meta_data$experiment_year)
```


Explanations of the above Multi-Model Fitting 

```{r}
# Load and assess the model results from the saved file
# Load the combined model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

# Evaluation function for updated cabbage-style model set
evaluate_model <- function(models, response_variable) {
  cat("\n======================")
  cat("\nEvaluating models for response variable:", response_variable)
  cat("\n======================\n")

  evaluation_results <- list()

  # Base multilevel model
  if (!is.null(models$base_model)) {
    evaluation_results$base_model <- summary(models$base_model)
    cat("\n[Base] Intercept-only model (random effects only):\n")
    cat(paste(capture.output(evaluation_results$base_model), collapse = "\n"), "\n")
  }

  # Individual moderator models
  moderator_names <- c("tree_type", "crop_type", "age_system", "season",
                       "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

  cat("\n[Moderators] Individual moderator models:\n")
  evaluation_results$moderators <- list()
  for (mod in moderator_names) {
    if (!is.null(models[[mod]])) {
      evaluation_results$moderators[[mod]] <- summary(models[[mod]])
      cat("\n[", mod, "]\n", sep = "")
      cat(paste(capture.output(evaluation_results$moderators[[mod]]), collapse = "\n"), "\n")
    } else {
      cat("\n[", mod, "] Model not available.\n", sep = "")
    }
  }

  # Two-way interaction models
  interaction_pairs <- list(
    c("tree_type", "crop_type"),
    c("tree_type", "age_system"),
    c("crop_type", "season"),
    c("soil_texture", "age_system"),
    c("tree_height", "alley_width")
  )
  cat("\n[Interactions] Two-way interaction models:\n")
  evaluation_results$interactions <- list()
  for (pair in interaction_pairs) {
    mod_name <- paste(pair, collapse = "_x_")
    if (!is.null(models[[mod_name]])) {
      evaluation_results$interactions[[mod_name]] <- summary(models[[mod_name]])
      cat("\n[", mod_name, "]\n", sep = "")
      cat(paste(capture.output(evaluation_results$interactions[[mod_name]]), collapse = "\n"), "\n")
    } else {
      cat("\n[", mod_name, "] Model not available.\n", sep = "")
    }
  }

  return(evaluation_results)
}

# Loop through each response variable and evaluate models
evaluation_results <- list()

for (response in names(model_results)) {
  evaluation_results[[response]] <- evaluate_model(models = model_results[[response]], response_variable = response)
}

cat("\nModel evaluation completed.\n")

# Save all evaluation results
eval_output_dir <- here::here("DATA", "OUTPUT_FROM_R", "MULTI_MODEL_EVALUATION_RESULTS")

saveRDS(evaluation_results, file = file.path(eval_output_dir, "evaluation_results_combined.rds"))

for (response in names(evaluation_results)) {
  saveRDS(evaluation_results[[response]],
          file = file.path(eval_output_dir, paste0("evaluation_results_", response, ".rds")))
}

cat("\nEvaluation results of the multi-model fitting have been saved successfully!\n")

evaluation_results$`Crop yield`$interactions$soil_texture_x_age_system
```





# STEP 4 MODEL EVALUATION AND SELECTION

## Extracting individual base model results

```{r}
# Example of extracting individual base model and moderator model results
evaluation_results$`Crop yield`$base_model
evaluation_results$`Crop yield`$moderators

evaluation_results$Biodiversity$base_model
evaluation_results$Biodiversity$moderators
```


## Assess AIC and BIC of all models

```{r}
##########################################################################
# Assess AIC, BIC, and LogLik from all models
##########################################################################


# Load saved model results
model_results <- readRDS(file = here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))

# Function to extract AIC, BIC, LogLik from all models
extract_model_fits <- function(model_list, response_variable) {
  # Loop over named models within a response variable
  tibble::tibble(
    response_variable = response_variable,
    model_name = names(model_list),
    AIC = map_dbl(model_list, ~ if (!is.null(.x)) AIC(.x) else NA_real_),
    BIC = map_dbl(model_list, ~ if (!is.null(.x)) BIC(.x) else NA_real_),
    logLik = map_dbl(model_list, ~ if (!is.null(.x)) logLik(.x) else NA_real_)
  )
}

# Apply to all response variables
model_fits <- purrr::map2_dfr(model_results, names(model_results), extract_model_fits)

# View summary
model_fits %>% dplyr::arrange(response_variable, AIC)

```




# STEP 6 ANOVA CONTRAST OF MULTI-MODEL EFFECTS ESTIMATES

anova(res, X=rbind(c(1,0,0),c(0,1,0),c(0,0,1)))

```{r}
# STEP 1: Extract the model object
model_results$Biodiversity$soil_texture  # <--- This might be the real model, not a summary

# Confirm it's an rma.mv object and not a data.frame
if (!inherits(soil_texture_model, "rma.mv")) stop("You are using the summary data.frame, not the actual model object.")

# 2. Extract coefficient names (will look like: "soil_textureClay", etc.)
coef_names <- rownames(soil_texture_model$b)
print(coef_names)  # Sanity check


# 3. Build contrast matrix — pairwise comparisons between 3 levels
contrast_matrix <- rbind(
  "Clay vs Sand" = c(1, -1, 0),
  "Clay vs Silt" = c(1, 0, -1),
  "Sand vs Silt" = c(0, 1, -1)
)
colnames(contrast_matrix) <- coef_names  # Align names!

# 4. Run ANOVA (Wald-type test for linear hypotheses)
anova_results <- anova(soil_texture_model, X = contrast_matrix)
print(anova_results)
```

Clay vs Sand: There is no difference in biodiversity effects between Clay and Sand soils. The estimate is essentially zero, and the p-value is extremely high (0.999). Clay vs Silt: Again, no meaningful difference. The negative estimate suggests a slight trend of lower effects in Silt, but it's not statistically significant. Sand vs Silt: This is significant (p = 0.012). The negative estimate (−0.110) means biodiversity effects under Silt soils are higher than under Sand soils. In other words, Silt soils support stronger biodiversity benefits from silvoarable systems compared to Sand soils — and this difference is statistically reliable.




# STEP 7 BACK-TRANSFORM MODEL RESULTS FROM LOG-ROM TO PERCENTAGE FOR ALL RESPONSE VARIABLES

## Function for extracting and back-transforming model evaluation results (base models)

```{r}
# Updated function: Back-transform and structure log-ROM base models only

back_transform_base_models <- function(evaluation_results) {
  all_base_results <- list()

  for (response in names(evaluation_results)) {
    model <- evaluation_results[[response]]$base_model

    if (is.null(model)) {
      all_base_results[[response]] <- NULL
      next
    }

    if (!is.null(model$b)) {
      estimate <- as.numeric(model$b)
      se <- model$se
      zval <- model$zval
      pval <- model$pval
      ci.lb <- model$ci.lb
      ci.ub <- model$ci.ub

      coef_df <- tibble(
        model = "base_model",
        response = response,
        estimate = estimate,
        se = se,
        zval = zval,
        pval = pval,
        ci.lb = ci.lb,
        ci.ub = ci.ub,
        ROM_percent = (exp(estimate) - 1) * 100,
        ROM_lower_percent = (exp(ci.lb) - 1) * 100,
        ROM_upper_percent = (exp(ci.ub) - 1) * 100,
        signif = case_when(
          pval < 0.001 ~ "***",
          pval < 0.01 ~ "**",
          pval < 0.05 ~ "*",
          pval < 0.1 ~ ".",
          pval < 0.15 ~ "?",
          TRUE ~ ""
        )
      )

      all_base_results[[response]] <- coef_df
    } else {
      all_base_results[[response]] <- NULL
    }
  }

  return(all_base_results)
}


back_transformed_base <- back_transform_base_models(evaluation_results)

back_transformed_base
```


## Function for extracting and back-transforming model evaluation results (moderator interaction models)

```{r}
# Fixed function: Back-transform moderator models (not interactions)
back_transform_moderator_models <- function(evaluation_results) {
  all_moderator_results <- list()

  for (response in names(evaluation_results)) {
    moderator_models <- evaluation_results[[response]]$moderators

    response_results <- list()

    for (model_name in names(moderator_models)) {
      model <- moderator_models[[model_name]]
      if (is.null(model)) next

      coef_df <- tryCatch({
        data.frame(
          moderator = rownames(model$b),
          estimate = as.numeric(model$b),
          se = as.numeric(model$se),
          zval = as.numeric(model$zval),
          pval = as.numeric(model$pval),
          ci.lb = as.numeric(model$ci.lb),
          ci.ub = as.numeric(model$ci.ub)
        ) %>% 
        mutate(
          ROM_percent = (exp(estimate) - 1) * 100,
          ROM_lower_percent = (exp(ci.lb) - 1) * 100,
          ROM_upper_percent = (exp(ci.ub) - 1) * 100,
          signif = case_when(
            pval < 0.001 ~ "***",
            pval < 0.01 ~ "**",
            pval < 0.05 ~ "*",
            pval < 0.1 ~ ".",
            pval < 0.15 ~ "?",
            TRUE ~ ""
          ),
          model = model_name,
          response = response,
          moderator = gsub(paste0("^", model_name), "", moderator),
          moderator = gsub("^_+", "", moderator),
          moderator = gsub("^:+", "", moderator)
        ) %>% 
          rename(moderator_model = model,
                 moderator_factor_level = moderator) |> 
        relocate(response, moderator_model, moderator_factor_level)
      }, error = function(e) {
        message("\u274c Error extracting moderator model for ", response, " ", model_name, ": ", e$message)
        NULL
      })

      response_results[[model_name]] <- coef_df
    }

    all_moderator_results[[response]] <- response_results
  }

  return(all_moderator_results)
}


back_transform_moderator_models <- back_transform_moderator_models(evaluation_results)

back_transform_moderator_models
```

```{r}
# New function: Back-transform interaction moderator models
back_transform_moderator_models_with_interactions <- function(evaluation_results) {
  all_interaction_results <- list()

  for (response in names(evaluation_results)) {
    interaction_models <- evaluation_results[[response]]$interactions

    response_results <- list()

    for (model_name in names(interaction_models)) {
      model <- interaction_models[[model_name]]
      if (is.null(model)) next

      vars <- strsplit(model_name, "_x_")[[1]]
      clean_interaction <- function(x) {
        for (v in vars) {
          x <- gsub(paste0(v), "", x)
        }
        x <- gsub("^:+", "", x)
        x <- gsub("^_+", "", x)
        x
      }

      coef_df <- tryCatch({
        data.frame(
          moderator_factor_level = rownames(model$b),
          estimate = as.numeric(model$b),
          se = as.numeric(model$se),
          zval = as.numeric(model$zval),
          pval = as.numeric(model$pval),
          ci.lb = as.numeric(model$ci.lb),
          ci.ub = as.numeric(model$ci.ub)
        ) %>% 
        mutate(
          ROM_percent = (exp(estimate) - 1) * 100,
          ROM_lower_percent = (exp(ci.lb) - 1) * 100,
          ROM_upper_percent = (exp(ci.ub) - 1) * 100,
          signif = case_when(
            pval < 0.001 ~ "***",
            pval < 0.01 ~ "**",
            pval < 0.05 ~ "*",
            pval < 0.1 ~ ".",
            pval < 0.15 ~ "?",
            TRUE ~ ""
          ),
          moderator_model = model_name,
          response = response,
          moderator_factor_level = clean_interaction(moderator_factor_level)
        ) %>% 
        relocate(moderator_model, response, moderator_factor_level)
      }, error = function(e) {
        message("\u274c Error extracting interaction model for ", response, " ", model_name, ": ", e$message)
        NULL
      })

      response_results[[model_name]] <- coef_df
    }

    all_interaction_results[[response]] <- response_results
  }

  return(all_interaction_results)
}


back_transformed_interactions <- back_transform_moderator_models_with_interactions(evaluation_results)

back_transformed_interactions
```











## Publication-ready table with model results 

```{r}
# Publication-ready summary tables

# Combine base model results
table_base <- bind_rows(back_transformed_base) %>%
  select(
    response, model = model,
    estimate, se, zval, pval, ci.lb, ci.ub,
    ROM_percent, ROM_lower_percent, ROM_upper_percent,
    signif
  ) %>%
  arrange(response)

# Combine moderator model results
table_moderators <- back_transform_moderator_models %>%
  purrr::compact() %>%
  purrr::map_dfr(~ purrr::compact(.x) %>% bind_rows(), .id = "response") %>%
  select(
    response, moderator_model,
    moderator_factor_level, estimate, se, zval, pval,
    ci.lb, ci.ub,
    ROM_percent, ROM_lower_percent, ROM_upper_percent,
    signif
  ) %>%
  arrange(response, moderator_model, moderator_factor_level)

# Combine interaction model results
table_interactions <- back_transformed_interactions %>%
  purrr::compact() %>%
  purrr::map_dfr(~ purrr::compact(.x) %>% bind_rows(), .id = "response") %>%
  select(
    response, moderator_model,
    moderator_factor_level, estimate, se, zval, pval,
    ci.lb, ci.ub,
    ROM_percent, ROM_lower_percent, ROM_upper_percent,
    signif
  ) %>%
  arrange(response, moderator_model, moderator_factor_level)

# Show result structure
list(
  base_models = table_base,
  moderator_models = table_moderators,
  interaction_models = table_interactions
)
```
## Generate GT tables

```{r}
# 1. Tidy table for base models
base_model_table <- table_base %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  gt() %>%
  tab_header(title = "Base Model Results") %>%
  cols_label(
    response = "Response",
    model = "Model",
    estimate = "Estimate",
    se = "SE",
    zval = "Z-value",
    pval = "P-value",
    ci.lb = "CI lower",
    ci.ub = "CI upper",
    ROM_percent = "ROM (%)",
    ROM_lower_percent = "ROM lower (%)",
    ROM_upper_percent = "ROM upper (%)",
    signif = "Significance"
  ) %>%
  cols_hide(columns = c("ci.lb", "ci.ub"))

base_model_table
```
```{r}

# Assuming the table has columns for 'estimate', 'ci.lb', and 'ci.ub', which are not backtransformed

# Create the table without any transformations
base_model_table_no_backtransformed <- table_base %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  gt() %>%
  tab_header(title = "Base Model Results - Non-backtransformed") %>%
  cols_label(
    response = "Response",
    model = "Model",
    estimate = "Estimate (non-backtransformed)",
    se = "SE",
    zval = "Z-value",
    pval = "P-value",
    ci.lb = "CI lower (non-backtransformed)",
    ci.ub = "CI upper (non-backtransformed)",
    ROM_percent = "ROM (%)",
    ROM_lower_percent = "ROM lower (%)",
    ROM_upper_percent = "ROM upper (%)",
    signif = "Significance"
  ) %>%
  cols_hide(columns = c("ROM_percent", "ROM_lower_percent", "ROM_upper_percent"))

# Extract the non-backtransformed estimates and CI
non_backtransformed_data <- table_base %>%
  select(response, model, estimate, ci.lb, ci.ub)

# Print the table with non-backtransformed values
print(base_model_table_no_backtransformed)

# Alternatively, if you have an additional column that indicates whether a transformation was applied, you can filter by that column
# For example, if you have a column `backtransformed` that indicates if the values were backtransformed, you could filter:
# table_base %>% filter(backtransformed == FALSE)


```


Extracting to non-backtransformed estimates and confidence intervals


```{r}
# 2. Tidy table for moderator models
moderator_model_table <- table_moderators %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  gt() %>%
  tab_header(title = "Moderator Model Results") %>%
  cols_label(
    response = "Response",
    moderator_model = "Moderator",
    moderator_factor_level = "Factor Level",
    estimate = "Estimate",
    se = "SE",
    zval = "Z-value",
    pval = "P-value",
    ci.lb = "CI lower",
    ci.ub = "CI upper",
    ROM_percent = "ROM (%)",
    ROM_lower_percent = "ROM lower (%)",
    ROM_upper_percent = "ROM upper (%)",
    signif = "Significance"
  ) %>%
  cols_hide(columns = c("ci.lb", "ci.ub"))

moderator_model_table
```


```{r}
# 3. Tidy table for interaction moderator models
interaction_model_table <- table_interactions %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  gt() %>%
  tab_header(title = "Interaction Moderator Model Results") %>%
  cols_label(
    response = "Response",
    moderator_model = "Interaction",
    moderator_factor_level = "Factor Level",
    estimate = "Estimate",
    se = "SE",
    zval = "Z-value",
    pval = "P-value",
    #ci.lb = "CI lower",
    #ci.ub = "CI upper",
    ROM_percent = "ROM (%)",
    ROM_lower_percent = "ROM lower (%)",
    ROM_upper_percent = "ROM upper (%)",
    signif = "Significance"
  ) %>%
  cols_hide(columns = c("ci.lb", "ci.ub"))

interaction_model_table
```




(OBS! Needs updating after the new random effects structure has been implemented)


Interpretation of Back-Transformed Effects (ROM %) for Agroforestry Outcomes
The back-transformed Ratio of Means (ROM) values, expressed as percentages, provide an interpretable measure of effect size across response variables, indicating the relative change under agroforestry compared to open-field controls. Confidence intervals (CIs) reflect the uncertainty around these estimates.

Among the seven response variables analyzed in the base models, biodiversity (+20.4% [CI: +1.3%, +43.1%]) and carbon sequestration (+6.3% [CI: +5.7%, +6.8%]) showed significant positive effects, highlighting robust ecosystem service benefits of agroforestry systems. Product quality declined slightly (-3.3% [CI: -6.5%, -0.01%]), with the effect reaching statistical significance.

For other variables, effects were more uncertain. Crop yield decreased on average (-8.3% [CI: -18.0%, +2.6%]), but the wide confidence interval overlapped zero, suggesting variability across sites and systems. Similarly, soil quality (+5.1% [CI: -3.7%, +14.7%]), pest and disease control (-24.9% [CI: -49.6%, +12.0%]), and water quality (+20.1% [CI: -16.0%, +71.5%]) all showed wide, non-significant intervals, indicating context-dependent or inconclusive effects.

Overall, these results suggest that agroforestry can deliver clear benefits for biodiversity and carbon storage, while impacts on crop production and other environmental indicators are variable and likely influenced by local conditions, management practices, and system design.




# STEP 7 META-ANALYSIS MODEL DIAGNOSTICS - HETEROGENEITY STATISTICS

```{r}
# model_results |> str()
# model_results$`Crop yield` |> str()

model_results$`Crop yield`$base_model
```


```{r}
##########################################################################################################################################
# A: Extract heterogeneity statistics from base models
##########################################################################################################################################

extract_heterogeneity_stats <- function(model_results) {
  heterogeneity_stats <- lapply(names(model_results), function(response) {
    
    model <- model_results[[response]]$base_model  # ⬅️ This is the correct slot for base (intercept-only) models
    if (is.null(model)) return(NULL)

    QE <- model$QE
    df <- model$QEdf
    I2 <- if (!is.null(QE) && QE > df) (QE - df) / QE * 100 else 0

    data.frame(
      Response_Variable = response,
      I2_percent = round(I2, 2),
      Tau2 = round(model$tau2, 4),
      QE = round(QE, 2),
      QE_pval = signif(model$QEp, 3),
      stringsAsFactors = FALSE
    )
  })

  # Combine into one data frame
  do.call(rbind, heterogeneity_stats)
}

# Extract heterogeneity statistics from saved models
heterogeneity_base <- extract_heterogeneity_stats(model_results)

# View results
heterogeneity_base
```

```{r}


##########################################################################################################################################
# B: Extract heterogeneity statistics from interaction models
##########################################################################################################################################

extract_all_heterogeneity_stats <- function(model_results) {
  heterogeneity_list <- list()

  for (response in names(model_results)) {
    models <- model_results[[response]]
    
    for (model_name in names(models)) {
      model <- models[[model_name]]
      
      if (is.null(model)) next
      
      QE <- model$QE
      df <- model$QEdf
      I2 <- if (!is.null(QE) && QE > df) (QE - df) / QE * 100 else 0
      
      heterogeneity_list[[paste(response, model_name, sep = "_")]] <- data.frame(
        Response = response,
        Model = model_name,
        I2_percent = round(I2, 2),
        Tau2 = model$tau2,
        QE = QE,
        QE_pval = model$QEp
      )
    }
  }

  # Combine all results
  heterogeneity_df <- do.call(rbind, heterogeneity_list)
  rownames(heterogeneity_df) <- NULL
  return(heterogeneity_df)
}


# Run and inspect
heterogeneity_moderators <- extract_all_heterogeneity_stats(model_results)


# Sort to see ordered by I² 
heterogeneity_moderators %>%
  arrange(Response, I2_percent) 
```



```{r}
# Sort to see which models reduce I² the most
heterogeneity_moderators %>%
  arrange(Response, I2_percent) %>%
  group_by(Response) %>%
  slice(1)  # Best model per response
```


Heterogeneity Diagnostics in the Base Meta-Analysis Models

Evaluating heterogeneity statistics across all fitted models provides insight into which moderators are most effective at explaining between-study variation. We focus on three key indicators: I² (percentage of total variability due to heterogeneity), Tau² (between-study variance), and QE (Cochran’s Q test of residual heterogeneity).

1. Overall Patterns of Heterogeneity
Across all response variables, I² values remain high, indicating persistent between-study variability. Notably, Tau² is zero for all models, which may suggest either low true between-study variance or insufficient power to detect it. Significant QE p-values (all < 0.001) across models confirm that residual heterogeneity remains after accounting for random effects—even in models with relatively low I².

2. Best Models for Reducing I² per Response Variable
By comparing I² across all models, we identified the best-performing moderator model for each response variable

3. Interpretation and Implications
Product Quality stands out: The model including number of trees per meter substantially reduces I² to 32.8%, suggesting this moderator meaningfully explains variation across studies. This is the only response where heterogeneity is reduced to a moderate level.

Carbon Sequestration and Crop Yield show notable I² reduction when modeled with soil texture × age system interactions, dropping from ~98.5% to ~97%. While still high, this suggests interactions capture part of the heterogeneity.

For Biodiversity, Soil Quality, Water Quality, and Pest & Disease Control, none of the tested moderators reduced I² relative to the base model. This points to unexplained heterogeneity and the potential need for more informative or context-specific moderators (e.g., climate, management, or methodological variables).

4. Conclusion
The consistently high I² across most models underscores the complexity of agroecological outcomes in silvoarable systems. While some moderators (notably number of trees per meter and soil × age interactions) show potential for explaining variation, substantial residual heterogeneity persists. This supports the need for multi-moderator or interaction models, and exploration of additional moderators not yet captured in this analysis.







# STEP 8 FOREST PLOTS FOR THE MINIMAL RANDOM EFFECTS MODEL (NOT THE FINAL FOREST PLOT)

## Simple Forest plot

```{r}
imp_dataset |> glimpse()
```

```{r}
# Custom color palette for each response variable
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Carbon sequestration"     = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC",
  "Water quality"            = "#9999FF"
)

# Extract back-transformed results from base_model for each response
forest_data <- lapply(names(model_results), function(response) {
  model <- model_results[[response]]$base_model
  if (is.null(model)) return(NULL)
  
  est <- model$b[1]
  ci.lb <- model$ci.lb[1]
  ci.ub <- model$ci.ub[1]
  pval <- model$pval[1]
  
  # Back-transform from logRR to ROM (%)
  rom_percent <- (exp(est) - 1) * 100
  rom_lower   <- (exp(ci.lb) - 1) * 100
  rom_upper   <- (exp(ci.ub) - 1) * 100
  
  tibble(
    response_variable = response,
    Estimate_logRR = est,
    CI_Lower_logRR = ci.lb,
    CI_Upper_logRR = ci.ub,
    ROM_percent = rom_percent,
    ROM_lower = rom_lower,
    ROM_upper = rom_upper,
    p_value = pval
  )
}) |> bind_rows()

# Order response variables by effect size or custom color order
forest_data <- forest_data %>%
  mutate(response_variable = factor(response_variable, levels = names(custom_colors))) %>%
  arrange(desc(ROM_percent))

# Forest plot (Back-transformed % Change from Control)
forest_plot_backtransformed <- forest_data |> 
  ggplot(aes(y = response_variable, x = ROM_percent, color = response_variable)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = ROM_lower, xmax = ROM_upper), height = 0.3, linewidth = 1) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  scale_color_manual(values = custom_colors) +
  scale_y_discrete(limits = rev(levels(forest_data$response_variable))) +
  labs(
    title = "Summary Effects by Response Variable (Back-Transformed % Change)",
    x = "Effect Size (%)",
    y = NULL
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 12, face = "bold"),
    axis.title.x = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold"),
    legend.position = "none"
  )

forest_plot_backtransformed
```

```{r}
library(tidyverse)
library(ggplot2)

# Set custom color palette and factor order
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Carbon sequestration"     = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC",
  "Water quality"            = "#9999FF"
)
response_levels <- names(custom_colors)

# Prepare raw data (back-transform) and filter extreme outliers
violin_data <- imp_dataset %>%
  filter(response_variable %in% response_levels) %>%
  mutate(
    response_variable = factor(response_variable, levels = rev(response_levels)),
    yi_back = (exp(yi) - 1) * 100
  ) %>%
  filter(abs(yi_back) <= 1000)  # filter out extreme values

# Extract summary model estimates (back-transformed)
summary_data <- map_dfr(response_levels, function(resp) {
  mod <- model_results[[resp]]$base_model
  if (is.null(mod)) return(NULL)
  estimate <- mod$b[1]
  ci_lb <- mod$ci.lb[1]
  ci_ub <- mod$ci.ub[1]
  
  tibble(
    response_variable = resp,
    summary_mean = (exp(estimate) - 1) * 100,
    summary_lower = (exp(ci_lb) - 1) * 100,
    summary_upper = (exp(ci_ub) - 1) * 100
  )
}) %>%
  mutate(response_variable = factor(response_variable, levels = rev(response_levels)))

# Plot: horizontal violin + summary point-range
ggplot() +
  geom_violin(
    data = violin_data,
    aes(y = response_variable, x = yi_back, fill = response_variable),
    color = NA, alpha = 0.35, trim = FALSE
  ) +
  geom_jitter(
    data = violin_data,
    aes(y = response_variable, x = yi_back),
    width = 0.1, height = 0.1, alpha = 0.15, size = 0.8, color = "black"
  ) +
  geom_pointrange(
    data = summary_data,
    aes(y = response_variable, x = summary_mean,
        xmin = summary_lower, xmax = summary_upper),
    shape = 21, fill = "darkgray", color = "black", stroke = 2, size = 0.5
  ) +
  scale_fill_manual(values = custom_colors) +
  scale_x_continuous(
    trans = pseudo_log_trans(base = 10),  # <- Pseudo-log transformation
    breaks = c(-100, -50, -10, 0, 10, 50, 100, 300, 500, 1000),
    labels = label_number(accuracy = 1)
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  labs(
    # title = "Effects of Silvoarable Systems on Agroecosystem Services",
    # subtitle = "Raw Effect Sizes and Summary (% Change from Control, Pseudo-Log Scale)",
    x = "Effect Size (%)", y = NULL, fill = NULL
  ) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(face = "bold"),
    legend.position = "none"
  )

```
Added log estimates and confidence interval without water quality

```{r}
library(tidyverse)
library(ggplot2)

# Set custom color palette and factor order
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Carbon sequestration"     = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC"
)
response_levels <- names(custom_colors)

# Prepare raw data (no back-transformation) and filter extreme outliers
violin_data <- imp_dataset %>%
  filter(response_variable %in% response_levels) %>%
  mutate(
    response_variable = factor(response_variable, levels = rev(response_levels))
  ) %>%
  filter(abs(yi) <= 1000)  # Filter out extreme values (no back-transformation needed)

# Extract summary model estimates (non-back-transformed)
summary_data <- map_dfr(response_levels, function(resp) {
  mod <- model_results[[resp]]$base_model
  if (is.null(mod)) return(NULL)
  estimate <- mod$b[1]
  ci_lb <- mod$ci.lb[1]
  ci_ub <- mod$ci.ub[1]
  
  tibble(
    response_variable = resp,
    summary_mean = estimate,       # Non-transformed estimate
    summary_lower = ci_lb,         # Non-transformed CI lower
    summary_upper = ci_ub          # Non-transformed CI upper
  )
}) %>%
  mutate(response_variable = factor(response_variable, levels = rev(response_levels)))

# Plot: horizontal violin + summary point-range (Non-back-transformed values)
ggplot() +
  # Violin plot with adjusted alpha
  geom_violin(
    data = violin_data,
    aes(y = response_variable, x = yi, fill = response_variable),
    color = NA, alpha = 0.4, trim = FALSE
  ) +
  # Jitter points for raw data
  geom_jitter(
    data = violin_data,
    aes(y = response_variable, x = yi),
    width = 0.15, height = 0.15, alpha = 0.2, size = 1, color = "black"
  ) +
  # Summary error bars with increased thickness
  geom_pointrange(
    data = summary_data,
    aes(y = response_variable, x = summary_mean,
        xmin = summary_lower, xmax = summary_upper),
    shape = 21, fill = "darkgray", color = "black", linewidth = 1  # Increased error bar thickness
  ) +
  # Larger summary points with stroke
  geom_point(
    data = summary_data,
    aes(y = response_variable, x = summary_mean),
    shape = 21, fill = "gray", color = "black", size = 2, stroke = 2  # Bigger points with border
  ) +
  scale_fill_manual(values = custom_colors) +
  scale_x_continuous(
    breaks = c(-100, -50, -10, 0, 10, 50, 100, 300, 500, 1000),
    labels = label_number(accuracy = 1)
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
  labs(
    x = "Effect Size (lnRR)", y = NULL, fill = NULL
  ) +
  theme_minimal(base_size = 15) +
  theme(
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    plot.title = element_text(face = "bold"),
    legend.position = "none"
  )


```

 
 
 
# STEP 9 EXTRACT MODEL WEIGHTS PER RESPONSE VARIABLE 

 

# STEP 10 SAVING DATASETS AND MODEL OBJECTS

 
 

Improvements and Adjustments
To address collinearity, pre-analysis checks such as variance inflation factors (VIF) or pairwise correlation matrices should be performed. Moderators with high collinearity or sparse data should be excluded or merged. Missing data can be handled using imputation methods or treated as a separate category. Log-transforming or standardizing `yi` and moderators could stabilize models with high variance ratios, while robust variance estimators, such as Knapp-Hartung adjustments, may improve reliability. Reducing the complexity of interaction models by focusing on key moderator pairs (e.g., `tree_type * crop_type`) rather than all interactions could improve convergence.

Model Diagnostics and Reporting
For each response variable, heterogeneity was assessed using statistics such as `I²` and `τ²`, and model fits were compared using AIC and BIC. Funnel plots, Egger’s test, and leave-one-out sensitivity analyses were conducted to evaluate publication bias and model robustness. Failed models were documented to ensure transparency, and systematic adjustments were reported to improve reproducibility. This approach balances explanatory power and interpretability, ensuring that the hierarchical complexity of moderators is appropriately captured.








