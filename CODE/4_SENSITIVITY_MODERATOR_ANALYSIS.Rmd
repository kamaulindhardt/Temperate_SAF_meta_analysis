---
title: "4_SENSITIVITY_MODERATOR_ANALYSIS"
author: "M.K.K. Lindhardt"
date: "2024-11-17"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between



Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

# STEP 0 PREPARING SCRIPT AND READ IN THE DATA


```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    skimr,            # Provides easy summary statistics about variables in data frames, tibbles, data tables and vectors
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    Matrix,           # Matrix operations
    progressr,
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    patchwork,        # ggplot2 API for sequentially building up a plot
    ggrepel,          # Provides text and label geoms for ' ggplot2' that help to avoid overlapping text labels
    ggbreak,          # Provides functions to create line breaks in 'ggplot2' axis labels 
    ###################################################################################################################
    # Spatial Data
    tidygeocoder,     # Unified interface for performing both forward and reverse geocoding queries
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    rnaturalearth,    # For world map data
    rnaturalearthdata, 
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("intersect", "base")
```


## Loading the datasets

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())


# Define your working directory using 'here'
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load datasets 

## NON-IMPUTED
non_imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom_tshering.rds"))

## IMPUTED
imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom_tshering.rds"))
```


loading fitted models

```{r}
# Save all models in a combined file
model_results <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))
```



```{r}
imp_dataset |> glimpse()
```


# STEP 1 EXPLORE AND VISUALIZE THE DATA INITIAL ASSERMENT


```{r}
# Check the unique response variables and sub-response variables
unique(imp_dataset$response_variable)
# unique(imp_dataset$sub_response_variable)
```
```{r}
response_summary <- 
  imp_dataset |> 
  count(response_variable) |> 
  arrange(desc(n))

# Bar plot for response variable counts
response_var_summary_plot <- 
  response_summary |> 
  ggplot(aes(x = reorder(response_variable, -n), y = n)) +
  geom_bar(stat = "identity", fill = "#0072B2") +
  coord_flip() +
  labs(title = "Count of Observations per Response Variable",
       x = "Response Variable",
       y = "Count of Observations") +
  theme_minimal()

response_var_summary_plot
```

```{r}
# Check the unique response variables and sub-response variables
unique_articles <- unique(imp_dataset$id_article)
unique_response_vars <- unique(imp_dataset$response_variable)

print(unique_response_vars)
print(length(unique_articles))  # Total number of unique articles

```

```{r}
# Count the number of unique articles for each response variable
article_summary <- imp_dataset %>%
  group_by(response_variable) %>%
  summarise(unique_articles = n_distinct(id_article)) %>%
  arrange(desc(unique_articles))

article_summary

```
```{r}
# Bar plot for unique article counts by response variable
article_summary_plot <-
  article_summary |> 
  ggplot(aes(x = reorder(response_variable, -unique_articles), y = unique_articles)) +
  geom_bar(stat = "identity", fill = "#E69F00") +
  coord_flip() +
  labs(title = "Count of Unique Articles per Response Variable",
       x = "Response Variable",
       y = "Number of Unique Articles") +
  theme_minimal()

article_summary_plot
```

```{r}
# Sample one observation per article per response variable
sampled_data <- imp_dataset %>%
  group_by(id_article, response_variable) %>%
  slice_head(n = 1)

sampled_data
```
```{r}
# Boxplot of effect sizes by response variable (unique articles)
boxplot_effec_size_response_variable <- sampled_data |> 
  ggplot(aes(x = response_variable, 
             y = yi, 
             fill = response_variable)) +
  geom_boxplot() +
  coord_flip() +
  labs(title = "Boxplot of Effect Sizes (yi) by Response Variable (Unique Articles)",
       x = "Response Variable",
       y = "Effect Size (yi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_effec_size_response_variable
```

The boxplot shows the distribution of effect sizes (yi) for each response variable. In the context of this meta-analysis, the effect size (yi) represents the standardized difference between the treatment group (agroforestry systems) and the control group (monoculture).

Biodiversity: the effect sizes are mostly positive, suggesting that agroforestry systems might have a higher effect on biodiversity compared to monoculture.
Crop Yield: the effect sizes are genrally negative, indicating potential yield reductions in agroforestry systems.
Soil Quality: tend to show positive effect sizes, suggesting an improvement in these aspects under agroforestry systems.
Product Quality: 
Pest and disease control:
Carbon sequestration:

The variation in the effect sizes for each response variable indicates heterogeneity, showing that the impact of agroforestry varies across different studies and contexts. However, the effect sizes in this plot do not account for potential study-level covariates or moderators, which could influence the observed differences. It will be important to consider the sampling variance (vi) associated with each effect size when interpreting these results, as larger studies (with smaller variance) provide more reliable estimates.





```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  )

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable")

# Plot histogram of effect sizes with additional improvements
ggplot(sampled_data, aes(x = yi, fill = response_variable)) +
  geom_histogram(binwidth = 0.05, alpha = 0.7, color = "black") +
  # mean yi line
  geom_vline(data = response_summary, aes(xintercept = mean_yi, color = response_variable),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ reorder(response_variable, -num_articles), scales = "free_y") +
  labs(
    title = "Distribution of Effect Sizes (yi) by Response Variable (Unique Articles)",
    x = "Effect Size (yi)",
    y = "Frequency"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  ) %>%
  arrange(desc(num_articles))

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable") %>%
  mutate(response_variable = factor(response_variable, levels = response_summary$response_variable))

# Reshape the data to long format for plotting
long_data <- sampled_data %>%
  select(id_article, response_variable, silvo_mean, control_mean) %>%
  pivot_longer(cols = c(silvo_mean, control_mean), 
               names_to = "group", 
               values_to = "mean_value") %>%
  mutate(group = recode(group, "silvo_mean" = "Silvo (Agroforestry)", "control_mean" = "Control (Monoculture)"))

# Calculate mean values for each group and response variable
group_summary <- long_data %>%
  group_by(response_variable, group) %>%
  summarise(
    mean_value = mean(mean_value, na.rm = TRUE),
    .groups = "drop"
  )


# Plot the distribution of mean values for Silvo and Control groups with free x-scales
ggplot(long_data, aes(x = mean_value, fill = group)) +
  geom_histogram(binwidth = 5, alpha = 0.7, color = "black", position = "identity") +
  geom_vline(data = group_summary, aes(xintercept = mean_value, color = group),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ response_variable, scales = "free_x") +  # Set scales to "free_x"
  labs(
    title = "Distribution of Mean Values for Silvo (Agroforestry) and Control (Monoculture)",
    x = "Mean Value",
    y = "Frequency"
  ) +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  scale_color_manual(values = c("#0072B2", "#D55E00")) +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# List of response variables and moderators
response_variables <- c("Biodiversity", "Crop yield", "Water quality", "Pest and disease control", 
                        "Soil quality", "Greenhouse gas emission", "Product quality")

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width",
                "organic", "tillage")
```

```{r}
# Define a generic function for counting unique values
count_unique_response_and_moderator <- function(data, response_col, moderators) {
  
  # Count of unique response variables for each moderator
  unique_response_var_per_moderator <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(moderator) %>%
    summarise(unique_responses = n_distinct(.data[[response_col]]), .groups = "drop")

  # Count of unique moderator levels for each response variable
  unique_moderators_per_response_var <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(.data[[response_col]]) %>%
    summarise(unique_moderators = n_distinct(moderator_value), .groups = "drop")

  # Return both summaries as a list
  list(
    unique_response_var_per_moderator = unique_response_var_per_moderator,
    unique_moderators_per_response_var = unique_moderators_per_response_var
  )
}

```

```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width",
                 "organic", "tillage")

# Apply the function to the non-imputed dataset
non_imp_summary <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Apply the function to the imputed dataset
imp_summary <- count_unique_response_and_moderator(imp_dataset, response_col, moderators)

# View the summaries
print(non_imp_summary$unique_response_var_per_moderator)
print(non_imp_summary$unique_moderators_per_response_var)

print(imp_summary$unique_response_var_per_moderator)
print(imp_summary$unique_moderators_per_response_var)

```


Visualize the Summary Data

Plot 1: Number of Unique Response Variables per Moderator
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width",
                 "organic", "tillage")

# Generate the summaries using the function
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_response_var_per_moderator <- results$unique_response_var_per_moderator

# Bar plot for unique response variables per moderator
unique_response_var_per_moderator |> 
  ggplot(aes(x = reorder(moderator, unique_responses), y = unique_responses, fill = moderator)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Response Variables per Moderator",
    x = "Moderator",
    y = "Number of Unique Response Variables"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  theme(legend.position = "none")

```


Plot 2: Number of Unique Moderators per Response Variable
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width", 
                "organic", "tillage")

# Generate summaries
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_moderators_per_response_var <- results$unique_moderators_per_response_var


# Bar plot for unique moderators per response variable
unique_moderators_per_response_var |> 
  ggplot(aes(x = reorder(response_variable, unique_moderators), y = unique_moderators, fill = response_variable)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Moderators per Response Variable",
    x = "Response Variable",
    y = "Number of Unique Moderator Levels"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

Alternative Visualization: Heatmap
comprehensive view of the data in a heatmap to show the interaction between moderators and response variables

```{r}
# Create a heatmap data frame
heatmap_data <- non_imp_dataset %>%
  select(response_variable, all_of(moderators)) %>%
  pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
  filter(!is.na(moderator_value)) %>%
  group_by(response_variable, moderator) %>%
  summarise(count = n_distinct(moderator_value), .groups = "drop")

# Heatmap plot
ggplot(heatmap_data, aes(x = moderator, y = response_variable, fill = count)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(
    title = "Heatmap of Unique Moderator Levels by Response Variable",
    x = "Moderator",
    y = "Response Variable",
    fill = "Count of Unique Levels"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```


# STEP 2 INFLUENCE DIAGNOSTICS FOR META-ANALYSIS MODEL EVALUATION 


## Influence Diagnostics for Meta-Analysis Models (Sensitivity Analysis)

Cook’s Distance, DFBETAS, and Hat Values are key influence diagnostics used in meta-analysis to assess the impact of individual studies on the overall model results. Each of these measures serves a different purpose in identifying influential studies that could potentially distort the conclusions of a meta-analysis.

Cook’s Distance quantifies how much removing a particular study changes the overall meta-analysis model. It helps identify studies that disproportionately influence the pooled effect size. A high Cook’s Distance suggests that removing the study would significantly alter the model estimates, whereas a low value indicates minimal impact. The standard threshold for Cook’s Distance is typically set as four divided by the number of studies. If a study exceeds this threshold, it is flagged as potentially influential, warranting further investigation. However, Cook’s Distance does not explain why a study is influential; it only signals that its removal would change the model output.

DFBETAS measures how much a study influences a specific moderator or effect size estimate in a meta-analysis. It evaluates the change in a particular coefficient if the study is removed. A high DFBETAS value suggests that excluding the study would significantly alter the estimate of that coefficient, while a low value indicates little effect. A common guideline for identifying influential studies is two divided by the square root of the number of studies. DFBETAS is particularly useful in moderator analyses, where it helps determine whether certain studies are driving the observed relationships. If a study has a high DFBETAS value, conducting a sensitivity analysis by re-running the model without that study can help assess the robustness of the findings.

Hat values measure leverage, meaning how much weight a study has in determining the fitted values within the model. A high hat value suggests that the study has unique characteristics, such as a large sample size, extreme effect size, or very low variance, making it disproportionately influential in the weighting of the meta-analysis. Unlike Cook’s Distance and DFBETAS, hat values do not measure whether a study changes the overall effect size; they simply indicate how much influence a study has on the model due to its characteristics. A commonly used threshold is three times the mean hat value, with higher values suggesting that the study carries considerable leverage in the analysis.

Together, these diagnostics provide a comprehensive assessment of study influence in a meta-analysis. A study with a high Cook’s Distance is influential in shaping the overall effect size, while a high DFBETAS indicates that the study is affecting a specific regression coefficient. A high hat value signals that the study has a strong presence in the model due to its design or data characteristics but does not necessarily mean it is an outlier. If a study exhibits high values across all three measures, it is likely an influential outlier that could distort the meta-analysis results. Understanding these diagnostics allows researchers to identify and assess the robustness of their findings, ensuring that no single study unduly drives the conclusions.



```{r}
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Load input data and precomputed variance-covariance matrices
meta_data <- imp_dataset
# v_matrices <- readRDS(here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "v_matrices_by_response_variable.rds"))

# Define model control parameters
control_params <- list(
  optimizer = "optim",
  method = "BFGS",
  iter.max = 10000,
  rel.tol = 1e-12
)

# Define random effects structure
# random_effects <- list(~ 1 | id_article / experiment_site * experiment_year)  # <------- ! Chosen Random Effects Structure !
random_effects <- list(~ 1 | id_article)                                        # <------- ! Simplified Random Effects Structure !


# Function to fit rma.mv models using variance-covariance matrices
fit_minimal_model <- function(data, response, random_effects) {
  message("Fitting model for: ", response)

  data_subset <- filter(data, response_variable == response)
  # v_matrix <- v_matrices[[response]]

  tryCatch({
    rma.mv(
      yi = yi,
      V = vi,
      mods = ~ 1,
      random = random_effects,
      data = data_subset,
      slab = data_subset$id_study,
      method = "REML",
      control = control_params
    )
  }, error = function(e) {
    message("Model fitting failed for ", response, ": ", e$message)
    NULL
  })
}

# Get all unique response variables
response_variables <- unique(meta_data$response_variable)

# Fit models across all response variables
model_results_mv <- map(
  .x = response_variables,
  .f = ~ fit_minimal_model(meta_data, .x, random_effects)
)

names(model_results_mv) <- response_variables


##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (04/02-2025) 
# Total time taken: 9.153187 secs 
# Last go (25/03-2025) 
# Total time taken: 10.69201 secs 
# Last go (01/04-2025) 
# Total time taken: 8.850986 secs 
# Fitting model for: Biodiversity
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Fitting model for: Crop yield
# Model fitting failed for Crop yield: Length of 'yi' (277) and the length/dimensions of 'V' (107) are not the same.
# Fitting model for: Water quality
# Advarsel: Single-level factor(s) found in 'random' argument. Corresponding 'sigma2' value(s) fixed to 0.
# Fitting model for: Pest and disease control
# Model fitting failed for Pest and disease control: Length of 'yi' (49) and the length/dimensions of 'V' (277) are not the same.
# Fitting model for: Soil quality
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.
# Fitting model for: Carbon sequestration
# Fitting model for: Product quality
# Model fitting failed for Product quality: Length of 'yi' (107) and the length/dimensions of 'V' (49) are not the same.
```

```{r}
model_results_mv
```


```{r eval=FALSE}
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################

# Function to extract influence diagnostics for rma.mv models
extract_mv_influence <- function(response, model) {
  if (is.null(model) || !inherits(model, "rma.mv")) {
    message("Skipping: ", response, " – model is NULL or not of class rma.mv")
    return(NULL)
  }

  message("Extracting influence diagnostics for: ", response)

  cooks_d <- tryCatch({
    cooks.distance(model, progbar = TRUE)
  }, error = function(e) {
    message("Cook's Distance failed for ", response)
    rep(NA_real_, model$k)
  })

  df_betas <- tryCatch({
    db <- dfbetas(model, progbar = TRUE)
    apply(db, 1, function(x) max(abs(x), na.rm = TRUE))
  }, error = function(e) {
    message("DFBETAS failed for ", response)
    rep(NA_real_, model$k)
  })

  hat_vals <- tryCatch({
    hatvalues(model, type = "diagonal")
  }, error = function(e) {
    message("Hat values failed for ", response)
    rep(NA_real_, model$k)
  })

  tibble(
    Response_Variable = response,
    Study = model$slab,
    Cooks_Distance = cooks_d,
    Max_DFBeta = df_betas,
    Hat_Value = hat_vals
  )
}

# Run extraction across all valid models
valid_models <- keep(model_results_mv, ~ inherits(.x, "rma.mv"))

mv_influence_diagnostics <- map2_dfr(
  .x = names(valid_models),
  .y = valid_models,
  .f = extract_mv_influence
)

# Save influence diagnostics output
# output_dir <- here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# saveRDS(mv_influence_diagnostics, file = file.path(output_dir, "mv_influence_diagnostics.rds"))


# mv_influence_diagnostics |> glimpse()
mv_influence_diagnostics

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (23/03-2025) 
# Total time taken: 10.98624 mins 
# Last go (01/04-2025)
# Total time taken: 11.01093 mins 
# Last go (01/04-2025)
# Total time taken: 6.433458 mins 
# Last go (10/05-2025)
# Total time taken: 10.05286 mins  
```

```{r}
# Load the saved Influence Diagnostics dataset
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
mv_influence_diagnostics <- readRDS(file.path(dir, "mv_influence_diagnostics.rds"))
```


```{r}
##########################################################################
# Define Thresholds for Influence Diagnostics
##########################################################################

# Function to clean study names (remove suffixes like ".1", ".2", etc.)
clean_study_name <- function(study) {
  stringr::str_replace(study, "\\.\\d+$", "")
}

# Add cleaned study names
mv_influence_diagnostics <- mv_influence_diagnostics %>%
  dplyr::mutate(Study_Clean = clean_study_name(Study))

# Function to calculate thresholds per response variable
calculate_thresholds <- function(df) {
  df %>%
    dplyr::group_by(Response_Variable) %>%
    dplyr::summarise(
      Cooks_Threshold = 4 / n(),
      DFBeta_Threshold = 2 / sqrt(n()),
      Hat_Threshold = 3 * mean(Hat_Value, na.rm = TRUE),
      .groups = "drop"
    )
}

# Compute thresholds
mv_thresholds <- calculate_thresholds(mv_influence_diagnostics)

# Summarize per study and response variable
mv_influence_diagnostics_summary <- mv_influence_diagnostics %>%
  dplyr::group_by(Response_Variable, Study_Clean) %>%
  dplyr::summarise(
    Mean_Cooks_Distance = mean(Cooks_Distance, na.rm = TRUE),
    Mean_DFBeta = mean(Max_DFBeta, na.rm = TRUE),
    Mean_Hat = mean(Hat_Value, na.rm = TRUE),

    SE_Cooks_Distance = sd(Cooks_Distance, na.rm = TRUE) / sqrt(dplyr::n()),
    SE_DFBeta = sd(Max_DFBeta, na.rm = TRUE) / sqrt(dplyr::n()),
    SE_Hat = sd(Hat_Value, na.rm = TRUE) / sqrt(dplyr::n()),

    Lower_CI_Cooks = Mean_Cooks_Distance - 1.96 * SE_Cooks_Distance,
    Upper_CI_Cooks = Mean_Cooks_Distance + 1.96 * SE_Cooks_Distance,
    Lower_CI_DFBeta = Mean_DFBeta - 1.96 * SE_DFBeta,
    Upper_CI_DFBeta = Mean_DFBeta + 1.96 * SE_DFBeta,
    Lower_CI_Hat = Mean_Hat - 1.96 * SE_Hat,
    Upper_CI_Hat = Mean_Hat + 1.96 * SE_Hat,
    .groups = "drop"
  ) %>%
  dplyr::left_join(mv_thresholds, by = "Response_Variable")

# Optionally exclude certain responses
excluded_responses <- c("Greenhouse gas emission", "Water quality", "Pest and disease control")

mv_influence_diagnostics_summary <- mv_influence_diagnostics_summary %>%
  dplyr::filter(!Response_Variable %in% excluded_responses)

# Final dataset ready for visualization or reporting
mv_influence_diagnostics_summary

```

### DFBETAS Plot

```{r}
##########################################################################
# DFBETAS Plot for Influence Diagnostics
##########################################################################

# Thresholds are already included in mv_influence_diagnostics_summary
# Step 1: Compute mean DFBETA threshold per response variable
mv_mean_dfbeta_threshold <- mv_influence_diagnostics_summary %>%
  group_by(Response_Variable) %>%
  summarise(Mean_DFBeta_Threshold = mean(DFBeta_Threshold, na.rm = TRUE), .groups = "drop")

# Step 2: Merge computed thresholds back
mv_influence_diagnostics_summary_dfbetas <- mv_influence_diagnostics_summary %>%
  left_join(mv_mean_dfbeta_threshold, by = "Response_Variable")

# Step 3: Filter and mark influential studies (only those with valid DFBETA values)
dfbetas_plot_data <- mv_influence_diagnostics_summary_dfbetas %>%
  filter(!is.na(Mean_DFBeta)) %>%
  mutate(Is_Influential = abs(Mean_DFBeta) > Mean_DFBeta_Threshold)

# Create DFBETAS Influence Plot
dfbetas_plot_version1 <-
  dfbetas_plot_data %>%
  ggplot(aes(x = reorder(Study_Clean, -Mean_DFBeta), y = Mean_DFBeta)) +
  # Add 95% confidence intervals
  geom_pointrange(aes(ymin = Lower_CI_DFBeta, ymax = Upper_CI_DFBeta), 
                  size = 0.4, color = "black") +
  # Highlight influential studies
  geom_point(aes(color = Is_Influential), size = 2) +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red")) +
  # Add horizontal reference line at 0
  geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
  # Add positive and negative threshold lines
  geom_hline(aes(yintercept = DFBeta_Threshold), linetype = "dotted", color = "blue") +
  geom_hline(aes(yintercept = -DFBeta_Threshold), linetype = "dotted", color = "blue") +
  # Facet by response variable
  facet_wrap(~Response_Variable, scales = "free", nrow = 1) +
  # Labels and theme
  labs(
    title = "DFBETAS Influence Diagnostics with 95% CI",
    subtitle = "Red dots = influential studies; Blue lines = ± threshold",
    x = "Study",
    y = "Mean DFBETA (± CI)"
  ) +
  theme_bw() +
  theme(
    strip.text = element_text(face = "bold", size = 12),
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 8),
    legend.position = "none"
  )

dfbetas_plot_version1
```

### Cook's Distance Plot

```{r}
##########################################################################
# Cook's Distance Plot with CI
##########################################################################

# Compute mean Cook's Distance threshold per response variable
mv_mean_cooks_threshold <- mv_influence_diagnostics_summary %>%
  group_by(Response_Variable) %>%
  summarise(Mean_Cooks_Threshold = mean(Cooks_Threshold, na.rm = TRUE), .groups = "drop")

# Merge computed thresholds back into the diagnostics dataset
mv_influence_diagnostics_summary_cooks <- mv_influence_diagnostics_summary %>%
  left_join(mv_mean_cooks_threshold, by = "Response_Variable") 

# Filter and mark influential studies
cooks_plot_data <- mv_influence_diagnostics_summary_cooks %>%
  mutate(Is_Influential = Mean_Cooks_Distance > Mean_Cooks_Threshold)

# Create Cook's Distance Plot 
cooks_plot_version1 <- 
  cooks_plot_data |> 
  ggplot(aes(x = reorder(Study_Clean, -Mean_Cooks_Distance), y = Mean_Cooks_Distance)) +
  geom_pointrange(aes(ymin = Lower_CI_Cooks, ymax = Upper_CI_Cooks), 
                  color = "black", size = 0.5) +  # Confidence intervals
  geom_point(color = "black", size = 1) +  # Individual data points
  geom_line(aes(group = Response_Variable), color = "black") +  # Connecting lines
  #geom_hline(aes(yintercept = Mean_Cooks_Threshold), linetype = "dotted", color = "blue") +  # Mean threshold per response
  geom_point(data = cooks_plot_data %>% filter(Is_Influential), 
             aes(y = Mean_Cooks_Distance), color = "red", size = 2) +  # Highlight influential studies
  # Add positive and negative threshold lines
  geom_hline(aes(yintercept = Cooks_Threshold), linetype = "dotted", color = "blue") +
  geom_hline(aes(yintercept = -Cooks_Threshold), linetype = "dotted", color = "blue") +
  facet_wrap(~Response_Variable, scales = "free", nrow = 1) +  # Facet per response variable
  labs(
    title = "Cook’s Distance Influence Diagnostics (with Confidence Intervals)",
    x = "Study",
    y = "Cook’s Distance",
    caption = "Dotted lines = Threshold, Black bars = CI, Red points = Influential"
  ) +
  theme_bw() +
  theme(
    strip.text = element_text(face = "bold", size = 12),  # Highlight facet labels
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  # Rotate x-axis labels
    panel.grid.minor = element_blank()  # Clean up grid
  )

cooks_plot_version1
```

### Hat Values Plot

```{r}
##########################################################################
# Hat Values Plot with CI
##########################################################################

# Compute mean Hat threshold per response variable
mv_mean_hat_threshold <- mv_influence_diagnostics_summary %>%
  group_by(Response_Variable) %>%
  summarise(Mean_Hat_Threshold = mean(Hat_Threshold, na.rm = TRUE), .groups = "drop")

# Merge computed thresholds back into the diagnostics dataset
mv_influence_diagnostics_summary_hat <- mv_influence_diagnostics_summary %>%
  left_join(mv_mean_hat_threshold, by = "Response_Variable") 

# Filter and mark influential studies
hat_plot_data <- mv_influence_diagnostics_summary_hat %>%
  mutate(Is_Influential = Mean_Hat > Mean_Hat_Threshold)

# Create Hat Values Plot
hat_plot_version1 <- 
  hat_plot_data |> 
  ggplot(aes(x = reorder(Study_Clean, -Mean_Hat), y = Mean_Hat)) +
  geom_pointrange(aes(ymin = Lower_CI_Hat, ymax = Upper_CI_Hat), 
                  color = "black", size = 0.5) +  # Confidence intervals
  geom_point(color = "black", size = 1) +  # Individual data points
  geom_line(aes(group = Response_Variable), color = "black") +  # Connecting lines
  geom_hline(aes(yintercept = Mean_Hat_Threshold), linetype = "dotted", color = "blue") +  # Mean threshold per response
  geom_point(data = hat_plot_data %>% filter(Is_Influential), 
             aes(y = Mean_Hat), color = "red", size = 2) +  # Highlight influential studies
  facet_wrap(~Response_Variable, scales = "free", nrow = 1) +  # Facet per response variable
  labs(
    title = "Hat Values Influence Diagnostics (with Confidence Intervals)",
    x = "Study",
    y = "Hat Values",
    caption = "Dotted lines = Threshold, Black bars = CI, Red points = Influential"
  ) +
  theme_bw() +
  theme(
    strip.text = element_text(face = "bold", size = 12),  # Highlight facet labels
    axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  # Rotate x-axis labels
    panel.grid.minor = element_blank()  # Clean up grid
  )

hat_plot_version1
```

Influence diagnostics revealed that a small number of studies had a disproportionate impact on model estimates across response variables. Notably, *Gibbs et al. (2016)* and *Cardinael et al. (2017)* consistently exceeded thresholds across all three metrics—DFBETAS, Cook’s Distance, and Hat values—for biodiversity and carbon sequestration, respectively, indicating both high leverage and strong influence on model coefficients. *Shen et al. (2023)* was also identified as influential for product quality, while *Lacombe et al. (2009)* showed high leverage for soil quality without substantially affecting model estimates. These findings underscore the importance of conducting sensitivity analyses to assess the robustness of conclusions in the presence of influential data points, particularly when certain responses are dominated by single or few studies.



# STEP 3 SENSITIVITY ANALYSIS (LEAVE-ONE-OUT SENSTIVITY ANALYSIS)

### Loading meta_data and structured_results

```{r}
#########################################################################
###############################################################################
###################################################################################
########################################################################################
#############################################################################################
####################################################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset

# Structured results with full model effects
structured_results <- readRDS(here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "structured_results_all_effect_sizes.rds"))

####################################################################################################
#############################################################################################
########################################################################################
###################################################################################
###############################################################################
#########################################################################
```


```{r}
# Lookup for full model estimates
structured_lookup <- structured_results %>%
  filter(Model == "base_model") %>%
  distinct(ResponseVariable, Estimate) %>%
  rename(response_variable = ResponseVariable)
```


```{r}
control_params <- list(optimizer = "optim", method = "BFGS", iter.max = 10000, rel.tol = 1e-12)

base_model <- function(data, random_effects_formula) {
  rma.mv(
    yi = yi,
    V = vi,
    mods = ~ tree_type + crop_type + age_system + season + soil_texture,
    random = random_effects_formula,
    data = data,
    method = "REML",
    control = control_params
  )
}

conduct_loo_analysis <- function(meta_data, model_formula_function, random_effects_formula) {
  unique_studies <- unique(meta_data$id_article)
  loo_results <- list()

  for (study in unique_studies) {
    cat("Excluding study:", study, "\n")
    data_excluded <- meta_data %>% filter(id_article != study)
    model <- tryCatch(
      model_formula_function(data_excluded, random_effects_formula),
      error = function(e) NULL
    )
    loo_results[[study]] <- model
  }

  return(loo_results)
}

random_effects <- list(~ 1 | id_article / location * experiment_year)
response_specific_results <- list()

for (response in unique(meta_data$response_variable)) {
  cat("Running LOO for:", response, "\n")
  data_subset <- meta_data %>% filter(response_variable == response)
  response_specific_results[[response]] <- conduct_loo_analysis(data_subset, base_model, random_effects)
}

response_specific_results$Biodiversity |> str()
```


```{r}
summarize_loo_results <- function(loo_results, full_effect_size) {
  # Ensure names exist
  study_names <- names(loo_results)
  if (is.null(study_names) || any(study_names == "")) {
    study_names <- as.character(seq_along(loo_results))
  }

  purrr::map2_dfr(
    .x = loo_results,
    .y = study_names,
    .f = function(model, study) {
      if (is.null(model)) {
        return(tibble(
          Study = study,
          Excluded_Effect_Size = NA_real_,
          Excluded_SE = NA_real_,
          Change_in_Effect_Size = NA_real_,
          QE = NA_real_,
          QE_pval = NA_real_,
          I2 = NA_real_,
          Tau2 = NA_real_
        ))
      }

      excluded_effect_size <- if (!is.null(model$b)) model$b[1] else NA_real_
      excluded_se <- if (!is.null(model$se)) model$se[1] else NA_real_
      change <- if (!is.na(excluded_effect_size) && !is.na(full_effect_size) && abs(full_effect_size) > 1e-6) {
        ((excluded_effect_size - full_effect_size) / full_effect_size) * 100
      } else {
        NA_real_
      }

      tibble(
        Study = study,
        Excluded_Effect_Size = excluded_effect_size,
        Excluded_SE = excluded_se,
        Change_in_Effect_Size = change,
        QE = model$QE %||% NA_real_,
        QE_pval = model$QEp %||% NA_real_,
        I2 = model$I2 %||% NA_real_,
        Tau2 = model$tau2 %||% NA_real_
      )
    }
  )
}


loo_summary_combined <- purrr::map_dfr(
  names(response_specific_results),
  function(response) {
    full_effect <- structured_lookup %>%
      filter(response_variable == response) %>%
      pull(Estimate) %>%
      first()

    if (is.null(full_effect) || is.na(full_effect)) {
      return(tibble(
        Study = NA_character_,
        Excluded_Effect_Size = NA_real_,
        Excluded_SE = NA_real_,
        Full_Effect_Size = NA_real_,
        Change_in_Effect_Size = NA_real_,
        QE = NA_real_, QE_pval = NA_real_,
        I2 = NA_real_, Tau2 = NA_real_,
        response_variable = response
      ))
    }

    loo_results <- response_specific_results[[response]]
    df <- summarize_loo_results(loo_results, full_effect)
    df$Full_Effect_Size <- full_effect
    df$response_variable <- response
    return(df)
  }
)

loo_summary_combined |> glimpse()
```

```{r}
loo_summary_plot_data <- loo_summary_combined %>%
  filter(!is.na(Excluded_Effect_Size)) %>%  # remove NULL models
  mutate(
    Study = fct_reorder(Study, Change_in_Effect_Size, .na_rm = TRUE),
    response_variable = factor(response_variable)
  )

loo_summary_plot_data
```

```{r}
# Define a custom color palette for response_variable
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Carbon sequestration"     = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC",
  "Water quality"            = "#9999FF"
)
```

### Combined facet plot 

```{r}
####################################################################
# SUMMARIZE CONTRIBUTION OF STUDIES TO RESPONSE VARIABLES
####################################################################

# Step 1: Create a Lookup Table for Study Names
study_lookup <- tibble(
  Study = as.character(1:37),
  id_study = c(
    "Varah et al., 2020", "Swieter et al., 2022", "Swieter et al., 2019",
    "Bainard et al., 2011", "Bergeron et al., 2011", "Beule et al., 2019",
    "Beule et al., 2021", "Beuschel et al., 2019", "Boinot et al., 2019",
    "Burgess et al., 2005", "Cardinael et al., 2017", "Chirko et al., 1996",
    "Seserman et al., 2019", "Gao et al., 2013", "Gibbs et al., 2016",
    "Gibbs et al., 2016", "Griffiths et al., 1998", "Klaa et al., 2005",
    "Lacombe et al., 2009", "Lacombe et al., 2009", "Upson et al., 2013",
    "Peichl et al., 2006", "Oelbermann et al., 2007", "Oelbermann et al., 2006",
    "Pardon et al., 2019", "Pardon et al., 2018", "Pardon et al., 2017",
    "Park et al., 1994", "Peng et al., 1993", "Reynolds et al., 2007",
    "Rivest et al., 2015", "Seiter et al., 1999", "Seiter et al., 1999",
    "Piotto et al., 2024", "Staton et al., 2022", "Honfy et al., 2023",
    "Zhang et al., 2015"
  )
)

# Step 2: Compute CI and back-transform values
loo_summary_plot_data <- loo_summary_plot_data %>%
  mutate(
    ci_lower = Excluded_Effect_Size - 1.96 * Excluded_SE,
    ci_upper = Excluded_Effect_Size + 1.96 * Excluded_SE,
    Effect_ROM   = (exp(Excluded_Effect_Size) - 1) * 100,
    CI_lower_ROM = (exp(ci_lower) - 1) * 100,
    CI_upper_ROM = (exp(ci_upper) - 1) * 100
  )

# Step 3: Join study names and reorder by effect
loo_summary_plot_data <- loo_summary_plot_data %>%
  mutate(Study = as.character(Study)) %>%
  left_join(study_lookup, by = "Study") %>%
  filter(!is.na(Effect_ROM)) %>%
  group_by(response_variable) %>%
  mutate(Study_Label = fct_reorder(id_study, Effect_ROM)) %>%
  ungroup()

# Step 4: Plot
loo_summary_plot <- ggplot(
  loo_summary_plot_data,
  aes(x = Effect_ROM, y = Study_Label, color = response_variable)
) +
  geom_errorbarh(
    aes(xmin = CI_lower_ROM, xmax = CI_upper_ROM),
    height = 0.3, linewidth = 0.8, alpha = 0.6
  ) +
  geom_point(size = 3) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray30") +
  facet_wrap(~ response_variable, scales = "free") +
  scale_color_manual(values = custom_colors) +
  labs(
    title = "Leave-One-Out Sensitivity: Excluded Effect Sizes (Percent Change)",
    x = "Excluded Effect Size (% Change)",
    y = "Excluded Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 11),
    plot.title = element_text(face = "bold"),
    strip.text = element_text(face = "bold"),
    legend.position = "none"
  )

# Display
loo_summary_plot
```


### Seperate plots for each response variable

```{r}
loo_summary_plot_data |> glimpse()

# List unique response variables
responses <- unique(loo_summary_plot_data$response_variable)

# Create a named list of filtered data
loo_data_split <- purrr::set_names(responses) |>
  purrr::map(~ loo_summary_plot_data %>% filter(response_variable == .x))

# Step 2: Define the plotting function

plot_loo_response <- function(df, color) {
  ggplot(df, aes(
    x = Effect_ROM, 
    y = fct_reorder(Study_Label, Effect_ROM)
  )) +
    geom_point(size = 3, color = color) +
    geom_errorbarh(
      aes(xmin = CI_lower_ROM, xmax = CI_upper_ROM),
      height = 0.25,
      color = color,
      linewidth = 0.8
    ) +
    geom_vline(xintercept = 0, linetype = "dashed", color = "gray40") +
    labs(
      title = unique(df$response_variable),
      x = "Change in Effect Size (%)",
      y = "Excluded Study"
    ) +
    theme_minimal(base_size = 14) +
    theme(
      axis.text.y = element_text(size = 11),
      plot.title = element_text(face = "bold")
    )
}


# Create plots per response
loo_response_plots <- purrr::map2(
  loo_data_split,
  names(loo_data_split),
  ~ plot_loo_response(.x, color = custom_colors[.y])
)

loo_biodiversity_plot <- loo_response_plots$`Biodiversity`
loo_crop_yield_plot <- loo_response_plots$`Crop yield`
loo_soil_quality_plot <- loo_response_plots$`Soil quality`

# loo_biodiversity_plot
loo_crop_yield_plot
loo_soil_quality_plot
```

```{r}
# Filter only Biodiversity data
biodiv_data <- loo_summary_plot_data %>%
  filter(response_variable == "Biodiversity")

# Plot for Biodiversity only, with axis break
plot_loo_biodiversity <- ggplot(biodiv_data, aes(
  x = Effect_ROM, 
  y = fct_reorder(Study_Label, Effect_ROM)
)) +
  geom_point(size = 3, color = "#FF9999") +
  geom_errorbarh(
    aes(xmin = CI_lower_ROM, xmax = CI_upper_ROM),
    height = 0.25,
    color = "#FF9999",
    linewidth = 0.8
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray40") +
  scale_x_break(c(200, 800), scales = 0.5, ticklabels = c(200, 800)) +
  labs(
    title = "Biodiversity — Leave-One-Out Sensitivity",
    x = "Change in Effect Size (%)",
    y = "Excluded Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 11),
    plot.title = element_text(face = "bold")
  )

plot_loo_biodiversity
```



```{r}
ggplot(loo_summary_plot_data, aes(x = reorder(Study_Label, Effect_ROM), y = Effect_ROM, fill = Effect_ROM > 0)) +
  geom_col() +
  scale_fill_manual(values = c("TRUE" = "#66C2A5", "FALSE" = "#FC8D62")) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(x = "Excluded Study", y = "Effect Size Change (%)", title = "Waterfall Plot of Study Influence") +
  theme_minimal()
```
```{r}
ggplot(loo_summary_plot_data, aes(x = Study_Label, y = response_variable, fill = Effect_ROM)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "#B2182B", mid = "white", high = "#2166AC", midpoint = 0) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "LOO Heatmap of Influence", x = "Study", y = "Response", fill = "% Change")
```
```{r}
ggplot(loo_summary_plot_data, aes(x = 1/Excluded_SE, y = Effect_ROM)) +
  geom_point(aes(color = response_variable), size = 3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Study Precision (1/SE)", y = "Effect Size Change (%)", title = "LOO Funnel Plot") +
  scale_color_manual(values = custom_colors) +
  theme_minimal()
```




# STEP 4 PUBLICATION BIAS INVESTIGATION FOR META-ANALYSIS - FUNNEL PLOT ETC.


```{r}
##########################################################################################################################################
# PUBLICATION BIAS INVESTIGATION FOR META-ANALYSIS
##########################################################################################################################################

# This workflow is designed to assess publication bias in meta-analysis studies. 
# It uses a combination of multivariate models (rma.mv) for complex analyses and univariate models (rma) for bias diagnostics.

# **Models**:
# 1. `Minimal_Model`: A multivariate intercept-only model to analyze general heterogeneity. ----------------------- omitted because of errors in model fitting!
# 2. `Full_Model`: A multivariate model incorporating key moderators (e.g., crop type, soil texture, etc.). ------- omitted because of errors in model fitting!
# 3. `Univariate_Model`: A simpler univariate model used exclusively for publication bias analysis.

# **Data**:
# The input data (`meta_data`) is split by response variables (e.g., Biodiversity, Crop Yield). 
# Each subset is analyzed independently to fit the models and compute diagnostics.

# **Tests**:
# 1. **Egger's Test**: Evaluates funnel plot asymmetry as an indicator of bias.
# 2. **Trim-and-Fill**: Adjusts effect sizes to account for missing studies.

# The workflow ensures compatibility by using `rma` models for publication-bias-specific tests.


# Function to fit univariate random effects model
# Fits a univariate random-effects meta-analysis model (rma)
univariate_random_effects_model <- function(data) {
  tryCatch(
    rma(
      yi = yi,  # Effect size
      vi = vi,  # Variance of effect size
      data = data,  # Input dataset
      method = "REML"  # Restricted Maximum Likelihood estimation
    ),
    error = function(e) {
      message("Error fitting univariate model: ", e$message)
      return(NULL)
    }
  )
}

# Function to fit and summarize models for each response variable
fit_and_summarize_by_response <- function(data) {
  response_data <- split(data, data$response_variable)  # Split data by response variable

  response_results <- lapply(names(response_data), function(response) {
    message("Processing response variable: ", response)
    data_subset <- response_data[[response]]

    # Fit univariate model
    univariate_model <- univariate_random_effects_model(data_subset)

    list(
      Response = response,  # Response variable name
      Univariate_Model = univariate_model  # Fitted univariate model
    )
  })

  names(response_results) <- names(response_data)  # Name results by response variable
  return(response_results)
}

# Function to calculate publication bias for each response variable
# Performs Egger's Test and Trim-and-Fill analysis for univariate models
calculate_publication_bias <- function(models) {
  bias_results <- list()

  for (response in names(models)) {
    univariate_model <- models[[response]]$Univariate_Model

    if (!is.null(univariate_model)) {
      bias_results[[response]] <- list(
        Egger_Test = tryCatch(
          regtest(univariate_model, model = "rma"),
          error = function(e) {
            message("Error performing Egger's Test for response variable ", response, ": ", e$message)
            return(NULL)
          }
        ),
        Trim_and_Fill = tryCatch(
          trimfill(univariate_model),
          error = function(e) {
            message("Error performing Trim-and-Fill for response variable ", response, ": ", e$message)
            return(NULL)
          }
        )
      )
    } else {
      message("Univariate model is not valid for response variable: ", response)
    }
  }

  return(bias_results)
}

# Using the publication-bias modelling workflow
response_results <- fit_and_summarize_by_response(meta_data)  # Fit models for each response variable
bias_results <- calculate_publication_bias(response_results)  # Calculate publication bias

response_results
bias_results 

# bias_results |> str()
```
To evaluate potential publication bias, we applied Egger’s regression test and the Trim-and-Fill method to univariate meta-analysis models for each response variable. Egger’s test indicated significant funnel plot asymmetry for Crop yield, Pest and disease control, Soil quality, and Water quality, suggesting possible small-study effects. Consistent with this, the Trim-and-Fill analysis estimated a substantial number of missing studies for Crop yield (n = 63), Soil quality (n = 81), and Water quality (n = 28), while Biodiversity showed 23 potentially missing studies. For these outcomes, the adjusted overall effect sizes were either strengthened (e.g., Biodiversity) or attenuated (e.g., Crop yield, Water quality), highlighting the influence of publication bias. In contrast, Carbon sequestration and Product quality showed no evidence of asymmetry or missing studies, reinforcing confidence in their reported effects. While high heterogeneity and variance ratios in several datasets warrant caution, the consistent detection of asymmetry and missing studies in select responses underscores the need to interpret these aggregated effects in light of potential reporting biases.

```{r}
##########################################################################################################################################
# SAVE PUBLICATION-BIAS RESULTS INTO DATAFRAME
##########################################################################################################################################

# Save publication bias results to a structured dataframe
save_bias_results <- function(bias_results) {
  results_list <- lapply(names(bias_results), function(response) {
    result <- bias_results[[response]]

    # Initialize Egger's Test row
    egger_row <- if (!is.null(result$Egger_Test)) {
      egger <- result$Egger_Test
      data.frame(
        Response = response,
        Test = "Egger's Test",
        Z_Value = if (!is.null(egger$zval)) egger$zval else NA,
        P_Value = if (!is.null(egger$pval)) egger$pval else NA,
        Limit_Estimate = if (!is.null(egger$b)) egger$b[1] else NA,
        CI_Lower = if (!is.null(egger$ci.lb)) egger$ci.lb else NA,
        CI_Upper = if (!is.null(egger$ci.ub)) egger$ci.ub else NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    } else {
      data.frame(
        Response = response,
        Test = "Egger's Test",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = NA,
        CI_Upper = NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    }

    # Initialize Trim-and-Fill row
    trim_row <- if (!is.null(result$Trim_and_Fill)) {
      trim <- result$Trim_and_Fill
      data.frame(
        Response = response,
        Test = "Trim-and-Fill",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = if (!is.null(trim$ci.lb)) trim$ci.lb else NA,
        CI_Upper = if (!is.null(trim$ci.ub)) trim$ci.ub else NA,
        Estimated_Missing_Studies = if (!is.null(trim$k0)) trim$k0 else NA,
        Adjusted_Estimate = if (!is.null(trim$b)) trim$b[1] else NA
      )
    } else {
      data.frame(
        Response = response,
        Test = "Trim-and-Fill",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = NA,
        CI_Upper = NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    }

    # Combine rows for the current response
    rbind(egger_row, trim_row)
  })

  # Combine all rows into a single dataframe
  results_df <- do.call(rbind, results_list)
  return(results_df)
}

# Save results to a dataframe for further analysis
bias_results_df <- save_bias_results(bias_results)

# Print results dataframe
bias_results_df

# bias_results_df |> glimpse()
```



```{r}
# Filter for Trim-and-Fill results
funnel_data <- bias_results_df %>% filter(Test == "Trim-and-Fill")

# Add precision (1 / SE)
funnel_data <- funnel_data %>%
  mutate(
    Precision = 1 / sqrt(Adjusted_Estimate + abs(CI_Upper - CI_Lower))
  )

# Funnel plot
ggplot(funnel_data, aes(x = Adjusted_Estimate, y = Precision)) +
  geom_point(color = "blue", size = 3) +
  geom_errorbarh(
    aes(xmin = CI_Lower, xmax = CI_Upper),
    height = 0.2,
    color = "gray"
  ) +
  geom_vline(
    xintercept = mean(funnel_data$Adjusted_Estimate, na.rm = TRUE),
    linetype = "dashed",
    color = "red",
    size = 1
  ) +
  facet_wrap(~ Response, ncol = 1) +
  theme_minimal() +
  labs(
    title = "Funnel Plot with Trim-and-Fill Adjustments",
    x = "Effect Size",
    y = "Precision (1/SE)"
  ) +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )
```

```{r}
egger_data <- bias_results_df |> dplyr::filter(Test == "Egger's Test")
ggplot(egger_data, aes(x = CI_Lower, y = CI_Upper)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "Egger's Regression Plot for Funnel Plot Asymmetry",
       x = "Effect Size (Lower CI)",
       y = "Effect Size (Upper CI)")
```

```{r}
trim_data <- bias_results_df |> dplyr::filter(Test == "Trim-and-Fill")
ggplot(trim_data, aes(x = Response, 
                      y = Estimated_Missing_Studies, 
                      fill = Adjusted_Estimate > 0)) +
  geom_col() +
  theme_minimal() +
  labs(title = "Number of Missing Studies Estimated (Trim-and-Fill)",
       x = "Response Variable",
       y = "Estimated Missing Studies") +
  scale_fill_manual(values = c("red", "green"), name = "Adjusted Estimate Positive")

```

```{r}
# Filter data for Trim-and-Fill results
forest_data <- bias_results_df %>%
  filter(Test == "Trim-and-Fill") %>%
  mutate(Response = factor(Response, levels = rev(Response))) # Reverse levels for proper ordering on y-axis

# Custom colors for each response variable
custom_colors <- c(
  "Biodiversity"             = "#FF9999",
  "Greenhouse gas emission"  = "#66C266",
  "Product quality"          = "#FFC000",
  "Crop yield"               = "#FF9933",
  "Pest and disease control" = "#33CCCC",
  "Soil quality"             = "#9966CC",
  "Water quality"            = "#9999FF"
)

# Plot with ggplot2
ggplot(forest_data, aes(
  x = Adjusted_Estimate,
  y = Response,
  xmin = CI_Lower,
  xmax = CI_Upper,
  color = Response
)) +
  geom_point(size = 3) +
  geom_errorbarh(height = 0.2, size = 0.8) +
  scale_color_manual(values = custom_colors) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray") +
  geom_text_repel(
    aes(label = paste0("Imputed: ", Estimated_Missing_Studies)),
    hjust = 0,
    nudge_x = 0.02,
    nudge_y = -0.3, # Adjust this value to move the text downward
    size = 4,
    color = "black"
  ) +
  labs(
    title = "Trim-and-Fill Adjusted Estimates with CIs",
    x = "Adjusted Effect Size",
    y = NULL,
    color = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(color = "black"),
    axis.text.x = element_text(color = "black")
  )
```


The Trim-and-Fill Test and Results: A Report Summary

The **Trim-and-Fill** method is a statistical tool used in meta-analysis to detect and adjust for **publication bias**, which occurs when studies with significant or positive results are more likely to be published, leading to distorted overall effect size estimates. This method ensures that meta-analytic conclusions are robust and unbiased.

Key Steps in the Trim-and-Fill Process:
1. **Detection of Funnel Plot Asymmetry**: A symmetrical funnel plot indicates no publication bias, while asymmetry suggests missing studies, often small studies with non-significant results.
2. **Trimming**: Studies causing asymmetry are temporarily removed to create symmetry.
3. **Filling**: Missing studies are imputed on the underreported side of the funnel plot.
4. **Re-estimation**: A new meta-analysis is performed with the original and imputed studies to calculate the **adjusted effect size** and its confidence intervals (CIs).

Trim-and-Fill Results:
The method outputs **adjusted estimates** that reflect the effect sizes after accounting for missing studies, along with:
- **Confidence Intervals (CIs)**: Indicating the range of plausible values for the adjusted effect size. If the CI includes zero, the adjusted estimate is not statistically significant.
- **Estimated Missing Studies**: The number of studies imputed to restore symmetry.
- **Direction of Bias**: Identifies the likely side where studies were underreported.

Purpose and Insights:
The Trim-and-Fill method evaluates whether the original meta-analytic estimate is robust to potential bias. A large difference between unadjusted and adjusted effect sizes indicates significant publication bias, while minimal changes suggest robustness.

Forest Plot Interpretation of Trim-and-Fill Results
The forest plot provides a visual summary of the Trim-and-Fill adjusted effect sizes and their corresponding CIs for various response variables:

1. **Adjusted Effect Sizes**: Represented by dots along horizontal bars (CIs), showing the mean effect size after adjusting for missing studies.
2. **Confidence Intervals (CIs)**: Bars extending from each dot. If they cross the vertical line at zero, the result is not statistically significant.
3. **Response Variables**: Listed on the y-axis, such as **Biodiversity**, **Crop yield**, and **Water quality**.
4. **Significance**: 
   - Positive or negative estimates excluding zero indicate significance.
   - Wide CIs suggest higher uncertainty, while narrow CIs indicate precision.



Observations:
- **Significant Findings**: "Water quality" has a positive adjusted estimate with CIs excluding zero, indicating statistical significance.
- **Negative Adjustments**: "Crop yield" and "Product quality" show negative adjusted estimates, with precise but non-significant results.
- **High Uncertainty**: "Pest and disease control" has wide CIs, indicating variability or uncertainty in its adjusted effect size.

This analysis demonstrates the importance of adjusting for publication bias, revealing both robust and potentially biased estimates across response variables. The plot provides clear, publication-ready visual insights for understanding the impact of bias adjustments in meta-analysis.



## Publication Bias Assessment - Funnel Plots

```{r}
model_results$`Crop yield`$base_model
```


```{r}
##########################################################################################################################################
# PUBLICATION BIAS ASSESSMENT - FUNNEL PLOTS
##########################################################################################################################################



# Function to generate contour-enhanced funnel plots for each response variable
create_contour_funnel_plots <- function(model_results) {
  # Loop through each response variable and generate a funnel plot
  for (response in names(model_results)) {
    
    # Set the model formula function to use for LOO analysis (e.g., base_model, minimal_random_effects_model, interaction_model or full_model)
    # Change this to minimal_random_effects_model if needed
    model <- model_results[[response]]$base_model

    # Skip if the model is NULL
    if (is.null(model)) {
      message(paste("No valid model for", response))
      next
    }

    # Generate and display the contour-enhanced funnel plot
    tryCatch({
      funnel(
        model, 
        level = c(90, 95, 99),  # Contours for statistical significance
        refline = 0,            # Center the funnel at 0
        legend = TRUE,          # Add a legend for the shaded regions
        main = paste("Contour-Enhanced Funnel Plot for", response)
      )
    }, error = function(e) {
      message(paste("Error generating contour funnel plot for", response, ":", e$message))
    })
  }
}

# Example usage with the model_results object
create_contour_funnel_plots(model_results)
```

Systematic Interpretation of Contour-Enhanced Funnel Plots Across All Response Variables

General Insights Across All Plots:
1. **Centering and Symmetry**:
   - All funnel plots are centered at `0`, representing the null hypothesis of no effect.
   - Symmetry in some plots (e.g., **Biodiversity**, **Soil Quality**, **Product Quality**) suggests minimal evidence of publication bias, while asymmetry in others (e.g., **Carbon sequestration**, **Crop Yield**, **Water Quality**) indicates potential bias or heterogeneity in reported effects.

2. **Shaded Regions**:
   - Most studies cluster in the **white region** (\( p > 0.10 \)), reflecting non-significant findings across the majority of studies.
   - A smaller number of studies extend into the **light gray** (\( 0.05 < p \leq 0.10 \)), **medium gray** (\( 0.01 < p \leq 0.05 \)), and **dark gray** (\( p \leq 0.01 \)) regions, indicating marginally significant to highly significant results.
   - The distribution of points in these shaded regions highlights varying levels of statistical significance across response variables.

3. **Funnel Width**:
   - The funnel shape consistently broadens as standard error increases, reflecting greater variability in effect sizes for less precise studies (higher standard error). This is consistent with expectations for meta-analyses.

4. **Potential Bias**:
   - Symmetrical plots (e.g., **Biodiversity**, **Soil Quality**) show little evidence of bias, while skewed plots (e.g., **Carbon sequestration**, **Crop Yield**, **Water Quality**) suggest possible **publication bias** or genuine heterogeneity.

Individual Response Variable Insights:

1. **Biodiversity**:
   - **Symmetry**: The symmetrical distribution around `0` suggests minimal publication bias.
   - **Findings**: Most studies are non-significant, clustering in the white region.
   - **Conclusion**: No strong evidence of bias; results are consistent with null or minor effects.

2. **Carbon sequestration**:
   - **Asymmetry**: Skewed to the right, indicating studies reporting positive effects are more frequent.
   - **Findings**: Non-significant results dominate, with fewer highly significant studies.
   - **Conclusion**: Potential publication bias favoring positive results; further statistical tests are recommended.

3. **Product Quality**:
   - **Symmetry**: Studies are distributed evenly around the null, with fewer significant findings.
   - **Findings**: Most studies fall in the non-significant range.
   - **Conclusion**: Minimal evidence of bias, indicating balanced reporting of positive and negative results.

4. **Crop Yield**:
   - **Asymmetry**: Skewed toward positive effects, with non-significant findings dominating.
   - **Findings**: The distribution suggests potential publication bias or selective reporting.
   - **Conclusion**: Asymmetry raises concerns; statistical tests (e.g., Egger’s test) are needed.

5. **Pest and disease control**:
   - **Symmetry**: Moderate symmetry with more studies closer to the center of the funnel.
   - **Findings**: Non-significant results dominate, with limited significant findings.
   - **Conclusion**: No substantial bias detected, but further analysis can confirm.

6. **Soil Quality**:
   - **Symmetry**: Highly symmetrical distribution, indicating a balanced representation of effects.
   - **Findings**: Predominantly non-significant findings, with very few highly significant studies.
   - **Conclusion**: Strong indication of no publication bias; results are consistent.

7. **Water Quality**:
   - **Asymmetry**: Right-skewed, with studies favoring positive effects.
   - **Findings**: Non-significant results are prevalent, with few moderately significant results.
   - **Conclusion**: Potential bias or heterogeneity; further exploration of data characteristics is needed.

Overall Conclusion:
- Symmetrical funnel plots (e.g., **Biodiversity**, **Soil Quality**, **Product Quality**) suggest **minimal publication bias** and consistent results.
- Asymmetric plots (e.g., **Carbon sequestration**, **Crop Yield**, **Water Quality**) highlight potential **publication bias** or **genuine heterogeneity**, warranting further statistical tests like Egger’s regression or subgroup analysis.


```{r}
######################################################################################################
# REFIT MODELS USING rma() FOR EGGER'S TEST
######################################################################################################

refit_rma_models <- function(meta_data, v_matrices) {
  rma_models <- list()
  
  for (response in unique(meta_data$response_variable)) {
    tryCatch({
      # Subset data for the specific response variable
      model_data <- meta_data[meta_data$response_variable == response, ]
      
      # Extract the variance-covariance matrix for the response
      v_matrix <- v_matrices[[response]]
      
      # Skip if variance matrix is missing
      if (is.null(v_matrix) || nrow(model_data) == 0) {
        cat("⚠ Skipping", response, "- No data or variance matrix found.\n")
        next
      }
      
      # Fit a standard random-effects model (no moderators, no multi-level structure)
      rma_model <- rma(
        yi = model_data$yi,  # Effect size
        vi = diag(v_matrix), # Within-study variance (diagonal of V)
        data = model_data,
        method = "REML"
      )
      
      # Store the model
      rma_models[[response]] <- rma_model
      cat("Model refitted for", response, "\n")
      
    }, error = function(e) {
      message("Error refitting model for", response, ":", e$message)
    })
  }
  
  return(rma_models)
}

######################################################################################################
# RUN EGGER'S TEST
######################################################################################################

run_eggers_test <- function(rma_models) {
  results <- list()
  
  for (response in names(rma_models)) {
    model <- rma_models[[response]]
    if (is.null(model)) next
    
    tryCatch({
      # Perform Egger's test
      egger_test <- regtest(model, model = "lm", predictor = "sei")  # `sei` = standard error
      
      # Store results
      results[[response]] <- egger_test
      
      # Print results
      cat("\n Egger's Test for", response, ":\n")
      print(egger_test)
      
    }, error = function(e) {
      message("Error running Egger's test for", response, ":", e$message)
    })
  }
  
  return(results)
}

######################################################################################################
# RUN THE PUBLICATION BIAS ASSESSMENT
######################################################################################################

# Refit models
rma_models <- refit_rma_models(meta_data, v_matrices)

# Run Egger's test on refitted models
eggers_results <- run_eggers_test(rma_models)

# Display final results
eggers_results
```

Summary of Egger’s Test for Publication Bias

* No Evidence of Publication Bias for Biodiversity, Crop Yield, Pest and disease control, and Product Quality (p > 0.05). No significant funnel plot asymmetry detected.
* Potential Publication Bias for Water Quality, Soil Quality, and Carbon sequestration (p < 0.0001). Significant asymmetry suggests small-study effects or selective reporting. Possible Causes of Asymmetry: 1) Selective reporting bias (e.g., unpublished non-significant studies), 2) Small-study effects (exaggerated results in smaller studies), 3) High study heterogeneity (differences in study design, location, crops).






# STEP 5 MODERATOR ANALYSIS - INFLUENCE OF SILVOARABLE AGROFORESTRY CHARACTERISTICS - (INCL. BOOTSTRAPPING)

```{r}
# model_results$`Crop yield`$full_model$tau2

# model_results$`Crop yield`$moderator_model$tau2
```

### Loading v_matrices

```{r}
# Load the saved v_matrices
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
v_matrices <- readRDS(file.path(output_dir, "v_matrices_by_response_variable.rds"))
```

Justifying the Use of a Model Without a Random Component

Proportion of Explained Heterogeneity (PEH) is derived by comparing between-study variance (τ²) in models with and without moderators. To estimate PEH, the null model provides a baseline τ² representing total heterogeneity, while models incorporating moderators help partition that heterogeneity and quantify the proportion explained. However, the data structure in this analysis is too sparse to support a hierarchical random-effects model with `~ 1 | id_article/exp_id`, as the number of studies per group is too low for the model to reliably estimate variance components. This led to convergence issues, requiring a modified approach where the models were refitted without the random-effects component.

Refitting was necessary because PEH is calculated as the proportionate reduction in τ² between models, and this requires the ability to fit both a null model and a moderator model under comparable conditions. Without refitting, it would be impossible to determine how much variance each moderator accounts for. The random-effects model structure introduced instability because the hierarchical variance component could not be estimated reliably, making it impractical for PEH analysis.

By removing the random component, the model focuses on within-study variance while still capturing residual heterogeneity (τ²). Although this shifts the approach closer to a fixed-effects model, the key objective here is not to make population-level inferences but rather to partition variance and assess the explanatory power of moderators. The simplified model structure ensures that τ² estimates remain valid, while bootstrapping compensates for potential limitations by providing empirical uncertainty estimates.

Critically, the model still accounts for variability through the study-level variance (`vi = diag(v_matrix)`), which ensures appropriate weighting of studies based on precision. While a full random-effects model is generally preferable when estimating overall heterogeneity, its use in this case was not feasible due to sparse data. Alternative approaches, such as Bayesian hierarchical modeling or aggregating studies within `exp_id`, would introduce additional assumptions or reduce statistical power. Removing the random component allowed for a more stable estimation of τ² and thus more reliable PEH calculations.

This approach ensures that the PEH estimates remain interpretable and statistically valid while avoiding model complexity that would otherwise compromise the analysis. The use of bootstrapping further strengthens the robustness of these estimates, providing confidence in the validity of the findings despite the necessary modifications to the modeling approach.

```{r}
####################################################################################################
# MODERATOR ANALYSIS - PROPORTION OF EXPLAINED HETEROGENEITY ACROSS ALL RESPONSE VARIABLES
####################################################################################################

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")


# Define global control parameters for model fitting
control_params <- list(
  optimizer = "optim",    # Use base R optimizer
  method = "BFGS",        # Broyden–Fletcher–Goldfarb–Shanno optimization method
  iter.max = 10000,       # Maximum number of iterations for convergence
  rel.tol = 1e-12         # Tolerance level for convergence (smaller = stricter)
)

####################################################################################################
# INITIALIZE STORAGE FOR RESULTS

# Create an empty data frame to store heterogeneity results for each response variable and moderator
heterogeneity_results <- data.frame()

# Extract unique response variables from the dataset
response_variables <- unique(meta_data$response_variable)

####################################################################################################
# LOOP THROUGH EACH RESPONSE VARIABLE

for (response_variable in response_variables) {
  
  cat("\n-------------------------\nProcessing:", response_variable, "\n-------------------------\n")
  
  # Subset data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response_variable, ]
  
  # Extract the corresponding variance-covariance matrix
  v_matrix <- v_matrices[[response_variable]]
  
  # Skip if variance matrix is missing
  if (is.null(v_matrix)) {
    cat("⚠ Skipping", response_variable, "- No variance matrix found.\n")
    next
  }

  # Define the random effects structure
  # random_effects <- list(~ 1 | id_article/exp_id)
  random_effects <- list(~ 1 | id_article / location * experiment_year)  # <------- ! Chosen Random Effects Structure !
  
  ###############################################################
  # NULL MODEL: GLOBAL AVERAGE WITHOUT MODERATORS

  null_model <- tryCatch({
    rma(
      yi = yi,                        # Effect size
      vi = diag(v_matrix),            # Use diagonal for within-study variance
      random = random_effects,        # Random effects structure
      data = data_subset,             # Data subset
      method = "REML",                # Restricted Maximum Likelihood Estimation
      control = control_params        # Optimizer control parameters
    )
  }, error = function(e) {
    cat("Error in null model for", response_variable, ":", e$message, "\n")
    return(NULL)
  })

  # Extract τ² from the null model if successfully fitted
  if (!is.null(null_model)) {
    tau2_null <- null_model$tau2
    cat("τ² (Null Model) for", response_variable, ":", tau2_null, "\n")
  } else {
    cat("⚠ Warning: τ² (Null Model) is 0 or model fitting failed for", response_variable, "\n")
    next  # Skip to next response variable if null model fails
  }

  ###############################################################
  # FULL MODERATOR MODEL: ALL MODERATORS ADDITIVE (NO INTERACTIONS)

    # Loop through each moderator for this response variable
  for (moderator in moderators) {
    cat("\nFitting model for moderator:", moderator, "on", response_variable, "\n")
    
    mod_model <- tryCatch({
      rma(
        yi = yi,
        vi = diag(v_matrix),
        mods = as.formula(paste("~", moderator)),  # Single moderator model
        data = data_subset,
        method = "REML",
        control = control_params
      )
    }, error = function(e) {
      message("Error in model for", moderator, "on", response_variable, ":", e$message)
      return(NULL)
    })
    
    # Extract tau² from the moderator model
    if (!is.null(mod_model)) {
      tau2_moderated <- mod_model$tau2
      cat("  τ² (Model with", moderator, "on", response_variable, "):", tau2_moderated, "\n")
      
      # Calculate proportion of explained heterogeneity
      proportion_explained <- ifelse(tau2_null > 0, ((tau2_null - tau2_moderated) / tau2_null) * 100, NA)
      proportion_explained <- max(min(proportion_explained, 100), 0)  # Ensure between 0-100%
      
      # Store results
      heterogeneity_results <- rbind(heterogeneity_results, 
                                     data.frame(ResponseVariable = response_variable,
                                                Moderator = moderator,
                                                Tau2_Null = tau2_null,
                                                Tau2_Moderated = tau2_moderated,
                                                ProportionExplained = proportion_explained))
    } else {
      cat("⚠ Warning: Model for", moderator, "on", response_variable, "failed.\n")
    }
  }
}

####################################################################################################
# OUTPUT FINAL RESULTS
####################################################################################################
# Print final heterogeneity results
heterogeneity_results

# Save results as an RDS file
# output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# saveRDS(heterogeneity_results, file = file.path(output_dir, "heterogeneity_explained_summary.rds"))
```


```{r}
####################################################################################################
# MODERATOR ANALYSIS - PROPORTION OF EXPLAINED HETEROGENEITY USING RE-FITTED MODELS
####################################################################################################

##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################


# Initialize an empty data frame to store results
heterogeneity_results_clean <- data.frame()

# Define all response variables
response_variables <- unique(meta_data$response_variable)

# Define moderators to include in the model
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Global control parameters for optimization
control_params <- list(
  optimizer = "optim",   
  method = "BFGS",       
  iter.max = 10000,      
  rel.tol = 1e-12        
)

# Loop through each response variable
for (response_variable in response_variables) {
  
  cat("\n-------------------------\nProcessing:", response_variable, "\n-------------------------\n")
  
  # Subset data for the response variable
  data_subset <- meta_data[meta_data$response_variable == response_variable, ]
  
  # Extract the variance-covariance matrix
  v_matrix <- v_matrices[[response_variable]]
  
  # Skip if variance matrix is missing
  if (is.null(v_matrix)) {
    cat("⚠ Skipping", response_variable, "- No variance matrix found.\n")
    next
  }
  
  # Fit the Null Model (Global Average without Moderators)
  null_model <- tryCatch({
    rma(
      yi = yi,                        
      vi = diag(v_matrix),    
      mods = ~ -1,  # Exclude the global intercept for comparability with the moderator model
      data = data_subset,             
      method = "REML",                
      control = control_params        
    )
  }, error = function(e) {
    cat("Error in null model for", response_variable, ":", e$message, "\n")
    return(NULL)
  })
  
  # Extract τ² from the null model
  if (!is.null(null_model)) {
    tau2_null <- null_model$tau2
    cat("τ² (Null Model) for", response_variable, ":", tau2_null, "\n")
  } else {
    cat("⚠ Warning: τ² (Null Model) is 0 or model fitting failed for", response_variable, "\n")
    next  
  }

  # Fit the Full Moderator Model (All Moderators additive, without Interactions)
  full_moderator_model <- tryCatch({
    rma(
      yi = yi,                                     
      vi = diag(v_matrix),                         
      mods = as.formula(paste("~ -1 +", paste(moderators, collapse = " + "))),  
      data = data_subset,                          
      method = "REML",                             
      control = control_params                     
    )
  }, error = function(e) {
    cat("Error in full moderator model for", response_variable, ":", e$message, "\n")
    return(NULL)
  })

  # Extract τ² from the full moderator model
  if (!is.null(full_moderator_model)) {
    tau2_full_moderator <- full_moderator_model$tau2
    cat("τ² (Full Moderator Model) for", response_variable, ":", tau2_full_moderator, "\n")
  } else {
    cat("⚠ Warning: τ² (Full Moderator Model) is 0 or model fitting failed for", response_variable, "\n")
    next  
  }

  # Compute proportion of explained heterogeneity
  proportion_explained <- abs((tau2_null - tau2_full_moderator) / tau2_null) * 100
  proportion_explained <- min(proportion_explained, 1000)  
  cat("\nProportion of Explained Heterogeneity:", proportion_explained, "%\n")

  # Loop through each moderator individually
  for (moderator in moderators) {
    
    if (!(moderator %in% colnames(data_subset))) {
      cat("\n⚠ Skipping", moderator, "for", response_variable, "- Not present in dataset.\n")
      next
    }

    cat("\nFitting model for moderator:", moderator, "on", response_variable, "\n")
    
    mod_model <- tryCatch({
      rma(
        yi = yi,                                 
        vi = diag(v_matrix),                     
        mods = as.formula(paste("~ -1 + ", moderator)), # Exclude global intercept 
        #-1 removes that constant term from the formula, ensuring that the model fits only the moderators as separate predictors, not an overall average.
        data = data_subset,                      
        method = "REML",                         
        control = control_params                 
      )
    }, error = function(e) {
      cat("Error in model for", moderator, "on", response_variable, ":", e$message, "\n")
      return(NULL)
    })
    
    # Extract τ² from the moderator model
    if (!is.null(mod_model)) {
      tau2_moderated <- mod_model$tau2
      cat("  τ² (Model with", moderator, "on", response_variable, "):", tau2_moderated, "\n")
      
      # Compute proportion of explained heterogeneity
      proportion_explained_mod <- abs((tau2_null - tau2_moderated) / tau2_null) * 100
      proportion_explained_mod <- min(proportion_explained_mod, 1000)  

      # Extract model summary
      model_summary <- summary(mod_model)

      # Extract estimates and statistics
      estimates <- as.numeric(model_summary$b)   # Effect sizes
      se_values <- as.numeric(model_summary$se)  # Standard errors
      z_values <- as.numeric(model_summary$zval) # Z-values
      p_values <- as.numeric(model_summary$pval) # P-values
      ci_lower <- as.numeric(model_summary$ci.lb) # Lower CI
      ci_upper <- as.numeric(model_summary$ci.ub) # Upper CI

      # Add significance codes
      significance_levels <- case_when(
        p_values < 0.001 ~ "***",
        p_values < 0.01  ~ "**",
        p_values < 0.05  ~ "*",
        p_values < 0.1   ~ ".",
        TRUE             ~ ""
      )

      # Store results
      mod_results_df <- data.frame(
        ResponseVariable = response_variable,
        Moderator = rownames(model_summary$b),
        Tau2_Null = tau2_null,
        Tau2_Moderated = tau2_moderated,
        ProportionExplained = proportion_explained_mod,
        Estimate = estimates,
        SE = se_values,
        Z_Value = z_values,
        P_Value = p_values,
        CI_Lower = ci_lower,
        CI_Upper = ci_upper,
        Significance = significance_levels
      )

      # Append results
      heterogeneity_results_clean <- rbind(heterogeneity_results_clean, mod_results_df)
    } else {
      cat("⚠ Warning: Model for", moderator, "on", response_variable, "failed.\n")
    }
  }
}

# Print results
heterogeneity_results_clean


##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (01/03-2025) 
# Total time taken: 8.381763 secs 
```
Updated Interpretation of Moderators' Effects on Model Heterogeneity with Proportion of Heterogeneity Explained (PEH)

1. **Significance of Moderators (P-value Interpretation):**
   - **P-values** reveal whether each moderator has a statistically significant effect on heterogeneity in the model.
     - A **P-value < 0.05** suggests that the moderator significantly influences heterogeneity. This is particularly important when examining the **Proportion of Heterogeneity Explained (PEH)**, as significant moderators will account for more of the variation in the data.
     - **P-values > 0.05** imply weak evidence of an effect, indicating that the moderator might not be explaining much heterogeneity, contributing less to PEH. For example, a high P-value means the moderator does not help in reducing unexplained variance and therefore, the PEH associated with it is likely low.

2. **Magnitude of Effects (Estimate and SE):**
   - The **Estimate** represents the strength and direction of the effect each moderator has on heterogeneity:
     - Positive estimates indicate that the moderator increases heterogeneity, meaning it explains a greater proportion of variance in the model, contributing significantly to PEH.
     - Negative estimates suggest that the moderator decreases heterogeneity, explaining a reduction in variability, which can still explain a significant portion of PEH by better specifying the model.
   - **Standard Error (SE)** reflects the precision of the estimate:
     - Lower SE values suggest a higher confidence in the moderator’s effect on heterogeneity, contributing more reliably to PEH.
     - Higher SE values indicate less certainty in the moderator’s contribution, making the PEH it explains less reliable.

3. **Confidence Intervals (CI.Lower and CI.Upper):**
   - The confidence intervals give the range within which the true effect size of the moderator is likely to fall.
     - If the confidence intervals **exclude zero**, it strengthens the belief that the moderator has a real and significant effect on heterogeneity, thus contributing to a higher PEH. A narrower interval indicates more precision, and therefore, more consistent explanation of variability.
     - If the intervals **include zero**, it indicates uncertainty about the moderator’s effect, suggesting it likely does not contribute significantly to heterogeneity or PEH.

4. **Specific Moderators' Contributions:**

   - **Tree Type**:
     - Moderators like "tree_typeTimber" show strong evidence of a significant effect (P-value < 0.001) and narrow confidence intervals excluding zero, suggesting they play an important role in explaining heterogeneity in biodiversity and other outcomes. The high significance of these terms (PEH contribution > 50%) indicates that tree type is a key factor in explaining variability in the data.
     - "tree_typeBiomass" shows a non-significant P-value (P-value = 0.891), indicating that it does not contribute to explaining heterogeneity, and thus, the PEH linked to this moderator is minimal.
     - As the PEH is higher for significant moderators like "tree_typeTimber" (explaining over 60% of heterogeneity), it suggests these categories help reduce unexplained variance in the model.

   - **Crop Type**:
     - "crop_typeLegume" shows a highly significant effect (P-value < 0.001) with confidence intervals excluding zero, indicating that legumes play a significant role in explaining heterogeneity, particularly in outcomes like crop yield and pest management. This moderator likely explains a large portion of the PEH, contributing to approximately 50-60% of the heterogeneity across studies.
     - "crop_typeCereal" is also significant (P-value < 0.05), but with a lower PEH contribution than legumes, as its impact on heterogeneity is slightly less robust.
     - "crop_typeTuber,root and other" is significant with a moderate P-value (P-value = 0.02), suggesting it explains variability in pest and disease outcomes, contributing moderately to PEH (~30%).

   - **Age System**:
     - "age_systemYoung" demonstrates the most substantial and consistent impact on heterogeneity, with P-values < 0.001 and narrow confidence intervals, explaining **nearly 90% of heterogeneity** in certain models. This indicates that age-related changes in systems (like agroforestry or forest management) are critical to understanding variability across outcomes.
     - "age_systemMedium" and "age_systemMature" contribute less to PEH, as their P-values suggest weaker effects on heterogeneity (P-value > 0.05), indicating they explain only a small portion of the variance (PEH < 30%).

   - **Season**:
     - "seasonSummer" is highly significant (P-value < 0.001) and explains a significant portion of heterogeneity, especially in biodiversity and crop yield models. This indicates that seasonal variations have a clear impact on heterogeneity, contributing **around 40-50% of the PEH** in these models.
     - "seasonWinter" has less consistent effects (P-value > 0.05), with wider confidence intervals including zero, indicating it has a weaker contribution to heterogeneity, and therefore, explains a smaller portion of PEH.

   - **Soil Texture**:
     - "soil_textureClay" shows a highly significant contribution to heterogeneity (P-value < 0.01), with a narrow confidence interval excluding zero, indicating that soil texture, particularly clay, significantly explains variability in biodiversity and crop yield. This moderator is a key contributor to PEH, accounting for **up to 60% of the heterogeneity**.
     - "soil_textureSand" and "soil_textureSilt" show weaker contributions (P-values > 0.05), suggesting that these soil textures explain less of the variability in the outcomes, resulting in a smaller proportion of PEH.

5. **Proportion of Heterogeneity Explained (PEH):**
   - **Age System** (especially "age_systemYoung") accounts for **the highest proportion of heterogeneity** (up to 90% in some cases). The effect of age-related changes in the system is highly consistent and significant, explaining a large portion of the variability in all outcomes.
   - **Tree Type** and **Crop Type** (especially "tree_typeTimber" and "crop_typeLegume") explain substantial portions of heterogeneity, contributing to **over 60%** of the total PEH, especially for biodiversity and pest management outcomes.
   - **Soil Texture** explains about **50-60%** of the variability, particularly in biodiversity and crop yield models, with "soil_textureClay" being the most significant contributor.
   - **Season** contributes **40-50%** of heterogeneity, particularly through summer season effects on biodiversity and yield.
   - **Less Impactful Moderators** like "seasonWinter" and some "Tree Type" subcategories ("tree_typeBiomass") have minimal contributions to PEH due to their non-significant or weak effects.

Summary:
- **Key Moderators:** "Age System" and "Crop Type" are the most impactful, explaining **over 70%** of the heterogeneity. "Age_systemYoung" stands out as the moderator with the largest PEH contribution.
- **Moderate Contributors:** "Tree Type" (especially "tree_typeTimber") and "Soil Texture" (with "soil_textureClay") explain **50-60%** of the heterogeneity, making them crucial for understanding variability in outcomes like crop yield and biodiversity.
- **Less Impactful:** "Season" (particularly "seasonWinter") and "Tree Type" subcategories like "tree_typeBiomass" show **low PEH** contributions, with weak or non-significant effects on heterogeneity.



```{r}
# Summarize the fraction of PEH for each individual response variables
summary_peh <- heterogeneity_results_clean %>%
  group_by(ResponseVariable) %>% # Group by the moderator variable
  summarise(Mean_PE_Heterogeneity = mean(ProportionExplained, na.rm = TRUE), # Calculate the mean PEH
            SD_PE_Heterogeneity = sd(ProportionExplained, na.rm = TRUE),    # Optionally calculate the standard deviation of PEH
            Min_PE_Heterogeneity = min(ProportionExplained, na.rm = TRUE),   # Minimum PEH for each moderator
            Max_PE_Heterogeneity = max(ProportionExplained, na.rm = TRUE))   # Maximum PEH for each moderator

summary_peh
```
```{r}
# moderators <- c("tree_type", "crop_type", "age_system", "season", 
#                 "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Create a helper function to extract the higher-level moderator name (e.g., 'tree_type', 'crop_type', etc.)
get_moderator_group <- function(moderator) {
  if (grepl("tree_type", moderator)) {
    return("tree_type")
  } else if (grepl("crop_type", moderator)) {
    return("crop_type")
  } else if (grepl("age_system", moderator)) {
    return("age_system")
  } else if (grepl("season", moderator)) {
    return("season")
  } else if (grepl("soil_texture", moderator)) {
    return("soil_texture")
  } else if (grepl("no_tree_per_m", moderator)) {
    return("no_tree_per_m")
  } else if (grepl("tree_height", moderator)) {
    return("tree_height")
  } else if (grepl("alley_width", moderator)) {
    return("alley_width")
    # The intercept is not relevant when the models have been fitted without global intercept
    # However, its apparently necessary for the response variables: Greenhouse gas emission, Pest and disease control, and Water quality. 
  } else if (grepl("intrcpt", moderator)) {  
    return("intrcpt")
  } else {
    return("other")  # In case a moderator doesn't fit the predefined categories
  }
}

# Add a new column for the higher-level moderator group
heterogeneity_results_clean <- heterogeneity_results_clean %>%
  mutate(ModeratorGroup = sapply(Moderator, get_moderator_group)) |> 
  # Only positive PEH values are relevant for visualization
  filter(ProportionExplained > 0) |> 
  # Exclude the intercept moderator - because it adds confusion
  filter(ModeratorGroup != "intrcpt")  

# Summarize the PEH for each ModeratorGroup and ResponseVariable
summary_peh_by_group <- heterogeneity_results_clean %>%
  group_by(ResponseVariable, ModeratorGroup) %>%
  summarise(Avg_PE_Heterogeneity = mean(ProportionExplained, na.rm = TRUE)) %>%
  arrange(ResponseVariable, ModeratorGroup)

# View the summarized result
summary_peh_by_group

summary_peh_by_group |> glimpse()
```

```{r}
summary_plot_proportion_explained_heterogeneity_by_group <-
  ggplot(summary_peh_by_group, aes(x = Avg_PE_Heterogeneity, y = ModeratorGroup, fill = ResponseVariable)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ ResponseVariable, scales = "free_x", nrow = 1) +  # Facet in one row
  scale_fill_manual(values = custom_colors) +
  labs(
    title = "Average Proportion of Heterogeneity Explained by Moderator Group for Each Response Variable",
    x = "Average PEH (%)",
    y = "Moderator Group"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(angle = 45, hjust = 1),  # Adjust for rotated y-axis labels
    strip.text = element_text(face = "bold"),
    legend.position = "none"  # Adjust legend position for clarity
  )

summary_plot_proportion_explained_heterogeneity_by_group
```







## Bootstrapping for Proportion of Explained Heterogeneity (PEH) Analysis

Bootstrapping involves resampling with replacement to estimate confidence intervals for PEH. 
This helps assess the robustness of the estimated heterogeneity explained

```{r, eval=FALSE}
####################################################################################################
# BOOTSTRAPPING FOR PROPORTION OF EXPLAINED HETEROGENEITY (PEH) ANALYSIS
####################################################################################################

##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################


moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

##########################################################################

# Global control parameters for optimization
control_params <- list(
  # Specifies the optimization function to use, "optim" is the base R optimizer, allowing for flexible tuning
  optimizer = "optim",
  # Defines the specific optimization algorithm. "BFGS" (Broyden–Fletcher–Goldfarb–Shanno) is a quasi-Newton method
  # This optimization algorithm is often used for unconstrained optimization problems and works well in meta-analytic models with moderate to large datasets
  method = "BFGS",
  # Maximum number of iterations for the optimization routine. If the models does not converge, increasing this value can help.
  # However, very high values may lead to excessive computation time.
  iter.max = 10000,
  # Relative tolerance level for convergence. Determines when the optimization process should stop.
  # Lower values (e.g., 1e-15) enforce stricter convergence, ensuring more precise results but requiring longer run times.
  # Higher values (e.g., 1e-4) allow faster convergence but may reduce accuracy (default in metafor is 1e-10).
  rel.tol = 1e-12
  # Uncomment this line if you want to track optimizer progress for each individual model
  # This will print detailed iteration steps, useful for debugging non-convergence issues.
  # verbose = TRUE   
)

##########################################################################

# Bootstrapping for PEH Analysis
# Bootstrapping is a resampling-based statistical method used to estimate the uncertainty and stability of a statistic by repeatedly sampling from the original dataset with replacement. In the context of Proportion of Explained Heterogeneity (PEH) analysis, bootstrapping provides confidence intervals (CIs) for the estimated PEH values and helps determine whether observed moderator effects are statistically robust or due to random noise.

# Set number of bootstrap iterations
n_boot <- 100  # was set to 1000 before, but reduced for testing purposes

# Initialize an empty list to store bootstrap results
bootstrap_results <- list()

# Function to compute PEH for bootstrapped samples
bootstrap_peh <- function(data_subset, v_matrix, response_variable, moderator) {
  # Resample data with replacement
  boot_data <- data_subset[sample(nrow(data_subset), replace = TRUE), ]
  
  # Fit the null model
  null_model <- tryCatch({
    rma(
      yi = yi,
      vi = diag(v_matrix),
      mods = ~ -1,  # Exclude the global intercept for comparability with the moderator model
      data = boot_data,
      method = "REML",
      control = control_params
    )
  }, error = function(e) NULL)
  
  if (is.null(null_model)) return(NA) # Return NA if null model fails
  
  tau2_null <- null_model$tau2  # Extract τ²
  
  # Fit the model with a single moderator
  mod_model <- tryCatch({
    rma(
      yi = yi,
      vi = diag(v_matrix),
      mods = as.formula(paste("~ -1 +", moderator)), # Exclude global intercept 
      #-1 removes that constant term from the formula, ensuring that the model fits only the moderators as separate predictors, not an overall average.
      data = boot_data,
      method = "REML",
      control = control_params
    )
  }, error = function(e) NULL)
  
  if (is.null(mod_model)) return(NA) # Return NA if model fails
  
  tau2_moderated <- mod_model$tau2
  
  # Compute PEH
  proportion_explained <- ifelse(tau2_null > 0, ((tau2_null - tau2_moderated) / tau2_null) * 100, NA)
  proportion_explained <- max(min(proportion_explained, 100), 0)  # Ensure PEH is between 0-100%
  
  return(proportion_explained)
}
##########################################################################
# Run bootstrap for each response variable and moderator
for (response_variable in unique(meta_data$response_variable)) {
  cat("\nBootstrapping for:", response_variable, "\n")
  
  # Subset data and extract variance-covariance matrix
  data_subset <- meta_data[meta_data$response_variable == response_variable, ]
  v_matrix <- v_matrices[[response_variable]]
  
  # Skip if variance matrix is missing
  if (is.null(v_matrix)) next
  
  for (moderator in moderators) {
    cat("Processing moderator:", moderator, "\n")
    
    # Run bootstrap
    boot_estimates <- replicate(n_boot, bootstrap_peh(data_subset, v_matrix, response_variable, moderator))
    
    # Compute summary statistics
    boot_summary <- data.frame(
      ResponseVariable = response_variable,
      Moderator = moderator,
      MeanPEH = mean(boot_estimates, na.rm = TRUE),
      LowerCI = quantile(boot_estimates, 0.025, na.rm = TRUE),
      UpperCI = quantile(boot_estimates, 0.975, na.rm = TRUE)
    )
    
    # Store results
    bootstrap_results[[paste(response_variable, moderator, sep = "_")]] <- boot_summary
  }
}
##########################################################################
# Convert list to data frame
bootstrap_results_df <- do.call(rbind, bootstrap_results)

# View resulting dataframe on PEH
bootstrap_results_df

##########################################################################
# Save the bootstrapped results as an RDS file
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

saveRDS(
  bootstrap_results_df,
  file = file.path(output_dir, "bootstrapped_PEH_results.rds")
)

cat("Bootstrapped results saved to:", file.path(output_dir, "bootstrapped_PEH_results.rds"), "\n")

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (04/02-2025) 
# Total time taken: 1.006638 hours 
# Last go (12/05-2025) 
# Total time taken: 52.94761 secs 
```

### Load the bootstrapped results

```{r}
# Load the bootstrapped results

output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

bootstrap_results_df <- readRDS(file.path(output_dir, "bootstrapped_PEH_results.rds"))
```

```{r}
# Verify whether the total Proportion of Explained Heterogeneity (PEH) for each response variable exceeds 100% across all moderators:

# View resulting dataframe on PEH
# bootstrap_results_df

# Summarize PEH per response variable
peh_summary <- bootstrap_results_df %>%
  group_by(ResponseVariable) %>%
  summarise(TotalPEH = sum(MeanPEH, na.rm = TRUE)) %>%
  mutate(Exceeds100 = TotalPEH > 100)  # Check if sum exceeds 100%

# Identify response variables where total PEH exceeds 100%
if (any(peh_summary$Exceeds100)) {
  warning("⚠ Some response variables have a total PEH exceeding 100%! Review the calculations.")
} else {
  cat("✅ All response variables have a total PEH ≤ 100%.")
}

# Display results
peh_summary |> 
  arrange(desc(TotalPEH)) 
```


```{r}
# Convert ResponseVariable and Moderator to factors for proper ordering
bootstrap_results_df$ResponseVariable <- factor(bootstrap_results_df$ResponseVariable, levels = unique(bootstrap_results_df$ResponseVariable))
bootstrap_results_df$Moderator <- factor(bootstrap_results_df$Moderator, levels = unique(bootstrap_results_df$Moderator))

# Create the bar plot with flipped axes
proportion_of_explained_heterogenity_per_response_plot <-
  ggplot(bootstrap_results_df, aes(x = ResponseVariable, y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +  # Flip the axes
  labs(title = "Bootstrapped Proportion of Explained Heterogeneity",
       x = "Response Variable",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1), # Ensure readability for y-axis labels
        legend.position = "none")  

proportion_of_explained_heterogenity_per_response_plot
```

```{r}
# Filter for selected response variables
filtered_data <- bootstrap_results_df %>%
  filter(ResponseVariable %in% c("Crop yield", "Soil quality", "Biodiversity"))

# Create faceted bar plot with fixed x-axis
ggplot(filtered_data, aes(x = Moderator, y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +  # Flip axes
  facet_wrap(~ResponseVariable, scales = "free_x") +  # Facet by response variable with fixed x-axis
  labs(title = "Bootstrapped Proportion of Explained Heterogeneity (PEH)",
       x = "Moderator",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  # Ensure labels remain readable
  theme(axis.text.y = element_text(angle = 0, hjust = 1),
        legend.position = "top")  
```



```{r}
# This aggregates all moderators for each response variable and visualizes the overall proportion explained
# Filter for Selected Response Variables (Optional)
selected_vars <- c("Crop yield", "Soil quality", "Biodiversity")
filtered_data <- bootstrap_results_df %>%
  filter(ResponseVariable %in% selected_vars)

# Summarize Total PEH per Response Variable
peh_overall <- filtered_data %>%
  group_by(ResponseVariable) %>%
  summarise(TotalPEH = sum(MeanPEH, na.rm = TRUE))  # Sum of PEH

# Overall Proportion of Explained Heterogeneity
ggplot(peh_overall, aes(x = reorder(ResponseVariable, TotalPEH), y = TotalPEH, fill = ResponseVariable)) +
  geom_bar(stat = "identity", color = "black", alpha = 0.8) +
  coord_flip() +
  labs(title = "Overall Proportion of Explained Heterogeneity (PEH)",
       x = "Response Variable",
       y = "Total PEH (%)") +
  theme_minimal() +
  theme(legend.position = "none",
        axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 14, face = "bold"))
```

```{r}
# This breaks down the contributions of different moderators per response variable
# Grouped PEH Bar Plot
ggplot(bootstrap_results_df, aes(x = reorder(ResponseVariable, -MeanPEH), y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), 
                position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +
  labs(title = "Proportion of Explained Heterogeneity (PEH) by Moderator",
       x = "Response Variable",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 14, face = "bold"),
        legend.position = "top")

```

```{r}
# Filter for Selected Response Variables (Optional)
selected_vars <- c("Crop yield", "Soil quality", "Biodiversity")
filtered_data <- bootstrap_results_df %>%
  filter(ResponseVariable %in% selected_vars)

# Faceted PEH Bar Plot

proportion_of_explained_heterogenity_plot <- 
ggplot(filtered_data, aes(x = Moderator, y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), 
                position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +
  facet_wrap(~ResponseVariable, scales = "free_x") +
  labs(title = "Proportion of Explained Heterogeneity (PEH) by Moderator",
       x = "Moderator",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"),
        axis.text.y = element_text(size = 12),
        plot.title = element_text(size = 14, face = "bold"))

proportion_of_explained_heterogenity_plot
```




# STEP 6 MODERATOR ANALYSIS - STATISTICAL ANALYSIS OF MODERATORS' EFFECTS FOR EACH RESPONSE VARIABLE - VISUALISED WITH FOREST PLOTS

```{r eval=FALSE}
# List of response variables and moderators
response_variables <- c("Biodiversity", "Crop yield", "Water quality", "Pest and disease control", 
                        "Soil quality", "Greenhouse gas emission", "Product quality")

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")
```

```{r}
# Function to fit individual and interaction moderator models using rma.mv
fit_moderator_models_mv <- function(meta_data, response_variables, moderators, v_matrices, control_params) {
  
  results_df <- data.frame()
  
  # Define minimal random effects structure
  # random_effects <- list(~ 1 | id_article/exp_id)
  random_effects <- list(~ 1 | id_article / location * experiment_year)  # <------- ! Chosen Random Effects Structure !

  for (response_variable in response_variables) {
    
    cat("\nProcessing:", response_variable, "\n")
    
    # Subset data for response variable
    data_subset <- meta_data %>% filter(response_variable == !!response_variable)
    
    # Extract variance-covariance matrix
    v_matrix <- v_matrices[[response_variable]]
    
    if (is.null(v_matrix)) {
      cat("⚠ Skipping", response_variable, "- No variance matrix found.\n")
      next
    }

    # INDIVIDUAL MODERATOR MODELS ---------------------------------------------------------------
    for (moderator in moderators) {
      if (!(moderator %in% colnames(data_subset))) {
        cat("⚠ Skipping", moderator, "for", response_variable, "- Not in dataset.\n")
        next
      }
      cat("  Fitting model for individual moderator:", moderator, "\n")
      
      mod_model <- tryCatch({
        rma.mv(
          yi = yi, 
          V = v_matrix, 
          mods = as.formula(paste("~", moderator, "-1")),  # "-1" Removes intercept 
          random = random_effects,  # Nested random effects
          data = data_subset, 
          method = "REML", 
          slab = data_subset$id_study,  # Study labels
          control = control_params
        )
      }, error = function(e) {
        cat("Error in individual model for", moderator, "on", response_variable, ":", e$message, "\n")
        return(NULL)
      })
      
      if (!is.null(mod_model)) {
        model_summary <- summary(mod_model)

        # Extract estimates and confidence intervals
        results_df <- rbind(
          results_df,
          data.frame(
            ResponseVariable = response_variable,
            Moderator = moderator,
            Type = "Individual",
            Term = rownames(model_summary$b),
            Estimate = model_summary$b[,1],
            SE = model_summary$se,
            P_Value = model_summary$pval,
            CI_Lower = model_summary$ci.lb,
            CI_Upper = model_summary$ci.ub
          )
        )
      }
    }

    # INTERACTION MODERATOR MODEL ---------------------------------------------------------------
    cat("  Fitting interaction model for", response_variable, "\n")
    
    interaction_formula <- paste("~", paste(moderators, collapse = " * "), "-1")  # Creates interaction terms - "-1" Removes intercept
    
    interaction_model <- tryCatch({
      rma.mv(
        yi = yi, 
        V = v_matrix, 
        mods = as.formula(interaction_formula),  # Interaction terms without intercept
        random = random_effects,  # Nested random effects
        data = data_subset, 
        method = "REML", 
        slab = data_subset$id_study,  # Study labels
        control = control_params
      )
    }, error = function(e) {
      cat("Error in interaction model for", response_variable, ":", e$message, "\n")
      return(NULL)
    })

    if (!is.null(interaction_model)) {
      model_summary <- summary(interaction_model)

      # Extract estimates and confidence intervals
      results_df <- rbind(
        results_df,
        data.frame(
          ResponseVariable = response_variable,
          Moderator = "Interaction Model",
          Type = "Interaction",
          Term = rownames(model_summary$b),
          Estimate = model_summary$b[,1],
          SE = model_summary$se,
          P_Value = model_summary$pval,
          CI_Lower = model_summary$ci.lb,
          CI_Upper = model_summary$ci.ub
        )
      )
    }
  }
  
  return(results_df)
}

# Define response variables and moderators
response_variables <- unique(meta_data$response_variable)
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Fit models and store results
moderator_results_mv <- fit_moderator_models_mv(meta_data, response_variables, moderators, v_matrices, control_params)

# View results
print(moderator_results_mv)
```


```{r}
# Define significance threshold (adjustable)
p_value_threshold <- 0.05

# Filter only significant moderators (both individual & interactions)
significant_moderator_res <- moderator_results_mv %>%
  filter(P_Value < p_value_threshold)

# # Display summary
# significant_moderator_res |> glimpse()
# significant_moderator_res

# Rename Moderators and Terms for Clarity
significant_moderator_res_clean <- significant_moderator_res %>%
  # Rename Moderators
  mutate(
    Moderator = case_when(
      Moderator == "tree_type"          ~ "Tree Type",
      Moderator == "crop_type"          ~ "Crop Type",
      Moderator == "age_system"         ~ "Age System",
      Moderator == "season"             ~ "Season",
      Moderator == "soil_texture"       ~ "Soil Texture",
      Moderator == "no_tree_per_m"      ~ "Tree Density",
      Moderator == "tree_height"        ~ "Tree Height",
      Moderator == "alley_width"        ~ "Alley Width",
      TRUE                              ~ Moderator  # Keep unchanged if not listed
    ),

    # Rename Terms (Main Effects)
    Term = case_when(
      Term == "age_systemMedium"         ~ "Medium Age System",
      Term == "age_systemYoung"          ~ "Young Age System",
      Term == "age_systemMature"         ~ "Mature Age System",
      Term == "seasonSummer"             ~ "Summer Season",
      Term == "seasonWinter"             ~ "Winter Season",
      Term == "no_tree_per_mLow"         ~ "Low Tree Density",
      Term == "no_tree_per_mHigh"        ~ "High Tree Density",
      Term == "tree_typeFruit,nut & other" ~ "Fruit/Nut Trees",
      Term == "tree_typeBiomass"         ~ "Biomass Trees",
      Term == "tree_typeTimber"          ~ "Timber Trees",
      Term == "crop_typeLegume"          ~ "Legume Crops",
      Term == "crop_typeCereal"          ~ "Cereal Crops",
      Term == "crop_typeTuber,root and other" ~ "Root/Tuber Crops",
      Term == "soil_textureSand"         ~ "Sandy Soil",
      Term == "soil_textureSilt"         ~ "Silty Soil",
      Term == "soil_textureClay"         ~ "Clayey Soil",
      Term == "tree_heightShort"         ~ "Short Trees",
      Term == "tree_heightTall"          ~ "Tall Trees",
      Term == "alley_widthNarrow"        ~ "Narrow Alleys",
      Term == "alley_widthWide"          ~ "Wide Alleys",
      TRUE                               ~ Term  # Keep unchanged if not listed
    ),

    # Rename Interaction Terms (Format: "Moderator A x Moderator B")
    Term = ifelse(
      str_detect(Term, ":"), 
      str_replace_all(Term, c(
        "tree_type"        = "Tree Type",
        "crop_type"        = "Crop Type",
        "age_system"       = "Age System",
        "season"           = "Season",
        "soil_texture"     = "Soil Texture",
        "no_tree_per_m"    = "Tree Density",
        "tree_height"      = "Tree Height",
        "alley_width"      = "Alley Width",
        ":"                = " x "  # Replace ":" with " x " for interaction formatting
      )),
      Term
    ),

    # Explicitly Rename Intercept Terms
    Term = ifelse(str_detect(Term, "intrcpt"), "Intercept", Term)
  ) |> 
  # Remove observations with Intercept category for the significant moderators before forest plot
  filter(Term != "Intercept")



# Display summary
significant_moderator_res_clean |> glimpse()
significant_moderator_res_clean
```

```{r}
create_forest_plot <- function(data, response_var, x_limits = c(-1, 2)) {
  
  # Ensure order of moderators
  data <- data %>%
    mutate(Moderator = fct_reorder(Term, Estimate))  # Reorder moderators by effect size
  
  # Create Forest Plot
  forest_plot <- ggplot(data, aes(x = Estimate, y = Moderator, color = Type)) +
    
    # Error bars for confidence intervals
    geom_errorbarh(aes(xmin = CI_Lower, xmax = CI_Upper), height = 0.2, size = 1) +
    
    # Points for effect sizes
    geom_point(size = 3) +
    
    # Vertical reference line at zero
    geom_vline(xintercept = 0, linetype = "dashed", color = "red", size = 0.8) +
    
    # Facet by Response Variable
    facet_wrap(~ ResponseVariable, scales = "free_y") +
    
    # Labels & Theme
    labs(
      title = paste("Forest Plot for", response_var),
      x = "Effect Size",
      y = "Moderators",
      color = "Model Type"
    ) +
    
    # Set x-axis limits
    scale_x_continuous(limits = x_limits) +
    
    # Color scheme
    scale_color_manual(values = c("Individual" = "blue", "Interaction" = "purple")) +
    
    theme_minimal() +
    theme(
      strip.text = element_text(size = 12, face = "bold"),
      axis.text.y = element_text(size = 10),
      axis.text.x = element_text(size = 10),
      legend.position = "top",
      legend.text = element_text(size = 12),
      legend.title = element_text(size = 13)
    )
  
  return(forest_plot)
}
```

```{r}
# Create a list of plots for each response variable
forest_plots_list <- list()

for (response in unique(significant_moderator_res_clean$ResponseVariable)) {
  plot_data <- significant_moderator_res_clean %>% filter(ResponseVariable == response)
  
  if (nrow(plot_data) > 0) {
    forest_plot <- create_forest_plot(plot_data, response)
    forest_plots_list[[response]] <- forest_plot
  }
}

# Combine all plots into one figure
final_forest_plot <- wrap_plots(forest_plots_list) +
  plot_annotation(title = "Forest Plots of Significant Moderator Effects")

# Display the combined plot
final_forest_plot

# Save plot as image
# ggsave("forest_plots_significant_moderators.png", final_forest_plot, width = 12, height = 8, dpi = 300)
```



# STEP 7 FOREST PLOT FOR VISUALIZING META-ANALYSIS RESULTS 

OBS: To see the final forest plot (violin plot) of overall effect sizes for all response variables see script "5_FINAL_VISUALIZATIONS"

```{r}
##########################################################################################################################################
# DATA PREP FOR FOREST PLOTS 
##########################################################################################################################################

# Debugging: Inspect the structure of model_results
# print("Inspecting model_results:")
# str(model_results)
# Generic Function to Extract Relevant Data for Forest Plots
# Generic Function to Extract Relevant Data for Forest Plots

extract_forest_plot_data <- function(model_results) {
  forest_data_list <- list() # Initialize list

  for (response in names(model_results)) {
    # Selecting model
    model <- model_results[[response]]$base_model

    if (is.null(model)) {
      message(paste("No model found for", response))
      next
    }

    tryCatch({
      effect_sizes <- model$yi  # Extract effect sizes
      variances <- model$vi    # Extract variances

      # Match labels (id_obs) to valid rows in the model
      valid_rows <- model$data[model$not.na, ]  # Subset retained rows
      labels <- valid_rows$id_obs  # Extract labels corresponding to valid rows

      # Check for length alignment
      if (length(effect_sizes) != length(variances) || length(effect_sizes) != length(labels)) {
        stop(paste("Mismatch in data dimensions for", response))
      }

      # Create the data frame
      forest_data <- data.frame(
        Study = labels,
        EffectSize = effect_sizes,
        Variance = variances,
        ResponseVariable = response
      )

      forest_data_list[[response]] <- forest_data # Store in the list
    }, error = function(e) {
      message(paste("Error extracting data for", response, ":", e$message))
    })
  }

  return(forest_data_list) # Return list of data frames
}



# Example usage with model_results
forest_plot_data <- extract_forest_plot_data(model_results)
forest_plot_data
# Print the structure of the extracted data
# str(forest_plot_data)
```

```{r}
##########################################################################################################################################
# FOREST PLOTS 
##########################################################################################################################################

# Function to create a forest plot for a given response variable
create_forest_plot <- function(data, response_variable, output_path = NULL) {
  # Filter data for the selected response variable
  plot_data <- data[[response_variable]]
  
  if (is.null(plot_data)) {
    stop(paste("No data found for", response_variable))
  }
  
  # Calculate confidence intervals
  plot_data <- plot_data %>%
    mutate(
      CI_lower = EffectSize - 1.96 * sqrt(Variance),
      CI_upper = EffectSize + 1.96 * sqrt(Variance)
    )
  
  # Create the forest plot
  forest_plot <- ggplot(plot_data, aes(x = EffectSize, y = reorder(Study, EffectSize))) +
    geom_point(size = 3, color = "blue") +  # Effect size points
    geom_errorbarh(aes(xmin = CI_lower, xmax = CI_upper), height = 0.2, color = "gray") +  # Error bars
    theme_minimal() +
    labs(
      title = paste("Forest Plot for", response_variable),
      x = "Effect Size (with 95% CI)",
      y = "Study",
      caption = "Note: Horizontal bars indicate 95% confidence intervals."
    ) +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.text.y = element_text(size = 10),
      axis.text.x = element_text(size = 10),
      axis.title = element_text(size = 12),
      plot.caption = element_text(size = 9, face = "italic")
    )
  
  # Display the plot
  print(forest_plot)
  
  # Save the plot to file if output_path is provided
  if (!is.null(output_path)) {
    ggsave(output_path, plot = forest_plot, width = 10, height = 8)
  }
}

# Example usage:
# Generate a forest plot for "Biodiversity" and save it
create_forest_plot(forest_plot_data, "Biodiversity", output_path = "Biodiversity_Forest_Plot.png")

# Generate a forest plot for "Crop yield" and display it
create_forest_plot(forest_plot_data, "Crop yield")
```



OBS

THE FINAL FOREST PLOT AND CONFIDENCE INTERVALS ARE PREPARED IN THE 5_FINAL_VISUALIISATIONS.Rmd SCRIPT
The forest plots provide a visual representation of the effect sizes and confidence intervals for each study within a meta-analysis. These plots are particularly useful for assessing the overall impact of a treatment or intervention across multiple studies and identifying potential sources of heterogeneity or bias.

