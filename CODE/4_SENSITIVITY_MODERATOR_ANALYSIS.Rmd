---
title: "4_SENSITIVITY_MODERATOR_ANALYSIS"
author: "M.K.K. Lindhardt"
date: "2024-11-17"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    skimr,            # Provides easy summary statistics about variables in data frames, tibbles, data tables and vectors
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    Matrix,           # Matrix operations
    progressr,
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    patchwork,        # ggplot2 API for sequentially building up a plot
    ###################################################################################################################
    # Spatial Data
    tidygeocoder,     # Unified interface for performing both forward and reverse geocoding queries
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    rnaturalearth,    # For world map data
    rnaturalearthdata, 
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("intersect", "base")
```


Loading the datasets

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())


# Define your working directory using 'here'
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load datasets 

## NON-IMPUTED
non_imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom.rds"))

## IMPUTED
imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))

```

```{r}
imp_dataset |> glimpse()
```

```{r}
# Check the unique response variables and sub-response variables
unique(imp_dataset$response_variable)
# unique(imp_dataset$sub_response_variable)
```
```{r}
response_summary <- 
  imp_dataset |> 
  count(response_variable) |> 
  arrange(desc(n))

# Bar plot for response variable counts
response_var_summary_plot <- 
  response_summary |> 
  ggplot(aes(x = reorder(response_variable, -n), y = n)) +
  geom_bar(stat = "identity", fill = "#0072B2") +
  coord_flip() +
  labs(title = "Count of Observations per Response Variable",
       x = "Response Variable",
       y = "Count of Observations") +
  theme_minimal()

response_var_summary_plot
```

```{r}
# Check the unique response variables and sub-response variables
unique_articles <- unique(imp_dataset$id_article)
unique_response_vars <- unique(imp_dataset$response_variable)

print(unique_response_vars)
print(length(unique_articles))  # Total number of unique articles

```

```{r}
# Count the number of unique articles for each response variable
article_summary <- imp_dataset %>%
  group_by(response_variable) %>%
  summarise(unique_articles = n_distinct(id_article)) %>%
  arrange(desc(unique_articles))

article_summary

```
```{r}
# Bar plot for unique article counts by response variable
article_summary_plot <-
  article_summary |> 
  ggplot(aes(x = reorder(response_variable, -unique_articles), y = unique_articles)) +
  geom_bar(stat = "identity", fill = "#E69F00") +
  coord_flip() +
  labs(title = "Count of Unique Articles per Response Variable",
       x = "Response Variable",
       y = "Number of Unique Articles") +
  theme_minimal()

article_summary_plot
```

```{r}
# Sample one observation per article per response variable
sampled_data <- imp_dataset %>%
  group_by(id_article, response_variable) %>%
  slice_head(n = 1)

sampled_data
```
```{r}
# Boxplot of effect sizes by response variable (unique articles)
boxplot_effec_size_response_variable <- sampled_data |> 
  ggplot(aes(x = response_variable, 
             y = yi, 
             fill = response_variable)) +
  geom_boxplot() +
  coord_flip() +
  labs(title = "Boxplot of Effect Sizes (yi) by Response Variable (Unique Articles)",
       x = "Response Variable",
       y = "Effect Size (yi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_effec_size_response_variable
```

The boxplot shows the distribution of effect sizes (yi) for each response variable. In the context of this meta-analysis, the effect size (yi) represents the standardized difference between the treatment group (agroforestry systems) and the control group (monoculture).

Biodiversity: the effect sizes are mostly positive, suggesting that agroforestry systems might have a higher effect on biodiversity compared to monoculture.
Crop Yield: the effect sizes are genrally negative, indicating potential yield reductions in agroforestry systems.
Soil Quality: tend to show positive effect sizes, suggesting an improvement in these aspects under agroforestry systems.
Product Quality: 
Pest and Diseases:
Greenhouse gas emissions:

The variation in the effect sizes for each response variable indicates heterogeneity, showing that the impact of agroforestry varies across different studies and contexts. However, the effect sizes in this plot do not account for potential study-level covariates or moderators, which could influence the observed differences. It will be important to consider the sampling variance (vi) associated with each effect size when interpreting these results, as larger studies (with smaller variance) provide more reliable estimates.





```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  )

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable")

# Plot histogram of effect sizes with additional improvements
ggplot(sampled_data, aes(x = yi, fill = response_variable)) +
  geom_histogram(binwidth = 0.05, alpha = 0.7, color = "black") +
  # mean yi line
  geom_vline(data = response_summary, aes(xintercept = mean_yi, color = response_variable),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ reorder(response_variable, -num_articles), scales = "free_y") +
  labs(
    title = "Distribution of Effect Sizes (yi) by Response Variable (Unique Articles)",
    x = "Effect Size (yi)",
    y = "Frequency"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  ) %>%
  arrange(desc(num_articles))

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable") %>%
  mutate(response_variable = factor(response_variable, levels = response_summary$response_variable))

# Reshape the data to long format for plotting
long_data <- sampled_data %>%
  select(id_article, response_variable, silvo_mean, control_mean) %>%
  pivot_longer(cols = c(silvo_mean, control_mean), 
               names_to = "group", 
               values_to = "mean_value") %>%
  mutate(group = recode(group, "silvo_mean" = "Silvo (Agroforestry)", "control_mean" = "Control (Monoculture)"))

# Calculate mean values for each group and response variable
group_summary <- long_data %>%
  group_by(response_variable, group) %>%
  summarise(
    mean_value = mean(mean_value, na.rm = TRUE),
    .groups = "drop"
  )


# Plot the distribution of mean values for Silvo and Control groups with free x-scales
ggplot(long_data, aes(x = mean_value, fill = group)) +
  geom_histogram(binwidth = 5, alpha = 0.7, color = "black", position = "identity") +
  geom_vline(data = group_summary, aes(xintercept = mean_value, color = group),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ response_variable, scales = "free_x") +  # Set scales to "free_x"
  labs(
    title = "Distribution of Mean Values for Silvo (Agroforestry) and Control (Monoculture)",
    x = "Mean Value",
    y = "Frequency"
  ) +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  scale_color_manual(values = c("#0072B2", "#D55E00")) +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# List of response variables and moderators
response_variables <- c("Biodiversity", "Crop yield", "Water quality", "Pest and Disease", 
                        "Soil quality", "Greenhouse gas emission", "Product quality")

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")
```

```{r}
# Define a generic function for counting unique values
count_unique_response_and_moderator <- function(data, response_col, moderators) {
  
  # Count of unique response variables for each moderator
  unique_response_var_per_moderator <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(moderator) %>%
    summarise(unique_responses = n_distinct(.data[[response_col]]), .groups = "drop")

  # Count of unique moderator levels for each response variable
  unique_moderators_per_response_var <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(.data[[response_col]]) %>%
    summarise(unique_moderators = n_distinct(moderator_value), .groups = "drop")

  # Return both summaries as a list
  list(
    unique_response_var_per_moderator = unique_response_var_per_moderator,
    unique_moderators_per_response_var = unique_moderators_per_response_var
  )
}

```

```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Apply the function to the non-imputed dataset
non_imp_summary <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Apply the function to the imputed dataset
imp_summary <- count_unique_response_and_moderator(imp_dataset, response_col, moderators)

# View the summaries
print(non_imp_summary$unique_response_var_per_moderator)
print(non_imp_summary$unique_moderators_per_response_var)

print(imp_summary$unique_response_var_per_moderator)
print(imp_summary$unique_moderators_per_response_var)

```


Visualize the Summary Data

Plot 1: Number of Unique Response Variables per Moderator
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Generate the summaries using the function
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_response_var_per_moderator <- results$unique_response_var_per_moderator

# Bar plot for unique response variables per moderator
unique_response_var_per_moderator |> 
  ggplot(aes(x = reorder(moderator, unique_responses), y = unique_responses, fill = moderator)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Response Variables per Moderator",
    x = "Moderator",
    y = "Number of Unique Response Variables"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  theme(legend.position = "none")

```


Plot 2: Number of Unique Moderators per Response Variable
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Generate summaries
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_moderators_per_response_var <- results$unique_moderators_per_response_var


# Bar plot for unique moderators per response variable
unique_moderators_per_response_var |> 
  ggplot(aes(x = reorder(response_variable, unique_moderators), y = unique_moderators, fill = response_variable)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Moderators per Response Variable",
    x = "Response Variable",
    y = "Number of Unique Moderator Levels"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

Alternative Visualization: Heatmap
comprehensive view of the data in a heatmap to show the interaction between moderators and response variables

```{r}
# Create a heatmap data frame
heatmap_data <- non_imp_dataset %>%
  select(response_variable, all_of(moderators)) %>%
  pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
  filter(!is.na(moderator_value)) %>%
  group_by(response_variable, moderator) %>%
  summarise(count = n_distinct(moderator_value), .groups = "drop")

# Heatmap plot
ggplot(heatmap_data, aes(x = moderator, y = response_variable, fill = count)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(
    title = "Heatmap of Unique Moderator Levels by Response Variable",
    x = "Moderator",
    y = "Response Variable",
    fill = "Count of Unique Levels"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```

















To make the meta-analysis more robust and comparable to the approach taken in the cabbage meta-analysis, its important to consider the following key steps to  address study heterogeneity, incorporate important moderators, and validate your findings in a rigorous manner. 

Outline based on the cabbage meta-analysis methodology:
Identify Key Moderators:
Conduct Subgroup Analysis:
Include Moderators in a Meta-Regression Model:
Assess Model Fit and Heterogeneity:
Check for Multicollinearity Among Moderators:
Leave-One-Out Sensitivity Analysis:
Publication Bias Assessment:
Visualize the Results:

Refined Plan for Moderator Analysis in the Meta-Analysis

Split the data by response variable (ecosystem service).
Recalculate the V_matrix for each subset, using robust variance estimation if needed.
Conduct moderator analysis (both subgroup analysis and meta-regression) within each ecosystem service subset.
Include heterogeneity diagnostics and sensitivity analysis (e.g., leave-one-out analysis).
Explore additional study-level covariates in the meta-regression models.


#############
# STEP 1
##########################################################################################################################################
SPLIT DATA BY RESPONSE VARIABLE
##########################################################################################################################################

Split by Response Variable (Ecosystem Service)

Split the data by response variable (ecosystem service).
Generate new variance-covariance matrices (V_matrix) for each subset.
Conduct moderator analysis within each ecosystem service subset, examining how each moderator affects the effect size.

Split Data by Response Variable

```{r}
# Define response variables (ecosystem services)
response_variables <- c("Biodiversity", 
                        "Crop yield", 
                        "Water quality", 
                        "Pest and Disease", 
                        "Soil quality", 
                        "Greenhouse gas emission", 
                        "Product quality"
                        )

# Define moderators
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")
```

```{r}
# Function to split dataset by response variable
split_data_by_response <- function(data, response_var) {
  cat("\nSplitting dataset by response variable:", response_var, "\n")
  subset(data, response_variable == response_var)
}

# Split non-imputed and imputed datasets by response variable
response_splits <- list(
  non_imp = lapply(response_variables, split_data_by_response, data = non_imp_dataset),
  imp = lapply(response_variables, split_data_by_response, data = imp_dataset)
)

# Name the lists by response variables
names(response_splits$non_imp) <- response_variables
names(response_splits$imp) <- response_variables

```



#############
# STEP 2
##########################################################################################################################################
RE-CALCULATE VARIANCE-CO-VARIANCE MATRICES
##########################################################################################################################################

Recalculate Variance-Covariance Matrices (V_matrix)

```{r}
# source("path/to/function/calculate_v_matrix.R")
calculate_v_matrix <- function(data, correlation = 0.5) {
  cat("Calculating variance-covariance matrix...\n")
  
  # Check if 'yi' and 'vi' columns exist
  if (!("yi" %in% colnames(data)) || !("vi" %in% colnames(data))) {
    stop("Data must contain 'yi' (effect size) and 'vi' (variance) columns.")
  }

  # Extract variances
  variances <- data$vi
  n <- length(variances)

  # Create a correlation matrix
  correlation_matrix <- matrix(correlation, nrow = n, ncol = n)
  diag(correlation_matrix) <- 1  # Set diagonal elements to 1

  # Calculate the variance-covariance matrix
  v_matrix <- outer(variances, variances) * correlation_matrix
  rownames(v_matrix) <- rownames(data)
  colnames(v_matrix) <- rownames(data)

  return(v_matrix)
}


# Function to calculate V_matrix with robust estimation
calculate_v_matrix_for_subset <- function(data, correlation = 0.5) {
  if (nrow(data) > 1) {
    cat("Calculating V_matrix for subset with robust estimation...\n")
    tryCatch({
      calculate_v_matrix(data, correlation = correlation)
    }, error = function(e) {
      cat("Error in V_matrix calculation:", e$message, "\n")
      return(NULL)
    })
  } else {
    cat("Insufficient data points. Skipping V_matrix calculation.\n")
    NULL
  }
}
```

```{r}
# Generate V_matrices for each response subset
v_matrices <- list(
  v_matrix_non_imp = lapply(response_splits$non_imp, calculate_v_matrix_for_subset),
  v_matrix_imp = lapply(response_splits$imp, calculate_v_matrix_for_subset)
)

# Name the V_matrices by response variables
names(v_matrices$v_matrix_non_imp) <- response_variables
names(v_matrices$v_matrix_imp) <- response_variables
```


Checking v_matrices

```{r}
# Function to print a random sample of the variance-covariance matrix
print_sample_v_matrix <- function(v_matrices, n = 5) {
  # Loop through each response variable
  for (response_var in names(v_matrices)) {
    cat("\n*** Checking V_matrix for:", response_var, "***\n")
    
    # Get the V_matrix for the current response variable
    v_matrix <- v_matrices[[response_var]]
    
    # Check if the V_matrix exists and is not NULL
    if (is.null(v_matrix)) {
      cat("V_matrix is NULL. Skipping...\n")
      next
    }
    
    # Ensure that the matrix is large enough for sampling
    if (nrow(v_matrix) < n || ncol(v_matrix) < n) {
      cat("V_matrix is too small for sampling. Displaying full matrix instead:\n")
      print(v_matrix)
    } else {
      # Randomly select 'n' rows and columns to print a submatrix
      random_indices <- sample(1:nrow(v_matrix), n)
      sampled_v_matrix <- v_matrix[random_indices, random_indices]
      
      # Print the sampled submatrix
      cat("Sampled V_matrix (first", n, "rows and columns):\n")
      print(sampled_v_matrix)
    }
  }
}

# Example usage with your V_matrices
cat("\nNon-Imputed Dataset:\n")
print_sample_v_matrix(v_matrices$v_matrix_non_imp, n = 5)

cat("\nImputed Dataset:\n")
print_sample_v_matrix(v_matrices$v_matrix_imp, n = 5)
```

```{r}
# Function to check data quality
inspect_data <- function(data, moderator) {
  summary_stats <- data %>%
    group_by(!!sym(moderator)) %>%
    summarise(
      n = n(),
      unique_ids = n_distinct(id_article),
      var_yi = var(yi, na.rm = TRUE)
    )
  print(summary_stats)
}

# Inspect data for a specific response variable and moderator
inspect_data(response_splits$imp[["Biodiversity"]], "tree_type")
inspect_data(response_splits$imp[["Crop yield"]], "tree_type")
inspect_data(response_splits$imp[["Soil quality"]], "tree_type")
```

```{r}
# Helper function to filter out single-level factors

# Enhanced helper function to filter out unsuitable data for meta-regression
filter_data_for_moderator_analysis <- function(data, moderators) {
  # Ensure `yi` and `vi` are included and remove single-level factors
  filtered_data <- data %>%
    select(yi, vi, response_variable, id_article, exp_id, all_of(moderators)) %>%
    filter(n_distinct(id_article) > 1)
  
  # Check each moderator and keep only those with at least two distinct levels
  valid_moderators <- moderators[sapply(moderators, function(mod) {
    n_distinct(filtered_data[[mod]], na.rm = TRUE) > 1
  })]

  # Remove rows with missing values for valid moderators
  filtered_data <- filtered_data %>%
    select(yi, vi, response_variable, id_article, exp_id, all_of(valid_moderators)) %>%
    drop_na()

  # Return the filtered data and the list of valid moderators
  list(data = filtered_data, valid_moderators = valid_moderators)
}
```


#############
# STEP 3
##########################################################################################################################################
PERFORM MODERATOR ANALYSIS FOR SUBGROUPS AND THEN INCLUDE IN GENERAL META-REGRESSION
##########################################################################################################################################

```{r}
# Helper function to align data and V_matrix
align_data_and_v_matrix <- function(data, V_matrix) {
  common_ids <- intersect(rownames(data), rownames(V_matrix))
  if (length(common_ids) < 2) {
    cat("Warning: Too few common rownames between data and V_matrix. Skipping analysis.\n")
    return(NULL)
  }
  data <- data[common_ids, , drop = FALSE]
  V_matrix <- V_matrix[common_ids, common_ids, drop = FALSE]
  return(list(data = data, V_matrix = V_matrix))
}

# Helper function to filter moderators with at least two levels
filter_valid_moderators <- function(data, moderators) {
  valid_moderators <- sapply(moderators, function(moderator) {
    n_distinct(data[[moderator]]) > 1
  })
  return(moderators[valid_moderators])
}
```

```{r}
# Function for subgroup analysis
run_subgroup_analysis <- function(data, moderator) {
  if (n_distinct(data[[moderator]]) < 2) {
    cat("Insufficient levels for moderator:", moderator, "\n")
    return(NULL)
  }
  
  subgroup_summary <- data %>%
    group_by(!!sym(moderator)) %>%
    summarise(
      mean_yi = mean(yi, na.rm = TRUE),
      ci_low = mean_yi - 1.96 * sd(yi) / sqrt(n()),
      ci_high = mean_yi + 1.96 * sd(yi) / sqrt(n())
    )
  
  print(subgroup_summary)
  return(subgroup_summary)
}
```

```{r}
# Function for meta-regression analysis
run_meta_regression <- function(data, V_matrix, moderator) {
  cat("\nAnalyzing moderator:", moderator, "\n")
  if (n_distinct(data[[moderator]]) < 2) {
    cat("Insufficient levels for moderator:", moderator, "\n")
    return(NULL)
  }
  
  tryCatch({
    model <- rma.mv(
      yi = yi,
      V = V_matrix,
      mods = as.formula(paste("~", moderator)),
      random = list(~ 1 | id_article, ~ 1 | id_article/response_variable),
      data = data,
      method = "REML"
    )
    print(summary(model))
    return(model)
  }, error = function(e) {
    cat("Error in meta-regression for moderator:", moderator, "-", e$message, "\n")
    return(NULL)
  })
}
```

```{r}
# List to store results
moderator_results <- list()

# Loop through response variables
for (response_var in response_variables) {
  cat("\nAnalyzing response variable:", response_var, "\n")
  
  # Get the subset and corresponding V_matrix
  data_subset <- response_splits$imp[[response_var]]
  V_matrix <- v_matrices$v_matrix_imp[[response_var]]
  
  # Align data and V_matrix
  aligned_data <- align_data_and_v_matrix(data_subset, V_matrix)
  if (is.null(aligned_data)) next
  
  data_subset <- aligned_data$data
  V_matrix <- aligned_data$V_matrix
  
  # Filter valid moderators
  valid_moderators <- filter_valid_moderators(data_subset, moderators)
  if (length(valid_moderators) == 0) {
    cat("No valid moderators for analysis. Skipping...\n")
    next
  }
  
  # Perform subgroup and meta-regression analysis
  response_results <- list()
  for (moderator in valid_moderators) {
    subgroup_result <- run_subgroup_analysis(data_subset, moderator)
    meta_regression_result <- run_meta_regression(data_subset, V_matrix, moderator)
    response_results[[moderator]] <- list(
      subgroup = subgroup_result,
      meta_regression = meta_regression_result
    )
  }
  
  moderator_results[[response_var]] <- response_results
}

##############################################################################
# Save the moderator results
# Define output directory using 'here'
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")
# Create the output directory if it doesn't exist
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}
# Define the file path for saving the results
output_file <- file.path(output_dir, "moderator_analysis_results.rds")
# Save the moderator results
saveRDS(moderator_results, file = output_file)
cat("Moderator analysis results saved to:", output_file, "\n")
```

##########################################################################################################################################
Check moderator analysis results
##########################################################################################################################################

Next Steps: Reporting
Once you have inspected the results, performed heterogeneity diagnostics, and completed sensitivity analyses, you can proceed to:

Summarize your findings, including which moderators showed significant effects and the overall heterogeneity (I²).
Interpret the results in the context of the agroforestry studies and compare with the findings from the cabbage meta-analysis.
Consider any additional analyses or data adjustments based on the outcomes of the sensitivity checks.


1. Inspect the Output

```{r}
# Load the results if not already loaded
# moderator_results <- readRDS(file.path(output_dir, "moderator_analysis_results.rds"))

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################


# Quick overview of the structure
# str(moderator_results)

# Function to check which analyses were successful
check_results <- function(results) {
  successful_analyses <- list()
  
  for (response_var in names(results)) {
    cat("\nResponse Variable:", response_var, "\n")
    response_results <- results[[response_var]]
    
    for (moderator in names(response_results)) {
      cat("Moderator:", moderator, "\n")
      
      subgroup <- response_results[[moderator]]$subgroup
      meta_regression <- response_results[[moderator]]$meta_regression
      
      if (!is.null(subgroup)) {
        cat("  Subgroup Analysis: Successful\n")
        successful_analyses[[response_var]][[moderator]]$subgroup <- "Successful"
      } else {
        cat("  Subgroup Analysis: Failed\n")
      }
      
      if (!is.null(meta_regression)) {
        cat("  Meta-Regression: Successful\n")
        successful_analyses[[response_var]][[moderator]]$meta_regression <- "Successful"
      } else {
        cat("  Meta-Regression: Failed\n")
      }
    }
  }
  return(successful_analyses)
}

##################################################
# End time tracking
end.time <- Sys.time()
# Calculate time taken
time.taken <- end.time - start.time
time.taken
##############################################################
# Last go: (17/11-24)
# Time difference of 0.2157011 secs

##############################################################
# Check the results
successful_analyses <- check_results(moderator_results)
# print(successful_analyses)
```

```{r}
# Function to extract successful subgroup analysis
extract_successful <- function(results) {
  data_frame <- list()
  for (response in names(results)) {
    for (moderator in names(results[[response]])) {
      if (!is.null(results[[response]][[moderator]]$subgroup) &&
          results[[response]][[moderator]]$subgroup == "Successful") {
        data_frame <- append(
          data_frame,
          list(data.frame(response_variable = response, moderator = moderator, status = "Successful"))
        )
      }
    }
  }
  bind_rows(data_frame)
}

# Create a data frame of successful analyses
success_df <- extract_successful(successful_analyses)
```

```{r}
# Plot the heatmap
success_df |> 
  ggplot(aes(x = moderator, y = response_variable, fill = status)) +
  geom_tile(color = "white") +
  scale_fill_manual(values = c("Successful" = "#1b9e77", "Unsuccessful" = "#d95f02"), na.value = "grey80") +
  labs(
    title = "Summary of Successful Subgroup Analyses",
    x = "Moderator",
    y = "Response Variable",
    fill = "Analysis Status"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )
```
```{r}
# Count the number of successful analyses per response variable
success_count <- success_df %>%
  count(response_variable)

# Bar plot of successful analyses
success_count |> 
  ggplot(aes(x = reorder(response_variable, n), y = n, fill = response_variable)) +
  geom_col() +
  coord_flip() +
  labs(
    title = "Number of Successful Subgroup Analyses per Response Variable",
    x = "Response Variable",
    y = "Count of Successful Analyses"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal()

```


############
# STEP 4
##########################################################################################################################################
HETEROGENITY DIAGNOSTICS
##########################################################################################################################################

Heterogeneity Diagnostics and Sensitivity Analysis

```{r}
# Function to calculate I² statistic for meta-regression models
calculate_I2 <- function(model) {
  if (!is.null(model)) {
    tau2 <- model$tau2
    sigma2 <- model$sigma2
    I2 <- 100 * (tau2 / (tau2 + sigma2))
    return(round(I2, 2))
  } else {
    return(NA)
  }
}

# Iterate through results and calculate I²
I2_diagnostics <- list()

for (response_var in names(moderator_results)) {
  response_results <- moderator_results[[response_var]]
  
  I2_diagnostics[[response_var]] <- list()
  
  for (moderator in names(response_results)) {
    meta_regression <- response_results[[moderator]]$meta_regression
    
    if (!is.null(meta_regression)) {
      I2_stat <- calculate_I2(meta_regression)
      I2_diagnostics[[response_var]][[moderator]] <- I2_stat
      cat("I² for", response_var, "and", moderator, ":", I2_stat, "%\n")
    }
  }
}

# Print the heterogeneity diagnostics
I2_diagnostics
```

Many/all moderator analyses resulted in NaN values for the heterogeneity statistic (I²), which is often due to issues such as:

Insufficient Data: When the sample size for certain subgroups is too low, the variance components cannot be estimated properly.
Zero Between-Study Variance (tau2): If there is no detected between-study variance, I² becomes zero, which might be misleading.
V_matrix Issues: Problems like non-positive definite matrices can affect the calculation of heterogeneity statistics.



############
# STEP 5
##########################################################################################################################################
ADDITIONAL MODEL COMPARISON AND DIAGNOSTICS
##########################################################################################################################################

Extract Model Fit Statistics

```{r}
# Helper function to extract model diagnostics
extract_model_diagnostics <- function(model) {
  if (!is.null(model)) {
    AIC_value <- AIC(model)
    BIC_value <- BIC(model)
    logLik_value <- logLik(model)
    k_all <- model$k.all  # Total number of studies included
    QM <- model$QM        # Omnibus test for moderators
    pval_QM <- model$pval.QM

    list(
      AIC = AIC_value,
      BIC = BIC_value,
      LogLik = logLik_value,
      k_all = k_all,
      QM = QM,
      pval_QM = pval_QM
    )
  } else {
    NULL
  }
}

# Extract diagnostics for each model
model_diagnostics <- lapply(moderator_results, function(response_result) {
  lapply(response_result, function(mod_result) {
    if (!is.null(mod_result$meta_regression)) {
      extract_model_diagnostics(mod_result$meta_regression)
    } else {
      NULL
    }
  })
})

# Print a summary of the model diagnostics
# print(model_diagnostics)


# Helper function to filter non-NULL diagnostics
filter_meaningful_diagnostics <- function(diagnostics) {
  meaningful_results <- list()

  for (response_var in names(diagnostics)) {
    response_results <- diagnostics[[response_var]]
    valid_results <- list()

    for (moderator in names(response_results)) {
      if (!is.null(response_results[[moderator]])) {
        valid_results[[moderator]] <- response_results[[moderator]]
      }
    }

    if (length(valid_results) > 0) {
      meaningful_results[[response_var]] <- valid_results
    }
  }

  return(meaningful_results)
}

# Apply the function to filter the model diagnostics
filtered_diagnostics <- filter_meaningful_diagnostics(model_diagnostics)

# Print the filtered diagnostics
print(filtered_diagnostics)

```
```{r}
# Convert the filtered diagnostics to a tidy data frame for visualization
extract_diagnostics_df <- function(filtered_diagnostics) {
  diagnostics_list <- list()

  for (response_var in names(filtered_diagnostics)) {
    for (moderator in names(filtered_diagnostics[[response_var]])) {
      diag <- filtered_diagnostics[[response_var]][[moderator]]
      if (!is.null(diag)) {
        diagnostics_list <- append(diagnostics_list, list(
          data.frame(
            Response = response_var,
            Moderator = moderator,
            AIC = diag$AIC,
            BIC = diag$BIC,
            LogLik = as.numeric(diag$LogLik),
            k_all = diag$k_all,
            QM = diag$QM
          )
        ))
      }
    }
  }

  return(do.call(rbind, diagnostics_list))
}

# Create a data frame for visualization
diagnostics_df <- extract_diagnostics_df(filtered_diagnostics)

# Plot AIC and BIC values
ggplot(diagnostics_df, aes(x = Moderator, y = AIC, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "AIC Values by Moderator and Response Variable",
       x = "Moderator", y = "AIC") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot number of studies (k_all) for each analysis
ggplot(diagnostics_df, aes(x = Moderator, y = k_all, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Number of Studies (k_all) by Moderator and Response Variable",
       x = "Moderator", y = "Number of Studies") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Assessing Diagnostics Across Response Variables

```{r}
# Function to extract diagnostics for both moderators and response variables
extract_diagnostics_df <- function(filtered_diagnostics) {
  diagnostics_list <- list()

  for (response_var in names(filtered_diagnostics)) {
    for (moderator in names(filtered_diagnostics[[response_var]])) {
      diag <- filtered_diagnostics[[response_var]][[moderator]]
      if (!is.null(diag) && !is.na(diag$AIC)) { # Filter out missing diagnostics
        diagnostics_list <- append(diagnostics_list, list(
          data.frame(
            Response = response_var,
            Moderator = moderator,
            AIC = diag$AIC,
            BIC = diag$BIC,
            LogLik = as.numeric(diag$LogLik),
            k_all = diag$k_all,
            QM = diag$QM,
            I2 = ifelse(!is.null(diag$I2), diag$I2, NA)
          )
        ))
      }
    }
  }

  return(do.call(rbind, diagnostics_list))
}

# Create a data frame for diagnostics
diagnostics_df <- extract_diagnostics_df(filtered_diagnostics)

# Check the structure of the data frame
str(diagnostics_df)

```

Plotting AIC and BIC by Response Variable

```{r}
# AIC values by Response and Moderator
ggplot(diagnostics_df, aes(x = Moderator, y = AIC, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "AIC Values by Moderator and Response Variable",
       x = "Moderator", y = "AIC") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plotting Number of Studies (k_all)

```{r}
# Number of Studies (k_all) by Response and Moderator
ggplot(diagnostics_df, aes(x = Moderator, y = k_all, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Number of Studies (k_all) by Moderator and Response Variable",
       x = "Moderator", y = "Number of Studies") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plotting I² Heterogeneity Statistics

```{r}
# I² Statistics by Response and Moderator
ggplot(diagnostics_df, aes(x = Moderator, y = I2, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "I² Heterogeneity Statistics by Moderator and Response Variable",
       x = "Moderator", y = "I² (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Plotting Log-Likelihood Values

```{r}
# Log-Likelihood by Response and Moderator
ggplot(diagnostics_df, aes(x = Moderator, y = LogLik, fill = Response)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Log-Likelihood by Moderator and Response Variable",
       x = "Moderator", y = "Log-Likelihood") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```





Check Fixed Effects Estimates

```{r}
# Function to extract fixed effects estimates
extract_fixed_effects <- function(model) {
  if (!is.null(model)) {
    coef_table <- summary(model)$b
    ci_lower <- summary(model)$ci.lb
    ci_upper <- summary(model)$ci.ub
    p_values <- summary(model)$pval

    data.frame(
      Estimate = coef_table,
      CI_Lower = ci_lower,
      CI_Upper = ci_upper,
      P_Value = p_values
    )
  } else {
    NULL
  }
}

# Extract fixed effects for each model
fixed_effects_summary <- lapply(moderator_results, function(response_result) {
  lapply(response_result, function(mod_result) {
    if (!is.null(mod_result$meta_regression)) {
      extract_fixed_effects(mod_result$meta_regression)
    } else {
      NULL
    }
  })
})

# Print the fixed effects estimates
print(fixed_effects_summary)
```


############
# STEP 6
##########################################################################################################################################
SENSITIVITY ANALYSIS (Leave-One-Out Sensitivity Analysis)
##########################################################################################################################################

non_imp_dataset 
imp_dataset 



Performing a Leave-One-Out (LOO) sensitivity analysis on the full datasets and full model can be justified. This analysis would complement the LOO performed on each individual meta-regression model and provide additional insights. Here’s a detailed explanation:

Justification for LOO Sensitivity Analysis on Full Model
Assess Overall Model Robustness:

Applying LOO sensitivity analysis to the full model allows you to evaluate the robustness of the overall meta-analytic findings. It helps identify if specific studies have a disproportionate influence on the aggregated results.
This is particularly useful when you have concerns about the quality or heterogeneity of the included studies. If the removal of a single study drastically changes the overall effect size or model fit, this study might need further investigation.
Comparison Between Datasets (Imputed vs Non-Imputed):

Conducting LOO on both non_imp_dataset and imp_dataset allows you to compare the stability of the results between datasets with and without imputation.
It helps validate the imputation process by checking whether imputed data introduces or mitigates influential observations.
Insights Across All Moderators:

The LOO analysis on individual meta-regression models examines the impact of leaving out observations within each moderator level. However, performing LOO on the full model assesses the overall influence of each study across all moderators combined.
This provides a broader view of the dataset and highlights influential studies that might not be detected when focusing only on specific moderators.
Pros and Cons of LOO on the Full Model
Pros:
Comprehensive Sensitivity Check: It provides a complete picture of the influence of each study across the entire dataset.
Validation of Imputed Data: It allows you to test the robustness of results obtained from imputed datasets, helping ensure that imputation did not introduce bias.
Identification of Influential Studies: It can detect influential studies that have a large impact on the overall meta-analytic effect size or variance components.
Cons:
Computational Intensity: The LOO analysis on the full model can be computationally expensive, especially with large datasets and complex random-effects structures.
Potential Overlap: If individual meta-regression models are already analyzed with LOO, the full-model LOO might yield redundant information. However, this risk is mitigated by focusing on the broader dataset perspective.
Complex Interpretation: If a study is found to be influential in the full model LOO but not in specific meta-regression models, interpretation can be challenging. It may indicate complex interactions or issues with the overall model specification.
Implementation Plan
You can implement the LOO sensitivity analysis on the full model using both imputed and non-imputed datasets. Here’s how to proceed:

Fit the Full Model on each dataset (non_imp_dataset, imp_dataset, non_imp_dataset_imputed, imp_dataset_imputed).
Run LOO Sensitivity Analysis using a function that iteratively removes one study at a time and refits the model.
Summarize the Results: Report changes in the effect size, heterogeneity statistics (I²), and model fit metrics (AIC, BIC, LogLik).

Why Split by Response Variable?
Distinct Moderation Effects: Response variables (e.g., ecosystem services like greenhouse gas emissions, soil quality, etc.) likely differ in how moderators (e.g., tree type, crop type, season) influence them. Splitting allows the model to isolate the unique relationships within each response variable.

Interpretability: Without splitting, estimates may conflate effects across distinct response variables, making it difficult to attribute results to a specific ecosystem service.

Appropriate LOO Sensitivity: Running LOO sensitivity on mixed-response datasets can be misleading, as the omitted studies might affect multiple response variables differently, introducing biases or artifacts.

Fits the Cabbage Approach: This methodology inherently groups analyses by discrete categories, and splitting by response variable mirrors that logic.


```{r}
# Set the working directory automatically using 'here'
setwd(here::here())


# Define your working directory using 'here'
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load datasets and V_matrices
non_imp_dataset <- readRDS(file.path(output_dir, "non_imp_dataset.rds"))
imp_dataset <- readRDS(file.path(output_dir, "imp_dataset.rds"))


V_matrix_non_imp <- readRDS(file.path(output_dir, "V_matrix_non_imp_dataset.rds"))
V_matrix_imp <- readRDS(file.path(output_dir, "V_matrix_imp_dataset.rds"))
```



```{r}
# Define random effects structure
random_effects_formular <- ~ 1 | id_article/id_obs

# Define all potential moderators
moderator_formula <- c("tree_type", "crop_type", "season", "soil_texture")  
```
OBS

Are they calculating the effect size on the full dataset or seperately on the subset datasets on each reponse variable? - it should be the same approach!
Are they running the LOO on the full dataset or the subset datasets (subsetted on individual responsive variables) seperately?
Are they doing publication bias evaluation (e.g. funnel plot) on the full dataset or the subset datasets (subsetted on individual responsive variables) seperately?
Is the current LOO assessment running through each study (id_article) or using another identifier (i.e. id_obs)? - because it should be using id_article!
I want to make a plot of overall effect size on the three main response variables (Biodiversity, Crop yield and Soil quality), like Fig. 1, however the plot I wish to make should have overall effects of agroforestry for each response variable relative to monocropping, this plot should include error bars represent 95% confidence intervals. Hence, visualising how confidence intervals overlapping zero indicate no significant differences with the monocropping and for each response variable numbers should be shown in parentheses indicating 1) the number of studies for the respective response variable and 2) the number of data records (observations) for the respective response variable
Progress bar refined classes


```{r}
split_by_response_variable <- function(dataset, selected_response_variables = NULL) {
  # Extract data and V_matrix
  data <- dataset$data
  V_matrix <- dataset$V_matrix

  # Ensure rownames for data
  if (is.null(rownames(data))) {
    rownames(data) <- as.character(data$id_obs)
  }

  # Ensure V_matrix dimnames align with data rownames
  if (is.null(dimnames(V_matrix))) {
    dimnames(V_matrix) <- list(rownames(data), rownames(data))
  }

  # If selected_response_variables is provided, filter the data
  if (!is.null(selected_response_variables)) {
    data <- data[data$response_variable %in% selected_response_variables, , drop = FALSE]

    # Check if any data remains after filtering
    if (nrow(data) == 0) {
      stop("No data remains after filtering for selected response variables.")
    }

    # Subset V_matrix to match filtered data
    indices <- rownames(data)
    V_matrix <- V_matrix[indices, indices, drop = FALSE]
  }

  # Split data by response variable
  response_splits <- split(data, data$response_variable)

  # Align and validate V_matrix for each subset
  splits <- lapply(response_splits, function(sub_data) {
    indices <- rownames(sub_data)
    V_matrix_subset <- V_matrix[indices, indices, drop = FALSE]
    if (!all(rownames(sub_data) == rownames(V_matrix_subset))) {
      stop("Mismatch between data rows and V_matrix rows.")
    }
    list(data = sub_data, V_matrix = V_matrix_subset)
  })

  return(splits)
}
```

```{r}
cat("Data rows:", nrow(imp_dataset), "\n")
cat("V_matrix dimensions:", dim(V_matrix_imp), "\n")
cat("Data rows:", nrow(non_imp_dataset), "\n")
cat("V_matrix dimensions:", dim(V_matrix_non_imp), "\n")
```


```{r}
# Define the selected response variables
selected_responses <- c("Crop yield", "Soil quality", "Biodiversity") # "Pests and Diseases", "Water quality", "Product quality"


####################################################################################################


# Prepare datasets and their corresponding V_matrices
datasets <- list(
  imp_dataset = list(data = imp_dataset, V_matrix = V_matrix_imp)
  #non_imp_dataset = list(data = non_imp_dataset, V_matrix = V_matrix_non_imp)
)

# Split datasets
splits <- lapply(datasets, function(ds) {
  split_by_response_variable(ds, selected_response_variables = selected_responses)
})

# Inspect the splits
str(splits)

# View sneak-peak
splits$imp_dataset$Biodiversity |> glimpse()
```



```{r}
# Get unique response variables
unique_response_vars <- unique(non_imp_dataset$response_variable)
print(unique_response_vars)

# Split the dataset
split_data <- split(non_imp_dataset, non_imp_dataset$response_variable)

# Assign names to the list elements
names(split_data) <- unique_response_vars
```


Based on the description in the methods section, the "cabbage approach" for Leave-One-Out (LOO) sensitivity analysis does not include moderators. Instead, it uses a global model to assess the overall effect size without accounting for moderators. This approach focuses solely on the effect size and how its confidence intervals change when individual studies are excluded.

```{r}
# Generic Leave-One-Out Sensitivity Analysis Function with Additional Metrics
loo_analysis <- function(data_split, response_var_name) {
  # Extract data and V_matrix for the current response variable
  data <- data_split$data
  V_matrix <- data_split$V_matrix
  
  # Initialize a data frame to store results
  exclude_study <- data.frame(
    id_article = character(0),
    estimate = numeric(0),
    se = numeric(0),
    p.value = numeric(0),
    tau2 = numeric(0),
    I2 = numeric(0),
    AIC = numeric(0),
    BIC = numeric(0),
    logLik = numeric(0),
    QM = numeric(0),
    pval_QM = numeric(0)
  )
  
  # Perform Leave-One-Out (LOO) analysis
  for (id in base::unique(data$id_article)) {
    # Exclude the current article
    reduced_data <- subset(data, id_article != id)
    
    # Subset the variance-covariance matrix
    indices <- which(data$id_article != id)
    reduced_V_matrix <- V_matrix[indices, indices, drop = FALSE]
    
    # Ensure the dimensions of the data and V_matrix match
    if (nrow(reduced_data) != nrow(reduced_V_matrix)) {
      cat("Skipping id_article", id, ": Dimension mismatch!\n")
      next
    }
    
    # Try to fit the model
    tryCatch({
      # Fit the model without the current article
      model_without_one <- rma.mv(
        yi = yi,
        V = reduced_V_matrix,
        random = ~1 | id_article,
        data = reduced_data,
        method = "REML"
      )
      
      # Collect results
      exclude_study <- rbind(
        exclude_study,
        data.frame(
          id_article = id,
          estimate = as.numeric(coef(model_without_one)),
          se = as.numeric(summary(model_without_one)$se),
          p.value = as.numeric(summary(model_without_one)$pval),
          tau2 = if (!is.null(model_without_one$tau2)) model_without_one$tau2 else NA,
          I2 = if (!is.null(model_without_one$tau2) && !is.null(model_without_one$sigma2)) {
            100 * model_without_one$tau2 / (model_without_one$tau2 + sum(model_without_one$sigma2))
          } else {
            NA
          },
          AIC = tryCatch(AIC(model_without_one), error = function(e) NA),
          BIC = tryCatch(BIC(model_without_one), error = function(e) NA),
          logLik = tryCatch(logLik(model_without_one), error = function(e) NA),
          QM = if (!is.null(model_without_one$QM)) model_without_one$QM else NA,
          pval_QM = if (!is.null(model_without_one$pval.QM)) model_without_one$pval.QM else NA
        )
      )
    }, error = function(e) {
      # Log errors but continue
      cat("Error excluding id_article", id, ":", conditionMessage(e), "\n")
    })
  }
  
  # Add a response variable column for clarity
  exclude_study$response_variable <- response_var_name
  
  return(exclude_study)
}
```

```{r, eval=FALSE}
##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##################################################
# Start time tracking
start.time <- Sys.time()
##################################################
##################################################
# Run Leave-One-Out (LOO) Sensitivity Analysis on dataset subsets for each response variable [SUBSET DATASETS]
# Simplified Leave-One-Out Sensitivity Analysis
# Perform LOO for all datasets and response variables
loo_results <- lapply(names(splits), function(dataset_name) {
  dataset_splits <- splits[[dataset_name]]
  
  # Perform LOO for each response variable in the dataset
  response_results <- lapply(names(dataset_splits), function(response_var) {
    cat("Processing dataset:", dataset_name, ", Response variable:", response_var, "\n")
    
    # Run the LOO analysis and add dataset and response variable columns
    loo_analysis(dataset_splits[[response_var]], response_var) %>%
      mutate(
        dataset = dataset_name,  # Add the dataset name
        response_variable = response_var  # Add the response variable
      )
  })
  
  # Combine results for all response variables in this dataset
  do.call(rbind, response_results)
})

# Combine LOO results across all datasets
final_loo_results <- do.call(rbind, loo_results)

##############################################################
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

# Save the full combined results
saveRDS(
  final_loo_results,
  file = file.path(output_dir, "final_loo_results_combined.rds")
)

# Save results for each dataset individually
names(loo_results) <- names(splits)  # Assign names for individual datasets
saveRDS(
  loo_results,
  file = file.path(output_dir, "loo_results_individual_datasets.rds")
)

# Messages for saved files
cat("Combined LOO sensitivity results saved to:", file.path(output_dir, "final_loo_results_combined.rds"), "\n")
cat("Individual LOO sensitivity results saved to:", file.path(output_dir, "loo_results_individual_datasets.rds"), "\n")
##############################################################

##################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("Total time taken:", time.taken, "\n")
##############################################################
# Last go: (24/11-24)

```

```{r}
# Load the saved results
# Load combined results
combined_loo_res <- readRDS(file.path(output_dir, "final_loo_results_combined.rds"))
combined_loo_res
# str(combined_loo_res)  # Inspect structure

# Load individual dataset results
# individual_results <- readRDS(file.path(output_dir, "loo_results_individual_datasets.rds"))
# names(individual_results)  # Should show dataset names
# str(individual_results[[1]])  # Inspect the first dataset's LOO results

```

Influence Diagnostics
```{r}
combined_loo_res |> str()
```

```{r}
# Step 1: Identify overlapping studies
overlapping_studies <- combined_loo_res %>%
  distinct(response_variable, id_article) %>%  # Get unique combinations
  count(id_article) %>%  # Count how many response variables each study appears in
  filter(n > 1) %>%  # Filter studies that appear in more than 1 response variable
  pull(id_article)  # Extract the IDs of these studies

# Step 2: Add a flag for overlapping studies
all_loo_results_for_plotting <- combined_loo_res %>%
  mutate(
    overlap_flag = ifelse(id_article %in% overlapping_studies, TRUE, FALSE)
  ) |> 
  mutate(
    lower_ci = estimate - 1.96 * se,
    upper_ci = estimate + 1.96 * se
  )

# Step 3: Create the forest plot with highlights
all_loo_results_plot <- all_loo_results_for_plotting %>%
  ggplot(aes(y = as.factor(id_article), x = estimate, color = response_variable)) +
  geom_point(aes(shape = overlap_flag), size = 3) +  # Different shape for overlapping studies
  geom_errorbarh(aes(xmin = lower_ci, xmax = upper_ci), height = 0.2, alpha = 0.7) +  # Horizontal CI bars
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +  # Reference line at 0
  facet_wrap(~response_variable, scales = "free_y") +  # Facet by response variable
  labs(
    y = "Excluded Study (ID)",
    x = "Estimated Effect Size",
    title = "Top 10 Most Influential Unique Studies (Leave-One-Out Analysis)",
    subtitle = "Highlighted studies appear in more than one response variable",
    color = "Response Variable",
    shape = "Overlapping Study"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    axis.text.y = element_text(size = 10),
    legend.position = "bottom",
    strip.text = element_text(size = 12)  # Larger facet labels
  )

all_loo_results_plot
# potentially highlight studies that are to-influential and present in more than 1 response variable, e.g. study 32 (in both crop yield and soil quality)
```



Between-Study Heterogeneity
```{r}
# Check data structure
str(imp_dataset)

# Check dimensions of V_matrix
dim(V_matrix_imp)

```


```{r}
# Simplified model fitting on non_imp_dataset
tryCatch({
  model <- rma.mv(
    yi = yi, 
    V = V_matrix_imp, 
    random = ~ 1 | id_article,  # Simplified random structure
    data = imp_dataset, 
    method = "REML"
  )
  summary(model)  # Print model summary
}, error = function(e) {
  message("Error: ", e$message)
})

```
```{r}
# Check dimensions
dim(V_matrix_imp)
nrow(imp_dataset)

# Check if V_matrix is symmetric
is_symmetric <- all.equal(V_matrix_imp, t(V_matrix_imp))
print(is_symmetric)

# Check diagonal elements
diag_positive <- all(diag(V_matrix_imp) > 0)
print(diag_positive)

# Inspect potential outliers in vi
summary(non_imp_dataset$vi)

```
```{r}
calculate_between_study_variance <- function(data, V_matrix, random_formula, dataset_name) {
  tryCatch({
    # Validate V_matrix and ensure positive definiteness
    is_symmetric <- all.equal(V_matrix, t(V_matrix))
    diag_positive <- all(diag(V_matrix) > 0)
    
    if (!is_symmetric || !diag_positive) {
      stop("V_matrix is invalid: Ensure it's symmetric and diagonals are positive.")
    }
    
    # Fit the random-effects model
    model <- rma.mv(
      yi = yi, 
      V = V_matrix, 
      random = random_formula, 
      data = data, 
      method = "ML"
    )
    
    # Extract key metrics
    tibble(
      dataset = dataset_name,
      tau2 = model$tau2,  # Between-study variance
      I2 = 100 * model$tau2 / (model$tau2 + sum(model$sigma2)),  # Proportion of heterogeneity
      H2 = 1 + (model$tau2 / mean(model$sigma2)),  # Total variance to sampling variance ratio
      Q = model$QE,  # Cochran's Q
      pval_Q = model$QEp,  # p-value for Q
      QM = model$QM,  # Test for moderators
      pval_QM = model$pval.QM  # p-value for moderators
    )
  }, error = function(e) {
    # Capture errors and return NA metrics
    message("Error for dataset: ", dataset_name, " - ", e$message)
    tibble(
      dataset = dataset_name,
      tau2 = NA, I2 = NA, H2 = NA, Q = NA, pval_Q = NA, QM = NA, pval_QM = NA
    )
  })
}
```

```{r}
# List of datasets and their V_matrices
datasets <- list(
  imp_dataset = list(data = imp_dataset, V_matrix = V_matrix_imp)
)

# Loop through datasets and compute Between-Study Heterogeneity
dataset_metrics <- lapply(names(datasets), function(dataset_name) {
  dataset <- datasets[[dataset_name]]
  calculate_between_study_variance(
    data = dataset$data, 
    V_matrix = dataset$V_matrix, 
    random_formula = ~ 1 | id_article,  # Adjust random structure if needed
    dataset_name = dataset_name
  )
}) %>% 
  bind_rows()

# View results
str(dataset_metrics)

```






Funnel Plot
```{r}
split_data |> str()
```
```{r}
# Function to calculate study-level effects
get_study_effects <- function(data, id_var, yi, vi, random_formula) {
  study_effects <- data.frame(id_article = character(0), effect_size = numeric(0), se = numeric(0))
  
  for (id in unique(data[[id_var]])) {
    subset_data <- subset(data, data[[id_var]] == id)
    cat("Processing id_article:", id, "- Rows:", nrow(subset_data), "\n")
    
    if (nrow(subset_data) > 1) {
      # Fit a random-effects model using metafor
      study_model <- tryCatch(
        {
          rma.mv(
            yi = subset_data[[yi]], 
            V = subset_data[[vi]], 
            random = random_formula, 
            data = subset_data, 
            method = "REML"
          )
        },
        error = function(e) {
          message("Error fitting model for id_article:", id, "-", e$message)
          return(NULL)
        }
      )
      
      if (!is.null(study_model)) {
        study_effects <- rbind(study_effects, data.frame(
          id_article = id,
          effect_size = as.numeric(study_model$b),
          se = as.numeric(study_model$se)
        ))
      }
    } else {
      # Handle cases with single observations
      study_effects <- rbind(study_effects, data.frame(
        id_article = id,
        effect_size = subset_data[[yi]],
        se = sqrt(subset_data[[vi]])
      ))
    }
  }
  
  return(study_effects)
}

# Function to generate funnel plots for each response variable
generate_funnel_plots <- function(split_data) {
  lapply(names(split_data), function(response_var) {
    data <- split_data[[response_var]]
    
    if (!is.null(data) && all(c("yi", "vi") %in% names(data))) {
      cat("Generating funnel plots for:", response_var, "\n")
      
      # Fit an equal-effects model using metafor
      res <- tryCatch(
        {
          rma(
            yi = data$yi, 
            vi = data$vi, 
            data = data, 
            measure = "GEN", 
            method = "EE"
          )
        },
        error = function(e) {
          message("Error fitting model for ", response_var, ": ", e$message)
          return(NULL)
        }
      )
      
      if (!is.null(res)) {
        # Create a 2x2 grid of metafor funnel plots
        par(mfrow = c(2, 2))
        funnel(res, main = paste("Standard Error -", response_var))
        funnel(res, yaxis = "vi", main = paste("Sampling Variance -", response_var))
        funnel(res, yaxis = "seinv", main = paste("Inverse Standard Error -", response_var))
        funnel(res, yaxis = "vinv", main = paste("Inverse Sampling Variance -", response_var))
      }
    } else {
      message("No valid data for response variable:", response_var)
    }
  })
}
```

```{r}
# Main Workflow
study_effects_results <- lapply(names(split_data), function(response_var) {
  data <- split_data[[response_var]]
  
  if (!is.null(data) && all(c("yi", "vi") %in% names(data))) {
    cat("Processing response variable:", response_var, "\n")
    result <- get_study_effects(
      data = data, 
      id_var = "id_article", 
      yi = "yi", 
      vi = "vi",
      random_formula = ~ 1 | exp_id / id_obs  # Hierarchical structure
    )
    
    if (!is.null(result)) {
      result <- result %>% mutate(response_variable = response_var)
    }
    return(result)
  } else {
    message("No valid data for:", response_var)
    return(NULL)
  }
})

# Combine results into a single data frame
study_effects_df <- do.call(rbind, study_effects_results)

# Debugging: Check structure of results
cat("Final study_effects_df structure:\n")
glimpse(study_effects_df)

# Generate and display funnel plots
cat("Generating funnel plots...\n")
generate_funnel_plots(split_data)
```

Forest Plot in RevMan Style

```{r}

```

Key Model Metrics and Regression Estimates

```{r}

```
























Heterogeneity Metrics Across Response Variables
```{r}

```





Extract Model Diagnostics for Response Variables

Prepare and Process LOO Data for Plotting

Visualize LOO Influence

Summarize LOO Results for Each Response Variable



Metafor Diagnostics Plots

```{r}

```

