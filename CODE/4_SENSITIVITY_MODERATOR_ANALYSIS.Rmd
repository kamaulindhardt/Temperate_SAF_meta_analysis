---
title: "4_SENSITIVITY_MODERATOR_ANALYSIS"
author: "M.K.K. Lindhardt"
date: "2024-11-17"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



################################################################################
Sources for developing approaches in meta-analysis: 

https://wviechtb.github.io/metafor/reference/rma.mv.html 
https://www.taylorfrancis.com/chapters/edit/10.1201/9780429061240-8/multivariate-meta-analysis-ding-geng-din-chen-karl-peace 
https://training.cochrane.org/handbook/current/chapter-06 
https://training.cochrane.org/handbook/current/chapter-10


It is not uncommon for studies to have multiple outcome measures which lead to statistical multivariate analysis. The results of studies with multiple outcomes and/or endpoints are typically synthesized via conventional univariate meta-analysis (UMA) on each outcome separately, ignoring the correlations between the outcomes. The impact of ignoring the within-study correlation has been explored extensively in the statistical literature, with issues including overestimated variance of the pooled eﬀect size and biased estimates, which in turn may inﬂuence statistical inferences. In this case, multivariate meta-analysis should be used to synthesize multiple outcomes while taking into account their correlations, often resulting in superior parameter estimation. With study-level moderators or predictors, multivariate meta-regression can also be developed in parallel with multivariate regression techniques.

Meta-Analysis with R Package metafor. Rearrange the Data Format. In order to use the metafor package for multivariate meta-analysis, meta-data
should be rearranged accordingly. With this rearranged data format, we then construct a list of the variance-covariance matrices of the observed outcomes for the ﬁve studies to create a block diagonal matrix, V, for metafor.
With the rearranged data and variance-covariance matrix, V, we now ﬁt the ﬁxed-eﬀects meta-analysis model using metafor with the option of
method="FE". To ﬁt the random-eﬀects multivariate meta-analysis model using the metafor package, we simply change the option to method="REML". We note that this reproduces the results, with this random-effects model, we can also test the difference between

#####################################################

Response Variables are measured on a continuous scale, where each individual outcome is a measurement of a numerical quantity
Chosen Effect Size:  

Formulas to estimate effects (and their standard errors)?

#####################################################
Step-by-Step Framework for Meta-Analysis

1) Data Preparation
Clean and transform the data.
Standardize location information and create unique identifiers.
Classify locations by continent.
--- DESCRIPTIVE_VIZ: Exploratory data analysis and visualization.
Standardize measures of variation and convert SE to SD (save this version).
Impute missing values (silvo_se, control_se, silvo_n, control_n).
Convert SE to SD in the imputed dataset (save this version).
Calculate effect sizes (ROM) for both non-imputed and imputed datasets.
Compare the imputed and non-imputed datasets using descriptive statistics (mean, SD, median) and tests (density plots, boxplots, t-tests, Kolmogorov-Smirnov test).

2) Meta-Analysis Model Fitting
Use multivariate/multilevel mixed-effects models (rma.mv).
Fit models on both non-imputed and imputed datasets.
Compare results side by side, including effect sizes, confidence intervals, and heterogeneity statistics.

3) Sensitivity Analysis and Diagnostics
Perform sensitivity analysis, including leave-one-out analysis.
Conduct trim-and-fill analysis to check for publication bias.

4) Moderator Analysis
Split the dataset by moderators and conduct analyses on both imputed and non-imputed data.
Consider meta-regression to formally test for differences in moderator effects between the datasets.

5) Visualizations
Create comprehensive visual summaries, including caterpillar plots, forest plots, and geographical maps of study locations.

#############
# STEP 0
##########################################################################################################################################
PREPARING SCRIPT AND READ IN THE DATA
##########################################################################################################################################

```{r}
# Clean workspace
rm(list = ls())
```


## Loading required packages and libraries

```{r Loading other needed packages, warning=FALSE}
# Suppress warnings to avoid clutter in the console output
suppressWarnings({

  # Load multiple add-on packages using pacman::p_load for efficiency
  pacman::p_load(
    # Data Manipulation / Transformation
    tidyverse,        # Comprehensive collection of R packages for data science
    readr,            # Read and write csv 
    dlookr,           # Diagnose, explore, and transform data with dlookr
    skimr,            # Provides easy summary statistics about variables in data frames, tibbles, data tables and vectors
    janitor,          # For cleaning and renaming data columns
    readxl,           # To read Excel files
    vroom,            # Fast reading of large datasets from local disk
    missForest,       # Random Forest method for imputing missing data
    mice,             # For dealing with missing data by creating multiple imputations for multivariate missing data
    missRanger,       # Fast missing value imputation by chained random forest
    conflicted,       # An alternative conflict resolution strategy
    future,           # Parallel processing
    future.apply,     # Parallel processing
    Matrix,           # Matrix operations
    progressr,
    ###################################################################################################################
    # Data Visualization
    ggplot2,          # Data visualization package (part of tidyverse)
    patchwork,        # ggplot2 API for sequentially building up a plot
    ggrepel,          # Provides text and label geoms for ' ggplot2' that help to avoid overlapping text labels
    ###################################################################################################################
    # Spatial Data
    tidygeocoder,     # Unified interface for performing both forward and reverse geocoding queries
    raster,           # For spatial data analysis, especially BioClim variables from WorldClim
    sp,               # For spatial data classes and methods
    sf,               # For simple features in R, handling vector data
    rnaturalearth,    # For world map data
    rnaturalearthdata, 
    ###################################################################################################################
    # Meta-Analysis
    metafor,          # For conducting meta-analysis, effect sizes, and response ratios
    clubSandwich,     # Cluster-robust variance estimators for ordinary and weighted least squares linear regression models
    ###################################################################################################################
    # Exploratory Data Analysis (EDA)
    DataExplorer,     # For exploratory data analysis
    SmartEDA,         # For smart exploratory data analysis
    ###################################################################################################################
    # Project Management and Code Styling
    here,             # Easy file referencing using the top-level directory of a file project
    styler            # For code formatting and styling
  )
  
  # If encountering issues with raster::getData(), consider using geodata::worldclim_global() from the geodata package
})

###################################################################################################################
# Set preferences for conflicting functions
conflict_prefer("filter", "dplyr")
conflict_prefer("select", "dplyr")
conflict_prefer("group_by", "dplyr") 
conflict_prefer("summarise", "dplyr")
conflict_prefer("mutate", "dplyr")
conflict_prefer("arrange", "dplyr")
conflict_prefer("locale", "readr")
conflict_prefer("extract", "raster")
conflict_prefer("intersect", "base")
```


Loading the datasets

```{r Loading database, warning=FALSE, message=FALSE}
# Set the working directory automatically using 'here'
setwd(here::here())


# Define your working directory using 'here'
dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Load datasets 

## NON-IMPUTED
non_imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "non_imp_data_rom.rds"))

## IMPUTED
imp_dataset <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "imp_data_rom.rds"))
```


loading fitted models

```{r}
# Save all models in a combined file
model_results <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "fitted_models_all_new.rds"))
```



```{r}
imp_dataset |> glimpse()
```

```{r}
# Check the unique response variables and sub-response variables
unique(imp_dataset$response_variable)
# unique(imp_dataset$sub_response_variable)
```
```{r}
response_summary <- 
  imp_dataset |> 
  count(response_variable) |> 
  arrange(desc(n))

# Bar plot for response variable counts
response_var_summary_plot <- 
  response_summary |> 
  ggplot(aes(x = reorder(response_variable, -n), y = n)) +
  geom_bar(stat = "identity", fill = "#0072B2") +
  coord_flip() +
  labs(title = "Count of Observations per Response Variable",
       x = "Response Variable",
       y = "Count of Observations") +
  theme_minimal()

response_var_summary_plot
```

```{r}
# Check the unique response variables and sub-response variables
unique_articles <- unique(imp_dataset$id_article)
unique_response_vars <- unique(imp_dataset$response_variable)

print(unique_response_vars)
print(length(unique_articles))  # Total number of unique articles

```

```{r}
# Count the number of unique articles for each response variable
article_summary <- imp_dataset %>%
  group_by(response_variable) %>%
  summarise(unique_articles = n_distinct(id_article)) %>%
  arrange(desc(unique_articles))

article_summary

```
```{r}
# Bar plot for unique article counts by response variable
article_summary_plot <-
  article_summary |> 
  ggplot(aes(x = reorder(response_variable, -unique_articles), y = unique_articles)) +
  geom_bar(stat = "identity", fill = "#E69F00") +
  coord_flip() +
  labs(title = "Count of Unique Articles per Response Variable",
       x = "Response Variable",
       y = "Number of Unique Articles") +
  theme_minimal()

article_summary_plot
```

```{r}
# Sample one observation per article per response variable
sampled_data <- imp_dataset %>%
  group_by(id_article, response_variable) %>%
  slice_head(n = 1)

sampled_data
```
```{r}
# Boxplot of effect sizes by response variable (unique articles)
boxplot_effec_size_response_variable <- sampled_data |> 
  ggplot(aes(x = response_variable, 
             y = yi, 
             fill = response_variable)) +
  geom_boxplot() +
  coord_flip() +
  labs(title = "Boxplot of Effect Sizes (yi) by Response Variable (Unique Articles)",
       x = "Response Variable",
       y = "Effect Size (yi)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

boxplot_effec_size_response_variable
```

The boxplot shows the distribution of effect sizes (yi) for each response variable. In the context of this meta-analysis, the effect size (yi) represents the standardized difference between the treatment group (agroforestry systems) and the control group (monoculture).

Biodiversity: the effect sizes are mostly positive, suggesting that agroforestry systems might have a higher effect on biodiversity compared to monoculture.
Crop Yield: the effect sizes are genrally negative, indicating potential yield reductions in agroforestry systems.
Soil Quality: tend to show positive effect sizes, suggesting an improvement in these aspects under agroforestry systems.
Product Quality: 
Pest and Diseases:
Greenhouse gas emissions:

The variation in the effect sizes for each response variable indicates heterogeneity, showing that the impact of agroforestry varies across different studies and contexts. However, the effect sizes in this plot do not account for potential study-level covariates or moderators, which could influence the observed differences. It will be important to consider the sampling variance (vi) associated with each effect size when interpreting these results, as larger studies (with smaller variance) provide more reliable estimates.





```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  )

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable")

# Plot histogram of effect sizes with additional improvements
ggplot(sampled_data, aes(x = yi, fill = response_variable)) +
  geom_histogram(binwidth = 0.05, alpha = 0.7, color = "black") +
  # mean yi line
  geom_vline(data = response_summary, aes(xintercept = mean_yi, color = response_variable),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ reorder(response_variable, -num_articles), scales = "free_y") +
  labs(
    title = "Distribution of Effect Sizes (yi) by Response Variable (Unique Articles)",
    x = "Effect Size (yi)",
    y = "Frequency"
  ) +
  scale_fill_brewer(palette = "Set2") +
  scale_color_brewer(palette = "Set2") +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# Calculate mean effect size and number of unique articles for each response variable
response_summary <- sampled_data %>%
  group_by(response_variable) %>%
  summarise(
    mean_yi = mean(yi, na.rm = TRUE),
    num_articles = n_distinct(id_article)
  ) %>%
  arrange(desc(num_articles))

# Merge the summary data back into the sampled data for ordering
sampled_data <- sampled_data %>%
  left_join(response_summary, by = "response_variable") %>%
  mutate(response_variable = factor(response_variable, levels = response_summary$response_variable))

# Reshape the data to long format for plotting
long_data <- sampled_data %>%
  select(id_article, response_variable, silvo_mean, control_mean) %>%
  pivot_longer(cols = c(silvo_mean, control_mean), 
               names_to = "group", 
               values_to = "mean_value") %>%
  mutate(group = recode(group, "silvo_mean" = "Silvo (Agroforestry)", "control_mean" = "Control (Monoculture)"))

# Calculate mean values for each group and response variable
group_summary <- long_data %>%
  group_by(response_variable, group) %>%
  summarise(
    mean_value = mean(mean_value, na.rm = TRUE),
    .groups = "drop"
  )


# Plot the distribution of mean values for Silvo and Control groups with free x-scales
ggplot(long_data, aes(x = mean_value, fill = group)) +
  geom_histogram(binwidth = 5, alpha = 0.7, color = "black", position = "identity") +
  geom_vline(data = group_summary, aes(xintercept = mean_value, color = group),
             linetype = "dashed", size = 0.8) +
  facet_wrap(~ response_variable, scales = "free_x") +  # Set scales to "free_x"
  labs(
    title = "Distribution of Mean Values for Silvo (Agroforestry) and Control (Monoculture)",
    x = "Mean Value",
    y = "Frequency"
  ) +
  scale_fill_manual(values = c("#0072B2", "#D55E00")) +
  scale_color_manual(values = c("#0072B2", "#D55E00")) +
  theme_minimal() +
  theme(
    legend.position = "top",
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5, size = 16)
  )

```

```{r}
# List of response variables and moderators
response_variables <- c("Biodiversity", "Crop yield", "Water quality", "Pest and Disease", 
                        "Soil quality", "Greenhouse gas emission", "Product quality")

moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")
```

```{r}
# Define a generic function for counting unique values
count_unique_response_and_moderator <- function(data, response_col, moderators) {
  
  # Count of unique response variables for each moderator
  unique_response_var_per_moderator <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(moderator) %>%
    summarise(unique_responses = n_distinct(.data[[response_col]]), .groups = "drop")

  # Count of unique moderator levels for each response variable
  unique_moderators_per_response_var <- data %>%
    select(all_of(response_col), all_of(moderators)) %>%
    pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
    filter(!is.na(moderator_value)) %>%
    group_by(.data[[response_col]]) %>%
    summarise(unique_moderators = n_distinct(moderator_value), .groups = "drop")

  # Return both summaries as a list
  list(
    unique_response_var_per_moderator = unique_response_var_per_moderator,
    unique_moderators_per_response_var = unique_moderators_per_response_var
  )
}

```

```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Apply the function to the non-imputed dataset
non_imp_summary <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Apply the function to the imputed dataset
imp_summary <- count_unique_response_and_moderator(imp_dataset, response_col, moderators)

# View the summaries
print(non_imp_summary$unique_response_var_per_moderator)
print(non_imp_summary$unique_moderators_per_response_var)

print(imp_summary$unique_response_var_per_moderator)
print(imp_summary$unique_moderators_per_response_var)

```


Visualize the Summary Data

Plot 1: Number of Unique Response Variables per Moderator
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Generate the summaries using the function
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_response_var_per_moderator <- results$unique_response_var_per_moderator

# Bar plot for unique response variables per moderator
unique_response_var_per_moderator |> 
  ggplot(aes(x = reorder(moderator, unique_responses), y = unique_responses, fill = moderator)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Response Variables per Moderator",
    x = "Moderator",
    y = "Number of Unique Response Variables"
  ) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  theme(legend.position = "none")

```


Plot 2: Number of Unique Moderators per Response Variable
```{r}
# Define your response column and list of moderators
response_col <- "response_variable"
moderators <- c("tree_type", "crop_type", "age_system", "season", 
                "soil_texture", "no_tree_per_m", "tree_height", "alley_width")

# Generate summaries
results <- count_unique_response_and_moderator(non_imp_dataset, response_col, moderators)

# Extract the specific summary for plotting
unique_moderators_per_response_var <- results$unique_moderators_per_response_var


# Bar plot for unique moderators per response variable
unique_moderators_per_response_var |> 
  ggplot(aes(x = reorder(response_variable, unique_moderators), y = unique_moderators, fill = response_variable)) +
  geom_bar(stat = "identity", color = "black") +
  coord_flip() +
  labs(
    title = "Number of Unique Moderators per Response Variable",
    x = "Response Variable",
    y = "Number of Unique Moderator Levels"
  ) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  theme(legend.position = "none")
```

Alternative Visualization: Heatmap
comprehensive view of the data in a heatmap to show the interaction between moderators and response variables

```{r}
# Create a heatmap data frame
heatmap_data <- non_imp_dataset %>%
  select(response_variable, all_of(moderators)) %>%
  pivot_longer(cols = all_of(moderators), names_to = "moderator", values_to = "moderator_value") %>%
  filter(!is.na(moderator_value)) %>%
  group_by(response_variable, moderator) %>%
  summarise(count = n_distinct(moderator_value), .groups = "drop")

# Heatmap plot
ggplot(heatmap_data, aes(x = moderator, y = response_variable, fill = count)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(
    title = "Heatmap of Unique Moderator Levels by Response Variable",
    x = "Moderator",
    y = "Response Variable",
    fill = "Count of Unique Levels"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.title = element_text(hjust = 0.5)
  )

```




############
# STEP 6
##########################################################################################################################################
SENSITIVITY ANALYSIS (Leave-One-Out Sensitivity Analysis)
##########################################################################################################################################


```{r}
#########################################################################
###############################################################################
###################################################################################
########################################################################################
#############################################################################################
####################################################################################################

# WORING ON THE IMPUTED DATASET
meta_data <- imp_dataset

####################################################################################################
#############################################################################################
########################################################################################
###################################################################################
###############################################################################
#########################################################################

```

```{r}
# Load effect sizes from the structured_results data

structured_results <- readRDS(here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R", "structured_results_all_effect_sizes.rds"))
```



```{r}
##########################################################################################################################################
# DYNAMIC LEAVE-ONE-OUT SENSITIVITY ANALYSIS ON STUDY EFFECTS - USING A SIMPLER rma MODEL
##########################################################################################################################################

##########################################################################
# Set up the parallel processing plan
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################

# Define the function for Leave-One-Out (LOO) sensitivity analysis
conduct_loo_analysis <- function(meta_data, model_formula_function, random_effects_formula) {
  
  # Extract unique studies
  unique_studies <- unique(meta_data$id_article)
  
  # Initialize an empty list to store LOO results
  loo_results <- list()
  
  # Iterate through each study
  for (study in unique_studies) {
    cat("Excluding study:", study, "\n")
    
    # Subset the data excluding the current study
    data_excluded <- meta_data[meta_data$id_article != study, ]
    
    # Refit the model without the excluded study using the provided model formula function
    loo_model <- tryCatch({
      model_formula_function(
        data = data_excluded,
        random_effects_formula = random_effects_formula
      )
    }, error = function(e) {
      cat("Error in fitting model for study:", study, "-", e$message, "\n")
      return(NULL)
    })
    
    # Store the results
    loo_results[[as.character(study)]] <- loo_model
  }
  
  return(loo_results)
}

# Define model formula functions
minimal_random_effects_model <- function(data, random_effects_formula) {
  rma.mv(
    yi = yi,
    V = vi,
    mods = ~ 1,  # Intercept-only model
    random = random_effects_formula,
    data = data,
    method = "REML",
    control = list(iter.max = 2000, rel.tol = 1e-9)
  )
}

full_model <- function(data, random_effects_formula) {
  rma.mv(
    yi = yi,
    V = vi,
    mods = as.formula("~ tree_type + crop_type + age_system + season + soil_texture"),
    random = random_effects_formula,
    data = data,
    method = "REML",
    control = list(iter.max = 2000, rel.tol = 1e-9)
  )
}

##########################################################################################################################################
# RUN DYNAMIC LEAVE-ONE-OUT ANALYSIS PER RESPONSE VARIABLE
##########################################################################################################################################

# Set the model formula function to use for LOO analysis (e.g., minimal_random_effects_model or full_model)
model_to_use <- minimal_random_effects_model  # Change this to full_model if needed

# Define random effects structure
random_effects_formula <- ~ 1 | exp_id

# Initialize a list to store results for each response variable
response_specific_results <- list()

# Loop through each response variable and conduct LOO analysis
for (response in unique(meta_data$response_variable)) {
  cat("Processing response variable:", response, "\n")
  
  # Subset the data for the current response variable
  data_subset <- meta_data[meta_data$response_variable == response, ]
  
  # Conduct Leave-One-Out (LOO) sensitivity analysis for the current response variable
  response_specific_results[[response]] <- conduct_loo_analysis(
    meta_data = data_subset,
    model_formula_function = model_to_use,
    random_effects_formula = random_effects_formula
  )
}
##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (26/01-2025)
# Total time taken: 13.77877 secs 

# Processing response variable: Biodiversity 
# Excluding study: 1 
# Excluding study: 4 
# Excluding study: 7 
# Excluding study: 9 
# Excluding study: 15 
# Excluding study: 18 
# Excluding study: 25 
# Excluding study: 29 
# Excluding study: 35 
# Processing response variable: Crop yield 
# Excluding study: 2 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 3 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 10 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 11 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 12 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 13 
# Excluding study: 14 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 16 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 20 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 25 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 26 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 30 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 31 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 33 
# Excluding study: 34 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 36 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 37 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Processing response variable: Water quality 
# Excluding study: 5 
# Error in fitting model for study: 5 - Processing terminated since k <= 1. 
# Processing response variable: Pest and Disease 
# Excluding study: 6 
# Excluding study: 17 
# Excluding study: 29 
# Processing response variable: Soil quality 
# Excluding study: 8 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 14 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 19 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 21 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 23 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 24 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 25 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 27 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 28 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 32 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Excluding study: 33 
# Advarsel: Ratio of largest to smallest sampling variance extremely large. May not be able to obtain stable results.Processing response variable: Greenhouse gas emission 
# Excluding study: 11 
# Advarsel: Single-level factor(s) found in 'random' argument. Corresponding 'sigma2' value(s) fixed to 0.Excluding study: 22 
# Advarsel: Single-level factor(s) found in 'random' argument. Corresponding 'sigma2' value(s) fixed to 0.Processing response variable: Product quality 
# Excluding study: 12 
# Excluding study: 20 
# Excluding study: 25 
# Excluding study: 26 
# Excluding study: 34 
# 
# Total time taken: 11.29175 secs 
```

```{r}
# response_specific_results$`Crop yield` |> str()
```

```{r}
##########################################################################################################################################
# INSPECT RESULTS
##########################################################################################################################################

# Summarize LOO results with detailed comparison to the full model
summarize_loo_results <- function(loo_results, full_effect_size) {
  summary_df <- do.call(rbind, lapply(names(loo_results), function(study) {
    model <- loo_results[[study]]
    if (is.null(model) || is.null(model$b)) {
      return(data.frame(
        Study = study,
        Excluded_Effect_Size = NA,
        Excluded_SE = NA,
        Full_Effect_Size = full_effect_size,
        Change_in_Effect_Size = NA,
        QE = NA,
        QE_pval = NA,
        I2 = NA,
        Tau2 = NA
      ))
    }
    
    # Extract effect size and standard error for the excluded study
    excluded_effect_size <- ifelse(length(model$b) > 0, model$b[1], NA)
    excluded_se <- ifelse(length(model$se) > 0, model$se[1], NA)
    
    # Calculate change in effect size with proper handling of zero or near-zero full effect size
    if (!is.na(full_effect_size) && abs(full_effect_size) > 1e-6) {
      change_in_effect_size <- ((excluded_effect_size - full_effect_size) / full_effect_size) * 100
    } else {
      change_in_effect_size <- NA
    }
    
    data.frame(
      Study = study,
      Excluded_Effect_Size = excluded_effect_size,
      Excluded_SE = excluded_se,
      Full_Effect_Size = full_effect_size,
      Change_in_Effect_Size = change_in_effect_size,
      QE = ifelse(!is.null(model$QE), model$QE, NA),
      QE_pval = ifelse(!is.null(model$QEp), model$QEp, NA),
      I2 = ifelse(!is.null(model$I2), model$I2, NA),
      Tau2 = ifelse(!is.null(model$tau2), model$tau2, NA)
    )
  }))
  
  return(summary_df)
}


# Generate the summary table for each response variable
response_summary <- lapply(names(response_specific_results), function(response) {
  cat("Summarizing LOO results for response variable:", response, "\n")
  
  loo_results <- response_specific_results[[response]]
  if (is.null(loo_results) || length(loo_results) == 0) {
    cat("No valid LOO results for response variable:", response, "\n")
    return(data.frame(
      Study = NA,
      Excluded_Effect_Size = NA,
      Excluded_SE = NA,
      Full_Effect_Size = NA,
      Change_in_Effect_Size = NA,
      QE = NA,
      QE_pval = NA,
      I2 = NA,
      Tau2 = NA,
      response_variable = response
    ))
  }
  
  # Extract the full effect size from structured_results
  full_effect_size <- structured_results %>%
    filter(ResponseVariable == response, 
           # Extracting from the minimal_random_effects model in the previously fitted model objects (structured_results_all_effect_sizes.rds)
           # This is used to compare with the LOO analysis per response variable and study
           Model == "minimal_random_effects") %>%
    pull(Estimate)
  
  if (length(full_effect_size) == 0) {
    cat("No valid full model result for response variable:", response, "\n")
    return(data.frame(
      Study = NA,
      Excluded_Effect_Size = NA,
      Excluded_SE = NA,
      Full_Effect_Size = NA,
      Change_in_Effect_Size = NA,
      QE = NA,
      QE_pval = NA,
      I2 = NA,
      Tau2 = NA,
      response_variable = response
    ))
  }
  
  # Use the first valid full effect size
  full_effect_size <- full_effect_size[1]
  summary_df <- summarize_loo_results(loo_results, full_effect_size)
  summary_df$response_variable <- response
  return(summary_df)
})

# Combine results into a single data frame
response_summary_combined <- do.call(rbind, response_summary) |> 
  relocate(Study, response_variable, Full_Effect_Size, Excluded_Effect_Size, Change_in_Effect_Size)

# Inspect the combined summary
print(response_summary_combined)
```

```{r}
##########################################################################################################################################
# SUMMARIZE CONTRIBUTION OF STUDIES TO RESPONSE VARIABLES
##########################################################################################################################################

# Summarize the overall contribution of each study
study_contribution_summary <- response_summary_combined %>%
  group_by(Study, response_variable) %>%
  summarise(
    Mean_Change_in_Effect_Size = mean(abs(Change_in_Effect_Size), na.rm = TRUE),
    Total_Change_in_Effect_Size = sum(abs(Change_in_Effect_Size), na.rm = TRUE),
    Mean_Excluded_Effect_Size = mean(Excluded_Effect_Size, na.rm = TRUE),
    Mean_Excluded_SE = mean(Excluded_SE, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    Study = as.numeric(Study)
  ) %>%
  arrange((Study))  # Correct sorting in ascending order

# Inspect the summarized contributions
print(study_contribution_summary)

# Optional: Save the summary to a CSV file for further analysis
# write.csv(study_contribution_summary, "study_contribution_summary.csv", row.names = FALSE)

study_contribution_summary |> glimpse()
```

```{r}
# Scatter plot of Excluded Effect Size vs. Mean Change
ggplot(study_contribution_summary, aes(x = Mean_Excluded_Effect_Size, y = Mean_Change_in_Effect_Size, color = response_variable)) +
  geom_point(size = 3) +
  geom_smooth(method = "lm", se = FALSE, linetype = "dashed") +
  labs(
    title = "Excluded Effect Size vs. Mean Change in Effect Size",
    x = "Mean Excluded Effect Size",
    y = "Mean Change in Effect Size (%)",
    color = "Response Variable"
  ) +
  theme_minimal()
```
```{r}
# Faceted bar plot
ggplot(study_contribution_summary, aes(x = reorder(as.factor(Study), -Mean_Change_in_Effect_Size), y = Mean_Change_in_Effect_Size)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    title = "Study Contributions by Response Variable",
    x = "Study",
    y = "Mean Change in Effect Size (%)"
  ) +
  coord_flip() +
  facet_wrap(~response_variable, scales = "free_y") +
  theme_minimal()
```

```{r}
# Heatmap of Total Change in Effect Size
ggplot(study_contribution_summary, aes(x = as.factor(Study), y = response_variable, fill = Total_Change_in_Effect_Size)) +
  geom_tile(color = "white") +
  scale_fill_viridis_c(option = "C") +
  labs(
    title = "Heatmap of Total Change in Effect Size",
    x = "Study",
    y = "Response Variable",
    fill = "Total Change (%)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```




```{r}
# Bar plot of Mean Change in Effect Size
ggplot(study_contribution_summary, aes(x = reorder(as.factor(Study), -Mean_Change_in_Effect_Size), y = Mean_Change_in_Effect_Size, fill = response_variable)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(
    title = "Mean Change in Effect Size by Study",
    x = "Study",
    y = "Mean Change in Effect Size (%)",
    fill = "Response Variable"
  ) +
  coord_flip() +
  theme_minimal()
```

```{r}
glimpse(study_contribution_summary)

# Check for missing or invalid values
summary(study_contribution_summary$Mean_Change_in_Effect_Size)

```

```{r}
# Caterpillar plot for LOO sensitivity analysis
ggplot(study_contribution_summary, aes(
  x = Mean_Change_in_Effect_Size,
  y = reorder(Study, Mean_Change_in_Effect_Size),
  fill = response_variable
)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Caterpillar Plot: Study Influence on Effect Size",
    x = "Mean Change in Effect Size (%)",
    y = "Study",
    fill = "Response Variable"
  ) +
  facet_wrap(~ response_variable, scales = "free_y") + # Facet by response_variable with free y-axis scale
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 10),
    legend.position = "bottom",
    strip.text = element_text(size = 12, face = "bold") # Customize facet labels
  )
```

```{r}
# Ensure the Full_Effect_Size column exists
if (!"Full_Effect_Size" %in% colnames(study_contribution_summary)) {
  study_contribution_summary <- study_contribution_summary %>%
    mutate(Full_Effect_Size = mean(Mean_Excluded_Effect_Size, na.rm = TRUE))
}

# Enhanced Forest Plot with Free Scales for Both Axes
ggplot(study_contribution_summary, aes(
  x = Mean_Excluded_Effect_Size,
  y = reorder(Study, Mean_Excluded_Effect_Size),
  xmin = Mean_Excluded_Effect_Size - Mean_Excluded_SE,
  xmax = Mean_Excluded_Effect_Size + Mean_Excluded_SE,
  color = response_variable
)) +
  geom_point(size = 3) +
  geom_errorbarh(height = 0.2) +
  geom_vline(
    xintercept = mean(study_contribution_summary$Full_Effect_Size, na.rm = TRUE),
    linetype = "dashed",
    color = "red"
  ) +
  facet_wrap(~response_variable, scales = "free", ncol = 2) +
  labs(
    title = "Forest Plot: LOO Sensitivity Analysis by Response Variable",
    x = "Effect Size (with Study Excluded)",
    y = "Studies",
    color = "Response Variable"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 8),
    axis.text.x = element_text(size = 10),
    legend.position = "bottom",
    strip.text = element_text(size = 10, face = "bold")
  )
```
```{r}
study_contribution_summary <- study_contribution_summary %>%
  mutate(High_Influence = ifelse(Mean_Change_in_Effect_Size > 50, "Yes", "No"))

```
```{r}
study_contribution_summary <- study_contribution_summary %>%
  arrange(desc(Mean_Change_in_Effect_Size))
```




############
# STEP 7
##########################################################################################################################################
PUBLICATION BIAS INVESTIGATION FOR META-ANALYSIS
##########################################################################################################################################


```{r}
##########################################################################################################################################
# PUBLICATION BIAS INVESTIGATION FOR META-ANALYSIS
##########################################################################################################################################

# This workflow is designed to assess publication bias in meta-analysis studies. 
# It uses a combination of multivariate models (rma.mv) for complex analyses and univariate models (rma) for bias diagnostics.

# **Models**:
# 1. `Minimal_Model`: A multivariate intercept-only model to analyze general heterogeneity. ----------------------- omitted because of errors in model fitting!
# 2. `Full_Model`: A multivariate model incorporating key moderators (e.g., crop type, soil texture, etc.). ------- omitted because of errors in model fitting!
# 3. `Univariate_Model`: A simpler univariate model used exclusively for publication bias analysis.

# **Data**:
# The input data (`meta_data`) is split by response variables (e.g., Biodiversity, Crop Yield). 
# Each subset is analyzed independently to fit the models and compute diagnostics.

# **Tests**:
# 1. **Egger's Test**: Evaluates funnel plot asymmetry as an indicator of bias.
# 2. **Trim-and-Fill**: Adjusts effect sizes to account for missing studies.

# The workflow ensures compatibility by using `rma` models for publication-bias-specific tests.


# Function to fit univariate random effects model
# Fits a univariate random-effects meta-analysis model (rma)
univariate_random_effects_model <- function(data) {
  tryCatch(
    rma(
      yi = yi,  # Effect size
      vi = vi,  # Variance of effect size
      data = data,  # Input dataset
      method = "REML"  # Restricted Maximum Likelihood estimation
    ),
    error = function(e) {
      message("Error fitting univariate model: ", e$message)
      return(NULL)
    }
  )
}

# Function to fit and summarize models for each response variable
fit_and_summarize_by_response <- function(data) {
  response_data <- split(data, data$response_variable)  # Split data by response variable

  response_results <- lapply(names(response_data), function(response) {
    message("Processing response variable: ", response)
    data_subset <- response_data[[response]]

    # Fit univariate model
    univariate_model <- univariate_random_effects_model(data_subset)

    list(
      Response = response,  # Response variable name
      Univariate_Model = univariate_model  # Fitted univariate model
    )
  })

  names(response_results) <- names(response_data)  # Name results by response variable
  return(response_results)
}

# Function to calculate publication bias for each response variable
# Performs Egger's Test and Trim-and-Fill analysis for univariate models
calculate_publication_bias <- function(models) {
  bias_results <- list()

  for (response in names(models)) {
    univariate_model <- models[[response]]$Univariate_Model

    if (!is.null(univariate_model)) {
      bias_results[[response]] <- list(
        Egger_Test = tryCatch(
          regtest(univariate_model, model = "rma"),
          error = function(e) {
            message("Error performing Egger's Test for response variable ", response, ": ", e$message)
            return(NULL)
          }
        ),
        Trim_and_Fill = tryCatch(
          trimfill(univariate_model),
          error = function(e) {
            message("Error performing Trim-and-Fill for response variable ", response, ": ", e$message)
            return(NULL)
          }
        )
      )
    } else {
      message("Univariate model is not valid for response variable: ", response)
    }
  }

  return(bias_results)
}

# Using the publication-bias modelling workflow
response_results <- fit_and_summarize_by_response(meta_data)  # Fit models for each response variable
bias_results <- calculate_publication_bias(response_results)  # Calculate publication bias

response_results
bias_results 

# bias_results |> str()
```

```{r}
##########################################################################################################################################
# SAVE PUBLICATION-BIAS RESULTS INTO DATAFRAME
##########################################################################################################################################

# Save publication bias results to a structured dataframe
save_bias_results <- function(bias_results) {
  results_list <- lapply(names(bias_results), function(response) {
    result <- bias_results[[response]]

    # Initialize Egger's Test row
    egger_row <- if (!is.null(result$Egger_Test)) {
      egger <- result$Egger_Test
      data.frame(
        Response = response,
        Test = "Egger's Test",
        Z_Value = if (!is.null(egger$zval)) egger$zval else NA,
        P_Value = if (!is.null(egger$pval)) egger$pval else NA,
        Limit_Estimate = if (!is.null(egger$b)) egger$b[1] else NA,
        CI_Lower = if (!is.null(egger$ci.lb)) egger$ci.lb else NA,
        CI_Upper = if (!is.null(egger$ci.ub)) egger$ci.ub else NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    } else {
      data.frame(
        Response = response,
        Test = "Egger's Test",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = NA,
        CI_Upper = NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    }

    # Initialize Trim-and-Fill row
    trim_row <- if (!is.null(result$Trim_and_Fill)) {
      trim <- result$Trim_and_Fill
      data.frame(
        Response = response,
        Test = "Trim-and-Fill",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = if (!is.null(trim$ci.lb)) trim$ci.lb else NA,
        CI_Upper = if (!is.null(trim$ci.ub)) trim$ci.ub else NA,
        Estimated_Missing_Studies = if (!is.null(trim$k0)) trim$k0 else NA,
        Adjusted_Estimate = if (!is.null(trim$b)) trim$b[1] else NA
      )
    } else {
      data.frame(
        Response = response,
        Test = "Trim-and-Fill",
        Z_Value = NA,
        P_Value = NA,
        Limit_Estimate = NA,
        CI_Lower = NA,
        CI_Upper = NA,
        Estimated_Missing_Studies = NA,
        Adjusted_Estimate = NA
      )
    }

    # Combine rows for the current response
    rbind(egger_row, trim_row)
  })

  # Combine all rows into a single dataframe
  results_df <- do.call(rbind, results_list)
  return(results_df)
}

# Save results to a dataframe for further analysis
bias_results_df <- save_bias_results(bias_results)

# Print results dataframe
print(bias_results_df)

bias_results_df |> glimpse()
```



```{r}
# Filter for Trim-and-Fill results
funnel_data <- bias_results_df %>% filter(Test == "Trim-and-Fill")

# Add precision (1 / SE)
funnel_data <- funnel_data %>%
  mutate(
    Precision = 1 / sqrt(Adjusted_Estimate + abs(CI_Upper - CI_Lower))
  )

# Funnel plot
ggplot(funnel_data, aes(x = Adjusted_Estimate, y = Precision)) +
  geom_point(color = "blue", size = 3) +
  geom_errorbarh(
    aes(xmin = CI_Lower, xmax = CI_Upper),
    height = 0.2,
    color = "gray"
  ) +
  geom_vline(
    xintercept = mean(funnel_data$Adjusted_Estimate, na.rm = TRUE),
    linetype = "dashed",
    color = "red",
    size = 1
  ) +
  facet_wrap(~ Response, scales = "free") +
  theme_minimal() +
  labs(
    title = "Funnel Plot with Trim-and-Fill Adjustments",
    x = "Effect Size",
    y = "Precision (1/SE)"
  ) +
  theme(
    strip.text = element_text(size = 12, face = "bold"),
    axis.text = element_text(size = 10),
    plot.title = element_text(hjust = 0.5)
  )

```

```{r}
egger_data <- bias_results_df |> dplyr::filter(Test == "Egger's Test")
ggplot(egger_data, aes(x = CI_Lower, y = CI_Upper)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "Egger's Regression Plot for Funnel Plot Asymmetry",
       x = "Effect Size (Lower CI)",
       y = "Effect Size (Upper CI)")
```

```{r}
trim_data <- bias_results_df |> dplyr::filter(Test == "Trim-and-Fill")
ggplot(trim_data, aes(x = Response, y = Estimated_Missing_Studies, fill = Adjusted_Estimate > 0)) +
  geom_col() +
  theme_minimal() +
  labs(title = "Number of Missing Studies Estimated (Trim-and-Fill)",
       x = "Response Variable",
       y = "Estimated Missing Studies") +
  scale_fill_manual(values = c("red", "green"), name = "Adjusted Estimate Positive")

```

```{r}
# Filter data for Trim-and-Fill results
forest_data <- bias_results_df %>%
  filter(Test == "Trim-and-Fill") %>%
  mutate(Response = factor(Response, levels = rev(Response))) # Reverse levels for proper ordering on y-axis

# Custom colors for each response variable
custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)

# Plot with ggplot2
ggplot(forest_data, aes(
  x = Adjusted_Estimate,
  y = Response,
  xmin = CI_Lower,
  xmax = CI_Upper,
  color = Response
)) +
  geom_point(size = 3) +
  geom_errorbarh(height = 0.2, size = 0.8) +
  scale_color_manual(values = custom_colors) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray") +
  geom_text_repel(
    aes(label = paste0("Imputed: ", Estimated_Missing_Studies)),
    hjust = 0,
    nudge_x = 0.02,
    nudge_y = -0.3, # Adjust this value to move the text downward
    size = 4,
    color = "black"
  ) +
  labs(
    title = "Trim-and-Fill Adjusted Estimates with CIs",
    x = "Adjusted Effect Size",
    y = NULL,
    color = "Response Variable"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(color = "black"),
    axis.text.x = element_text(color = "black")
  )

```


### The Trim-and-Fill Test and Results: A Report Summary

The **Trim-and-Fill** method is a statistical tool used in meta-analysis to detect and adjust for **publication bias**, which occurs when studies with significant or positive results are more likely to be published, leading to distorted overall effect size estimates. This method ensures that meta-analytic conclusions are robust and unbiased.

#### Key Steps in the Trim-and-Fill Process:
1. **Detection of Funnel Plot Asymmetry**: A symmetrical funnel plot indicates no publication bias, while asymmetry suggests missing studies, often small studies with non-significant results.
2. **Trimming**: Studies causing asymmetry are temporarily removed to create symmetry.
3. **Filling**: Missing studies are imputed on the underreported side of the funnel plot.
4. **Re-estimation**: A new meta-analysis is performed with the original and imputed studies to calculate the **adjusted effect size** and its confidence intervals (CIs).

#### Trim-and-Fill Results:
The method outputs **adjusted estimates** that reflect the effect sizes after accounting for missing studies, along with:
- **Confidence Intervals (CIs)**: Indicating the range of plausible values for the adjusted effect size. If the CI includes zero, the adjusted estimate is not statistically significant.
- **Estimated Missing Studies**: The number of studies imputed to restore symmetry.
- **Direction of Bias**: Identifies the likely side where studies were underreported.

#### Purpose and Insights:
The Trim-and-Fill method evaluates whether the original meta-analytic estimate is robust to potential bias. A large difference between unadjusted and adjusted effect sizes indicates significant publication bias, while minimal changes suggest robustness.

---

### Forest Plot Interpretation of Trim-and-Fill Results
The forest plot provides a visual summary of the Trim-and-Fill adjusted effect sizes and their corresponding CIs for various response variables:

1. **Adjusted Effect Sizes**: Represented by dots along horizontal bars (CIs), showing the mean effect size after adjusting for missing studies.
2. **Confidence Intervals (CIs)**: Bars extending from each dot. If they cross the vertical line at zero, the result is not statistically significant.
3. **Response Variables**: Listed on the y-axis, such as **Biodiversity**, **Crop yield**, and **Water quality**.
4. **Significance**: 
   - Positive or negative estimates excluding zero indicate significance.
   - Wide CIs suggest higher uncertainty, while narrow CIs indicate precision.

---

### Observations:
- **Significant Findings**: "Water quality" has a positive adjusted estimate with CIs excluding zero, indicating statistical significance.
- **Negative Adjustments**: "Crop yield" and "Product quality" show negative adjusted estimates, with precise but non-significant results.
- **High Uncertainty**: "Pest and Disease" has wide CIs, indicating variability or uncertainty in its adjusted effect size.

This analysis demonstrates the importance of adjusting for publication bias, revealing both robust and potentially biased estimates across response variables. The plot provides clear, publication-ready visual insights for understanding the impact of bias adjustments in meta-analysis.



############
# STEP 8
##########################################################################################################################################
MODERATOR ANALYSIS - INFLUENCE OF SILVOARABLE AGROFORESTRY CHARACTERISTICS
##########################################################################################################################################

```{r}
# model_results$`Crop yield`$full_model$tau2

# model_results$`Crop yield`$moderator_model$tau2
```


```{r}
####################################################################################################
# MODERATOR ANALYSIS - PROPORTION OF EXPLAINED HETEROGENEITY USING RE-FITTED MODELS NO RANDOM INTERCEPT
####################################################################################################

# Define response variable
response_variable <- "Crop yield"  # Change accordingly

# Subset data for the response variable
data_subset <- meta_data[meta_data$response_variable == response_variable, ]

# Extract the variance-covariance matrix
v_matrix <- v_matrices[[response_variable]]

# Define the moderators to include in the model
moderators <- c("tree_type", "crop_type", "age_system", "season", "soil_texture")

# Define the random effects structure
random_effects <- list(~ 1 | exp_id)

# Print data checks
print(dim(data_subset))
print(head(data_subset))
```
```{r}
# Fit the Null Model
# null_model <- tryCatch({
#   rma.mv(
#     yi = yi,
#     V = v_matrix,
#     random = random_effects,
#     data = data_subset,
#     method = "REML",
#     control = list(iter.max = 2000, rel.tol = 1e-9)
#   )
# }, error = function(e) {
#   message("Error in null model: ", e$message)
#   return(NULL)
# })
# 
# # Check if model fitted correctly
# if (!is.null(null_model)) {
#   print(null_model)
#   tau2_null <- sum(null_model$tau2)  # Extract τ²
#   cat("τ² (Null Model):", tau2_null, "\n")
# } else {
#   cat("⚠ Warning: τ² (Null Model) is 0 or model fitting failed.\n")
# }


# Fit the Null Model (NO RANDOM EFFECTS)
null_model <- tryCatch({
  rma(
    yi = yi,
    vi = diag(v_matrix),  # Use diagonal for within-study variance
    data = data_subset,
    method = "REML",
    control = list(iter.max = 2000, rel.tol = 1e-9)
  )
}, error = function(e) {
  message("Error in null model: ", e$message)
  return(NULL)
})

# Check if model fitted correctly
if (!is.null(null_model)) {
  print(null_model)
  tau2_null <- null_model$tau2  # Extract τ²
  cat("τ² (Null Model):", tau2_null, "\n")
} else {
  cat("⚠ Warning: τ² (Null Model) is 0 or model fitting failed.\n")
}

```

```{r}
# Fit the Full Model

# full_model <- tryCatch({
#   rma.mv(
#     yi = yi,
#     V = v_matrix,
#     mods = as.formula(paste("~", paste(moderators, collapse = " + "))),
#     random = random_effects,
#     data = data_subset,
#     method = "REML",
#     control = list(iter.max = 2000, rel.tol = 1e-9)
#   )
# }, error = function(e) {
#   message("Error in full model: ", e$message)
#   return(NULL)
# })
# 
# # Check if full model fitted correctly
# if (!is.null(full_model)) {
#   print(full_model)
#   tau2_full <- sum(full_model$tau2)  # Extract τ²
#   cat("τ² (Full Model):", tau2_full, "\n")
# } else {
#   cat("⚠ Warning: τ² (Full Model) is 0 or model fitting failed.\n")
# }

# Fit the Full Model (NO RANDOM EFFECTS)
full_model <- tryCatch({
  rma(
    yi = yi,
    vi = diag(v_matrix),
    mods = as.formula(paste("~", paste(moderators, collapse = " + "))),
    data = data_subset,
    method = "REML",
    control = list(iter.max = 2000, rel.tol = 1e-9)
  )
}, error = function(e) {
  message("Error in full model: ", e$message)
  return(NULL)
})

# Check if full model fitted correctly
if (!is.null(full_model)) {
  print(full_model)
  tau2_full <- full_model$tau2  # Extract τ²
  cat("τ² (Full Model):", tau2_full, "\n")
} else {
  cat("⚠ Warning: τ² (Full Model) is 0 or model fitting failed.\n")
}

```

```{r}
# Calculate proportion of explained heterogeneity

if (!is.null(null_model) && !is.null(full_model)) {
  proportion_explained <- ((tau2_null - tau2_full) / tau2_null) * 100
  proportion_explained <- max(min(proportion_explained, 100), 0)  # Ensure within 0-100%

  cat("\nProportion of Explained Heterogeneity:", proportion_explained, "%\n")
} else {
  cat("\nCannot compute explained heterogeneity due to missing models.\n")
}
```

Justifying the Use of a Model Without a Random Component

Proportion of Explained Heterogeneity (PEH) is derived by comparing between-study variance (τ²) in models with and without moderators. To estimate PEH, the null model provides a baseline τ² representing total heterogeneity, while models incorporating moderators help partition that heterogeneity and quantify the proportion explained. However, the data structure in this analysis is too sparse to support a hierarchical random-effects model with `~ 1 | exp_id`, as the number of studies per group is too low for the model to reliably estimate variance components. This led to convergence issues, requiring a modified approach where the models were refitted without the random-effects component.

Refitting was necessary because PEH is calculated as the proportionate reduction in τ² between models, and this requires the ability to fit both a null model and a moderator model under comparable conditions. Without refitting, it would be impossible to determine how much variance each moderator accounts for. The random-effects model structure introduced instability because the hierarchical variance component could not be estimated reliably, making it impractical for PEH analysis.

By removing the random component, the model focuses on within-study variance while still capturing residual heterogeneity (τ²). Although this shifts the approach closer to a fixed-effects model, the key objective here is not to make population-level inferences but rather to partition variance and assess the explanatory power of moderators. The simplified model structure ensures that τ² estimates remain valid, while bootstrapping compensates for potential limitations by providing empirical uncertainty estimates.

Critically, the model still accounts for variability through the study-level variance (`vi = diag(V)`), which ensures appropriate weighting of studies based on precision. While a full random-effects model is generally preferable when estimating overall heterogeneity, its use in this case was not feasible due to sparse data. Alternative approaches, such as Bayesian hierarchical modeling or aggregating studies within `exp_id`, would introduce additional assumptions or reduce statistical power. Removing the random component allowed for a more stable estimation of τ² and thus more reliable PEH calculations.

This approach ensures that the PEH estimates remain interpretable and statistically valid while avoiding model complexity that would otherwise compromise the analysis. The use of bootstrapping further strengthens the robustness of these estimates, providing confidence in the validity of the findings despite the necessary modifications to the modeling approach.


```{r}
# Initialize an empty data frame to store results
heterogeneity_results <- data.frame()

# Define all response variables
response_variables <- unique(meta_data$response_variable)

# Loop through each response variable
for (response_variable in response_variables) {
  
  cat("\n-------------------------\nProcessing:", response_variable, "\n-------------------------\n")
  
  # Subset data for the response variable
  data_subset <- meta_data[meta_data$response_variable == response_variable, ]
  
  # Extract the variance-covariance matrix
  v_matrix <- v_matrices[[response_variable]]
  
  # Skip if variance matrix is missing
  if (is.null(v_matrix)) {
    cat("⚠ Skipping", response_variable, "- No variance matrix found.\n")
    next
  }
  
  # Fit the Null Model (NO RANDOM EFFECTS)
  null_model <- tryCatch({
    rma(
      yi = yi,
      vi = diag(v_matrix),  # Use diagonal for within-study variance
      data = data_subset,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) {
    message("Error in null model for", response_variable, ":", e$message)
    return(NULL)
  })
  
  # Extract tau² from the null model
  if (!is.null(null_model)) {
    tau2_null <- null_model$tau2
    cat("τ² (Null Model) for", response_variable, ":", tau2_null, "\n")
  } else {
    cat("⚠ Warning: τ² (Null Model) is 0 or model fitting failed for", response_variable, "\n")
    next  # Skip to next response variable if null model fails
  }
  
  # Loop through each moderator for this response variable
  for (moderator in moderators) {
    cat("\nFitting model for moderator:", moderator, "on", response_variable, "\n")
    
    mod_model <- tryCatch({
      rma(
        yi = yi,
        vi = diag(v_matrix),
        mods = as.formula(paste("~", moderator)),  # Single moderator model
        data = data_subset,
        method = "REML",
        control = list(iter.max = 2000, rel.tol = 1e-9)
      )
    }, error = function(e) {
      message("Error in model for", moderator, "on", response_variable, ":", e$message)
      return(NULL)
    })
    
    # Extract tau² from the moderator model
    if (!is.null(mod_model)) {
      tau2_moderated <- mod_model$tau2
      cat("  τ² (Model with", moderator, "on", response_variable, "):", tau2_moderated, "\n")
      
      # Calculate proportion of explained heterogeneity
      proportion_explained <- ifelse(tau2_null > 0, ((tau2_null - tau2_moderated) / tau2_null) * 100, NA)
      proportion_explained <- max(min(proportion_explained, 100), 0)  # Ensure between 0-100%
      
      # Store results
      heterogeneity_results <- rbind(heterogeneity_results, 
                                     data.frame(ResponseVariable = response_variable,
                                                Moderator = moderator,
                                                Tau2_Null = tau2_null,
                                                Tau2_Moderated = tau2_moderated,
                                                ProportionExplained = proportion_explained))
    } else {
      cat("⚠ Warning: Model for", moderator, "on", response_variable, "failed.\n")
    }
  }
}

# Print results
heterogeneity_results
```

Bootstrapping involves resampling with replacement to estimate confidence intervals for PEH. 
This helps assess the robustness of the estimated heterogeneity explained

```{r, eval=FALSE}
# Bootstrapping for Statistical Validation
##########################################################################
# Start time tracking
start.time <- Sys.time()
##########################################################################
# Set up parallel processing
plan(multisession, workers = parallel::detectCores() - 1)
##########################################################################


# Bootstrapping is a resampling-based statistical method used to estimate the uncertainty and stability of a statistic by repeatedly sampling from the original dataset with replacement. In the context of Proportion of Explained Heterogeneity (PEH) analysis, bootstrapping provides confidence intervals (CIs) for the estimated PEH values and helps determine whether observed moderator effects are statistically robust or due to random noise.

# Set number of bootstrap iterations
n_boot <- 1000  

# Initialize an empty list to store bootstrap results
bootstrap_results <- list()

# Function to compute PEH for bootstrapped samples
bootstrap_peh <- function(data_subset, v_matrix, response_variable, moderator) {
  # Resample data with replacement
  boot_data <- data_subset[sample(nrow(data_subset), replace = TRUE), ]
  
  # Fit the null model
  null_model <- tryCatch({
    rma(
      yi = yi,
      vi = diag(v_matrix),
      data = boot_data,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) NULL)
  
  if (is.null(null_model)) return(NA) # Return NA if null model fails
  
  tau2_null <- null_model$tau2  # Extract τ²
  
  # Fit the model with a single moderator
  mod_model <- tryCatch({
    rma(
      yi = yi,
      vi = diag(v_matrix),
      mods = as.formula(paste("~", moderator)),
      data = boot_data,
      method = "REML",
      control = list(iter.max = 2000, rel.tol = 1e-9)
    )
  }, error = function(e) NULL)
  
  if (is.null(mod_model)) return(NA) # Return NA if model fails
  
  tau2_moderated <- mod_model$tau2
  
  # Compute PEH
  proportion_explained <- ifelse(tau2_null > 0, ((tau2_null - tau2_moderated) / tau2_null) * 100, NA)
  proportion_explained <- max(min(proportion_explained, 100), 0)  # Ensure PEH is between 0-100%
  
  return(proportion_explained)
}

# Run bootstrap for each response variable and moderator
for (response_variable in unique(meta_data$response_variable)) {
  cat("\nBootstrapping for:", response_variable, "\n")
  
  # Subset data and extract variance-covariance matrix
  data_subset <- meta_data[meta_data$response_variable == response_variable, ]
  v_matrix <- v_matrices[[response_variable]]
  
  # Skip if variance matrix is missing
  if (is.null(v_matrix)) next
  
  for (moderator in moderators) {
    cat("Processing moderator:", moderator, "\n")
    
    # Run bootstrap
    boot_estimates <- replicate(n_boot, bootstrap_peh(data_subset, v_matrix, response_variable, moderator))
    
    # Compute summary statistics
    boot_summary <- data.frame(
      ResponseVariable = response_variable,
      Moderator = moderator,
      MeanPEH = mean(boot_estimates, na.rm = TRUE),
      LowerCI = quantile(boot_estimates, 0.025, na.rm = TRUE),
      UpperCI = quantile(boot_estimates, 0.975, na.rm = TRUE)
    )
    
    # Store results
    bootstrap_results[[paste(response_variable, moderator, sep = "_")]] <- boot_summary
  }
}

# Convert list to data frame
bootstrap_results_df <- do.call(rbind, bootstrap_results)

# View resulting dataframe on PEH
bootstrap_results_df

# Save the bootstrapped results as an RDS file
# Define the output directory
output_dir <- here::here("DATA", "OUTPUT_FROM_R", "SAVED_OBJECTS_FROM_R")

# Ensure the directory exists
if (!dir.exists(output_dir)) {
  dir.create(output_dir, recursive = TRUE)
}

saveRDS(
  bootstrap_results_df,
  file = file.path(output_dir, "bootstrapped_PEH_results.rds")
)

cat("Bootstrapped results saved to:", file.path(output_dir, "bootstrapped_PEH_results.rds"), "\n")

##########################################################################
# End time tracking
end.time <- Sys.time()
time.taken <- end.time - start.time
cat("\nTotal time taken:", time.taken, units(time.taken), "\n")
##########################################################################
# Last go (04/02-2025) 
# Total time taken: 
```

```{r}
# erify whether the total Proportion of Explained Heterogeneity (PEH) for each response variable exceeds 100% across all moderators:

# View resulting dataframe on PEH
# bootstrap_results_df

# Summarize PEH per response variable
peh_summary <- bootstrap_results_df %>%
  group_by(ResponseVariable) %>%
  summarise(TotalPEH = sum(MeanPEH, na.rm = TRUE)) %>%
  mutate(Exceeds100 = TotalPEH > 100)  # Check if sum exceeds 100%

# Identify response variables where total PEH exceeds 100%
if (any(peh_summary$Exceeds100)) {
  warning("⚠ Some response variables have a total PEH exceeding 100%! Review the calculations.")
} else {
  cat("✅ All response variables have a total PEH ≤ 100%.")
}

# Display results
print(peh_summary)
```


```{r}
# Convert ResponseVariable and Moderator to factors for proper ordering
bootstrap_results_df$ResponseVariable <- factor(bootstrap_results_df$ResponseVariable, levels = unique(bootstrap_results_df$ResponseVariable))
bootstrap_results_df$Moderator <- factor(bootstrap_results_df$Moderator, levels = unique(bootstrap_results_df$Moderator))

# Create the bar plot with flipped axes
ggplot(bootstrap_results_df, aes(x = ResponseVariable, y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +  # Flip the axes
  labs(title = "Bootstrapped Proportion of Explained Heterogeneity",
       x = "Response Variable",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1))  # Ensure readability for y-axis labels
```

```{r}
# Filter for selected response variables
filtered_data <- bootstrap_results_df %>%
  filter(ResponseVariable %in% c("Crop yield", "Soil quality", "Biodiversity"))

# Create faceted bar plot with fixed x-axis
ggplot(filtered_data, aes(x = Moderator, y = MeanPEH, fill = Moderator)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.7), color = "black") +
  geom_errorbar(aes(ymin = LowerCI, ymax = UpperCI), position = position_dodge(width = 0.7), width = 0.2) +
  coord_flip() +  # Flip axes
  facet_wrap(~ResponseVariable, scales = "fixed") +  # Facet by response variable with fixed x-axis
  labs(title = "Bootstrapped Proportion of Explained Heterogeneity (PEH)",
       x = "Moderator",
       y = "Proportion Explained (%)",
       fill = "Moderator") +
  theme_minimal() +
  theme(axis.text.y = element_text(angle = 0, hjust = 1))  # Ensure labels remain readable
```





















```{r}
# Visualize Proportion Explained for Overall and Response Variable-Specific Situations


```


Updated Interpretation of Moderators' Effects on Model Heterogeneity

1. Significance of Moderators (P-value Interpretation):
- **P-values** reflect whether the moderator has a statistically significant effect on the response variable. 
  - A **P-value < 0.05** suggests strong evidence that the moderator significantly affects the heterogeneity in effect sizes.
  - Higher P-values indicate weaker evidence for significant effects, meaning the moderator’s influence may not be consistent across the response variables.

2. Magnitude of Effects (Estimate and SE):
- The **Estimate** represents the effect size or influence of each moderator term.
  - Positive values suggest that the moderator increases heterogeneity or variability.
  - Negative values suggest it reduces variability or explains heterogeneity in a systematic way.
- The **Standard Error (SE)** indicates the precision of the estimate.
  - Lower SE values imply higher confidence in the estimates, whereas higher SEs indicate less precise estimates.

3. Confidence Intervals (CI.Lower and CI.Upper):
- The confidence intervals provide the range within which the true effect size is likely to fall.
  - Moderators with confidence intervals that **exclude zero** are more likely to have consistent and meaningful effects.

4. Specific Moderators' Contributions:
1. **Tree Type**:
   - While some terms (e.g., "tree_typeTimber") have moderate P-values (e.g., ~0.19), the confidence intervals often include zero, indicating less consistent influence.
   - Moderators under "tree_type" show mixed evidence, with high variability between terms.
2. **Crop Type**:
   - Some subcategories (e.g., "crop_typeLegume") exhibit low P-values (e.g., < 0.001) and confidence intervals excluding zero, suggesting significant effects.
   - This moderator likely contributes moderately to explaining heterogeneity in effect sizes.
3. **Age System**:
   - Terms such as "age_systemYoung" consistently show low P-values (<0.01) and confidence intervals excluding zero, highlighting a strong and significant influence on heterogeneity.
   - This moderator seems to have one of the most consistent and impactful effects.
4. **Season**:
   - The influence of "season" varies, with subcategories like "seasonWinter" having moderate P-values (~0.13) and wider confidence intervals.
   - Its effects are less consistent compared to age system or crop type.
5. **Soil Texture**:
   - Subcategories like "soil_textureSand" often show significant effects (P-values < 0.05), with narrow confidence intervals excluding zero.
   - This suggests that soil texture is a critical moderator for explaining heterogeneity.

5. Proportion of Heterogeneity Explained:
- Combining the above data with the proportion of heterogeneity explained reveals:
  - **Age System** consistently explains the highest proportion of heterogeneity (e.g., 95.47%).
  - **Soil Texture** follows closely, explaining ~82.4%.
  - **Crop Type** and **Season** contribute moderately (64.5% and 45.2%, respectively).
  - **Tree Type** has a lower overall contribution (~50.6%).

Summary:
- **Key Moderators:** "Age System" and "Soil Texture" are the most impactful, with consistently significant effects and the highest proportions of heterogeneity explained.
- **Moderate Contributors:** "Crop Type" and "Season" show variable but important contributions to explaining heterogeneity.
- **Least Impactful:** "Tree Type" appears to have inconsistent effects, with many subcategories not significantly contributing to heterogeneity.



```{r}
##########################################################################################################################################
# PUBLICATION BIAS ASSESSMENT - FUNNEL PLOTS
##########################################################################################################################################


# Custom colors for each response variable
custom_colors <- c(
  "Biodiversity" = "#FF9999",
  "Greenhouse gas emission" = "#66C266",
  "Product quality" = "#FFC000",
  "Crop yield" = "#FF9933",
  "Pest and Disease" = "#33CCCC",
  "Soil quality" = "#9966CC",
  "Water quality" = "#9999FF"
)


# Function to generate contour-enhanced funnel plots for each response variable
create_contour_funnel_plots <- function(model_results) {
  # Loop through each response variable and generate a funnel plot
  for (response in names(model_results)) {
    model <- model_results[[response]]$full_model

    # Skip if the model is NULL
    if (is.null(model)) {
      message(paste("No valid model for", response))
      next
    }

    # Generate and display the contour-enhanced funnel plot
    tryCatch({
      funnel(
        model, 
        level = c(90, 95, 99),  # Contours for statistical significance
        refline = 0,            # Center the funnel at 0
        legend = TRUE,          # Add a legend for the shaded regions
        main = paste("Contour-Enhanced Funnel Plot for", response)
      )
    }, error = function(e) {
      message(paste("Error generating contour funnel plot for", response, ":", e$message))
    })
  }
}

# Example usage with the model_results object
create_contour_funnel_plots(model_results)

```

Systematic Interpretation of Contour-Enhanced Funnel Plots Across All Response Variables

General Insights Across All Plots:
1. **Centering and Symmetry**:
   - All funnel plots are centered at `0`, representing the null hypothesis of no effect.
   - Symmetry in some plots (e.g., **Biodiversity**, **Soil Quality**, **Product Quality**) suggests minimal evidence of publication bias, while asymmetry in others (e.g., **Greenhouse Gas Emissions**, **Crop Yield**, **Water Quality**) indicates potential bias or heterogeneity in reported effects.

2. **Shaded Regions**:
   - Most studies cluster in the **white region** (\( p > 0.10 \)), reflecting non-significant findings across the majority of studies.
   - A smaller number of studies extend into the **light gray** (\( 0.05 < p \leq 0.10 \)), **medium gray** (\( 0.01 < p \leq 0.05 \)), and **dark gray** (\( p \leq 0.01 \)) regions, indicating marginally significant to highly significant results.
   - The distribution of points in these shaded regions highlights varying levels of statistical significance across response variables.

3. **Funnel Width**:
   - The funnel shape consistently broadens as standard error increases, reflecting greater variability in effect sizes for less precise studies (higher standard error). This is consistent with expectations for meta-analyses.

4. **Potential Bias**:
   - Symmetrical plots (e.g., **Biodiversity**, **Soil Quality**) show little evidence of bias, while skewed plots (e.g., **Greenhouse Gas Emissions**, **Crop Yield**, **Water Quality**) suggest possible **publication bias** or genuine heterogeneity.

Individual Response Variable Insights:

1. **Biodiversity**:
   - **Symmetry**: The symmetrical distribution around `0` suggests minimal publication bias.
   - **Findings**: Most studies are non-significant, clustering in the white region.
   - **Conclusion**: No strong evidence of bias; results are consistent with null or minor effects.

2. **Greenhouse Gas Emissions**:
   - **Asymmetry**: Skewed to the right, indicating studies reporting positive effects are more frequent.
   - **Findings**: Non-significant results dominate, with fewer highly significant studies.
   - **Conclusion**: Potential publication bias favoring positive results; further statistical tests are recommended.

3. **Product Quality**:
   - **Symmetry**: Studies are distributed evenly around the null, with fewer significant findings.
   - **Findings**: Most studies fall in the non-significant range.
   - **Conclusion**: Minimal evidence of bias, indicating balanced reporting of positive and negative results.

4. **Crop Yield**:
   - **Asymmetry**: Skewed toward positive effects, with non-significant findings dominating.
   - **Findings**: The distribution suggests potential publication bias or selective reporting.
   - **Conclusion**: Asymmetry raises concerns; statistical tests (e.g., Egger’s test) are needed.

5. **Pest and Disease**:
   - **Symmetry**: Moderate symmetry with more studies closer to the center of the funnel.
   - **Findings**: Non-significant results dominate, with limited significant findings.
   - **Conclusion**: No substantial bias detected, but further analysis can confirm.

6. **Soil Quality**:
   - **Symmetry**: Highly symmetrical distribution, indicating a balanced representation of effects.
   - **Findings**: Predominantly non-significant findings, with very few highly significant studies.
   - **Conclusion**: Strong indication of no publication bias; results are consistent.

7. **Water Quality**:
   - **Asymmetry**: Right-skewed, with studies favoring positive effects.
   - **Findings**: Non-significant results are prevalent, with few moderately significant results.
   - **Conclusion**: Potential bias or heterogeneity; further exploration of data characteristics is needed.

Overall Conclusion:
- Symmetrical funnel plots (e.g., **Biodiversity**, **Soil Quality**, **Product Quality**) suggest **minimal publication bias** and consistent results.
- Asymmetric plots (e.g., **Greenhouse Gas Emissions**, **Crop Yield**, **Water Quality**) highlight potential **publication bias** or **genuine heterogeneity**, warranting further statistical tests like Egger’s regression or subgroup analysis.





```{r}
##########################################################################################################################################
# PUBLICATION BIAS ASSESSMENT - EGGER'S TEST
##########################################################################################################################################


# Refit models using rma
refit_rma_models <- function(model_results) {
  rma_models <- list()
  
  for (response in names(model_results)) {
    tryCatch({
      # Assuming `yi` and `vi` are your effect sizes and variances
      model_data <- model_results[[response]]$data
      if (is.null(model_data)) next
      
      rma_model <- rma(yi = model_data$EffectSize, 
                       vi = model_data$Variance, 
                       data = model_data,
                       method = "REML")
      
      rma_models[[response]] <- rma_model
      cat(paste("Model refitted for", response, "\n"))
    }, error = function(e) {
      message(paste("Error refitting model for", response, ":", e$message))
    })
  }
  
  return(rma_models)
}

# Example usage
rma_models <- refit_rma_models(model_results)


# Run Egger's test on the refitted rma models
run_eggers_test <- function(rma_models) {
  results <- list()
  
  for (response in names(rma_models)) {
    model <- rma_models[[response]]
    if (is.null(model)) next
    
    tryCatch({
      egger_test <- regtest(model, model = "lm", predictor = "sei")
      results[[response]] <- egger_test
      cat(paste("\nEgger's Test for", response, ":\n"))
      print(egger_test)
    }, error = function(e) {
      message(paste("Error running Egger's test for", response, ":", e$message))
    })
  }
  
  return(results)
}

# Run Egger's test on refitted models
eggers_results <- run_eggers_test(rma_models)

```


```{r}
##########################################################################################################################################
# DATA PREP FOR FOREST PLOTS 
##########################################################################################################################################

# Debugging: Inspect the structure of model_results
# print("Inspecting model_results:")
# str(model_results)
# Generic Function to Extract Relevant Data for Forest Plots
# Generic Function to Extract Relevant Data for Forest Plots

extract_forest_plot_data <- function(model_results) {
  forest_data_list <- list() # Initialize list

  for (response in names(model_results)) {
    model <- model_results[[response]]$full_model

    if (is.null(model)) {
      message(paste("No model found for", response))
      next
    }

    tryCatch({
      effect_sizes <- model$yi  # Extract effect sizes
      variances <- model$vi    # Extract variances

      # Match labels (id_obs) to valid rows in the model
      valid_rows <- model$data[model$not.na, ]  # Subset retained rows
      labels <- valid_rows$id_obs  # Extract labels corresponding to valid rows

      # Check for length alignment
      if (length(effect_sizes) != length(variances) || length(effect_sizes) != length(labels)) {
        stop(paste("Mismatch in data dimensions for", response))
      }

      # Create the data frame
      forest_data <- data.frame(
        Study = labels,
        EffectSize = effect_sizes,
        Variance = variances,
        ResponseVariable = response
      )

      forest_data_list[[response]] <- forest_data # Store in the list
    }, error = function(e) {
      message(paste("Error extracting data for", response, ":", e$message))
    })
  }

  return(forest_data_list) # Return list of data frames
}



# Example usage with model_results
forest_plot_data <- extract_forest_plot_data(model_results)

# Print the structure of the extracted data
str(forest_plot_data)

```

```{r}
##########################################################################################################################################
# FOREST PLOTS 
##########################################################################################################################################

# Function to create a forest plot for a given response variable
create_forest_plot <- function(data, response_variable, output_path = NULL) {
  # Filter data for the selected response variable
  plot_data <- data[[response_variable]]
  
  if (is.null(plot_data)) {
    stop(paste("No data found for", response_variable))
  }
  
  # Calculate confidence intervals
  plot_data <- plot_data %>%
    mutate(
      CI_lower = EffectSize - 1.96 * sqrt(Variance),
      CI_upper = EffectSize + 1.96 * sqrt(Variance)
    )
  
  # Create the forest plot
  forest_plot <- ggplot(plot_data, aes(x = EffectSize, y = reorder(Study, EffectSize))) +
    geom_point(size = 3, color = "blue") +  # Effect size points
    geom_errorbarh(aes(xmin = CI_lower, xmax = CI_upper), height = 0.2, color = "gray") +  # Error bars
    theme_minimal() +
    labs(
      title = paste("Forest Plot for", response_variable),
      x = "Effect Size (with 95% CI)",
      y = "Study",
      caption = "Note: Horizontal bars indicate 95% confidence intervals."
    ) +
    theme(
      plot.title = element_text(size = 14, face = "bold"),
      axis.text.y = element_text(size = 10),
      axis.text.x = element_text(size = 10),
      axis.title = element_text(size = 12),
      plot.caption = element_text(size = 9, face = "italic")
    )
  
  # Display the plot
  print(forest_plot)
  
  # Save the plot to file if output_path is provided
  if (!is.null(output_path)) {
    ggsave(output_path, plot = forest_plot, width = 10, height = 8)
  }
}

# Example usage:
# Generate a forest plot for "Biodiversity" and save it
create_forest_plot(forest_plot_data, "Biodiversity", output_path = "Biodiversity_Forest_Plot.png")

# Generate a forest plot for "Crop yield" and display it
create_forest_plot(forest_plot_data, "Crop yield")

```





